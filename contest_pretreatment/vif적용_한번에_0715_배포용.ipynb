{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 기본 패키지 준비\n",
    "\n",
    "# 데이터 처리 필요 패키지\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import math\n",
    "\n",
    "# 다중공선성(multicollinearity) 처리를 위한VIF 확인 패키지\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# 시각화 필요 패키지\n",
    "%matplotlib inline\n",
    "from plotnine import *\n",
    "import folium\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc, font_manager\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Machine Learning 분석 환경 준비\n",
    "\n",
    "# 전처리, 스케일링\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# 선형회귀분석\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from scipy import stats\n",
    "\n",
    "# OLS회귀분석\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# # GAM 일반화가법모형\n",
    "# # LinearGAM, LogisticGAM, PoissonGAM, GammaGAM, InvGuss\n",
    "# from pygam import LinearGAM, LogisticGAM, PoissonGAM, GammaGAM\n",
    "\n",
    "# # Boosting\n",
    "\n",
    "#데이터셋 분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 한글 처리\n",
    "font_name = font_manager.FontProperties(fname='C:/Windows/Fonts/NanumGothicCoding.ttf').get_name()\n",
    "rc('font',family=font_name)\n",
    "\n",
    "# - 마이너스 사인 처리\n",
    "matplotlib.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# jupyter notebook에서 warning 무시하기\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData():\n",
    "    # 데이터 불러오기 (전처리 된 GS, 랄라블라, 날씨)\n",
    "    gs = pd.read_csv('d:/project/contest/data/processed/p_gs.csv', parse_dates=['date'])\n",
    "    lv = pd.read_csv('d:/project/contest/data/processed/p_lavla.csv', parse_dates=['date'])\n",
    "    w = pd.read_csv('d:/project/contest/data/processed/p_wUVair_seoul.csv', parse_dates=['date'], index_col=0)\n",
    "    sns_all = pd.read_csv('d:/project/contest/data/processed/social_all.csv', parse_dates=['date'])\n",
    "    return gs, lv, w, sns_all\n",
    "#########################################################################\n",
    "# MAD 기반 예제코드\n",
    "def mad_based_outlier(points, thresh=3.5):\n",
    "    if len(points.shape) == 1:\n",
    "        points = points[:,None]\n",
    "    median = np.median(points, axis=0)\n",
    "    diff = np.sum((points - median)**2, axis=-1)\n",
    "    diff = np.sqrt(diff)\n",
    "    med_abs_deviation = np.median(diff)\n",
    "    modified_z_score = 0.6745 * diff / med_abs_deviation\n",
    "    return modified_z_score > thresh \n",
    "\n",
    "# 출처: https://pythonanalysis.tistory.com/7 [Python 데이터 분석]\n",
    "#########################################################################\n",
    "\n",
    "# 소셜 데이터 처리를 위한 함수\n",
    "# 1. 모든 소셜 데이터 column들의 첫번째는 : 날짜다.\n",
    "# 2. 각 소셜데이터는 social_키워드.블로그/트위터/뉴스/총합 으로 되어 있다.\n",
    "def changeColNames(d, before, after) : \n",
    "    # 컬럼이름 시리즈로 만들어 반환\n",
    "    # 통합하기 쉽게, 모든 데이터들의 날짜컬럼 이름을 date로 통일\n",
    "    new_col_names = ['date']\n",
    "    new_col_names.extend(list(d.columns)[1:])\n",
    "    d.columns = new_col_names\n",
    "    return pd.Series(d.columns).apply(lambda x : x.replace(before,after))\n",
    "\n",
    "#########################################################################\n",
    "# modeling 함수로 만들어 처리하기\n",
    "def linReg(df, item, cols_using):\n",
    "    cols = cols_using\n",
    "    X = df.loc[df['category']==item, cols]\n",
    "    y = df.loc[df['category']==item,'qty']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=0)\n",
    "\n",
    "    lin_model = LinearRegression().fit(X_train, y_train)\n",
    "  \n",
    "    print('LinearRegression을 이용한 %s의 회귀분석 결과 :'%item)\n",
    "    print('훈련세트점수 : {:.2f}'.format(lin_model.score(X_train, y_train)))\n",
    "    print('검증세트점수 : {:.2f}'.format(lin_model.score(X_test, y_test)))\n",
    "\n",
    "    \n",
    "def ridgeReg(df, item, cols_using):\n",
    "    cols = cols_using\n",
    "    X = df.loc[df['category']==item,cols]\n",
    "    y = df.loc[df['category']==item,'qty']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=0)\n",
    "\n",
    "    ridge = Ridge(alpha=0.1, normalize=True, random_state=0, tol=0.001).fit(X_train, y_train)\n",
    "    \n",
    "    print('RidgeRegression을 이용한 %s의 회귀분석 결과 :'%item)\n",
    "    print('훈련세트점수 : {:.2f}'.format(ridge.score(X_train, y_train)))\n",
    "    print('검증세트점수 : {:.2f}'.format(ridge.score(X_test, y_test)))\n",
    "\n",
    "\n",
    "def lassoReg(df, item, cols_using):\n",
    "    cols = cols_using\n",
    "    X = df.loc[df['category']==item,cols]\n",
    "    y = df.loc[df['category']==item,'qty']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=0)\n",
    "\n",
    "    lasso = Lasso(alpha=0.1, max_iter=1000).fit(X=X_train, y=y_train)\n",
    "  \n",
    "    print('LassoRegression을 이용한 %s의 회귀분석 결과 :'%item)\n",
    "    print('훈련세트점수 : {:.2f}'.format(lasso.score(X_train, y_train)) )\n",
    "    print('검증세트점수 : {:.2f}'.format(lasso.score(X_test, y_test)) )\n",
    "\n",
    "    #사용한 특성수\n",
    "    print('사용한 특성수 : {}'.format(np.sum(lasso.coef_ != 0)) )\n",
    "#########################################################################\n",
    "\n",
    "# 자료가 1일 1행이라는 전제하에\n",
    "# df길이를 이용하여 날짜수를 계산, 이후 2016년 1월1일을 1번째주 1일이라 기준하에\n",
    "# 몇번째 주인지 알려주는 컬럼 추가\n",
    "def addDayWeek(df):\n",
    "    df_work = df.copy()\n",
    "    df_work['day'] = pd.Series(range(1,df_work.shape[0]+1))\n",
    "    df_work['week'] = df_work['day'].apply(lambda x : math.ceil(x/7))\n",
    "    return df_work\n",
    "#########################################################################\n",
    "# 자료를 병합해주는 함수, 어떤 item인지 어느 컬럼을 기준으로 할지 받아서 병합\n",
    "def mergeForAnalysis(df1, df2, df3, item, on_what='date'):\n",
    "    merged_df = pd.merge(df1.loc[df1.category==item], df2, on=on_what, how='left')\n",
    "    merged_df = pd.merge(merged_df, df3, on=on_what, how='left')\n",
    "    return merged_df\n",
    "#########################################################################\n",
    "def lowVIF(df, n=7, cols_using =['temp', 'cloud', 'wind','humid', 'hpa', 'sun_time', 'lgt_time', \n",
    "       'SO2', 'CO', 'O3', 'NO2', 'PM10', 'PM25'] ):\n",
    "    col_to_use = cols_using\n",
    "    vif = pd.DataFrame()\n",
    "    vif[\"VIF_Factor\"] = [variance_inflation_factor(\n",
    "        df[col_to_use].values, i) for i in range(df[col_to_use].shape[1])]\n",
    "    vif[\"features\"] = col_to_use\n",
    "    vif.sort_values(\"VIF_Factor\")\n",
    "    lowest_vif = vif.sort_values(\"VIF_Factor\")[:n].reset_index()\n",
    "    lowest_vif.drop(columns='index', inplace=True)\n",
    "    return lowest_vif\n",
    "#########################################################################\n",
    "\n",
    "def chiCheck_byP(df, col1, col2):\n",
    "    chis = stats.chisquare(df[col1], df[col2])\n",
    "    return chis\n",
    "\n",
    "#########################################################################\n",
    "# ols모델용 formula 생성\n",
    "def formulaGen(target, ind_features):\n",
    "    '''\n",
    "    formulaGen(목표컬럼명,[변수컬럼명1, 변수컬럼명2,...])\n",
    "    '''\n",
    "    custom_formula = target + \" ~ \"\n",
    "    for f in range(len(ind_features)):\n",
    "        custom_formula += ind_features[f]\n",
    "        if f!=(len(ind_features)-1):\n",
    "            custom_formula += \" + \"\n",
    "    return custom_formula\n",
    "\n",
    "\n",
    "#########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def allAtOnce(sales_df, \n",
    "              weather_df, \n",
    "              item, \n",
    "              sales_cols=['date','bor_nm','gender','age_cd','category'],\n",
    "              w_cols=['date','temp','humid','wind','rain','snow','cloud','sun_time','lgt_time','hpa',\n",
    "                      'SO2','CO','O3','NO2','PM10','PM25'],\n",
    "              n_vif_asc=7,\n",
    "              target='qty'):\n",
    "    '''\n",
    "    sales_df = gs/lv데이터만 넣어주세요. 일단위로 종합된 데이터프레임에만 작동합니다.\n",
    "    weather_df = w데이터만 넣어주세요. 일단위로 종합된 데이터프레임에만 작동합니다.\n",
    "    item = str객체로, 한개의 물품만 넣어주세요\n",
    "    w_cols = 기본적으로 'uv'데이터를 제외한 컬럼명들입니다.\n",
    "    '''\n",
    "    # 오류발생 어느정도 잡기 위한 부분\n",
    "    if 'category' not in list(sales_df.columns):\n",
    "        print('적법한 df를 넣으세요')\n",
    "        return\n",
    "    elif item not in list(sales_df.category.unique()):\n",
    "        print('%s가 df안에 존재 하지 않습니다.'%item)\n",
    "        return\n",
    "    \n",
    "    # GS/lv 서울시만\n",
    "    sales_seoul = sales_df.loc[sales_df.pvn_nm =='서울특별시']\n",
    "    w_seoul = weather_df.loc[weather_df['loc']==108]\n",
    "    sales_seoul_grouped = sales_seoul[sales_cols+[target]].groupby(by=['date','category']).sum().reset_index()\n",
    "    sales_seoul_grouped_w_item = pd.merge(sales_seoul_grouped.loc[sales_seoul_grouped.category==item], \n",
    "                                          w_seoul, on='date', how='left')\n",
    "\n",
    "    Xy = sales_seoul_grouped_w_item[w_cols+['category',target]]\n",
    "    \n",
    "    low_vif_list = lowVIF(Xy,n_vif_asc)\n",
    "    \n",
    "    linReg(df=Xy,item=item,cols_using=low_vif_list.features)\n",
    "    ridgeReg(df=Xy,item=item,cols_using=low_vif_list.features)\n",
    "    lassoReg(df=Xy,item=item,cols_using=low_vif_list.features)\n",
    "\n",
    "    cust_F = formulaGen(target=target,ind_features=low_vif_list.features)\n",
    "    ols_model = sm.OLS.from_formula(cust_F, data=Xy)\n",
    "    print(ols_model.fit().summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기 (전처리 된 GS, 랄라블라, 날씨)\n",
    "gs, lv, w, sns_all = loadData()\n",
    "# gs = pd.read_csv('d:/project/contest/data/processed/p_gs.csv', parse_dates=['date'])\n",
    "# lv = pd.read_csv('d:/project/contest/data/processed/p_lavla.csv', parse_dates=['date'])\n",
    "# w = pd.read_csv('d:/project/contest/data/processed/p_wUVair_seoul.csv', parse_dates=['date'], index_col=0)\n",
    "# sns_all = pd.read_csv('d:/project/contest/data/processed/social_all.csv', parse_dates=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression을 이용한 아이스크림의 회귀분석 결과 :\n",
      "훈련세트점수 : 0.73\n",
      "검증세트점수 : 0.71\n",
      "RidgeRegression을 이용한 아이스크림의 회귀분석 결과 :\n",
      "훈련세트점수 : 0.72\n",
      "검증세트점수 : 0.71\n",
      "LassoRegression을 이용한 아이스크림의 회귀분석 결과 :\n",
      "훈련세트점수 : 0.73\n",
      "검증세트점수 : 0.71\n",
      "사용한 특성수 : 4\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    qty   R-squared:                       0.723\n",
      "Model:                            OLS   Adj. R-squared:                  0.722\n",
      "Method:                 Least Squares   F-statistic:                     713.4\n",
      "Date:                Mon, 15 Jul 2019   Prob (F-statistic):          1.29e-302\n",
      "Time:                        18:34:19   Log-Likelihood:                -11172.\n",
      "No. Observations:                1096   AIC:                         2.235e+04\n",
      "Df Residuals:                    1091   BIC:                         2.238e+04\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept   5519.9582    910.115      6.065      0.000    3734.185    7305.732\n",
      "temp         989.8535     18.967     52.189      0.000     952.638    1027.069\n",
      "cloud       -548.8315     66.178     -8.293      0.000    -678.683    -418.980\n",
      "wind         942.2192    286.012      3.294      0.001     381.024    1503.414\n",
      "PM10          31.5416      8.675      3.636      0.000      14.520      48.563\n",
      "==============================================================================\n",
      "Omnibus:                       16.696   Durbin-Watson:                   0.412\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               17.280\n",
      "Skew:                           0.304   Prob(JB):                     0.000177\n",
      "Kurtosis:                       2.913   Cond. No.                         253.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "allAtOnce(sales_df=gs, weather_df=w, item='아이스크림', n_vif_asc=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
