{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "# 인공신경망관련 패키지\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "\n",
    "# 회귀분석 관련 패키지\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error \n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from scipy import stats\n",
    "\n",
    "# R2 값, 결정계수 계산\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# OLS회귀분석\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# 시각화 패키지\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sb\n",
    "\n",
    "# 데이터 처리를 위한 패키지\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# 다중공선성(multicollinearity) 처리를 위한VIF 확인 패키지\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# 한글 처리\n",
    "from matplotlib import rc, font_manager\n",
    "font_name = font_manager.FontProperties(fname='C:/Windows/Fonts/NanumGothicCoding.ttf').get_name()\n",
    "rc('font',family=font_name)\n",
    "\n",
    "# from matplotlib import rcParams\n",
    "# rcParams['font.family'] = 'NanumGothicCoding'\n",
    "\n",
    "# - 마이너스 사인 처리\n",
    "matplotlib.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# DeprecationWarning경고 무시\n",
    "# 향후 안쓰일 함수들을 이용해서 만들어져 있기 때문에 필요하다 없으면, 사방이 붉어진다.\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "# MAD 기반 예제코드\n",
    "def mad_based_outlier(points, thresh=3.5):\n",
    "    if len(points.shape) == 1:\n",
    "        points = points[:,None]\n",
    "    median = np.median(points, axis=0)\n",
    "    diff = np.sum((points - median)**2, axis=-1)\n",
    "    diff = np.sqrt(diff)\n",
    "    med_abs_deviation = np.median(diff)\n",
    "    modified_z_score = 0.6745 * diff / med_abs_deviation\n",
    "    return modified_z_score > thresh \n",
    "\n",
    "# 출처: https://pythonanalysis.tistory.com/7 [Python 데이터 분석]\n",
    "#########################################################################\n",
    "\n",
    "# 소셜 데이터 처리를 위한 함수\n",
    "# 1. 모든 소셜 데이터 column들의 첫번째는 : 날짜다.\n",
    "# 2. 각 소셜데이터는 social_키워드.블로그/트위터/뉴스/총합 으로 되어 있다.\n",
    "def changeColNames(d,before, after) : \n",
    "    # 컬럼이름 시리즈로 만들어 반환\n",
    "    # 통합하기 쉽게, 모든 데이터들의 날짜컬럼 이름을 date로 통일\n",
    "    new_col_names = ['date']\n",
    "    new_col_names.extend(list(d.columns)[1:])\n",
    "    d.columns = new_col_names\n",
    "    return pd.Series(d.columns).apply(lambda x : x.replace(before,after))\n",
    "\n",
    "#########################################################################\n",
    "# modeling 함수로 만들어 처리하기\n",
    "def linReg(df, item, cols_using):\n",
    "    cols = cols_using\n",
    "    X = df.loc[df['category']==item, cols]\n",
    "    y = df.loc[df['category']==item,'qty']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=0)\n",
    "\n",
    "    model = LinearRegression().fit(X_train, y_train)\n",
    "  \n",
    "    print('LinearRegression을 이용한 %s의 회귀분석 결과 :'%item)\n",
    "    print('훈련세트점수 : {:.2f}'.format(model.score(X_train, y_train)))\n",
    "    print('검증세트점수 : {:.2f}'.format(model.score(X_test, y_test)))\n",
    "\n",
    "    \n",
    "def ridgeReg(df, item, cols_using):\n",
    "    cols = cols_using\n",
    "    X = df.loc[df['category']==item,cols]\n",
    "    y = df.loc[df['category']==item,'qty']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=0)\n",
    "\n",
    "    ridge = Ridge(alpha=0.1, normalize=True, random_state=0, tol=0.001).fit(X_train, y_train)\n",
    "    \n",
    "    print('RidgeRegression을 이용한 %s의 회귀분석 결과 :'%item)\n",
    "    print('훈련세트점수 : {:.2f}'.format(ridge.score(X_train, y_train)))\n",
    "    print('검증세트점수 : {:.2f}'.format(ridge.score(X_test, y_test)))\n",
    "\n",
    "\n",
    "def lassoReg(df, item, cols_using):\n",
    "    cols = cols_using\n",
    "    X = df.loc[df['category']==item,cols]\n",
    "    y = df.loc[df['category']==item,'qty']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=0)\n",
    "\n",
    "    lasso = Lasso(alpha=0.1, max_iter=1000).fit(X=X_train, y=y_train)\n",
    "  \n",
    "    print('LassoRegression을 이용한 %s의 회귀분석 결과 :'%item)\n",
    "    print('훈련세트점수 : {:.2f}'.format(lasso.score(X_train, y_train)) )\n",
    "    print('검증세트점수 : {:.2f}'.format(lasso.score(X_test, y_test)) )\n",
    "\n",
    "    #사용한 특성수\n",
    "    print('사용한 특성수 : {}'.format(np.sum(lasso.coef_ != 0)) )\n",
    "#########################################################################\n",
    "\n",
    "# 자료가 1일 1행이라는 전제하에\n",
    "# df길이를 이용하여 날짜수를 계산, 이후 2016년 1월1일을 1번째주 1일이라 기준하에\n",
    "# 몇번째 주인지 알려주는 컬럼 추가. 향후 주단위로 종합할때 스인다.\n",
    "def addDayWeek(df):\n",
    "    df_work = df.copy()\n",
    "    df_work['day'] = pd.Series(range(1,df_work.shape[0]+1)).astype('int64')\n",
    "    df_work['week'] = df_work['day'].apply(lambda x : math.ceil(x/7))\n",
    "    return df_work\n",
    "#########################################################################\n",
    "# 자료를 병합해주는 함수, 어떤 item인지 어느 컬럼을 기준으로 할지 받아서 병합\n",
    "def mergeForAnalysis(df1, df2, df3, item, on_what='date'):\n",
    "    merged_df = pd.merge(df1.loc[df1.category==item], df2, on=on_what, how='left')\n",
    "    merged_df = pd.merge(merged_df, df3, on=on_what, how='left')\n",
    "    return merged_df\n",
    "\n",
    "\n",
    "#########################################################################\n",
    "def lowVIF(df, n=7, cols_using =['temp', 'cloud', 'wind','humid', 'hpa', 'sun_time', 'lgt_time', \n",
    "       'SO2', 'CO', 'O3', 'NO2', 'PM10', 'PM25'] ):\n",
    "    col_to_use = cols_using\n",
    "    vif = pd.DataFrame()\n",
    "    vif[\"VIF_Factor\"] = [variance_inflation_factor(\n",
    "        df[col_to_use].values, i) for i in range(df[col_to_use].shape[1])]\n",
    "    vif[\"features\"] = col_to_use\n",
    "    vif.sort_values(\"VIF_Factor\")\n",
    "    lowest_vif = vif.sort_values(\"VIF_Factor\")[:n].reset_index()\n",
    "    lowest_vif.drop(columns='index', inplace=True)\n",
    "    return lowest_vif\n",
    "\n",
    "#########################################################################\n",
    "# ols모델용 formula 생성\n",
    "def formulaGen(target, ind_features):\n",
    "    '''\n",
    "    formulaGen(목표컬럼명,[변수컬럼명1, 변수컬럼명2,...])\n",
    "    '''\n",
    "    custom_formula = target + \" ~ \"\n",
    "    for f in range(len(ind_features)):\n",
    "        custom_formula += ind_features[f]\n",
    "        if f!=(len(ind_features)-1):\n",
    "            custom_formula += \" + \"\n",
    "    return custom_formula\n",
    "#########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기 (전처리 된 GS, 랄라블라, 날씨)\n",
    "gs = pd.read_csv('d:/project/contest/data/processed/p_gs.csv', parse_dates=['date'])\n",
    "lv = pd.read_csv('d:/project/contest/data/processed/p_lavla.csv', parse_dates=['date'])\n",
    "# w = pd.read_csv('d:/project/contest/data/processed/p_wUVair_seoul_category.csv', parse_dates=['date'], index_col=0)\n",
    "w = pd.read_csv('d:/project/contest/data/processed/날씨_ver071915.csv', parse_dates=['date'], index_col=0)\n",
    "sns_all = pd.read_csv('d:/project/contest/data/processed/social_all.csv', parse_dates=['date'])\n",
    "\n",
    "# GS/lv 서울시만\n",
    "gs_seoul = gs.loc[gs.pvn_nm =='서울특별시']\n",
    "lv_seoul = lv.loc[lv.pvn_nm =='서울특별시']\n",
    "w_seoul = w.loc[w['loc']==108]\n",
    "\n",
    "cols_to_keep = ['date','bor_nm','gender','age_cd','category','qty']\n",
    "\n",
    "# 일일, 구단위, 상품별 판매량 종합\n",
    "lv_grouped = lv_seoul[cols_to_keep].groupby(by=['date','bor_nm','category']).sum().reset_index()\n",
    "\n",
    "# 일단위로 자료 종합(qty는 일일 합계)\n",
    "day_lv_grouped = lv_grouped.groupby(by=['date','category']).sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '제모제'만 빼서 df생성\n",
    "item = '제모제'\n",
    "grouped_by = 'date'\n",
    "day_lv_grouped_w_item = pd.merge(day_lv_grouped.loc[day_lv_grouped.category==item],w_seoul,on='date',how='left')\n",
    "# day_gs_grouped_w_item.head(3)\n",
    "day_lv_grouped_w_sns_item = pd.merge(day_lv_grouped_w_item, sns_all,on='date',how='left')\n",
    "\n",
    "# 일단 uv = 자외선 지수는 결측치가 많아서 제외\n",
    "selected_cols = ['date', 'category', 'qty', 'temp', 'rain', 'cloud', 'wind','humid', 'hpa',\n",
    "                 'sun_time', 'lgt_time', 'snow','rain_or_not','snow_or_not','미세', '초미세', '공기상태',\n",
    "                 'SO2', 'CO', 'O3', 'NO2', 'PM10', 'PM25',\n",
    "                 'pm_blog', 'pm_twitter', 'pm_news', 'pm_total',\n",
    "                 'health_blog', 'health_twitter', 'health_news', 'health_total',\n",
    "                 'date_blog', 'date_twitter', 'date_news', 'date_total',\n",
    "                 'br_blog', 'br_twitter', 'br_news', 'br_total',\n",
    "                 'hobby_blog', 'hobby_twitter', 'hobby_news', 'hobby_total']\n",
    "lv_day_w = day_lv_grouped_w_sns_item[selected_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAD적용\n",
    "lv_day_w['outlier'] = pd.DataFrame(mad_based_outlier(lv_day_w['qty']))\n",
    "lv_day_w = lv_day_w.loc[lv_day_w.outlier==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VIF_Factor</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.239620</td>\n",
       "      <td>snow_or_not</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.479988</td>\n",
       "      <td>rain_or_not</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.114369</td>\n",
       "      <td>공기상태</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.013218</td>\n",
       "      <td>temp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.725926</td>\n",
       "      <td>cloud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8.084050</td>\n",
       "      <td>lgt_time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9.334878</td>\n",
       "      <td>wind</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VIF_Factor     features\n",
       "0    1.239620  snow_or_not\n",
       "1    2.479988  rain_or_not\n",
       "2    3.114369         공기상태\n",
       "3    4.013218         temp\n",
       "4    6.725926        cloud\n",
       "5    8.084050     lgt_time\n",
       "6    9.334878         wind"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list_col = ['temp', 'cloud', 'wind', 'lgt_time', 'PM10'] # +,'rain_or_not','snow_or_not'\n",
    "list_col = ['temp', 'cloud', 'wind','lgt_time',\n",
    "            'rain_or_not', 'snow_or_not', '공기상태'] #+'rain_or_not', 'snow_or_not'\n",
    "lowVIF(w,20,list_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data = lv_day_w.loc[lv_day_w.date.between('2016-01-01','2017-12-31')]\n",
    "test_data = lv_day_w.loc[lv_day_w.date.between('2018-01-01','2018-12-31')]\n",
    "\n",
    "# 3년치 데이터 분리 : 종속변수('qty': 판매량)와 독립변수(판매량 제외 나머지 전부)\n",
    "# 날씨 데이터만\n",
    "combined = lv_day_w.loc[:,list_col]\n",
    "target = lv_day_w.loc[:,'qty']\n",
    "Xy = pd.concat([target,combined], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cols_with_no_nans(df,col_type):\n",
    "    '''\n",
    "    Arguments :\n",
    "    df : The dataframe to process\n",
    "    col_type : \n",
    "          num : to only get numerical columns with no nans\n",
    "          no_num : to only get nun-numerical columns with no nans\n",
    "          all : to get any columns with no nans    \n",
    "    '''\n",
    "    if (col_type == 'num'):\n",
    "        predictors = df.select_dtypes(exclude=['object'])\n",
    "    elif (col_type == 'no_num'):\n",
    "        predictors = df.select_dtypes(include=['object'])\n",
    "    elif (col_type == 'all'):\n",
    "        predictors = df\n",
    "    else :\n",
    "        print('Error : choose a type (num, no_num, all)')\n",
    "        return 0\n",
    "    cols_with_no_nans = []\n",
    "    for col in predictors.columns:\n",
    "        if not df[col].isnull().any():\n",
    "            cols_with_no_nans.append(col)\n",
    "    return cols_with_no_nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "수치형 자료 컬럼 갯수 : 7\n",
      "오브젝트형 자료 컬럼 갯수 : 0\n"
     ]
    }
   ],
   "source": [
    "num_cols = get_cols_with_no_nans(combined , 'num')\n",
    "cat_cols = get_cols_with_no_nans(combined , 'no_num')\n",
    "\n",
    "print ('수치형 자료 컬럼 갯수 :',len(num_cols))\n",
    "print ('오브젝트형 자료 컬럼 갯수 :',len(cat_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x720 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "combined = combined[num_cols + cat_cols]\n",
    "combined.hist(figsize = (12,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data = train_data[num_cols + cat_cols]\n",
    "train_data['Target'] = target\n",
    "\n",
    "C_mat = train_data.corr()\n",
    "fig = plt.figure(figsize = (15,15))\n",
    "\n",
    "sb.heatmap(C_mat, vmax = .8, square = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분류형(category형) 컬럼 수정 전, 총 7 개의 columns이 있었습니다.\n",
      "분류형(category형) 컬럼 수정 후, 총 10 개의 columns이 있었습니다.\n"
     ]
    }
   ],
   "source": [
    "def oneHotEncode(df,colNames):\n",
    "    for col in colNames:\n",
    "        # 해당 컬럼의 데이터 타입이 object란 소리는 숫자가 아니다 = 분류형 데이터\n",
    "        if( df[col].dtype == np.dtype('object')):\n",
    "            # 더미 컬럼 생성\n",
    "            dummies = pd.get_dummies(df[col],prefix=col)\n",
    "            # 원본 데이터에 이어 붙이기 axis=1 컬럼방향으로 \n",
    "            df = pd.concat([df,dummies],axis=1)\n",
    "\n",
    "            # 기존의 str형 컬럼 삭제\n",
    "            df.drop([col],axis = 1 , inplace=True)\n",
    "    return df\n",
    "    \n",
    "\n",
    "print('분류형(category형) 컬럼 수정 전, 총 {} 개의 columns이 있었습니다.'.format(combined.shape[1]))\n",
    "combined = oneHotEncode(combined, cat_cols)\n",
    "#### 내가 '공기상태'라는 컬럼이 사실은 category형이라는것을 알기에 직접 dummy컬럼 생성\n",
    "airCondition_dummies = pd.get_dummies(combined['공기상태'],prefix='공기상태')\n",
    "combined = pd.concat([combined, airCondition_dummies], axis=1)\n",
    "combined.drop(['공기상태'],axis = 1 , inplace=True)\n",
    "######################################################################################\n",
    "print('분류형(category형) 컬럼 수정 후, 총 {} 개의 columns이 있었습니다.'.format(combined.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temp</th>\n",
       "      <th>cloud</th>\n",
       "      <th>wind</th>\n",
       "      <th>lgt_time</th>\n",
       "      <th>rain_or_not</th>\n",
       "      <th>snow_or_not</th>\n",
       "      <th>공기상태_0</th>\n",
       "      <th>공기상태_1</th>\n",
       "      <th>공기상태_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   temp  cloud  wind  lgt_time  rain_or_not  snow_or_not  공기상태_0  공기상태_1  \\\n",
       "0   1.2    7.0   1.6       2.1            0            0       0       0   \n",
       "\n",
       "   공기상태_2  \n",
       "0       1  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 공기상태_0,공기상태_1,공기상태_2가 전부 0이면,   공기상태_3이 1이란 소리고\n",
    "#                                                               공기상태가 '매우나쁨' 임을 추정할수 있다.\n",
    "# 그런이유로 공기상태_3삭제\n",
    "combined.drop(['공기상태_3'],axis = 1 , inplace=True)\n",
    "combined.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xy = pd.concat([target,combined], axis=1)\n",
    "# Xy.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(732, 9)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 첫 2년 : 732 일\n",
    "cut_line = 732\n",
    "def split_combined():\n",
    "    global combined\n",
    "    train = combined[:cut_line]\n",
    "    test = combined[cut_line:]\n",
    "\n",
    "    return train , test \n",
    "  \n",
    "train, test = split_combined()\n",
    "\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0719 21:10:01.992248  8536 deprecation_wrapper.py:119] From C:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0719 21:10:02.008201  8536 deprecation_wrapper.py:119] From C:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0719 21:10:02.010172  8536 deprecation_wrapper.py:119] From C:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4115: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "W0719 21:10:02.064028  8536 deprecation_wrapper.py:119] From C:\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 128)               1280      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 166,145\n",
      "Trainable params: 166,145\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 신경망 모델 생성\n",
    "NN_model = Sequential()\n",
    "\n",
    "# The Input Layer :\n",
    "NN_model.add(Dense(128, kernel_initializer='normal',input_dim = train.shape[1], activation='relu'))\n",
    "\n",
    "# The Hidden Layers :\n",
    "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "\n",
    "# The Output Layer :\n",
    "NN_model.add(Dense(1, kernel_initializer='normal',activation='linear'))\n",
    "\n",
    "# Compile the network :\n",
    "# optimizer에 여러 방식이 있다.\n",
    "NN_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
    "NN_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인공 신경망에 의해 생성된 weight 자료를 저장하기 위해서\n",
    "checkpoint_name = item+grouped_by+'-Weights-{epoch:03d}--{val_loss:.5f}-cat04-vf05.hdf5' \n",
    "\n",
    "# save_best_only값이 저장되어, 모든 weight값을 저장하지 않고, val_loss값이 줄어들때마다(적을수록 좋다.) 저장\n",
    "checkpoint = ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose = 1, save_best_only = True, mode ='auto')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0719 21:10:08.802263  8536 deprecation_wrapper.py:119] From C:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "W0719 21:10:08.900768  8536 deprecation_wrapper.py:119] From C:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 585 samples, validate on 147 samples\n",
      "Epoch 1/500\n",
      "585/585 [==============================] - 0s 515us/step - loss: 1347.7128 - mean_absolute_error: 1347.7128 - val_loss: 617.7628 - val_mean_absolute_error: 617.7628\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 617.76282, saving model to 제모제date-Weights-001--617.76282-cat04-vf05.hdf5\n",
      "Epoch 2/500\n",
      "585/585 [==============================] - 0s 104us/step - loss: 874.1719 - mean_absolute_error: 874.1719 - val_loss: 668.9546 - val_mean_absolute_error: 668.9546\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 617.76282\n",
      "Epoch 3/500\n",
      "585/585 [==============================] - 0s 75us/step - loss: 615.8285 - mean_absolute_error: 615.8285 - val_loss: 422.2048 - val_mean_absolute_error: 422.2048\n",
      "\n",
      "Epoch 00003: val_loss improved from 617.76282 to 422.20477, saving model to 제모제date-Weights-003--422.20477-cat04-vf05.hdf5\n",
      "Epoch 4/500\n",
      "585/585 [==============================] - 0s 73us/step - loss: 566.2930 - mean_absolute_error: 566.2930 - val_loss: 528.2927 - val_mean_absolute_error: 528.2927\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 422.20477\n",
      "Epoch 5/500\n",
      "585/585 [==============================] - 0s 70us/step - loss: 556.3882 - mean_absolute_error: 556.3882 - val_loss: 548.2399 - val_mean_absolute_error: 548.2399\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 422.20477\n",
      "Epoch 6/500\n",
      "585/585 [==============================] - 0s 77us/step - loss: 550.2741 - mean_absolute_error: 550.2741 - val_loss: 517.4670 - val_mean_absolute_error: 517.4670\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 422.20477\n",
      "Epoch 7/500\n",
      "585/585 [==============================] - 0s 80us/step - loss: 547.0884 - mean_absolute_error: 547.0884 - val_loss: 527.6384 - val_mean_absolute_error: 527.6384\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 422.20477\n",
      "Epoch 8/500\n",
      "585/585 [==============================] - 0s 82us/step - loss: 546.6937 - mean_absolute_error: 546.6937 - val_loss: 516.2416 - val_mean_absolute_error: 516.2416\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 422.20477\n",
      "Epoch 9/500\n",
      "585/585 [==============================] - 0s 77us/step - loss: 542.4169 - mean_absolute_error: 542.4169 - val_loss: 509.6366 - val_mean_absolute_error: 509.6366\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 422.20477\n",
      "Epoch 10/500\n",
      "585/585 [==============================] - 0s 73us/step - loss: 536.6375 - mean_absolute_error: 536.6375 - val_loss: 540.2285 - val_mean_absolute_error: 540.2285\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 422.20477\n",
      "Epoch 11/500\n",
      "585/585 [==============================] - 0s 73us/step - loss: 529.9597 - mean_absolute_error: 529.9597 - val_loss: 508.1724 - val_mean_absolute_error: 508.1724\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 422.20477\n",
      "Epoch 12/500\n",
      "585/585 [==============================] - 0s 75us/step - loss: 530.6353 - mean_absolute_error: 530.6353 - val_loss: 517.5930 - val_mean_absolute_error: 517.5930\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 422.20477\n",
      "Epoch 13/500\n",
      "585/585 [==============================] - 0s 84us/step - loss: 524.1861 - mean_absolute_error: 524.1861 - val_loss: 499.1781 - val_mean_absolute_error: 499.1781\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 422.20477\n",
      "Epoch 14/500\n",
      "585/585 [==============================] - 0s 82us/step - loss: 523.9085 - mean_absolute_error: 523.9085 - val_loss: 485.8265 - val_mean_absolute_error: 485.8265\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 422.20477\n",
      "Epoch 15/500\n",
      "585/585 [==============================] - 0s 80us/step - loss: 521.1857 - mean_absolute_error: 521.1857 - val_loss: 497.4529 - val_mean_absolute_error: 497.4529\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 422.20477\n",
      "Epoch 16/500\n",
      "585/585 [==============================] - 0s 73us/step - loss: 521.3792 - mean_absolute_error: 521.3792 - val_loss: 500.3124 - val_mean_absolute_error: 500.3124\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 422.20477\n",
      "Epoch 17/500\n",
      "585/585 [==============================] - 0s 84us/step - loss: 515.4389 - mean_absolute_error: 515.4389 - val_loss: 457.4760 - val_mean_absolute_error: 457.4760\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 422.20477\n",
      "Epoch 18/500\n",
      "585/585 [==============================] - 0s 78us/step - loss: 518.4305 - mean_absolute_error: 518.4305 - val_loss: 463.9643 - val_mean_absolute_error: 463.9643\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 422.20477\n",
      "Epoch 19/500\n",
      "585/585 [==============================] - 0s 82us/step - loss: 511.6026 - mean_absolute_error: 511.6026 - val_loss: 452.4166 - val_mean_absolute_error: 452.4166\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 422.20477\n",
      "Epoch 20/500\n",
      "585/585 [==============================] - 0s 77us/step - loss: 513.5658 - mean_absolute_error: 513.5658 - val_loss: 446.4107 - val_mean_absolute_error: 446.4107\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 422.20477\n",
      "Epoch 21/500\n",
      "585/585 [==============================] - 0s 80us/step - loss: 510.0339 - mean_absolute_error: 510.0339 - val_loss: 435.5893 - val_mean_absolute_error: 435.5893\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 422.20477\n",
      "Epoch 22/500\n",
      "585/585 [==============================] - 0s 77us/step - loss: 509.6392 - mean_absolute_error: 509.6392 - val_loss: 454.4294 - val_mean_absolute_error: 454.4294\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 422.20477\n",
      "Epoch 23/500\n",
      "585/585 [==============================] - 0s 78us/step - loss: 505.9052 - mean_absolute_error: 505.9052 - val_loss: 473.6789 - val_mean_absolute_error: 473.6789\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 422.20477\n",
      "Epoch 24/500\n",
      "585/585 [==============================] - 0s 77us/step - loss: 506.1892 - mean_absolute_error: 506.1892 - val_loss: 419.0887 - val_mean_absolute_error: 419.0887\n",
      "\n",
      "Epoch 00024: val_loss improved from 422.20477 to 419.08865, saving model to 제모제date-Weights-024--419.08865-cat04-vf05.hdf5\n",
      "Epoch 25/500\n",
      "585/585 [==============================] - 0s 75us/step - loss: 509.0277 - mean_absolute_error: 509.0277 - val_loss: 432.8601 - val_mean_absolute_error: 432.8601\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 419.08865\n",
      "Epoch 26/500\n",
      "585/585 [==============================] - 0s 80us/step - loss: 504.8176 - mean_absolute_error: 504.8176 - val_loss: 453.7866 - val_mean_absolute_error: 453.7866\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 419.08865\n",
      "Epoch 27/500\n",
      "585/585 [==============================] - 0s 75us/step - loss: 503.5748 - mean_absolute_error: 503.5748 - val_loss: 480.2727 - val_mean_absolute_error: 480.2727\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 419.08865\n",
      "Epoch 28/500\n",
      "585/585 [==============================] - 0s 82us/step - loss: 524.8768 - mean_absolute_error: 524.8768 - val_loss: 490.8727 - val_mean_absolute_error: 490.8727\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 419.08865\n",
      "Epoch 29/500\n",
      "585/585 [==============================] - 0s 78us/step - loss: 516.3521 - mean_absolute_error: 516.3521 - val_loss: 486.7993 - val_mean_absolute_error: 486.7993\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 419.08865\n",
      "Epoch 30/500\n",
      "585/585 [==============================] - 0s 77us/step - loss: 500.9652 - mean_absolute_error: 500.9652 - val_loss: 475.2547 - val_mean_absolute_error: 475.2547\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 419.08865\n",
      "Epoch 31/500\n",
      "585/585 [==============================] - 0s 77us/step - loss: 514.2603 - mean_absolute_error: 514.2603 - val_loss: 508.2914 - val_mean_absolute_error: 508.2914\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 419.08865\n",
      "Epoch 32/500\n",
      "585/585 [==============================] - 0s 77us/step - loss: 512.9306 - mean_absolute_error: 512.9306 - val_loss: 492.6425 - val_mean_absolute_error: 492.6425\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 419.08865\n",
      "Epoch 33/500\n",
      "585/585 [==============================] - 0s 72us/step - loss: 504.3257 - mean_absolute_error: 504.3257 - val_loss: 441.8750 - val_mean_absolute_error: 441.8750\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 419.08865\n",
      "Epoch 34/500\n",
      "585/585 [==============================] - 0s 75us/step - loss: 498.2725 - mean_absolute_error: 498.2725 - val_loss: 421.8980 - val_mean_absolute_error: 421.8980\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 419.08865\n",
      "Epoch 35/500\n",
      "585/585 [==============================] - 0s 73us/step - loss: 513.3163 - mean_absolute_error: 513.3163 - val_loss: 450.2501 - val_mean_absolute_error: 450.2501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00035: val_loss did not improve from 419.08865\n",
      "Epoch 36/500\n",
      "585/585 [==============================] - 0s 80us/step - loss: 496.7852 - mean_absolute_error: 496.7852 - val_loss: 478.6696 - val_mean_absolute_error: 478.6696\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 419.08865\n",
      "Epoch 37/500\n",
      "585/585 [==============================] - 0s 82us/step - loss: 503.7247 - mean_absolute_error: 503.7247 - val_loss: 440.0845 - val_mean_absolute_error: 440.0845\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 419.08865\n",
      "Epoch 38/500\n",
      "585/585 [==============================] - 0s 78us/step - loss: 491.8728 - mean_absolute_error: 491.8728 - val_loss: 419.4090 - val_mean_absolute_error: 419.4090\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 419.08865\n",
      "Epoch 39/500\n",
      "585/585 [==============================] - 0s 77us/step - loss: 496.6707 - mean_absolute_error: 496.6707 - val_loss: 414.3638 - val_mean_absolute_error: 414.3638\n",
      "\n",
      "Epoch 00039: val_loss improved from 419.08865 to 414.36376, saving model to 제모제date-Weights-039--414.36376-cat04-vf05.hdf5\n",
      "Epoch 40/500\n",
      "585/585 [==============================] - 0s 73us/step - loss: 490.7317 - mean_absolute_error: 490.7317 - val_loss: 419.3765 - val_mean_absolute_error: 419.3765\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 414.36376\n",
      "Epoch 41/500\n",
      "585/585 [==============================] - 0s 80us/step - loss: 490.8703 - mean_absolute_error: 490.8703 - val_loss: 429.0591 - val_mean_absolute_error: 429.0591\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 414.36376\n",
      "Epoch 42/500\n",
      "585/585 [==============================] - 0s 78us/step - loss: 496.0197 - mean_absolute_error: 496.0197 - val_loss: 449.4433 - val_mean_absolute_error: 449.4433\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 414.36376\n",
      "Epoch 43/500\n",
      "585/585 [==============================] - 0s 78us/step - loss: 488.8593 - mean_absolute_error: 488.8593 - val_loss: 398.6641 - val_mean_absolute_error: 398.6641\n",
      "\n",
      "Epoch 00043: val_loss improved from 414.36376 to 398.66414, saving model to 제모제date-Weights-043--398.66414-cat04-vf05.hdf5\n",
      "Epoch 44/500\n",
      "585/585 [==============================] - 0s 73us/step - loss: 492.2398 - mean_absolute_error: 492.2398 - val_loss: 425.4567 - val_mean_absolute_error: 425.4567\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 398.66414\n",
      "Epoch 45/500\n",
      "585/585 [==============================] - 0s 73us/step - loss: 489.8465 - mean_absolute_error: 489.8465 - val_loss: 432.7677 - val_mean_absolute_error: 432.7677\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 398.66414\n",
      "Epoch 46/500\n",
      "585/585 [==============================] - 0s 73us/step - loss: 488.4626 - mean_absolute_error: 488.4626 - val_loss: 440.9696 - val_mean_absolute_error: 440.9696\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 398.66414\n",
      "Epoch 47/500\n",
      "585/585 [==============================] - 0s 77us/step - loss: 490.0952 - mean_absolute_error: 490.0952 - val_loss: 409.8575 - val_mean_absolute_error: 409.8575\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 398.66414\n",
      "Epoch 48/500\n",
      "585/585 [==============================] - 0s 75us/step - loss: 494.0954 - mean_absolute_error: 494.0954 - val_loss: 436.3068 - val_mean_absolute_error: 436.3068\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 398.66414\n",
      "Epoch 49/500\n",
      "585/585 [==============================] - 0s 82us/step - loss: 486.4068 - mean_absolute_error: 486.4068 - val_loss: 400.4110 - val_mean_absolute_error: 400.4110\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 398.66414\n",
      "Epoch 50/500\n",
      "585/585 [==============================] - 0s 77us/step - loss: 485.3258 - mean_absolute_error: 485.3258 - val_loss: 407.0496 - val_mean_absolute_error: 407.0496\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 398.66414\n",
      "Epoch 51/500\n",
      "585/585 [==============================] - 0s 80us/step - loss: 485.0713 - mean_absolute_error: 485.0713 - val_loss: 417.7471 - val_mean_absolute_error: 417.7471\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 398.66414\n",
      "Epoch 52/500\n",
      "585/585 [==============================] - 0s 82us/step - loss: 495.4805 - mean_absolute_error: 495.4805 - val_loss: 405.9777 - val_mean_absolute_error: 405.9777\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 398.66414\n",
      "Epoch 53/500\n",
      "585/585 [==============================] - 0s 85us/step - loss: 486.0824 - mean_absolute_error: 486.0824 - val_loss: 451.7083 - val_mean_absolute_error: 451.7083\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 398.66414\n",
      "Epoch 54/500\n",
      "585/585 [==============================] - 0s 82us/step - loss: 495.7788 - mean_absolute_error: 495.7788 - val_loss: 431.9819 - val_mean_absolute_error: 431.9819\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 398.66414\n",
      "Epoch 55/500\n",
      "585/585 [==============================] - 0s 75us/step - loss: 505.5485 - mean_absolute_error: 505.5485 - val_loss: 465.4079 - val_mean_absolute_error: 465.4079\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 398.66414\n",
      "Epoch 56/500\n",
      "585/585 [==============================] - 0s 78us/step - loss: 498.4845 - mean_absolute_error: 498.4845 - val_loss: 450.0837 - val_mean_absolute_error: 450.0837\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 398.66414\n",
      "Epoch 57/500\n",
      "585/585 [==============================] - 0s 85us/step - loss: 479.1647 - mean_absolute_error: 479.1647 - val_loss: 407.8256 - val_mean_absolute_error: 407.8256\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 398.66414\n",
      "Epoch 58/500\n",
      "585/585 [==============================] - 0s 87us/step - loss: 482.4130 - mean_absolute_error: 482.4130 - val_loss: 425.5031 - val_mean_absolute_error: 425.5031\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 398.66414\n",
      "Epoch 59/500\n",
      "585/585 [==============================] - 0s 80us/step - loss: 478.5952 - mean_absolute_error: 478.5952 - val_loss: 431.6707 - val_mean_absolute_error: 431.6707\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 398.66414\n",
      "Epoch 60/500\n",
      "585/585 [==============================] - 0s 87us/step - loss: 477.5494 - mean_absolute_error: 477.5494 - val_loss: 407.3139 - val_mean_absolute_error: 407.3139\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 398.66414\n",
      "Epoch 61/500\n",
      "585/585 [==============================] - 0s 90us/step - loss: 480.8260 - mean_absolute_error: 480.8260 - val_loss: 442.7761 - val_mean_absolute_error: 442.7761\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 398.66414\n",
      "Epoch 62/500\n",
      "585/585 [==============================] - 0s 92us/step - loss: 472.3959 - mean_absolute_error: 472.3959 - val_loss: 387.8332 - val_mean_absolute_error: 387.8332\n",
      "\n",
      "Epoch 00062: val_loss improved from 398.66414 to 387.83319, saving model to 제모제date-Weights-062--387.83319-cat04-vf05.hdf5\n",
      "Epoch 63/500\n",
      "585/585 [==============================] - 0s 84us/step - loss: 475.5792 - mean_absolute_error: 475.5792 - val_loss: 426.4669 - val_mean_absolute_error: 426.4669\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 387.83319\n",
      "Epoch 64/500\n",
      "585/585 [==============================] - 0s 75us/step - loss: 474.0390 - mean_absolute_error: 474.0390 - val_loss: 421.3881 - val_mean_absolute_error: 421.3881\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 387.83319\n",
      "Epoch 65/500\n",
      "585/585 [==============================] - 0s 85us/step - loss: 482.6885 - mean_absolute_error: 482.6885 - val_loss: 406.9527 - val_mean_absolute_error: 406.9527\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 387.83319\n",
      "Epoch 66/500\n",
      "585/585 [==============================] - 0s 82us/step - loss: 475.6193 - mean_absolute_error: 475.6193 - val_loss: 429.9820 - val_mean_absolute_error: 429.9820\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 387.83319\n",
      "Epoch 67/500\n",
      "585/585 [==============================] - 0s 90us/step - loss: 478.3389 - mean_absolute_error: 478.3389 - val_loss: 444.3546 - val_mean_absolute_error: 444.3546\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 387.83319\n",
      "Epoch 68/500\n",
      "585/585 [==============================] - 0s 78us/step - loss: 470.1017 - mean_absolute_error: 470.1017 - val_loss: 445.4688 - val_mean_absolute_error: 445.4688\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 387.83319\n",
      "Epoch 69/500\n",
      "585/585 [==============================] - 0s 85us/step - loss: 475.9707 - mean_absolute_error: 475.9707 - val_loss: 415.3084 - val_mean_absolute_error: 415.3084\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 387.83319\n",
      "Epoch 70/500\n",
      "585/585 [==============================] - 0s 87us/step - loss: 471.4820 - mean_absolute_error: 471.4820 - val_loss: 423.5462 - val_mean_absolute_error: 423.5462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00070: val_loss did not improve from 387.83319\n",
      "Epoch 71/500\n",
      "585/585 [==============================] - 0s 90us/step - loss: 469.5108 - mean_absolute_error: 469.5108 - val_loss: 397.9005 - val_mean_absolute_error: 397.9005\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 387.83319\n",
      "Epoch 72/500\n",
      "585/585 [==============================] - 0s 92us/step - loss: 471.1749 - mean_absolute_error: 471.1749 - val_loss: 423.3961 - val_mean_absolute_error: 423.3961\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 387.83319\n",
      "Epoch 73/500\n",
      "585/585 [==============================] - 0s 90us/step - loss: 464.2818 - mean_absolute_error: 464.2818 - val_loss: 386.2634 - val_mean_absolute_error: 386.2634\n",
      "\n",
      "Epoch 00073: val_loss improved from 387.83319 to 386.26336, saving model to 제모제date-Weights-073--386.26336-cat04-vf05.hdf5\n",
      "Epoch 74/500\n",
      "585/585 [==============================] - 0s 85us/step - loss: 465.6379 - mean_absolute_error: 465.6379 - val_loss: 420.2848 - val_mean_absolute_error: 420.2848\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 386.26336\n",
      "Epoch 75/500\n",
      "585/585 [==============================] - 0s 84us/step - loss: 465.5877 - mean_absolute_error: 465.5877 - val_loss: 451.3990 - val_mean_absolute_error: 451.3990\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 386.26336\n",
      "Epoch 76/500\n",
      "585/585 [==============================] - 0s 90us/step - loss: 461.5046 - mean_absolute_error: 461.5046 - val_loss: 402.0481 - val_mean_absolute_error: 402.0481\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 386.26336\n",
      "Epoch 77/500\n",
      "585/585 [==============================] - 0s 87us/step - loss: 461.7688 - mean_absolute_error: 461.7688 - val_loss: 378.7722 - val_mean_absolute_error: 378.7722\n",
      "\n",
      "Epoch 00077: val_loss improved from 386.26336 to 378.77219, saving model to 제모제date-Weights-077--378.77219-cat04-vf05.hdf5\n",
      "Epoch 78/500\n",
      "585/585 [==============================] - 0s 89us/step - loss: 462.2971 - mean_absolute_error: 462.2971 - val_loss: 424.7772 - val_mean_absolute_error: 424.7772\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 378.77219\n",
      "Epoch 79/500\n",
      "585/585 [==============================] - 0s 84us/step - loss: 453.2234 - mean_absolute_error: 453.2234 - val_loss: 465.0917 - val_mean_absolute_error: 465.0917\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 378.77219\n",
      "Epoch 80/500\n",
      "585/585 [==============================] - 0s 84us/step - loss: 458.0956 - mean_absolute_error: 458.0956 - val_loss: 407.8683 - val_mean_absolute_error: 407.8683\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 378.77219\n",
      "Epoch 81/500\n",
      "585/585 [==============================] - 0s 84us/step - loss: 463.9760 - mean_absolute_error: 463.9760 - val_loss: 425.1110 - val_mean_absolute_error: 425.1110\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 378.77219\n",
      "Epoch 82/500\n",
      "585/585 [==============================] - 0s 83us/step - loss: 454.8225 - mean_absolute_error: 454.8225 - val_loss: 410.3678 - val_mean_absolute_error: 410.3678\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 378.77219\n",
      "Epoch 83/500\n",
      "585/585 [==============================] - 0s 84us/step - loss: 470.5268 - mean_absolute_error: 470.5268 - val_loss: 384.7328 - val_mean_absolute_error: 384.7328\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 378.77219\n",
      "Epoch 84/500\n",
      "585/585 [==============================] - 0s 82us/step - loss: 458.7071 - mean_absolute_error: 458.7071 - val_loss: 423.8753 - val_mean_absolute_error: 423.8753\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 378.77219\n",
      "Epoch 85/500\n",
      "585/585 [==============================] - 0s 85us/step - loss: 453.0729 - mean_absolute_error: 453.0729 - val_loss: 425.6920 - val_mean_absolute_error: 425.6920\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 378.77219\n",
      "Epoch 86/500\n",
      "585/585 [==============================] - 0s 92us/step - loss: 464.8116 - mean_absolute_error: 464.8116 - val_loss: 401.2591 - val_mean_absolute_error: 401.2591\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 378.77219\n",
      "Epoch 87/500\n",
      "585/585 [==============================] - 0s 94us/step - loss: 460.4014 - mean_absolute_error: 460.4014 - val_loss: 447.3066 - val_mean_absolute_error: 447.3066\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 378.77219\n",
      "Epoch 88/500\n",
      "585/585 [==============================] - 0s 90us/step - loss: 447.1995 - mean_absolute_error: 447.1995 - val_loss: 426.0372 - val_mean_absolute_error: 426.0372\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 378.77219\n",
      "Epoch 89/500\n",
      "585/585 [==============================] - 0s 95us/step - loss: 453.1019 - mean_absolute_error: 453.1019 - val_loss: 432.3078 - val_mean_absolute_error: 432.3078\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 378.77219\n",
      "Epoch 90/500\n",
      "585/585 [==============================] - 0s 92us/step - loss: 449.8394 - mean_absolute_error: 449.8394 - val_loss: 455.1739 - val_mean_absolute_error: 455.1739\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 378.77219\n",
      "Epoch 91/500\n",
      "585/585 [==============================] - 0s 94us/step - loss: 450.8337 - mean_absolute_error: 450.8337 - val_loss: 416.2795 - val_mean_absolute_error: 416.2795\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 378.77219\n",
      "Epoch 92/500\n",
      "585/585 [==============================] - 0s 92us/step - loss: 453.3408 - mean_absolute_error: 453.3408 - val_loss: 464.5136 - val_mean_absolute_error: 464.5136\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 378.77219\n",
      "Epoch 93/500\n",
      "585/585 [==============================] - 0s 80us/step - loss: 457.1288 - mean_absolute_error: 457.1288 - val_loss: 387.9444 - val_mean_absolute_error: 387.9444\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 378.77219\n",
      "Epoch 94/500\n",
      "585/585 [==============================] - 0s 82us/step - loss: 464.7218 - mean_absolute_error: 464.7218 - val_loss: 396.6363 - val_mean_absolute_error: 396.6363\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 378.77219\n",
      "Epoch 95/500\n",
      "585/585 [==============================] - 0s 97us/step - loss: 472.2199 - mean_absolute_error: 472.2199 - val_loss: 385.7886 - val_mean_absolute_error: 385.7886\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 378.77219\n",
      "Epoch 96/500\n",
      "585/585 [==============================] - 0s 95us/step - loss: 448.7744 - mean_absolute_error: 448.7744 - val_loss: 425.8392 - val_mean_absolute_error: 425.8392\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 378.77219\n",
      "Epoch 97/500\n",
      "585/585 [==============================] - 0s 92us/step - loss: 445.1511 - mean_absolute_error: 445.1511 - val_loss: 430.4605 - val_mean_absolute_error: 430.4605\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 378.77219\n",
      "Epoch 98/500\n",
      "585/585 [==============================] - 0s 113us/step - loss: 445.1623 - mean_absolute_error: 445.1623 - val_loss: 415.7515 - val_mean_absolute_error: 415.7515\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 378.77219\n",
      "Epoch 99/500\n",
      "585/585 [==============================] - 0s 92us/step - loss: 439.7611 - mean_absolute_error: 439.7611 - val_loss: 418.1248 - val_mean_absolute_error: 418.1248\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 378.77219\n",
      "Epoch 100/500\n",
      "585/585 [==============================] - 0s 101us/step - loss: 439.6755 - mean_absolute_error: 439.6755 - val_loss: 433.9488 - val_mean_absolute_error: 433.9488\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 378.77219\n",
      "Epoch 101/500\n",
      "585/585 [==============================] - 0s 97us/step - loss: 453.8274 - mean_absolute_error: 453.8274 - val_loss: 399.5893 - val_mean_absolute_error: 399.5893\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 378.77219\n",
      "Epoch 102/500\n",
      "585/585 [==============================] - 0s 95us/step - loss: 448.6799 - mean_absolute_error: 448.6799 - val_loss: 400.5288 - val_mean_absolute_error: 400.5288\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 378.77219\n",
      "Epoch 103/500\n",
      "585/585 [==============================] - 0s 113us/step - loss: 441.7517 - mean_absolute_error: 441.7517 - val_loss: 438.6369 - val_mean_absolute_error: 438.6369\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 378.77219\n",
      "Epoch 104/500\n",
      "585/585 [==============================] - 0s 89us/step - loss: 447.8696 - mean_absolute_error: 447.8696 - val_loss: 398.7568 - val_mean_absolute_error: 398.7568\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 378.77219\n",
      "Epoch 105/500\n",
      "585/585 [==============================] - 0s 94us/step - loss: 439.1518 - mean_absolute_error: 439.1518 - val_loss: 404.3288 - val_mean_absolute_error: 404.3288\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 378.77219\n",
      "Epoch 106/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "585/585 [==============================] - 0s 94us/step - loss: 456.9183 - mean_absolute_error: 456.9183 - val_loss: 447.8516 - val_mean_absolute_error: 447.8516\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 378.77219\n",
      "Epoch 107/500\n",
      "585/585 [==============================] - 0s 102us/step - loss: 432.5460 - mean_absolute_error: 432.5460 - val_loss: 439.5629 - val_mean_absolute_error: 439.5629\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 378.77219\n",
      "Epoch 108/500\n",
      "585/585 [==============================] - 0s 101us/step - loss: 442.0177 - mean_absolute_error: 442.0177 - val_loss: 400.3775 - val_mean_absolute_error: 400.3775\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 378.77219\n",
      "Epoch 109/500\n",
      "585/585 [==============================] - 0s 99us/step - loss: 432.0891 - mean_absolute_error: 432.0891 - val_loss: 447.8290 - val_mean_absolute_error: 447.8290\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 378.77219\n",
      "Epoch 110/500\n",
      "585/585 [==============================] - 0s 99us/step - loss: 437.0438 - mean_absolute_error: 437.0438 - val_loss: 441.6366 - val_mean_absolute_error: 441.6366\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 378.77219\n",
      "Epoch 111/500\n",
      "585/585 [==============================] - 0s 92us/step - loss: 429.8201 - mean_absolute_error: 429.8201 - val_loss: 461.8666 - val_mean_absolute_error: 461.8666\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 378.77219\n",
      "Epoch 112/500\n",
      "585/585 [==============================] - 0s 106us/step - loss: 436.5317 - mean_absolute_error: 436.5317 - val_loss: 406.4833 - val_mean_absolute_error: 406.4833\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 378.77219\n",
      "Epoch 113/500\n",
      "585/585 [==============================] - 0s 94us/step - loss: 434.3511 - mean_absolute_error: 434.3511 - val_loss: 444.1418 - val_mean_absolute_error: 444.1418\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 378.77219\n",
      "Epoch 114/500\n",
      "585/585 [==============================] - 0s 106us/step - loss: 428.8810 - mean_absolute_error: 428.8810 - val_loss: 446.0629 - val_mean_absolute_error: 446.0629\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 378.77219\n",
      "Epoch 115/500\n",
      "585/585 [==============================] - 0s 102us/step - loss: 447.5713 - mean_absolute_error: 447.5713 - val_loss: 424.0242 - val_mean_absolute_error: 424.0242\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 378.77219\n",
      "Epoch 116/500\n",
      "585/585 [==============================] - 0s 99us/step - loss: 464.8178 - mean_absolute_error: 464.8178 - val_loss: 344.8202 - val_mean_absolute_error: 344.8202\n",
      "\n",
      "Epoch 00116: val_loss improved from 378.77219 to 344.82021, saving model to 제모제date-Weights-116--344.82021-cat04-vf05.hdf5\n",
      "Epoch 117/500\n",
      "585/585 [==============================] - 0s 94us/step - loss: 452.2047 - mean_absolute_error: 452.2047 - val_loss: 410.3515 - val_mean_absolute_error: 410.3515\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 344.82021\n",
      "Epoch 118/500\n",
      "585/585 [==============================] - 0s 94us/step - loss: 440.0172 - mean_absolute_error: 440.0172 - val_loss: 399.5664 - val_mean_absolute_error: 399.5664\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 344.82021\n",
      "Epoch 119/500\n",
      "585/585 [==============================] - 0s 95us/step - loss: 434.3601 - mean_absolute_error: 434.3601 - val_loss: 463.3040 - val_mean_absolute_error: 463.3040\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 344.82021\n",
      "Epoch 120/500\n",
      "585/585 [==============================] - 0s 94us/step - loss: 433.3108 - mean_absolute_error: 433.3108 - val_loss: 440.5971 - val_mean_absolute_error: 440.5971\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 344.82021\n",
      "Epoch 121/500\n",
      "585/585 [==============================] - 0s 101us/step - loss: 432.9636 - mean_absolute_error: 432.9636 - val_loss: 421.5056 - val_mean_absolute_error: 421.5056\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 344.82021\n",
      "Epoch 122/500\n",
      "585/585 [==============================] - 0s 102us/step - loss: 428.5557 - mean_absolute_error: 428.5557 - val_loss: 402.4489 - val_mean_absolute_error: 402.4489\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 344.82021\n",
      "Epoch 123/500\n",
      "585/585 [==============================] - 0s 124us/step - loss: 431.9847 - mean_absolute_error: 431.9847 - val_loss: 458.8693 - val_mean_absolute_error: 458.8693\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 344.82021\n",
      "Epoch 124/500\n",
      "585/585 [==============================] - 0s 104us/step - loss: 428.0932 - mean_absolute_error: 428.0932 - val_loss: 432.6988 - val_mean_absolute_error: 432.6988\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 344.82021\n",
      "Epoch 125/500\n",
      "585/585 [==============================] - 0s 123us/step - loss: 438.3449 - mean_absolute_error: 438.3449 - val_loss: 469.0898 - val_mean_absolute_error: 469.0898\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 344.82021\n",
      "Epoch 126/500\n",
      "585/585 [==============================] - 0s 102us/step - loss: 480.1689 - mean_absolute_error: 480.1689 - val_loss: 460.5879 - val_mean_absolute_error: 460.5879\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 344.82021\n",
      "Epoch 127/500\n",
      "585/585 [==============================] - 0s 118us/step - loss: 431.1628 - mean_absolute_error: 431.1628 - val_loss: 458.2408 - val_mean_absolute_error: 458.2408\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 344.82021\n",
      "Epoch 128/500\n",
      "585/585 [==============================] - 0s 107us/step - loss: 438.5154 - mean_absolute_error: 438.5154 - val_loss: 401.1852 - val_mean_absolute_error: 401.1852\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 344.82021\n",
      "Epoch 129/500\n",
      "585/585 [==============================] - 0s 113us/step - loss: 437.9509 - mean_absolute_error: 437.9509 - val_loss: 432.1625 - val_mean_absolute_error: 432.1625\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 344.82021\n",
      "Epoch 130/500\n",
      "585/585 [==============================] - 0s 99us/step - loss: 422.4084 - mean_absolute_error: 422.4084 - val_loss: 421.0104 - val_mean_absolute_error: 421.0104\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 344.82021\n",
      "Epoch 131/500\n",
      "585/585 [==============================] - 0s 113us/step - loss: 428.2188 - mean_absolute_error: 428.2188 - val_loss: 446.1545 - val_mean_absolute_error: 446.1545\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 344.82021\n",
      "Epoch 132/500\n",
      "585/585 [==============================] - 0s 107us/step - loss: 435.0660 - mean_absolute_error: 435.0660 - val_loss: 441.0254 - val_mean_absolute_error: 441.0254\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 344.82021\n",
      "Epoch 133/500\n",
      "585/585 [==============================] - 0s 114us/step - loss: 428.4472 - mean_absolute_error: 428.4472 - val_loss: 434.7726 - val_mean_absolute_error: 434.7726\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 344.82021\n",
      "Epoch 134/500\n",
      "585/585 [==============================] - 0s 118us/step - loss: 421.7667 - mean_absolute_error: 421.7667 - val_loss: 440.9252 - val_mean_absolute_error: 440.9252\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 344.82021\n",
      "Epoch 135/500\n",
      "585/585 [==============================] - 0s 114us/step - loss: 425.5207 - mean_absolute_error: 425.5207 - val_loss: 468.1840 - val_mean_absolute_error: 468.1840\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 344.82021\n",
      "Epoch 136/500\n",
      "585/585 [==============================] - 0s 101us/step - loss: 431.1749 - mean_absolute_error: 431.1749 - val_loss: 456.9327 - val_mean_absolute_error: 456.9327\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 344.82021\n",
      "Epoch 137/500\n",
      "585/585 [==============================] - 0s 101us/step - loss: 424.8513 - mean_absolute_error: 424.8513 - val_loss: 422.7031 - val_mean_absolute_error: 422.7031\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 344.82021\n",
      "Epoch 138/500\n",
      "585/585 [==============================] - 0s 97us/step - loss: 426.9436 - mean_absolute_error: 426.9436 - val_loss: 440.3309 - val_mean_absolute_error: 440.3309\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 344.82021\n",
      "Epoch 139/500\n",
      "585/585 [==============================] - 0s 101us/step - loss: 420.9213 - mean_absolute_error: 420.9213 - val_loss: 441.9675 - val_mean_absolute_error: 441.9675\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 344.82021\n",
      "Epoch 140/500\n",
      "585/585 [==============================] - 0s 101us/step - loss: 424.8749 - mean_absolute_error: 424.8749 - val_loss: 416.0134 - val_mean_absolute_error: 416.0134\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 344.82021\n",
      "Epoch 141/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "585/585 [==============================] - 0s 102us/step - loss: 423.3560 - mean_absolute_error: 423.3560 - val_loss: 418.8804 - val_mean_absolute_error: 418.8804\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 344.82021\n",
      "Epoch 142/500\n",
      "585/585 [==============================] - 0s 97us/step - loss: 436.9141 - mean_absolute_error: 436.9141 - val_loss: 466.8482 - val_mean_absolute_error: 466.8482\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 344.82021\n",
      "Epoch 143/500\n",
      "585/585 [==============================] - 0s 97us/step - loss: 424.8704 - mean_absolute_error: 424.8704 - val_loss: 460.4839 - val_mean_absolute_error: 460.4839\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 344.82021\n",
      "Epoch 144/500\n",
      "585/585 [==============================] - 0s 101us/step - loss: 416.9075 - mean_absolute_error: 416.9075 - val_loss: 413.3830 - val_mean_absolute_error: 413.3830\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 344.82021\n",
      "Epoch 145/500\n",
      "585/585 [==============================] - 0s 119us/step - loss: 429.0986 - mean_absolute_error: 429.0986 - val_loss: 450.8667 - val_mean_absolute_error: 450.8667\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 344.82021\n",
      "Epoch 146/500\n",
      "585/585 [==============================] - 0s 126us/step - loss: 429.8437 - mean_absolute_error: 429.8437 - val_loss: 437.1877 - val_mean_absolute_error: 437.1877\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 344.82021\n",
      "Epoch 147/500\n",
      "585/585 [==============================] - 0s 119us/step - loss: 421.5693 - mean_absolute_error: 421.5693 - val_loss: 439.9462 - val_mean_absolute_error: 439.9462\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 344.82021\n",
      "Epoch 148/500\n",
      "585/585 [==============================] - 0s 113us/step - loss: 416.5800 - mean_absolute_error: 416.5800 - val_loss: 456.0513 - val_mean_absolute_error: 456.0513\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 344.82021\n",
      "Epoch 149/500\n",
      "585/585 [==============================] - 0s 116us/step - loss: 418.6288 - mean_absolute_error: 418.6288 - val_loss: 457.6237 - val_mean_absolute_error: 457.6237\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 344.82021\n",
      "Epoch 150/500\n",
      "585/585 [==============================] - 0s 124us/step - loss: 421.0225 - mean_absolute_error: 421.0225 - val_loss: 440.2641 - val_mean_absolute_error: 440.2641\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 344.82021\n",
      "Epoch 151/500\n",
      "585/585 [==============================] - 0s 113us/step - loss: 419.8001 - mean_absolute_error: 419.8001 - val_loss: 464.8092 - val_mean_absolute_error: 464.8092\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 344.82021\n",
      "Epoch 152/500\n",
      "585/585 [==============================] - 0s 116us/step - loss: 428.0978 - mean_absolute_error: 428.0978 - val_loss: 456.0004 - val_mean_absolute_error: 456.0004\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 344.82021\n",
      "Epoch 153/500\n",
      "585/585 [==============================] - 0s 113us/step - loss: 419.0069 - mean_absolute_error: 419.0069 - val_loss: 402.4168 - val_mean_absolute_error: 402.4168\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 344.82021\n",
      "Epoch 154/500\n",
      "585/585 [==============================] - 0s 111us/step - loss: 422.2949 - mean_absolute_error: 422.2949 - val_loss: 438.5122 - val_mean_absolute_error: 438.5122\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 344.82021\n",
      "Epoch 155/500\n",
      "585/585 [==============================] - 0s 119us/step - loss: 415.9959 - mean_absolute_error: 415.9959 - val_loss: 430.7295 - val_mean_absolute_error: 430.7295\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 344.82021\n",
      "Epoch 156/500\n",
      "585/585 [==============================] - 0s 123us/step - loss: 418.6588 - mean_absolute_error: 418.6588 - val_loss: 464.5507 - val_mean_absolute_error: 464.5507\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 344.82021\n",
      "Epoch 157/500\n",
      "585/585 [==============================] - 0s 124us/step - loss: 416.6484 - mean_absolute_error: 416.6484 - val_loss: 464.6757 - val_mean_absolute_error: 464.6757\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 344.82021\n",
      "Epoch 158/500\n",
      "585/585 [==============================] - 0s 118us/step - loss: 422.3598 - mean_absolute_error: 422.3598 - val_loss: 451.4039 - val_mean_absolute_error: 451.4039\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 344.82021\n",
      "Epoch 159/500\n",
      "585/585 [==============================] - 0s 124us/step - loss: 435.8652 - mean_absolute_error: 435.8652 - val_loss: 443.6785 - val_mean_absolute_error: 443.6785\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 344.82021\n",
      "Epoch 160/500\n",
      "585/585 [==============================] - 0s 118us/step - loss: 427.4277 - mean_absolute_error: 427.4277 - val_loss: 414.8597 - val_mean_absolute_error: 414.8597\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 344.82021\n",
      "Epoch 161/500\n",
      "585/585 [==============================] - 0s 126us/step - loss: 417.8245 - mean_absolute_error: 417.8245 - val_loss: 415.7521 - val_mean_absolute_error: 415.7521\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 344.82021\n",
      "Epoch 162/500\n",
      "585/585 [==============================] - 0s 119us/step - loss: 414.6691 - mean_absolute_error: 414.6691 - val_loss: 452.1021 - val_mean_absolute_error: 452.1021\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 344.82021\n",
      "Epoch 163/500\n",
      "585/585 [==============================] - 0s 123us/step - loss: 416.2536 - mean_absolute_error: 416.2536 - val_loss: 457.3745 - val_mean_absolute_error: 457.3745\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 344.82021\n",
      "Epoch 164/500\n",
      "585/585 [==============================] - 0s 102us/step - loss: 418.5481 - mean_absolute_error: 418.5481 - val_loss: 451.0902 - val_mean_absolute_error: 451.0902\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 344.82021\n",
      "Epoch 165/500\n",
      "585/585 [==============================] - 0s 123us/step - loss: 416.1859 - mean_absolute_error: 416.1859 - val_loss: 415.9466 - val_mean_absolute_error: 415.9466\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 344.82021\n",
      "Epoch 166/500\n",
      "585/585 [==============================] - 0s 118us/step - loss: 413.7133 - mean_absolute_error: 413.7133 - val_loss: 437.6842 - val_mean_absolute_error: 437.6842\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 344.82021\n",
      "Epoch 167/500\n",
      "585/585 [==============================] - 0s 126us/step - loss: 414.3093 - mean_absolute_error: 414.3093 - val_loss: 472.9326 - val_mean_absolute_error: 472.9326\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 344.82021\n",
      "Epoch 168/500\n",
      "585/585 [==============================] - 0s 123us/step - loss: 419.1129 - mean_absolute_error: 419.1129 - val_loss: 452.6751 - val_mean_absolute_error: 452.6751\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 344.82021\n",
      "Epoch 169/500\n",
      "585/585 [==============================] - 0s 119us/step - loss: 412.8614 - mean_absolute_error: 412.8614 - val_loss: 421.7805 - val_mean_absolute_error: 421.7805\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 344.82021\n",
      "Epoch 170/500\n",
      "585/585 [==============================] - 0s 114us/step - loss: 414.6330 - mean_absolute_error: 414.6330 - val_loss: 454.1519 - val_mean_absolute_error: 454.1519\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 344.82021\n",
      "Epoch 171/500\n",
      "585/585 [==============================] - 0s 111us/step - loss: 432.6228 - mean_absolute_error: 432.6228 - val_loss: 461.0779 - val_mean_absolute_error: 461.0779\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 344.82021\n",
      "Epoch 172/500\n",
      "585/585 [==============================] - 0s 123us/step - loss: 414.7708 - mean_absolute_error: 414.7708 - val_loss: 456.7715 - val_mean_absolute_error: 456.7715\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 344.82021\n",
      "Epoch 173/500\n",
      "585/585 [==============================] - 0s 123us/step - loss: 413.9192 - mean_absolute_error: 413.9192 - val_loss: 403.2852 - val_mean_absolute_error: 403.2852\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 344.82021\n",
      "Epoch 174/500\n",
      "585/585 [==============================] - 0s 119us/step - loss: 424.0842 - mean_absolute_error: 424.0842 - val_loss: 408.6735 - val_mean_absolute_error: 408.6735\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 344.82021\n",
      "Epoch 175/500\n",
      "585/585 [==============================] - 0s 123us/step - loss: 418.9325 - mean_absolute_error: 418.9325 - val_loss: 423.9994 - val_mean_absolute_error: 423.9994\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 344.82021\n",
      "Epoch 176/500\n",
      "585/585 [==============================] - 0s 118us/step - loss: 413.3657 - mean_absolute_error: 413.3657 - val_loss: 435.7097 - val_mean_absolute_error: 435.7097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00176: val_loss did not improve from 344.82021\n",
      "Epoch 177/500\n",
      "585/585 [==============================] - 0s 113us/step - loss: 416.7990 - mean_absolute_error: 416.7990 - val_loss: 442.7164 - val_mean_absolute_error: 442.7164\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 344.82021\n",
      "Epoch 178/500\n",
      "585/585 [==============================] - 0s 113us/step - loss: 409.0791 - mean_absolute_error: 409.0791 - val_loss: 470.1693 - val_mean_absolute_error: 470.1693\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 344.82021\n",
      "Epoch 179/500\n",
      "585/585 [==============================] - 0s 118us/step - loss: 416.8746 - mean_absolute_error: 416.8746 - val_loss: 428.1046 - val_mean_absolute_error: 428.1046\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 344.82021\n",
      "Epoch 180/500\n",
      "585/585 [==============================] - 0s 118us/step - loss: 411.7038 - mean_absolute_error: 411.7038 - val_loss: 433.3519 - val_mean_absolute_error: 433.3519\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 344.82021\n",
      "Epoch 181/500\n",
      "585/585 [==============================] - 0s 118us/step - loss: 411.1465 - mean_absolute_error: 411.1465 - val_loss: 497.0160 - val_mean_absolute_error: 497.0160\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 344.82021\n",
      "Epoch 182/500\n",
      "585/585 [==============================] - 0s 128us/step - loss: 413.0324 - mean_absolute_error: 413.0324 - val_loss: 436.6175 - val_mean_absolute_error: 436.6175\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 344.82021\n",
      "Epoch 183/500\n",
      "585/585 [==============================] - 0s 116us/step - loss: 410.0915 - mean_absolute_error: 410.0915 - val_loss: 448.2003 - val_mean_absolute_error: 448.2003\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 344.82021\n",
      "Epoch 184/500\n",
      "585/585 [==============================] - 0s 121us/step - loss: 406.6470 - mean_absolute_error: 406.6470 - val_loss: 436.0571 - val_mean_absolute_error: 436.0571\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 344.82021\n",
      "Epoch 185/500\n",
      "585/585 [==============================] - 0s 116us/step - loss: 415.5882 - mean_absolute_error: 415.5882 - val_loss: 423.0962 - val_mean_absolute_error: 423.0962\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 344.82021\n",
      "Epoch 186/500\n",
      "585/585 [==============================] - 0s 116us/step - loss: 418.0751 - mean_absolute_error: 418.0751 - val_loss: 409.0738 - val_mean_absolute_error: 409.0738\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 344.82021\n",
      "Epoch 187/500\n",
      "585/585 [==============================] - 0s 113us/step - loss: 405.6255 - mean_absolute_error: 405.6255 - val_loss: 494.8522 - val_mean_absolute_error: 494.8522\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 344.82021\n",
      "Epoch 188/500\n",
      "585/585 [==============================] - 0s 128us/step - loss: 409.7089 - mean_absolute_error: 409.7089 - val_loss: 460.7729 - val_mean_absolute_error: 460.7729\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 344.82021\n",
      "Epoch 189/500\n",
      "585/585 [==============================] - 0s 109us/step - loss: 414.0721 - mean_absolute_error: 414.0721 - val_loss: 469.6602 - val_mean_absolute_error: 469.6602\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 344.82021\n",
      "Epoch 190/500\n",
      "585/585 [==============================] - 0s 126us/step - loss: 413.0544 - mean_absolute_error: 413.0544 - val_loss: 475.3441 - val_mean_absolute_error: 475.3441\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 344.82021\n",
      "Epoch 191/500\n",
      "585/585 [==============================] - 0s 133us/step - loss: 419.7773 - mean_absolute_error: 419.7773 - val_loss: 459.2681 - val_mean_absolute_error: 459.2681\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 344.82021\n",
      "Epoch 192/500\n",
      "585/585 [==============================] - 0s 123us/step - loss: 424.1782 - mean_absolute_error: 424.1782 - val_loss: 432.7603 - val_mean_absolute_error: 432.7603\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 344.82021\n",
      "Epoch 193/500\n",
      "585/585 [==============================] - 0s 135us/step - loss: 412.6979 - mean_absolute_error: 412.6979 - val_loss: 433.7353 - val_mean_absolute_error: 433.7353\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 344.82021\n",
      "Epoch 194/500\n",
      "585/585 [==============================] - 0s 123us/step - loss: 411.1312 - mean_absolute_error: 411.1312 - val_loss: 431.3907 - val_mean_absolute_error: 431.3907\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 344.82021\n",
      "Epoch 195/500\n",
      "585/585 [==============================] - 0s 116us/step - loss: 407.2176 - mean_absolute_error: 407.2176 - val_loss: 433.4956 - val_mean_absolute_error: 433.4956\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 344.82021\n",
      "Epoch 196/500\n",
      "585/585 [==============================] - 0s 113us/step - loss: 404.0263 - mean_absolute_error: 404.0263 - val_loss: 450.2942 - val_mean_absolute_error: 450.2942\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 344.82021\n",
      "Epoch 197/500\n",
      "585/585 [==============================] - 0s 118us/step - loss: 410.0592 - mean_absolute_error: 410.0592 - val_loss: 453.9012 - val_mean_absolute_error: 453.9012\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 344.82021\n",
      "Epoch 198/500\n",
      "585/585 [==============================] - 0s 124us/step - loss: 405.4658 - mean_absolute_error: 405.4658 - val_loss: 437.8084 - val_mean_absolute_error: 437.8084\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 344.82021\n",
      "Epoch 199/500\n",
      "585/585 [==============================] - 0s 113us/step - loss: 405.5338 - mean_absolute_error: 405.5338 - val_loss: 445.2938 - val_mean_absolute_error: 445.2938\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 344.82021\n",
      "Epoch 200/500\n",
      "585/585 [==============================] - 0s 114us/step - loss: 402.8400 - mean_absolute_error: 402.8400 - val_loss: 439.9592 - val_mean_absolute_error: 439.9592\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 344.82021\n",
      "Epoch 201/500\n",
      "585/585 [==============================] - 0s 116us/step - loss: 406.0768 - mean_absolute_error: 406.0768 - val_loss: 492.7403 - val_mean_absolute_error: 492.7403\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 344.82021\n",
      "Epoch 202/500\n",
      "585/585 [==============================] - 0s 128us/step - loss: 405.5904 - mean_absolute_error: 405.5904 - val_loss: 429.1879 - val_mean_absolute_error: 429.1879\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 344.82021\n",
      "Epoch 203/500\n",
      "585/585 [==============================] - 0s 123us/step - loss: 407.3454 - mean_absolute_error: 407.3454 - val_loss: 481.2407 - val_mean_absolute_error: 481.2407\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 344.82021\n",
      "Epoch 204/500\n",
      "585/585 [==============================] - 0s 131us/step - loss: 421.5271 - mean_absolute_error: 421.5271 - val_loss: 422.9200 - val_mean_absolute_error: 422.9200\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 344.82021\n",
      "Epoch 205/500\n",
      "585/585 [==============================] - 0s 128us/step - loss: 413.2772 - mean_absolute_error: 413.2772 - val_loss: 445.1019 - val_mean_absolute_error: 445.1019\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 344.82021\n",
      "Epoch 206/500\n",
      "585/585 [==============================] - 0s 131us/step - loss: 398.7262 - mean_absolute_error: 398.7262 - val_loss: 427.5849 - val_mean_absolute_error: 427.5849\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 344.82021\n",
      "Epoch 207/500\n",
      "585/585 [==============================] - 0s 116us/step - loss: 403.3288 - mean_absolute_error: 403.3288 - val_loss: 445.8797 - val_mean_absolute_error: 445.8797\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 344.82021\n",
      "Epoch 208/500\n",
      "585/585 [==============================] - 0s 136us/step - loss: 401.9527 - mean_absolute_error: 401.9527 - val_loss: 451.7196 - val_mean_absolute_error: 451.7196\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 344.82021\n",
      "Epoch 209/500\n",
      "585/585 [==============================] - 0s 116us/step - loss: 400.5986 - mean_absolute_error: 400.5986 - val_loss: 497.9042 - val_mean_absolute_error: 497.9042\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 344.82021\n",
      "Epoch 210/500\n",
      "585/585 [==============================] - 0s 131us/step - loss: 401.0270 - mean_absolute_error: 401.0270 - val_loss: 479.9403 - val_mean_absolute_error: 479.9403\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 344.82021\n",
      "Epoch 211/500\n",
      "585/585 [==============================] - 0s 123us/step - loss: 404.4896 - mean_absolute_error: 404.4896 - val_loss: 457.4426 - val_mean_absolute_error: 457.4426\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 344.82021\n",
      "Epoch 212/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "585/585 [==============================] - 0s 123us/step - loss: 404.7240 - mean_absolute_error: 404.7240 - val_loss: 434.1830 - val_mean_absolute_error: 434.1830\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 344.82021\n",
      "Epoch 213/500\n",
      "585/585 [==============================] - 0s 124us/step - loss: 413.5151 - mean_absolute_error: 413.5151 - val_loss: 447.1134 - val_mean_absolute_error: 447.1134\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 344.82021\n",
      "Epoch 214/500\n",
      "585/585 [==============================] - 0s 138us/step - loss: 411.1302 - mean_absolute_error: 411.1302 - val_loss: 452.0747 - val_mean_absolute_error: 452.0747\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 344.82021\n",
      "Epoch 215/500\n",
      "585/585 [==============================] - 0s 140us/step - loss: 398.0179 - mean_absolute_error: 398.0179 - val_loss: 451.4684 - val_mean_absolute_error: 451.4684\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 344.82021\n",
      "Epoch 216/500\n",
      "585/585 [==============================] - 0s 128us/step - loss: 402.4241 - mean_absolute_error: 402.4241 - val_loss: 451.8813 - val_mean_absolute_error: 451.8813\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 344.82021\n",
      "Epoch 217/500\n",
      "585/585 [==============================] - 0s 128us/step - loss: 399.4858 - mean_absolute_error: 399.4858 - val_loss: 443.4896 - val_mean_absolute_error: 443.4896\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 344.82021\n",
      "Epoch 218/500\n",
      "585/585 [==============================] - 0s 121us/step - loss: 408.5696 - mean_absolute_error: 408.5696 - val_loss: 469.2327 - val_mean_absolute_error: 469.2327\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 344.82021\n",
      "Epoch 219/500\n",
      "585/585 [==============================] - 0s 143us/step - loss: 409.9258 - mean_absolute_error: 409.9258 - val_loss: 426.2067 - val_mean_absolute_error: 426.2067\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 344.82021\n",
      "Epoch 220/500\n",
      "585/585 [==============================] - 0s 140us/step - loss: 408.7803 - mean_absolute_error: 408.7803 - val_loss: 468.8023 - val_mean_absolute_error: 468.8023\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 344.82021\n",
      "Epoch 221/500\n",
      "585/585 [==============================] - 0s 145us/step - loss: 399.9444 - mean_absolute_error: 399.9444 - val_loss: 456.3020 - val_mean_absolute_error: 456.3020\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 344.82021\n",
      "Epoch 222/500\n",
      "585/585 [==============================] - 0s 140us/step - loss: 397.0234 - mean_absolute_error: 397.0234 - val_loss: 464.8797 - val_mean_absolute_error: 464.8797\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 344.82021\n",
      "Epoch 223/500\n",
      "585/585 [==============================] - 0s 133us/step - loss: 395.1952 - mean_absolute_error: 395.1952 - val_loss: 441.6534 - val_mean_absolute_error: 441.6534\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 344.82021\n",
      "Epoch 224/500\n",
      "585/585 [==============================] - 0s 133us/step - loss: 409.6398 - mean_absolute_error: 409.6398 - val_loss: 441.6564 - val_mean_absolute_error: 441.6564\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 344.82021\n",
      "Epoch 225/500\n",
      "585/585 [==============================] - 0s 131us/step - loss: 406.8844 - mean_absolute_error: 406.8844 - val_loss: 454.5629 - val_mean_absolute_error: 454.5629\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 344.82021\n",
      "Epoch 226/500\n",
      "585/585 [==============================] - 0s 140us/step - loss: 397.2957 - mean_absolute_error: 397.2957 - val_loss: 461.1999 - val_mean_absolute_error: 461.1999\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 344.82021\n",
      "Epoch 227/500\n",
      "585/585 [==============================] - 0s 133us/step - loss: 398.4324 - mean_absolute_error: 398.4324 - val_loss: 482.5648 - val_mean_absolute_error: 482.5648\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 344.82021\n",
      "Epoch 228/500\n",
      "585/585 [==============================] - 0s 133us/step - loss: 398.3064 - mean_absolute_error: 398.3064 - val_loss: 468.3709 - val_mean_absolute_error: 468.3709\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 344.82021\n",
      "Epoch 229/500\n",
      "585/585 [==============================] - 0s 142us/step - loss: 394.8709 - mean_absolute_error: 394.8709 - val_loss: 462.3442 - val_mean_absolute_error: 462.3442\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 344.82021\n",
      "Epoch 230/500\n",
      "585/585 [==============================] - 0s 130us/step - loss: 396.6184 - mean_absolute_error: 396.6184 - val_loss: 469.2052 - val_mean_absolute_error: 469.2052\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 344.82021\n",
      "Epoch 231/500\n",
      "585/585 [==============================] - 0s 128us/step - loss: 397.3856 - mean_absolute_error: 397.3856 - val_loss: 439.4259 - val_mean_absolute_error: 439.4259\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 344.82021\n",
      "Epoch 232/500\n",
      "585/585 [==============================] - 0s 130us/step - loss: 422.1903 - mean_absolute_error: 422.1903 - val_loss: 504.1753 - val_mean_absolute_error: 504.1753\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 344.82021\n",
      "Epoch 233/500\n",
      "585/585 [==============================] - 0s 128us/step - loss: 436.5464 - mean_absolute_error: 436.5464 - val_loss: 450.5656 - val_mean_absolute_error: 450.5656\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 344.82021\n",
      "Epoch 234/500\n",
      "585/585 [==============================] - 0s 124us/step - loss: 411.0742 - mean_absolute_error: 411.0742 - val_loss: 447.8134 - val_mean_absolute_error: 447.8134\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 344.82021\n",
      "Epoch 235/500\n",
      "585/585 [==============================] - 0s 133us/step - loss: 409.3016 - mean_absolute_error: 409.3016 - val_loss: 428.8651 - val_mean_absolute_error: 428.8651\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 344.82021\n",
      "Epoch 236/500\n",
      "585/585 [==============================] - 0s 136us/step - loss: 401.4387 - mean_absolute_error: 401.4387 - val_loss: 433.5716 - val_mean_absolute_error: 433.5716\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 344.82021\n",
      "Epoch 237/500\n",
      "585/585 [==============================] - 0s 135us/step - loss: 400.8382 - mean_absolute_error: 400.8382 - val_loss: 442.3171 - val_mean_absolute_error: 442.3171\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 344.82021\n",
      "Epoch 238/500\n",
      "585/585 [==============================] - 0s 136us/step - loss: 393.2628 - mean_absolute_error: 393.2628 - val_loss: 472.8633 - val_mean_absolute_error: 472.8633\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 344.82021\n",
      "Epoch 239/500\n",
      "585/585 [==============================] - 0s 135us/step - loss: 397.8563 - mean_absolute_error: 397.8563 - val_loss: 471.4461 - val_mean_absolute_error: 471.4461\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 344.82021\n",
      "Epoch 240/500\n",
      "585/585 [==============================] - 0s 138us/step - loss: 400.1846 - mean_absolute_error: 400.1846 - val_loss: 434.2744 - val_mean_absolute_error: 434.2744\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 344.82021\n",
      "Epoch 241/500\n",
      "585/585 [==============================] - 0s 126us/step - loss: 402.6184 - mean_absolute_error: 402.6184 - val_loss: 464.3407 - val_mean_absolute_error: 464.3407\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 344.82021\n",
      "Epoch 242/500\n",
      "585/585 [==============================] - 0s 135us/step - loss: 391.8486 - mean_absolute_error: 391.8486 - val_loss: 446.5738 - val_mean_absolute_error: 446.5738\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 344.82021\n",
      "Epoch 243/500\n",
      "585/585 [==============================] - 0s 131us/step - loss: 400.8523 - mean_absolute_error: 400.8523 - val_loss: 485.4077 - val_mean_absolute_error: 485.4077\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 344.82021\n",
      "Epoch 244/500\n",
      "585/585 [==============================] - 0s 116us/step - loss: 408.3586 - mean_absolute_error: 408.3586 - val_loss: 450.0972 - val_mean_absolute_error: 450.0972\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 344.82021\n",
      "Epoch 245/500\n",
      "585/585 [==============================] - 0s 121us/step - loss: 395.2076 - mean_absolute_error: 395.2076 - val_loss: 455.3697 - val_mean_absolute_error: 455.3697\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 344.82021\n",
      "Epoch 246/500\n",
      "585/585 [==============================] - 0s 133us/step - loss: 395.9420 - mean_absolute_error: 395.9420 - val_loss: 491.1549 - val_mean_absolute_error: 491.1549\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 344.82021\n",
      "Epoch 247/500\n",
      "585/585 [==============================] - 0s 121us/step - loss: 412.9690 - mean_absolute_error: 412.9690 - val_loss: 445.9913 - val_mean_absolute_error: 445.9913\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00247: val_loss did not improve from 344.82021\n",
      "Epoch 248/500\n",
      "585/585 [==============================] - 0s 142us/step - loss: 410.5234 - mean_absolute_error: 410.5234 - val_loss: 433.4661 - val_mean_absolute_error: 433.4661\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 344.82021\n",
      "Epoch 249/500\n",
      "585/585 [==============================] - 0s 147us/step - loss: 397.8347 - mean_absolute_error: 397.8347 - val_loss: 467.0217 - val_mean_absolute_error: 467.0217\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 344.82021\n",
      "Epoch 250/500\n",
      "585/585 [==============================] - 0s 136us/step - loss: 401.6409 - mean_absolute_error: 401.6409 - val_loss: 502.3575 - val_mean_absolute_error: 502.3575\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 344.82021\n",
      "Epoch 251/500\n",
      "585/585 [==============================] - 0s 131us/step - loss: 399.7545 - mean_absolute_error: 399.7545 - val_loss: 433.6940 - val_mean_absolute_error: 433.6940\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 344.82021\n",
      "Epoch 252/500\n",
      "585/585 [==============================] - 0s 131us/step - loss: 406.6289 - mean_absolute_error: 406.6289 - val_loss: 439.4693 - val_mean_absolute_error: 439.4693\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 344.82021\n",
      "Epoch 253/500\n",
      "585/585 [==============================] - 0s 135us/step - loss: 402.5407 - mean_absolute_error: 402.5407 - val_loss: 519.0501 - val_mean_absolute_error: 519.0501\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 344.82021\n",
      "Epoch 254/500\n",
      "585/585 [==============================] - 0s 126us/step - loss: 404.3086 - mean_absolute_error: 404.3086 - val_loss: 482.8973 - val_mean_absolute_error: 482.8973\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 344.82021\n",
      "Epoch 255/500\n",
      "585/585 [==============================] - 0s 130us/step - loss: 393.0599 - mean_absolute_error: 393.0599 - val_loss: 438.4388 - val_mean_absolute_error: 438.4388\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 344.82021\n",
      "Epoch 256/500\n",
      "585/585 [==============================] - 0s 126us/step - loss: 391.4633 - mean_absolute_error: 391.4633 - val_loss: 460.1899 - val_mean_absolute_error: 460.1899\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 344.82021\n",
      "Epoch 257/500\n",
      "585/585 [==============================] - 0s 148us/step - loss: 394.2237 - mean_absolute_error: 394.2237 - val_loss: 455.4826 - val_mean_absolute_error: 455.4826\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 344.82021\n",
      "Epoch 258/500\n",
      "585/585 [==============================] - 0s 136us/step - loss: 392.6211 - mean_absolute_error: 392.6211 - val_loss: 440.4399 - val_mean_absolute_error: 440.4399\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 344.82021\n",
      "Epoch 259/500\n",
      "585/585 [==============================] - 0s 138us/step - loss: 397.2697 - mean_absolute_error: 397.2697 - val_loss: 454.0077 - val_mean_absolute_error: 454.0077\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 344.82021\n",
      "Epoch 260/500\n",
      "585/585 [==============================] - 0s 143us/step - loss: 397.1830 - mean_absolute_error: 397.1830 - val_loss: 475.7291 - val_mean_absolute_error: 475.7291\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 344.82021\n",
      "Epoch 261/500\n",
      "585/585 [==============================] - 0s 121us/step - loss: 397.6187 - mean_absolute_error: 397.6187 - val_loss: 452.7552 - val_mean_absolute_error: 452.7552\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 344.82021\n",
      "Epoch 262/500\n",
      "585/585 [==============================] - 0s 140us/step - loss: 393.1877 - mean_absolute_error: 393.1877 - val_loss: 477.3806 - val_mean_absolute_error: 477.3806\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 344.82021\n",
      "Epoch 263/500\n",
      "585/585 [==============================] - 0s 140us/step - loss: 407.2728 - mean_absolute_error: 407.2728 - val_loss: 443.5083 - val_mean_absolute_error: 443.5083\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 344.82021\n",
      "Epoch 264/500\n",
      "585/585 [==============================] - 0s 138us/step - loss: 394.6915 - mean_absolute_error: 394.6915 - val_loss: 488.9821 - val_mean_absolute_error: 488.9821\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 344.82021\n",
      "Epoch 265/500\n",
      "585/585 [==============================] - 0s 130us/step - loss: 397.5635 - mean_absolute_error: 397.5635 - val_loss: 469.1682 - val_mean_absolute_error: 469.1682\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 344.82021\n",
      "Epoch 266/500\n",
      "585/585 [==============================] - 0s 142us/step - loss: 397.1233 - mean_absolute_error: 397.1233 - val_loss: 455.6143 - val_mean_absolute_error: 455.6143\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 344.82021\n",
      "Epoch 267/500\n",
      "585/585 [==============================] - 0s 133us/step - loss: 401.2423 - mean_absolute_error: 401.2423 - val_loss: 446.7653 - val_mean_absolute_error: 446.7653\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 344.82021\n",
      "Epoch 268/500\n",
      "585/585 [==============================] - 0s 131us/step - loss: 392.4393 - mean_absolute_error: 392.4393 - val_loss: 466.3943 - val_mean_absolute_error: 466.3943\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 344.82021\n",
      "Epoch 269/500\n",
      "585/585 [==============================] - 0s 138us/step - loss: 385.1211 - mean_absolute_error: 385.1211 - val_loss: 452.9677 - val_mean_absolute_error: 452.9677\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 344.82021\n",
      "Epoch 270/500\n",
      "585/585 [==============================] - 0s 128us/step - loss: 384.6350 - mean_absolute_error: 384.6350 - val_loss: 499.2671 - val_mean_absolute_error: 499.2671\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 344.82021\n",
      "Epoch 271/500\n",
      "585/585 [==============================] - 0s 138us/step - loss: 409.2447 - mean_absolute_error: 409.2447 - val_loss: 464.0009 - val_mean_absolute_error: 464.0009\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 344.82021\n",
      "Epoch 272/500\n",
      "585/585 [==============================] - 0s 133us/step - loss: 418.5824 - mean_absolute_error: 418.5824 - val_loss: 436.6544 - val_mean_absolute_error: 436.6544\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 344.82021\n",
      "Epoch 273/500\n",
      "585/585 [==============================] - 0s 119us/step - loss: 397.0862 - mean_absolute_error: 397.0862 - val_loss: 433.5938 - val_mean_absolute_error: 433.5938\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 344.82021\n",
      "Epoch 274/500\n",
      "585/585 [==============================] - 0s 126us/step - loss: 385.2943 - mean_absolute_error: 385.2943 - val_loss: 496.8854 - val_mean_absolute_error: 496.8854\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 344.82021\n",
      "Epoch 275/500\n",
      "585/585 [==============================] - 0s 150us/step - loss: 400.2343 - mean_absolute_error: 400.2343 - val_loss: 490.3111 - val_mean_absolute_error: 490.3111\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 344.82021\n",
      "Epoch 276/500\n",
      "585/585 [==============================] - 0s 130us/step - loss: 391.2338 - mean_absolute_error: 391.2338 - val_loss: 447.6176 - val_mean_absolute_error: 447.6176\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 344.82021\n",
      "Epoch 277/500\n",
      "585/585 [==============================] - 0s 130us/step - loss: 389.9481 - mean_absolute_error: 389.9481 - val_loss: 423.4920 - val_mean_absolute_error: 423.4920\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 344.82021\n",
      "Epoch 278/500\n",
      "585/585 [==============================] - 0s 123us/step - loss: 417.8374 - mean_absolute_error: 417.8374 - val_loss: 445.3958 - val_mean_absolute_error: 445.3958\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 344.82021\n",
      "Epoch 279/500\n",
      "585/585 [==============================] - 0s 128us/step - loss: 387.0637 - mean_absolute_error: 387.0637 - val_loss: 464.4023 - val_mean_absolute_error: 464.4023\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 344.82021\n",
      "Epoch 280/500\n",
      "585/585 [==============================] - 0s 126us/step - loss: 394.4889 - mean_absolute_error: 394.4889 - val_loss: 438.5323 - val_mean_absolute_error: 438.5323\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 344.82021\n",
      "Epoch 281/500\n",
      "585/585 [==============================] - 0s 121us/step - loss: 391.2872 - mean_absolute_error: 391.2872 - val_loss: 442.8601 - val_mean_absolute_error: 442.8601\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 344.82021\n",
      "Epoch 282/500\n",
      "585/585 [==============================] - 0s 119us/step - loss: 412.1213 - mean_absolute_error: 412.1213 - val_loss: 476.8125 - val_mean_absolute_error: 476.8125\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 344.82021\n",
      "Epoch 283/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "585/585 [==============================] - 0s 128us/step - loss: 415.9088 - mean_absolute_error: 415.9088 - val_loss: 457.0174 - val_mean_absolute_error: 457.0174\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 344.82021\n",
      "Epoch 284/500\n",
      "585/585 [==============================] - 0s 123us/step - loss: 387.9388 - mean_absolute_error: 387.9388 - val_loss: 431.9342 - val_mean_absolute_error: 431.9342\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 344.82021\n",
      "Epoch 285/500\n",
      "585/585 [==============================] - 0s 118us/step - loss: 387.9056 - mean_absolute_error: 387.9056 - val_loss: 425.7830 - val_mean_absolute_error: 425.7830\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 344.82021\n",
      "Epoch 286/500\n",
      "585/585 [==============================] - 0s 121us/step - loss: 392.1406 - mean_absolute_error: 392.1406 - val_loss: 476.7167 - val_mean_absolute_error: 476.7167\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 344.82021\n",
      "Epoch 287/500\n",
      "585/585 [==============================] - 0s 131us/step - loss: 411.6198 - mean_absolute_error: 411.6198 - val_loss: 499.5010 - val_mean_absolute_error: 499.5010\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 344.82021\n",
      "Epoch 288/500\n",
      "585/585 [==============================] - 0s 152us/step - loss: 394.7170 - mean_absolute_error: 394.7170 - val_loss: 455.8140 - val_mean_absolute_error: 455.8140\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 344.82021\n",
      "Epoch 289/500\n",
      "585/585 [==============================] - 0s 150us/step - loss: 388.7706 - mean_absolute_error: 388.7706 - val_loss: 436.1389 - val_mean_absolute_error: 436.1389\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 344.82021\n",
      "Epoch 290/500\n",
      "585/585 [==============================] - 0s 147us/step - loss: 389.1189 - mean_absolute_error: 389.1189 - val_loss: 474.5117 - val_mean_absolute_error: 474.5117\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 344.82021\n",
      "Epoch 291/500\n",
      "585/585 [==============================] - 0s 149us/step - loss: 385.4445 - mean_absolute_error: 385.4445 - val_loss: 471.2802 - val_mean_absolute_error: 471.2802\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 344.82021\n",
      "Epoch 292/500\n",
      "585/585 [==============================] - 0s 150us/step - loss: 390.7132 - mean_absolute_error: 390.7132 - val_loss: 475.9482 - val_mean_absolute_error: 475.9482\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 344.82021\n",
      "Epoch 293/500\n",
      "585/585 [==============================] - 0s 143us/step - loss: 388.1607 - mean_absolute_error: 388.1607 - val_loss: 442.6207 - val_mean_absolute_error: 442.6207\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 344.82021\n",
      "Epoch 294/500\n",
      "585/585 [==============================] - 0s 147us/step - loss: 387.0280 - mean_absolute_error: 387.0280 - val_loss: 463.5518 - val_mean_absolute_error: 463.5518\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 344.82021\n",
      "Epoch 295/500\n",
      "585/585 [==============================] - 0s 128us/step - loss: 393.8544 - mean_absolute_error: 393.8544 - val_loss: 464.4372 - val_mean_absolute_error: 464.4372\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 344.82021\n",
      "Epoch 296/500\n",
      "585/585 [==============================] - 0s 126us/step - loss: 379.6607 - mean_absolute_error: 379.6607 - val_loss: 426.8768 - val_mean_absolute_error: 426.8768\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 344.82021\n",
      "Epoch 297/500\n",
      "585/585 [==============================] - 0s 136us/step - loss: 397.9326 - mean_absolute_error: 397.9326 - val_loss: 447.9518 - val_mean_absolute_error: 447.9518\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 344.82021\n",
      "Epoch 298/500\n",
      "585/585 [==============================] - 0s 135us/step - loss: 400.7672 - mean_absolute_error: 400.7672 - val_loss: 456.9066 - val_mean_absolute_error: 456.9066\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 344.82021\n",
      "Epoch 299/500\n",
      "585/585 [==============================] - 0s 126us/step - loss: 387.5712 - mean_absolute_error: 387.5712 - val_loss: 468.4394 - val_mean_absolute_error: 468.4394\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 344.82021\n",
      "Epoch 300/500\n",
      "585/585 [==============================] - 0s 136us/step - loss: 386.5649 - mean_absolute_error: 386.5649 - val_loss: 479.3815 - val_mean_absolute_error: 479.3815\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 344.82021\n",
      "Epoch 301/500\n",
      "585/585 [==============================] - 0s 159us/step - loss: 390.1136 - mean_absolute_error: 390.1136 - val_loss: 449.3970 - val_mean_absolute_error: 449.3970\n",
      "\n",
      "Epoch 00301: val_loss did not improve from 344.82021\n",
      "Epoch 302/500\n",
      "585/585 [==============================] - 0s 155us/step - loss: 410.1236 - mean_absolute_error: 410.1236 - val_loss: 460.6423 - val_mean_absolute_error: 460.6423\n",
      "\n",
      "Epoch 00302: val_loss did not improve from 344.82021\n",
      "Epoch 303/500\n",
      "585/585 [==============================] - 0s 153us/step - loss: 399.1096 - mean_absolute_error: 399.1096 - val_loss: 483.0887 - val_mean_absolute_error: 483.0887\n",
      "\n",
      "Epoch 00303: val_loss did not improve from 344.82021\n",
      "Epoch 304/500\n",
      "585/585 [==============================] - 0s 147us/step - loss: 399.2690 - mean_absolute_error: 399.2690 - val_loss: 505.1627 - val_mean_absolute_error: 505.1627\n",
      "\n",
      "Epoch 00304: val_loss did not improve from 344.82021\n",
      "Epoch 305/500\n",
      "585/585 [==============================] - 0s 147us/step - loss: 390.9372 - mean_absolute_error: 390.9372 - val_loss: 474.4214 - val_mean_absolute_error: 474.4214\n",
      "\n",
      "Epoch 00305: val_loss did not improve from 344.82021\n",
      "Epoch 306/500\n",
      "585/585 [==============================] - 0s 138us/step - loss: 395.8920 - mean_absolute_error: 395.8920 - val_loss: 431.3574 - val_mean_absolute_error: 431.3574\n",
      "\n",
      "Epoch 00306: val_loss did not improve from 344.82021\n",
      "Epoch 307/500\n",
      "585/585 [==============================] - 0s 142us/step - loss: 400.1838 - mean_absolute_error: 400.1838 - val_loss: 468.4008 - val_mean_absolute_error: 468.4008\n",
      "\n",
      "Epoch 00307: val_loss did not improve from 344.82021\n",
      "Epoch 308/500\n",
      "585/585 [==============================] - 0s 128us/step - loss: 386.3076 - mean_absolute_error: 386.3076 - val_loss: 505.2032 - val_mean_absolute_error: 505.2032\n",
      "\n",
      "Epoch 00308: val_loss did not improve from 344.82021\n",
      "Epoch 309/500\n",
      "585/585 [==============================] - 0s 148us/step - loss: 393.6769 - mean_absolute_error: 393.6769 - val_loss: 437.8296 - val_mean_absolute_error: 437.8296\n",
      "\n",
      "Epoch 00309: val_loss did not improve from 344.82021\n",
      "Epoch 310/500\n",
      "585/585 [==============================] - 0s 124us/step - loss: 378.9200 - mean_absolute_error: 378.9200 - val_loss: 424.3381 - val_mean_absolute_error: 424.3381\n",
      "\n",
      "Epoch 00310: val_loss did not improve from 344.82021\n",
      "Epoch 311/500\n",
      "585/585 [==============================] - 0s 123us/step - loss: 397.0543 - mean_absolute_error: 397.0543 - val_loss: 483.4544 - val_mean_absolute_error: 483.4544\n",
      "\n",
      "Epoch 00311: val_loss did not improve from 344.82021\n",
      "Epoch 312/500\n",
      "585/585 [==============================] - 0s 128us/step - loss: 398.0510 - mean_absolute_error: 398.0510 - val_loss: 485.2487 - val_mean_absolute_error: 485.2487\n",
      "\n",
      "Epoch 00312: val_loss did not improve from 344.82021\n",
      "Epoch 313/500\n",
      "585/585 [==============================] - 0s 128us/step - loss: 403.5882 - mean_absolute_error: 403.5882 - val_loss: 479.8046 - val_mean_absolute_error: 479.8046\n",
      "\n",
      "Epoch 00313: val_loss did not improve from 344.82021\n",
      "Epoch 314/500\n",
      "585/585 [==============================] - 0s 133us/step - loss: 376.1164 - mean_absolute_error: 376.1164 - val_loss: 434.9040 - val_mean_absolute_error: 434.9040\n",
      "\n",
      "Epoch 00314: val_loss did not improve from 344.82021\n",
      "Epoch 315/500\n",
      "585/585 [==============================] - 0s 130us/step - loss: 393.8965 - mean_absolute_error: 393.8965 - val_loss: 463.8093 - val_mean_absolute_error: 463.8093\n",
      "\n",
      "Epoch 00315: val_loss did not improve from 344.82021\n",
      "Epoch 316/500\n",
      "585/585 [==============================] - 0s 133us/step - loss: 380.0593 - mean_absolute_error: 380.0593 - val_loss: 438.6907 - val_mean_absolute_error: 438.6907\n",
      "\n",
      "Epoch 00316: val_loss did not improve from 344.82021\n",
      "Epoch 317/500\n",
      "585/585 [==============================] - 0s 142us/step - loss: 387.0475 - mean_absolute_error: 387.0475 - val_loss: 454.6738 - val_mean_absolute_error: 454.6738\n",
      "\n",
      "Epoch 00317: val_loss did not improve from 344.82021\n",
      "Epoch 318/500\n",
      "585/585 [==============================] - 0s 153us/step - loss: 387.0084 - mean_absolute_error: 387.0084 - val_loss: 481.9123 - val_mean_absolute_error: 481.9123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00318: val_loss did not improve from 344.82021\n",
      "Epoch 319/500\n",
      "585/585 [==============================] - 0s 138us/step - loss: 389.8587 - mean_absolute_error: 389.8587 - val_loss: 475.9194 - val_mean_absolute_error: 475.9194\n",
      "\n",
      "Epoch 00319: val_loss did not improve from 344.82021\n",
      "Epoch 320/500\n",
      "585/585 [==============================] - 0s 133us/step - loss: 386.0461 - mean_absolute_error: 386.0461 - val_loss: 453.6157 - val_mean_absolute_error: 453.6157\n",
      "\n",
      "Epoch 00320: val_loss did not improve from 344.82021\n",
      "Epoch 321/500\n",
      "585/585 [==============================] - 0s 153us/step - loss: 395.1284 - mean_absolute_error: 395.1284 - val_loss: 443.9415 - val_mean_absolute_error: 443.9415\n",
      "\n",
      "Epoch 00321: val_loss did not improve from 344.82021\n",
      "Epoch 322/500\n",
      "585/585 [==============================] - 0s 140us/step - loss: 382.1609 - mean_absolute_error: 382.1609 - val_loss: 468.0272 - val_mean_absolute_error: 468.0272\n",
      "\n",
      "Epoch 00322: val_loss did not improve from 344.82021\n",
      "Epoch 323/500\n",
      "585/585 [==============================] - 0s 152us/step - loss: 380.7566 - mean_absolute_error: 380.7566 - val_loss: 435.1498 - val_mean_absolute_error: 435.1498\n",
      "\n",
      "Epoch 00323: val_loss did not improve from 344.82021\n",
      "Epoch 324/500\n",
      "585/585 [==============================] - 0s 148us/step - loss: 380.5000 - mean_absolute_error: 380.5000 - val_loss: 467.1323 - val_mean_absolute_error: 467.1323\n",
      "\n",
      "Epoch 00324: val_loss did not improve from 344.82021\n",
      "Epoch 325/500\n",
      "585/585 [==============================] - 0s 155us/step - loss: 384.9666 - mean_absolute_error: 384.9666 - val_loss: 482.1950 - val_mean_absolute_error: 482.1950\n",
      "\n",
      "Epoch 00325: val_loss did not improve from 344.82021\n",
      "Epoch 326/500\n",
      "585/585 [==============================] - 0s 157us/step - loss: 380.7729 - mean_absolute_error: 380.7729 - val_loss: 459.0465 - val_mean_absolute_error: 459.0465\n",
      "\n",
      "Epoch 00326: val_loss did not improve from 344.82021\n",
      "Epoch 327/500\n",
      "585/585 [==============================] - 0s 615us/step - loss: 374.7936 - mean_absolute_error: 374.7936 - val_loss: 444.0622 - val_mean_absolute_error: 444.0622\n",
      "\n",
      "Epoch 00327: val_loss did not improve from 344.82021\n",
      "Epoch 328/500\n",
      "585/585 [==============================] - 0s 189us/step - loss: 381.7926 - mean_absolute_error: 381.7926 - val_loss: 482.1112 - val_mean_absolute_error: 482.1112\n",
      "\n",
      "Epoch 00328: val_loss did not improve from 344.82021\n",
      "Epoch 329/500\n",
      "585/585 [==============================] - 0s 155us/step - loss: 382.6694 - mean_absolute_error: 382.6694 - val_loss: 450.8466 - val_mean_absolute_error: 450.8466\n",
      "\n",
      "Epoch 00329: val_loss did not improve from 344.82021\n",
      "Epoch 330/500\n",
      "585/585 [==============================] - 0s 152us/step - loss: 385.5649 - mean_absolute_error: 385.5649 - val_loss: 470.3214 - val_mean_absolute_error: 470.3214\n",
      "\n",
      "Epoch 00330: val_loss did not improve from 344.82021\n",
      "Epoch 331/500\n",
      "585/585 [==============================] - 0s 150us/step - loss: 375.9990 - mean_absolute_error: 375.9990 - val_loss: 487.8078 - val_mean_absolute_error: 487.8078\n",
      "\n",
      "Epoch 00331: val_loss did not improve from 344.82021\n",
      "Epoch 332/500\n",
      "585/585 [==============================] - 0s 172us/step - loss: 379.3341 - mean_absolute_error: 379.3341 - val_loss: 515.7738 - val_mean_absolute_error: 515.7738\n",
      "\n",
      "Epoch 00332: val_loss did not improve from 344.82021\n",
      "Epoch 333/500\n",
      "585/585 [==============================] - 0s 143us/step - loss: 404.5065 - mean_absolute_error: 404.5065 - val_loss: 425.9892 - val_mean_absolute_error: 425.9892\n",
      "\n",
      "Epoch 00333: val_loss did not improve from 344.82021\n",
      "Epoch 334/500\n",
      "585/585 [==============================] - 0s 160us/step - loss: 395.1809 - mean_absolute_error: 395.1809 - val_loss: 433.8998 - val_mean_absolute_error: 433.8998\n",
      "\n",
      "Epoch 00334: val_loss did not improve from 344.82021\n",
      "Epoch 335/500\n",
      "585/585 [==============================] - 0s 145us/step - loss: 380.0894 - mean_absolute_error: 380.0894 - val_loss: 469.5362 - val_mean_absolute_error: 469.5362\n",
      "\n",
      "Epoch 00335: val_loss did not improve from 344.82021\n",
      "Epoch 336/500\n",
      "585/585 [==============================] - 0s 140us/step - loss: 369.7103 - mean_absolute_error: 369.7103 - val_loss: 449.0527 - val_mean_absolute_error: 449.0527\n",
      "\n",
      "Epoch 00336: val_loss did not improve from 344.82021\n",
      "Epoch 337/500\n",
      "585/585 [==============================] - 0s 160us/step - loss: 380.9836 - mean_absolute_error: 380.9836 - val_loss: 458.3337 - val_mean_absolute_error: 458.3337\n",
      "\n",
      "Epoch 00337: val_loss did not improve from 344.82021\n",
      "Epoch 338/500\n",
      "585/585 [==============================] - 0s 159us/step - loss: 376.4148 - mean_absolute_error: 376.4148 - val_loss: 418.3274 - val_mean_absolute_error: 418.3274\n",
      "\n",
      "Epoch 00338: val_loss did not improve from 344.82021\n",
      "Epoch 339/500\n",
      "585/585 [==============================] - 0s 143us/step - loss: 383.4090 - mean_absolute_error: 383.4090 - val_loss: 444.2309 - val_mean_absolute_error: 444.2309\n",
      "\n",
      "Epoch 00339: val_loss did not improve from 344.82021\n",
      "Epoch 340/500\n",
      "585/585 [==============================] - 0s 133us/step - loss: 378.2013 - mean_absolute_error: 378.2013 - val_loss: 457.9804 - val_mean_absolute_error: 457.9804\n",
      "\n",
      "Epoch 00340: val_loss did not improve from 344.82021\n",
      "Epoch 341/500\n",
      "585/585 [==============================] - 0s 133us/step - loss: 379.3318 - mean_absolute_error: 379.3318 - val_loss: 450.0460 - val_mean_absolute_error: 450.0460\n",
      "\n",
      "Epoch 00341: val_loss did not improve from 344.82021\n",
      "Epoch 342/500\n",
      "585/585 [==============================] - 0s 128us/step - loss: 378.1577 - mean_absolute_error: 378.1577 - val_loss: 493.5201 - val_mean_absolute_error: 493.5201\n",
      "\n",
      "Epoch 00342: val_loss did not improve from 344.82021\n",
      "Epoch 343/500\n",
      "585/585 [==============================] - 0s 140us/step - loss: 373.9519 - mean_absolute_error: 373.9519 - val_loss: 461.4692 - val_mean_absolute_error: 461.4692\n",
      "\n",
      "Epoch 00343: val_loss did not improve from 344.82021\n",
      "Epoch 344/500\n",
      "585/585 [==============================] - 0s 152us/step - loss: 374.4468 - mean_absolute_error: 374.4468 - val_loss: 484.6423 - val_mean_absolute_error: 484.6423\n",
      "\n",
      "Epoch 00344: val_loss did not improve from 344.82021\n",
      "Epoch 345/500\n",
      "585/585 [==============================] - 0s 131us/step - loss: 390.5809 - mean_absolute_error: 390.5809 - val_loss: 452.9069 - val_mean_absolute_error: 452.9069\n",
      "\n",
      "Epoch 00345: val_loss did not improve from 344.82021\n",
      "Epoch 346/500\n",
      "585/585 [==============================] - 0s 181us/step - loss: 378.1006 - mean_absolute_error: 378.1006 - val_loss: 441.0513 - val_mean_absolute_error: 441.0513\n",
      "\n",
      "Epoch 00346: val_loss did not improve from 344.82021\n",
      "Epoch 347/500\n",
      "585/585 [==============================] - 0s 148us/step - loss: 373.4181 - mean_absolute_error: 373.4181 - val_loss: 445.3644 - val_mean_absolute_error: 445.3644\n",
      "\n",
      "Epoch 00347: val_loss did not improve from 344.82021\n",
      "Epoch 348/500\n",
      "585/585 [==============================] - 0s 155us/step - loss: 395.3136 - mean_absolute_error: 395.3136 - val_loss: 473.1995 - val_mean_absolute_error: 473.1995\n",
      "\n",
      "Epoch 00348: val_loss did not improve from 344.82021\n",
      "Epoch 349/500\n",
      "585/585 [==============================] - 0s 150us/step - loss: 388.3027 - mean_absolute_error: 388.3027 - val_loss: 491.2190 - val_mean_absolute_error: 491.2190\n",
      "\n",
      "Epoch 00349: val_loss did not improve from 344.82021\n",
      "Epoch 350/500\n",
      "585/585 [==============================] - 0s 164us/step - loss: 385.7541 - mean_absolute_error: 385.7541 - val_loss: 446.8262 - val_mean_absolute_error: 446.8262\n",
      "\n",
      "Epoch 00350: val_loss did not improve from 344.82021\n",
      "Epoch 351/500\n",
      "585/585 [==============================] - 0s 143us/step - loss: 370.3466 - mean_absolute_error: 370.3466 - val_loss: 470.3624 - val_mean_absolute_error: 470.3624\n",
      "\n",
      "Epoch 00351: val_loss did not improve from 344.82021\n",
      "Epoch 352/500\n",
      "585/585 [==============================] - 0s 142us/step - loss: 382.9590 - mean_absolute_error: 382.9590 - val_loss: 496.8729 - val_mean_absolute_error: 496.8729\n",
      "\n",
      "Epoch 00352: val_loss did not improve from 344.82021\n",
      "Epoch 353/500\n",
      "585/585 [==============================] - 0s 142us/step - loss: 381.1912 - mean_absolute_error: 381.1912 - val_loss: 454.3566 - val_mean_absolute_error: 454.3566\n",
      "\n",
      "Epoch 00353: val_loss did not improve from 344.82021\n",
      "Epoch 354/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "585/585 [==============================] - 0s 142us/step - loss: 378.3980 - mean_absolute_error: 378.3980 - val_loss: 457.3311 - val_mean_absolute_error: 457.3311\n",
      "\n",
      "Epoch 00354: val_loss did not improve from 344.82021\n",
      "Epoch 355/500\n",
      "585/585 [==============================] - 0s 152us/step - loss: 370.7625 - mean_absolute_error: 370.7625 - val_loss: 469.2248 - val_mean_absolute_error: 469.2248\n",
      "\n",
      "Epoch 00355: val_loss did not improve from 344.82021\n",
      "Epoch 356/500\n",
      "585/585 [==============================] - 0s 136us/step - loss: 368.4414 - mean_absolute_error: 368.4414 - val_loss: 471.1557 - val_mean_absolute_error: 471.1557\n",
      "\n",
      "Epoch 00356: val_loss did not improve from 344.82021\n",
      "Epoch 357/500\n",
      "585/585 [==============================] - 0s 148us/step - loss: 372.8635 - mean_absolute_error: 372.8635 - val_loss: 444.2415 - val_mean_absolute_error: 444.2415\n",
      "\n",
      "Epoch 00357: val_loss did not improve from 344.82021\n",
      "Epoch 358/500\n",
      "585/585 [==============================] - 0s 145us/step - loss: 366.9353 - mean_absolute_error: 366.9353 - val_loss: 439.1156 - val_mean_absolute_error: 439.1156\n",
      "\n",
      "Epoch 00358: val_loss did not improve from 344.82021\n",
      "Epoch 359/500\n",
      "585/585 [==============================] - 0s 152us/step - loss: 376.6776 - mean_absolute_error: 376.6776 - val_loss: 478.4911 - val_mean_absolute_error: 478.4911\n",
      "\n",
      "Epoch 00359: val_loss did not improve from 344.82021\n",
      "Epoch 360/500\n",
      "585/585 [==============================] - 0s 124us/step - loss: 382.4725 - mean_absolute_error: 382.4725 - val_loss: 475.6454 - val_mean_absolute_error: 475.6454\n",
      "\n",
      "Epoch 00360: val_loss did not improve from 344.82021\n",
      "Epoch 361/500\n",
      "585/585 [==============================] - 0s 140us/step - loss: 366.9425 - mean_absolute_error: 366.9425 - val_loss: 459.7290 - val_mean_absolute_error: 459.7290\n",
      "\n",
      "Epoch 00361: val_loss did not improve from 344.82021\n",
      "Epoch 362/500\n",
      "585/585 [==============================] - 0s 133us/step - loss: 365.2840 - mean_absolute_error: 365.2840 - val_loss: 440.5425 - val_mean_absolute_error: 440.5425\n",
      "\n",
      "Epoch 00362: val_loss did not improve from 344.82021\n",
      "Epoch 363/500\n",
      "585/585 [==============================] - 0s 152us/step - loss: 371.8860 - mean_absolute_error: 371.8860 - val_loss: 485.5931 - val_mean_absolute_error: 485.5931\n",
      "\n",
      "Epoch 00363: val_loss did not improve from 344.82021\n",
      "Epoch 364/500\n",
      "585/585 [==============================] - 0s 136us/step - loss: 376.4491 - mean_absolute_error: 376.4491 - val_loss: 442.8926 - val_mean_absolute_error: 442.8926\n",
      "\n",
      "Epoch 00364: val_loss did not improve from 344.82021\n",
      "Epoch 365/500\n",
      "585/585 [==============================] - 0s 148us/step - loss: 374.8509 - mean_absolute_error: 374.8509 - val_loss: 433.2759 - val_mean_absolute_error: 433.2759\n",
      "\n",
      "Epoch 00365: val_loss did not improve from 344.82021\n",
      "Epoch 366/500\n",
      "585/585 [==============================] - 0s 136us/step - loss: 375.7222 - mean_absolute_error: 375.7222 - val_loss: 438.8387 - val_mean_absolute_error: 438.8387\n",
      "\n",
      "Epoch 00366: val_loss did not improve from 344.82021\n",
      "Epoch 367/500\n",
      "585/585 [==============================] - 0s 147us/step - loss: 384.2156 - mean_absolute_error: 384.2156 - val_loss: 453.9413 - val_mean_absolute_error: 453.9413\n",
      "\n",
      "Epoch 00367: val_loss did not improve from 344.82021\n",
      "Epoch 368/500\n",
      "585/585 [==============================] - 0s 142us/step - loss: 364.4059 - mean_absolute_error: 364.4059 - val_loss: 445.2775 - val_mean_absolute_error: 445.2775\n",
      "\n",
      "Epoch 00368: val_loss did not improve from 344.82021\n",
      "Epoch 369/500\n",
      "585/585 [==============================] - 0s 153us/step - loss: 364.1293 - mean_absolute_error: 364.1293 - val_loss: 473.4243 - val_mean_absolute_error: 473.4243\n",
      "\n",
      "Epoch 00369: val_loss did not improve from 344.82021\n",
      "Epoch 370/500\n",
      "585/585 [==============================] - 0s 152us/step - loss: 369.1727 - mean_absolute_error: 369.1727 - val_loss: 450.1833 - val_mean_absolute_error: 450.1833\n",
      "\n",
      "Epoch 00370: val_loss did not improve from 344.82021\n",
      "Epoch 371/500\n",
      "585/585 [==============================] - 0s 143us/step - loss: 369.7855 - mean_absolute_error: 369.7855 - val_loss: 463.7645 - val_mean_absolute_error: 463.7645\n",
      "\n",
      "Epoch 00371: val_loss did not improve from 344.82021\n",
      "Epoch 372/500\n",
      "585/585 [==============================] - 0s 133us/step - loss: 377.3672 - mean_absolute_error: 377.3672 - val_loss: 444.8172 - val_mean_absolute_error: 444.8172\n",
      "\n",
      "Epoch 00372: val_loss did not improve from 344.82021\n",
      "Epoch 373/500\n",
      "585/585 [==============================] - 0s 138us/step - loss: 367.3782 - mean_absolute_error: 367.3782 - val_loss: 477.7749 - val_mean_absolute_error: 477.7749\n",
      "\n",
      "Epoch 00373: val_loss did not improve from 344.82021\n",
      "Epoch 374/500\n",
      "585/585 [==============================] - 0s 150us/step - loss: 368.5516 - mean_absolute_error: 368.5516 - val_loss: 521.0911 - val_mean_absolute_error: 521.0911\n",
      "\n",
      "Epoch 00374: val_loss did not improve from 344.82021\n",
      "Epoch 375/500\n",
      "585/585 [==============================] - 0s 136us/step - loss: 379.8451 - mean_absolute_error: 379.8451 - val_loss: 459.6670 - val_mean_absolute_error: 459.6670\n",
      "\n",
      "Epoch 00375: val_loss did not improve from 344.82021\n",
      "Epoch 376/500\n",
      "585/585 [==============================] - 0s 147us/step - loss: 363.5980 - mean_absolute_error: 363.5980 - val_loss: 515.6701 - val_mean_absolute_error: 515.6701\n",
      "\n",
      "Epoch 00376: val_loss did not improve from 344.82021\n",
      "Epoch 377/500\n",
      "585/585 [==============================] - 0s 131us/step - loss: 410.3903 - mean_absolute_error: 410.3903 - val_loss: 430.4036 - val_mean_absolute_error: 430.4036\n",
      "\n",
      "Epoch 00377: val_loss did not improve from 344.82021\n",
      "Epoch 378/500\n",
      "585/585 [==============================] - 0s 150us/step - loss: 363.6812 - mean_absolute_error: 363.6812 - val_loss: 449.3521 - val_mean_absolute_error: 449.3521\n",
      "\n",
      "Epoch 00378: val_loss did not improve from 344.82021\n",
      "Epoch 379/500\n",
      "585/585 [==============================] - 0s 130us/step - loss: 371.7744 - mean_absolute_error: 371.7744 - val_loss: 447.7863 - val_mean_absolute_error: 447.7863\n",
      "\n",
      "Epoch 00379: val_loss did not improve from 344.82021\n",
      "Epoch 380/500\n",
      "585/585 [==============================] - 0s 136us/step - loss: 366.1586 - mean_absolute_error: 366.1586 - val_loss: 453.5491 - val_mean_absolute_error: 453.5491\n",
      "\n",
      "Epoch 00380: val_loss did not improve from 344.82021\n",
      "Epoch 381/500\n",
      "585/585 [==============================] - 0s 124us/step - loss: 369.5193 - mean_absolute_error: 369.5193 - val_loss: 476.3323 - val_mean_absolute_error: 476.3323\n",
      "\n",
      "Epoch 00381: val_loss did not improve from 344.82021\n",
      "Epoch 382/500\n",
      "585/585 [==============================] - 0s 133us/step - loss: 363.3063 - mean_absolute_error: 363.3063 - val_loss: 458.6840 - val_mean_absolute_error: 458.6840\n",
      "\n",
      "Epoch 00382: val_loss did not improve from 344.82021\n",
      "Epoch 383/500\n",
      "585/585 [==============================] - 0s 138us/step - loss: 365.5105 - mean_absolute_error: 365.5105 - val_loss: 440.5078 - val_mean_absolute_error: 440.5078\n",
      "\n",
      "Epoch 00383: val_loss did not improve from 344.82021\n",
      "Epoch 384/500\n",
      "585/585 [==============================] - 0s 143us/step - loss: 363.9766 - mean_absolute_error: 363.9766 - val_loss: 454.3888 - val_mean_absolute_error: 454.3888\n",
      "\n",
      "Epoch 00384: val_loss did not improve from 344.82021\n",
      "Epoch 385/500\n",
      "585/585 [==============================] - 0s 135us/step - loss: 359.6758 - mean_absolute_error: 359.6758 - val_loss: 497.7986 - val_mean_absolute_error: 497.7986\n",
      "\n",
      "Epoch 00385: val_loss did not improve from 344.82021\n",
      "Epoch 386/500\n",
      "585/585 [==============================] - 0s 142us/step - loss: 369.4939 - mean_absolute_error: 369.4939 - val_loss: 478.3739 - val_mean_absolute_error: 478.3739\n",
      "\n",
      "Epoch 00386: val_loss did not improve from 344.82021\n",
      "Epoch 387/500\n",
      "585/585 [==============================] - 0s 126us/step - loss: 367.5097 - mean_absolute_error: 367.5097 - val_loss: 450.9361 - val_mean_absolute_error: 450.9361\n",
      "\n",
      "Epoch 00387: val_loss did not improve from 344.82021\n",
      "Epoch 388/500\n",
      "585/585 [==============================] - 0s 123us/step - loss: 365.7801 - mean_absolute_error: 365.7801 - val_loss: 510.5957 - val_mean_absolute_error: 510.5957\n",
      "\n",
      "Epoch 00388: val_loss did not improve from 344.82021\n",
      "Epoch 389/500\n",
      "585/585 [==============================] - 0s 133us/step - loss: 363.6056 - mean_absolute_error: 363.6056 - val_loss: 498.9040 - val_mean_absolute_error: 498.9040\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00389: val_loss did not improve from 344.82021\n",
      "Epoch 390/500\n",
      "585/585 [==============================] - 0s 126us/step - loss: 361.5194 - mean_absolute_error: 361.5194 - val_loss: 471.1891 - val_mean_absolute_error: 471.1891\n",
      "\n",
      "Epoch 00390: val_loss did not improve from 344.82021\n",
      "Epoch 391/500\n",
      "585/585 [==============================] - 0s 128us/step - loss: 361.5123 - mean_absolute_error: 361.5123 - val_loss: 448.8311 - val_mean_absolute_error: 448.8311\n",
      "\n",
      "Epoch 00391: val_loss did not improve from 344.82021\n",
      "Epoch 392/500\n",
      "585/585 [==============================] - 0s 124us/step - loss: 369.5274 - mean_absolute_error: 369.5274 - val_loss: 451.8816 - val_mean_absolute_error: 451.8816\n",
      "\n",
      "Epoch 00392: val_loss did not improve from 344.82021\n",
      "Epoch 393/500\n",
      "585/585 [==============================] - 0s 155us/step - loss: 362.2154 - mean_absolute_error: 362.2154 - val_loss: 446.8989 - val_mean_absolute_error: 446.8989\n",
      "\n",
      "Epoch 00393: val_loss did not improve from 344.82021\n",
      "Epoch 394/500\n",
      "585/585 [==============================] - 0s 136us/step - loss: 378.0724 - mean_absolute_error: 378.0724 - val_loss: 476.0401 - val_mean_absolute_error: 476.0401\n",
      "\n",
      "Epoch 00394: val_loss did not improve from 344.82021\n",
      "Epoch 395/500\n",
      "585/585 [==============================] - 0s 143us/step - loss: 373.2910 - mean_absolute_error: 373.2910 - val_loss: 492.2420 - val_mean_absolute_error: 492.2420\n",
      "\n",
      "Epoch 00395: val_loss did not improve from 344.82021\n",
      "Epoch 396/500\n",
      "585/585 [==============================] - 0s 147us/step - loss: 368.3524 - mean_absolute_error: 368.3524 - val_loss: 478.4126 - val_mean_absolute_error: 478.4126\n",
      "\n",
      "Epoch 00396: val_loss did not improve from 344.82021\n",
      "Epoch 397/500\n",
      "585/585 [==============================] - 0s 138us/step - loss: 369.7810 - mean_absolute_error: 369.7810 - val_loss: 481.5274 - val_mean_absolute_error: 481.5274\n",
      "\n",
      "Epoch 00397: val_loss did not improve from 344.82021\n",
      "Epoch 398/500\n",
      "585/585 [==============================] - 0s 142us/step - loss: 376.5143 - mean_absolute_error: 376.5143 - val_loss: 475.1621 - val_mean_absolute_error: 475.1621\n",
      "\n",
      "Epoch 00398: val_loss did not improve from 344.82021\n",
      "Epoch 399/500\n",
      "585/585 [==============================] - 0s 147us/step - loss: 358.4564 - mean_absolute_error: 358.4564 - val_loss: 474.7424 - val_mean_absolute_error: 474.7424\n",
      "\n",
      "Epoch 00399: val_loss did not improve from 344.82021\n",
      "Epoch 400/500\n",
      "585/585 [==============================] - 0s 152us/step - loss: 356.5942 - mean_absolute_error: 356.5942 - val_loss: 443.5570 - val_mean_absolute_error: 443.5570\n",
      "\n",
      "Epoch 00400: val_loss did not improve from 344.82021\n",
      "Epoch 401/500\n",
      "585/585 [==============================] - 0s 143us/step - loss: 355.6953 - mean_absolute_error: 355.6953 - val_loss: 473.4801 - val_mean_absolute_error: 473.4801\n",
      "\n",
      "Epoch 00401: val_loss did not improve from 344.82021\n",
      "Epoch 402/500\n",
      "585/585 [==============================] - 0s 143us/step - loss: 357.8465 - mean_absolute_error: 357.8465 - val_loss: 482.6519 - val_mean_absolute_error: 482.6519\n",
      "\n",
      "Epoch 00402: val_loss did not improve from 344.82021\n",
      "Epoch 403/500\n",
      "585/585 [==============================] - 0s 150us/step - loss: 360.9998 - mean_absolute_error: 360.9998 - val_loss: 453.9198 - val_mean_absolute_error: 453.9198\n",
      "\n",
      "Epoch 00403: val_loss did not improve from 344.82021\n",
      "Epoch 404/500\n",
      "585/585 [==============================] - 0s 147us/step - loss: 357.9851 - mean_absolute_error: 357.9851 - val_loss: 454.6291 - val_mean_absolute_error: 454.6291\n",
      "\n",
      "Epoch 00404: val_loss did not improve from 344.82021\n",
      "Epoch 405/500\n",
      "585/585 [==============================] - 0s 150us/step - loss: 357.5529 - mean_absolute_error: 357.5529 - val_loss: 511.0634 - val_mean_absolute_error: 511.0634\n",
      "\n",
      "Epoch 00405: val_loss did not improve from 344.82021\n",
      "Epoch 406/500\n",
      "585/585 [==============================] - 0s 155us/step - loss: 355.6155 - mean_absolute_error: 355.6155 - val_loss: 497.6811 - val_mean_absolute_error: 497.6811\n",
      "\n",
      "Epoch 00406: val_loss did not improve from 344.82021\n",
      "Epoch 407/500\n",
      "585/585 [==============================] - 0s 136us/step - loss: 356.0661 - mean_absolute_error: 356.0661 - val_loss: 466.3498 - val_mean_absolute_error: 466.3498\n",
      "\n",
      "Epoch 00407: val_loss did not improve from 344.82021\n",
      "Epoch 408/500\n",
      "585/585 [==============================] - 0s 147us/step - loss: 351.9739 - mean_absolute_error: 351.9739 - val_loss: 438.7162 - val_mean_absolute_error: 438.7162\n",
      "\n",
      "Epoch 00408: val_loss did not improve from 344.82021\n",
      "Epoch 409/500\n",
      "585/585 [==============================] - 0s 143us/step - loss: 357.6974 - mean_absolute_error: 357.6974 - val_loss: 509.2260 - val_mean_absolute_error: 509.2260\n",
      "\n",
      "Epoch 00409: val_loss did not improve from 344.82021\n",
      "Epoch 410/500\n",
      "585/585 [==============================] - 0s 142us/step - loss: 367.3722 - mean_absolute_error: 367.3722 - val_loss: 470.0467 - val_mean_absolute_error: 470.0467\n",
      "\n",
      "Epoch 00410: val_loss did not improve from 344.82021\n",
      "Epoch 411/500\n",
      "585/585 [==============================] - 0s 138us/step - loss: 361.2750 - mean_absolute_error: 361.2750 - val_loss: 468.9472 - val_mean_absolute_error: 468.9472\n",
      "\n",
      "Epoch 00411: val_loss did not improve from 344.82021\n",
      "Epoch 412/500\n",
      "585/585 [==============================] - 0s 138us/step - loss: 363.8065 - mean_absolute_error: 363.8065 - val_loss: 468.3342 - val_mean_absolute_error: 468.3342\n",
      "\n",
      "Epoch 00412: val_loss did not improve from 344.82021\n",
      "Epoch 413/500\n",
      "585/585 [==============================] - 0s 153us/step - loss: 360.8349 - mean_absolute_error: 360.8349 - val_loss: 440.6149 - val_mean_absolute_error: 440.6149\n",
      "\n",
      "Epoch 00413: val_loss did not improve from 344.82021\n",
      "Epoch 414/500\n",
      "585/585 [==============================] - 0s 150us/step - loss: 351.4784 - mean_absolute_error: 351.4784 - val_loss: 436.7308 - val_mean_absolute_error: 436.7308\n",
      "\n",
      "Epoch 00414: val_loss did not improve from 344.82021\n",
      "Epoch 415/500\n",
      "585/585 [==============================] - 0s 136us/step - loss: 366.2356 - mean_absolute_error: 366.2356 - val_loss: 437.6809 - val_mean_absolute_error: 437.6809\n",
      "\n",
      "Epoch 00415: val_loss did not improve from 344.82021\n",
      "Epoch 416/500\n",
      "585/585 [==============================] - 0s 147us/step - loss: 368.1178 - mean_absolute_error: 368.1178 - val_loss: 466.9843 - val_mean_absolute_error: 466.9843\n",
      "\n",
      "Epoch 00416: val_loss did not improve from 344.82021\n",
      "Epoch 417/500\n",
      "585/585 [==============================] - 0s 160us/step - loss: 368.3233 - mean_absolute_error: 368.3233 - val_loss: 460.6414 - val_mean_absolute_error: 460.6414\n",
      "\n",
      "Epoch 00417: val_loss did not improve from 344.82021\n",
      "Epoch 418/500\n",
      "585/585 [==============================] - 0s 123us/step - loss: 356.0760 - mean_absolute_error: 356.0760 - val_loss: 454.9025 - val_mean_absolute_error: 454.9025\n",
      "\n",
      "Epoch 00418: val_loss did not improve from 344.82021\n",
      "Epoch 419/500\n",
      "585/585 [==============================] - 0s 140us/step - loss: 355.4509 - mean_absolute_error: 355.4509 - val_loss: 431.4992 - val_mean_absolute_error: 431.4992\n",
      "\n",
      "Epoch 00419: val_loss did not improve from 344.82021\n",
      "Epoch 420/500\n",
      "585/585 [==============================] - 0s 128us/step - loss: 356.3739 - mean_absolute_error: 356.3739 - val_loss: 459.2819 - val_mean_absolute_error: 459.2819\n",
      "\n",
      "Epoch 00420: val_loss did not improve from 344.82021\n",
      "Epoch 421/500\n",
      "585/585 [==============================] - 0s 133us/step - loss: 373.3522 - mean_absolute_error: 373.3522 - val_loss: 495.3528 - val_mean_absolute_error: 495.3528\n",
      "\n",
      "Epoch 00421: val_loss did not improve from 344.82021\n",
      "Epoch 422/500\n",
      "585/585 [==============================] - 0s 140us/step - loss: 358.9588 - mean_absolute_error: 358.9588 - val_loss: 456.0082 - val_mean_absolute_error: 456.0082\n",
      "\n",
      "Epoch 00422: val_loss did not improve from 344.82021\n",
      "Epoch 423/500\n",
      "585/585 [==============================] - 0s 145us/step - loss: 354.5847 - mean_absolute_error: 354.5847 - val_loss: 480.6496 - val_mean_absolute_error: 480.6496\n",
      "\n",
      "Epoch 00423: val_loss did not improve from 344.82021\n",
      "Epoch 424/500\n",
      "585/585 [==============================] - 0s 142us/step - loss: 367.5549 - mean_absolute_error: 367.5549 - val_loss: 429.2591 - val_mean_absolute_error: 429.2591\n",
      "\n",
      "Epoch 00424: val_loss did not improve from 344.82021\n",
      "Epoch 425/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "585/585 [==============================] - 0s 130us/step - loss: 363.2906 - mean_absolute_error: 363.2906 - val_loss: 458.9128 - val_mean_absolute_error: 458.9128\n",
      "\n",
      "Epoch 00425: val_loss did not improve from 344.82021\n",
      "Epoch 426/500\n",
      "585/585 [==============================] - 0s 126us/step - loss: 353.6886 - mean_absolute_error: 353.6886 - val_loss: 471.3624 - val_mean_absolute_error: 471.3624\n",
      "\n",
      "Epoch 00426: val_loss did not improve from 344.82021\n",
      "Epoch 427/500\n",
      "585/585 [==============================] - 0s 133us/step - loss: 353.9127 - mean_absolute_error: 353.9127 - val_loss: 464.6285 - val_mean_absolute_error: 464.6285\n",
      "\n",
      "Epoch 00427: val_loss did not improve from 344.82021\n",
      "Epoch 428/500\n",
      "585/585 [==============================] - 0s 136us/step - loss: 352.5082 - mean_absolute_error: 352.5082 - val_loss: 464.4457 - val_mean_absolute_error: 464.4457\n",
      "\n",
      "Epoch 00428: val_loss did not improve from 344.82021\n",
      "Epoch 429/500\n",
      "585/585 [==============================] - 0s 162us/step - loss: 349.1757 - mean_absolute_error: 349.1757 - val_loss: 472.0213 - val_mean_absolute_error: 472.0213\n",
      "\n",
      "Epoch 00429: val_loss did not improve from 344.82021\n",
      "Epoch 430/500\n",
      "585/585 [==============================] - 0s 142us/step - loss: 350.9780 - mean_absolute_error: 350.9780 - val_loss: 451.6241 - val_mean_absolute_error: 451.6241\n",
      "\n",
      "Epoch 00430: val_loss did not improve from 344.82021\n",
      "Epoch 431/500\n",
      "585/585 [==============================] - 0s 150us/step - loss: 367.6887 - mean_absolute_error: 367.6887 - val_loss: 444.0114 - val_mean_absolute_error: 444.0114\n",
      "\n",
      "Epoch 00431: val_loss did not improve from 344.82021\n",
      "Epoch 432/500\n",
      "585/585 [==============================] - 0s 152us/step - loss: 359.8884 - mean_absolute_error: 359.8884 - val_loss: 449.1028 - val_mean_absolute_error: 449.1028\n",
      "\n",
      "Epoch 00432: val_loss did not improve from 344.82021\n",
      "Epoch 433/500\n",
      "585/585 [==============================] - 0s 160us/step - loss: 359.6582 - mean_absolute_error: 359.6582 - val_loss: 432.2442 - val_mean_absolute_error: 432.2442\n",
      "\n",
      "Epoch 00433: val_loss did not improve from 344.82021\n",
      "Epoch 434/500\n",
      "585/585 [==============================] - 0s 140us/step - loss: 349.0227 - mean_absolute_error: 349.0227 - val_loss: 495.5037 - val_mean_absolute_error: 495.5037\n",
      "\n",
      "Epoch 00434: val_loss did not improve from 344.82021\n",
      "Epoch 435/500\n",
      "585/585 [==============================] - 0s 157us/step - loss: 360.9413 - mean_absolute_error: 360.9413 - val_loss: 459.8103 - val_mean_absolute_error: 459.8103\n",
      "\n",
      "Epoch 00435: val_loss did not improve from 344.82021\n",
      "Epoch 436/500\n",
      "585/585 [==============================] - 0s 153us/step - loss: 354.9751 - mean_absolute_error: 354.9751 - val_loss: 499.3458 - val_mean_absolute_error: 499.3458\n",
      "\n",
      "Epoch 00436: val_loss did not improve from 344.82021\n",
      "Epoch 437/500\n",
      "585/585 [==============================] - 0s 157us/step - loss: 354.9998 - mean_absolute_error: 354.9998 - val_loss: 471.1067 - val_mean_absolute_error: 471.1067\n",
      "\n",
      "Epoch 00437: val_loss did not improve from 344.82021\n",
      "Epoch 438/500\n",
      "585/585 [==============================] - 0s 143us/step - loss: 357.6936 - mean_absolute_error: 357.6936 - val_loss: 448.7313 - val_mean_absolute_error: 448.7313\n",
      "\n",
      "Epoch 00438: val_loss did not improve from 344.82021\n",
      "Epoch 439/500\n",
      "585/585 [==============================] - 0s 140us/step - loss: 364.7366 - mean_absolute_error: 364.7366 - val_loss: 448.4786 - val_mean_absolute_error: 448.4786\n",
      "\n",
      "Epoch 00439: val_loss did not improve from 344.82021\n",
      "Epoch 440/500\n",
      "585/585 [==============================] - 0s 157us/step - loss: 347.0903 - mean_absolute_error: 347.0903 - val_loss: 459.2660 - val_mean_absolute_error: 459.2660\n",
      "\n",
      "Epoch 00440: val_loss did not improve from 344.82021\n",
      "Epoch 441/500\n",
      "585/585 [==============================] - 0s 153us/step - loss: 346.1713 - mean_absolute_error: 346.1713 - val_loss: 496.8178 - val_mean_absolute_error: 496.8178\n",
      "\n",
      "Epoch 00441: val_loss did not improve from 344.82021\n",
      "Epoch 442/500\n",
      "585/585 [==============================] - 0s 159us/step - loss: 358.4517 - mean_absolute_error: 358.4517 - val_loss: 459.0602 - val_mean_absolute_error: 459.0602\n",
      "\n",
      "Epoch 00442: val_loss did not improve from 344.82021\n",
      "Epoch 443/500\n",
      "585/585 [==============================] - 0s 165us/step - loss: 347.1889 - mean_absolute_error: 347.1889 - val_loss: 474.3292 - val_mean_absolute_error: 474.3292\n",
      "\n",
      "Epoch 00443: val_loss did not improve from 344.82021\n",
      "Epoch 444/500\n",
      "585/585 [==============================] - 0s 155us/step - loss: 343.9971 - mean_absolute_error: 343.9971 - val_loss: 466.5474 - val_mean_absolute_error: 466.5474\n",
      "\n",
      "Epoch 00444: val_loss did not improve from 344.82021\n",
      "Epoch 445/500\n",
      "585/585 [==============================] - 0s 140us/step - loss: 357.4715 - mean_absolute_error: 357.4715 - val_loss: 437.6896 - val_mean_absolute_error: 437.6896\n",
      "\n",
      "Epoch 00445: val_loss did not improve from 344.82021\n",
      "Epoch 446/500\n",
      "585/585 [==============================] - 0s 167us/step - loss: 344.7419 - mean_absolute_error: 344.7419 - val_loss: 455.2441 - val_mean_absolute_error: 455.2441\n",
      "\n",
      "Epoch 00446: val_loss did not improve from 344.82021\n",
      "Epoch 447/500\n",
      "585/585 [==============================] - 0s 160us/step - loss: 342.7038 - mean_absolute_error: 342.7038 - val_loss: 466.9710 - val_mean_absolute_error: 466.9710\n",
      "\n",
      "Epoch 00447: val_loss did not improve from 344.82021\n",
      "Epoch 448/500\n",
      "585/585 [==============================] - 0s 169us/step - loss: 346.1865 - mean_absolute_error: 346.1865 - val_loss: 445.8802 - val_mean_absolute_error: 445.8802\n",
      "\n",
      "Epoch 00448: val_loss did not improve from 344.82021\n",
      "Epoch 449/500\n",
      "585/585 [==============================] - 0s 147us/step - loss: 352.3567 - mean_absolute_error: 352.3567 - val_loss: 467.0548 - val_mean_absolute_error: 467.0548\n",
      "\n",
      "Epoch 00449: val_loss did not improve from 344.82021\n",
      "Epoch 450/500\n",
      "585/585 [==============================] - 0s 159us/step - loss: 344.9094 - mean_absolute_error: 344.9094 - val_loss: 440.6560 - val_mean_absolute_error: 440.6560\n",
      "\n",
      "Epoch 00450: val_loss did not improve from 344.82021\n",
      "Epoch 451/500\n",
      "585/585 [==============================] - 0s 147us/step - loss: 346.4331 - mean_absolute_error: 346.4331 - val_loss: 476.2823 - val_mean_absolute_error: 476.2823\n",
      "\n",
      "Epoch 00451: val_loss did not improve from 344.82021\n",
      "Epoch 452/500\n",
      "585/585 [==============================] - 0s 164us/step - loss: 346.0855 - mean_absolute_error: 346.0855 - val_loss: 444.2791 - val_mean_absolute_error: 444.2791\n",
      "\n",
      "Epoch 00452: val_loss did not improve from 344.82021\n",
      "Epoch 453/500\n",
      "585/585 [==============================] - 0s 155us/step - loss: 352.1133 - mean_absolute_error: 352.1133 - val_loss: 482.5432 - val_mean_absolute_error: 482.5432\n",
      "\n",
      "Epoch 00453: val_loss did not improve from 344.82021\n",
      "Epoch 454/500\n",
      "585/585 [==============================] - 0s 142us/step - loss: 360.2194 - mean_absolute_error: 360.2194 - val_loss: 421.1144 - val_mean_absolute_error: 421.1144\n",
      "\n",
      "Epoch 00454: val_loss did not improve from 344.82021\n",
      "Epoch 455/500\n",
      "585/585 [==============================] - 0s 145us/step - loss: 356.4171 - mean_absolute_error: 356.4171 - val_loss: 441.4726 - val_mean_absolute_error: 441.4726\n",
      "\n",
      "Epoch 00455: val_loss did not improve from 344.82021\n",
      "Epoch 456/500\n",
      "585/585 [==============================] - 0s 145us/step - loss: 346.1764 - mean_absolute_error: 346.1764 - val_loss: 459.1357 - val_mean_absolute_error: 459.1357\n",
      "\n",
      "Epoch 00456: val_loss did not improve from 344.82021\n",
      "Epoch 457/500\n",
      "585/585 [==============================] - 0s 159us/step - loss: 380.7166 - mean_absolute_error: 380.7166 - val_loss: 432.5451 - val_mean_absolute_error: 432.5451\n",
      "\n",
      "Epoch 00457: val_loss did not improve from 344.82021\n",
      "Epoch 458/500\n",
      "585/585 [==============================] - 0s 174us/step - loss: 344.9979 - mean_absolute_error: 344.9979 - val_loss: 435.4135 - val_mean_absolute_error: 435.4135\n",
      "\n",
      "Epoch 00458: val_loss did not improve from 344.82021\n",
      "Epoch 459/500\n",
      "585/585 [==============================] - 0s 174us/step - loss: 347.6392 - mean_absolute_error: 347.6392 - val_loss: 466.7057 - val_mean_absolute_error: 466.7057\n",
      "\n",
      "Epoch 00459: val_loss did not improve from 344.82021\n",
      "Epoch 460/500\n",
      "585/585 [==============================] - 0s 170us/step - loss: 363.6879 - mean_absolute_error: 363.6879 - val_loss: 452.6815 - val_mean_absolute_error: 452.6815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00460: val_loss did not improve from 344.82021\n",
      "Epoch 461/500\n",
      "585/585 [==============================] - 0s 162us/step - loss: 348.1199 - mean_absolute_error: 348.1199 - val_loss: 437.3016 - val_mean_absolute_error: 437.3016\n",
      "\n",
      "Epoch 00461: val_loss did not improve from 344.82021\n",
      "Epoch 462/500\n",
      "585/585 [==============================] - 0s 174us/step - loss: 351.1342 - mean_absolute_error: 351.1342 - val_loss: 485.9227 - val_mean_absolute_error: 485.9227\n",
      "\n",
      "Epoch 00462: val_loss did not improve from 344.82021\n",
      "Epoch 463/500\n",
      "585/585 [==============================] - 0s 165us/step - loss: 345.2352 - mean_absolute_error: 345.2352 - val_loss: 454.3418 - val_mean_absolute_error: 454.3418\n",
      "\n",
      "Epoch 00463: val_loss did not improve from 344.82021\n",
      "Epoch 464/500\n",
      "585/585 [==============================] - 0s 165us/step - loss: 337.3288 - mean_absolute_error: 337.3288 - val_loss: 482.4752 - val_mean_absolute_error: 482.4752\n",
      "\n",
      "Epoch 00464: val_loss did not improve from 344.82021\n",
      "Epoch 465/500\n",
      "585/585 [==============================] - 0s 172us/step - loss: 333.4620 - mean_absolute_error: 333.4620 - val_loss: 464.5660 - val_mean_absolute_error: 464.5660\n",
      "\n",
      "Epoch 00465: val_loss did not improve from 344.82021\n",
      "Epoch 466/500\n",
      "585/585 [==============================] - 0s 159us/step - loss: 343.7724 - mean_absolute_error: 343.7724 - val_loss: 456.7756 - val_mean_absolute_error: 456.7756\n",
      "\n",
      "Epoch 00466: val_loss did not improve from 344.82021\n",
      "Epoch 467/500\n",
      "585/585 [==============================] - 0s 176us/step - loss: 341.7924 - mean_absolute_error: 341.7924 - val_loss: 476.6545 - val_mean_absolute_error: 476.6545\n",
      "\n",
      "Epoch 00467: val_loss did not improve from 344.82021\n",
      "Epoch 468/500\n",
      "585/585 [==============================] - 0s 159us/step - loss: 366.1385 - mean_absolute_error: 366.1385 - val_loss: 454.3704 - val_mean_absolute_error: 454.3704\n",
      "\n",
      "Epoch 00468: val_loss did not improve from 344.82021\n",
      "Epoch 469/500\n",
      "585/585 [==============================] - 0s 159us/step - loss: 346.8094 - mean_absolute_error: 346.8094 - val_loss: 496.4386 - val_mean_absolute_error: 496.4386\n",
      "\n",
      "Epoch 00469: val_loss did not improve from 344.82021\n",
      "Epoch 470/500\n",
      "585/585 [==============================] - 0s 165us/step - loss: 338.9560 - mean_absolute_error: 338.9560 - val_loss: 475.1231 - val_mean_absolute_error: 475.1231\n",
      "\n",
      "Epoch 00470: val_loss did not improve from 344.82021\n",
      "Epoch 471/500\n",
      "585/585 [==============================] - 0s 126us/step - loss: 346.6506 - mean_absolute_error: 346.6506 - val_loss: 443.7586 - val_mean_absolute_error: 443.7586\n",
      "\n",
      "Epoch 00471: val_loss did not improve from 344.82021\n",
      "Epoch 472/500\n",
      "585/585 [==============================] - 0s 159us/step - loss: 343.5080 - mean_absolute_error: 343.5080 - val_loss: 463.3462 - val_mean_absolute_error: 463.3462\n",
      "\n",
      "Epoch 00472: val_loss did not improve from 344.82021\n",
      "Epoch 473/500\n",
      "585/585 [==============================] - 0s 147us/step - loss: 335.3150 - mean_absolute_error: 335.3150 - val_loss: 438.2945 - val_mean_absolute_error: 438.2945\n",
      "\n",
      "Epoch 00473: val_loss did not improve from 344.82021\n",
      "Epoch 474/500\n",
      "585/585 [==============================] - 0s 148us/step - loss: 365.0968 - mean_absolute_error: 365.0968 - val_loss: 467.1446 - val_mean_absolute_error: 467.1446\n",
      "\n",
      "Epoch 00474: val_loss did not improve from 344.82021\n",
      "Epoch 475/500\n",
      "585/585 [==============================] - 0s 145us/step - loss: 348.6587 - mean_absolute_error: 348.6587 - val_loss: 443.8163 - val_mean_absolute_error: 443.8163\n",
      "\n",
      "Epoch 00475: val_loss did not improve from 344.82021\n",
      "Epoch 476/500\n",
      "585/585 [==============================] - 0s 142us/step - loss: 337.6085 - mean_absolute_error: 337.6085 - val_loss: 438.5949 - val_mean_absolute_error: 438.5949\n",
      "\n",
      "Epoch 00476: val_loss did not improve from 344.82021\n",
      "Epoch 477/500\n",
      "585/585 [==============================] - 0s 135us/step - loss: 329.3212 - mean_absolute_error: 329.3212 - val_loss: 450.2509 - val_mean_absolute_error: 450.2509\n",
      "\n",
      "Epoch 00477: val_loss did not improve from 344.82021\n",
      "Epoch 478/500\n",
      "585/585 [==============================] - 0s 131us/step - loss: 333.8075 - mean_absolute_error: 333.8075 - val_loss: 453.0210 - val_mean_absolute_error: 453.0210\n",
      "\n",
      "Epoch 00478: val_loss did not improve from 344.82021\n",
      "Epoch 479/500\n",
      "585/585 [==============================] - 0s 131us/step - loss: 340.2804 - mean_absolute_error: 340.2804 - val_loss: 465.4230 - val_mean_absolute_error: 465.4230\n",
      "\n",
      "Epoch 00479: val_loss did not improve from 344.82021\n",
      "Epoch 480/500\n",
      "585/585 [==============================] - 0s 128us/step - loss: 365.4342 - mean_absolute_error: 365.4342 - val_loss: 461.8863 - val_mean_absolute_error: 461.8863\n",
      "\n",
      "Epoch 00480: val_loss did not improve from 344.82021\n",
      "Epoch 481/500\n",
      "585/585 [==============================] - 0s 135us/step - loss: 366.4242 - mean_absolute_error: 366.4242 - val_loss: 462.2355 - val_mean_absolute_error: 462.2355\n",
      "\n",
      "Epoch 00481: val_loss did not improve from 344.82021\n",
      "Epoch 482/500\n",
      "585/585 [==============================] - 0s 142us/step - loss: 335.2703 - mean_absolute_error: 335.2703 - val_loss: 433.8471 - val_mean_absolute_error: 433.8471\n",
      "\n",
      "Epoch 00482: val_loss did not improve from 344.82021\n",
      "Epoch 483/500\n",
      "585/585 [==============================] - 0s 142us/step - loss: 365.8262 - mean_absolute_error: 365.8262 - val_loss: 415.7122 - val_mean_absolute_error: 415.7122\n",
      "\n",
      "Epoch 00483: val_loss did not improve from 344.82021\n",
      "Epoch 484/500\n",
      "585/585 [==============================] - 0s 157us/step - loss: 357.3500 - mean_absolute_error: 357.3500 - val_loss: 496.4370 - val_mean_absolute_error: 496.4370\n",
      "\n",
      "Epoch 00484: val_loss did not improve from 344.82021\n",
      "Epoch 485/500\n",
      "585/585 [==============================] - 0s 143us/step - loss: 359.5800 - mean_absolute_error: 359.5800 - val_loss: 423.1432 - val_mean_absolute_error: 423.1432\n",
      "\n",
      "Epoch 00485: val_loss did not improve from 344.82021\n",
      "Epoch 486/500\n",
      "585/585 [==============================] - 0s 140us/step - loss: 335.4166 - mean_absolute_error: 335.4166 - val_loss: 474.0805 - val_mean_absolute_error: 474.0805\n",
      "\n",
      "Epoch 00486: val_loss did not improve from 344.82021\n",
      "Epoch 487/500\n",
      "585/585 [==============================] - 0s 148us/step - loss: 337.1410 - mean_absolute_error: 337.1410 - val_loss: 462.3954 - val_mean_absolute_error: 462.3954\n",
      "\n",
      "Epoch 00487: val_loss did not improve from 344.82021\n",
      "Epoch 488/500\n",
      "585/585 [==============================] - 0s 155us/step - loss: 352.1058 - mean_absolute_error: 352.1058 - val_loss: 447.2378 - val_mean_absolute_error: 447.2378\n",
      "\n",
      "Epoch 00488: val_loss did not improve from 344.82021\n",
      "Epoch 489/500\n",
      "585/585 [==============================] - 0s 138us/step - loss: 351.8475 - mean_absolute_error: 351.8475 - val_loss: 470.2447 - val_mean_absolute_error: 470.2447\n",
      "\n",
      "Epoch 00489: val_loss did not improve from 344.82021\n",
      "Epoch 490/500\n",
      "585/585 [==============================] - 0s 147us/step - loss: 336.1152 - mean_absolute_error: 336.1152 - val_loss: 460.5867 - val_mean_absolute_error: 460.5867\n",
      "\n",
      "Epoch 00490: val_loss did not improve from 344.82021\n",
      "Epoch 491/500\n",
      "585/585 [==============================] - 0s 143us/step - loss: 334.5386 - mean_absolute_error: 334.5386 - val_loss: 433.1612 - val_mean_absolute_error: 433.1612\n",
      "\n",
      "Epoch 00491: val_loss did not improve from 344.82021\n",
      "Epoch 492/500\n",
      "585/585 [==============================] - 0s 152us/step - loss: 345.2304 - mean_absolute_error: 345.2304 - val_loss: 486.1027 - val_mean_absolute_error: 486.1027\n",
      "\n",
      "Epoch 00492: val_loss did not improve from 344.82021\n",
      "Epoch 493/500\n",
      "585/585 [==============================] - 0s 153us/step - loss: 387.3622 - mean_absolute_error: 387.3622 - val_loss: 524.3334 - val_mean_absolute_error: 524.3334\n",
      "\n",
      "Epoch 00493: val_loss did not improve from 344.82021\n",
      "Epoch 494/500\n",
      "585/585 [==============================] - 0s 142us/step - loss: 366.8628 - mean_absolute_error: 366.8628 - val_loss: 465.9098 - val_mean_absolute_error: 465.9098\n",
      "\n",
      "Epoch 00494: val_loss did not improve from 344.82021\n",
      "Epoch 495/500\n",
      "585/585 [==============================] - 0s 153us/step - loss: 338.2733 - mean_absolute_error: 338.2733 - val_loss: 451.2500 - val_mean_absolute_error: 451.2500\n",
      "\n",
      "Epoch 00495: val_loss did not improve from 344.82021\n",
      "Epoch 496/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "585/585 [==============================] - 0s 152us/step - loss: 343.6395 - mean_absolute_error: 343.6395 - val_loss: 439.4208 - val_mean_absolute_error: 439.4208\n",
      "\n",
      "Epoch 00496: val_loss did not improve from 344.82021\n",
      "Epoch 497/500\n",
      "585/585 [==============================] - 0s 147us/step - loss: 343.6142 - mean_absolute_error: 343.6142 - val_loss: 443.4623 - val_mean_absolute_error: 443.4623\n",
      "\n",
      "Epoch 00497: val_loss did not improve from 344.82021\n",
      "Epoch 498/500\n",
      "585/585 [==============================] - 0s 147us/step - loss: 338.0465 - mean_absolute_error: 338.0465 - val_loss: 469.7024 - val_mean_absolute_error: 469.7024\n",
      "\n",
      "Epoch 00498: val_loss did not improve from 344.82021\n",
      "Epoch 499/500\n",
      "585/585 [==============================] - 0s 164us/step - loss: 335.1659 - mean_absolute_error: 335.1659 - val_loss: 483.5010 - val_mean_absolute_error: 483.5010\n",
      "\n",
      "Epoch 00499: val_loss did not improve from 344.82021\n",
      "Epoch 500/500\n",
      "585/585 [==============================] - 0s 160us/step - loss: 344.9576 - mean_absolute_error: 344.9576 - val_loss: 461.6319 - val_mean_absolute_error: 461.6319\n",
      "\n",
      "Epoch 00500: val_loss did not improve from 344.82021\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2940e434710>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예제에서는 target을 대회에서 주는 target데이터를 기준으로 미리 train데이터와 맞춰졌있지만\n",
    "# gs/lv데이터는 아니다. 그래서 위에서 나누는 기준으로 삼은cut_line=732을 이용하여 데이터 사이즈를 맞춰준다.\n",
    "# 아니면 애시당초에(맨처음에) 훈련용 데이터와 타겟을 만들어 놓는것도 좋다.\n",
    "NN_model.fit(train, target[:cut_line], epochs=500, batch_size=32, validation_split = 0.2, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 500번을 학습하여 나온 결과들중, 가장 좋은(마지막에 저장된) Weights파일을 가져온다.\n",
    "# Load wights file of the best model :\n",
    "# 파일은 이 코드랑 같은 폴더에 위치해있어야 작동\n",
    "wights_file = '제모제date-Weights-412--365.57752-cat04-vf05.hdf5'\n",
    "NN_model.load_weights(wights_file) # load it\n",
    "NN_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "여기서 점수란 R-square값을 의미한다.\n",
      "Random forest을 이용한 제모제의 회귀분석 결과 :\n",
      "훈련세트점수 : 0.925\n",
      "검증세트점수 : 0.365\n",
      "XGBoost을 이용한 제모제의 회귀분석 결과 :\n",
      "훈련세트점수 : 0.799\n",
      "검증세트점수 : 0.425\n",
      "LinearRegression을 이용한 제모제의 회귀분석 결과 :\n",
      "훈련세트점수 : 0.516\n",
      "검증세트점수 : 0.423\n",
      "RidgeRegression을 이용한 제모제의 회귀분석 결과 :\n",
      "훈련세트점수 : 0.509\n",
      "검증세트점수 : 0.435\n",
      "LassoRegression을 이용한 제모제의 회귀분석 결과 :\n",
      "훈련세트점수 : 0.516\n",
      "검증세트점수 : 0.423\n",
      "OLS을 이용한 제모제의 회귀분석 결과 :\n",
      "훈련세트점수 : 0.516\n",
      "검증세트점수 : 0.423\n"
     ]
    }
   ],
   "source": [
    "#2016~2018전체를 난수로 0.67:0.33 = 2:1\n",
    "# train3 = combined.loc[:,'temp':]\n",
    "# target3 = combined.loc[:,'qty']\n",
    "# train_X, val_X, train_y, val_y = train_test_split(train3, target3, test_size = 0.33, random_state = 14)\n",
    "\n",
    "# 2016~2017 : 훈련 / 2018 검증 2:1\n",
    "# 1~732 / 732~1096\n",
    "trainXy = Xy[:cut_line]\n",
    "testXy = Xy[cut_line:]\n",
    "\n",
    "# 독립변수들\n",
    "train_X = trainXy.loc[:,'temp':]\n",
    "# 정답(판매량)\n",
    "train_y = trainXy.loc[:,'qty']\n",
    "\n",
    "val_X = testXy.loc[:,'temp':]\n",
    "val_y = testXy.loc[:,'qty']\n",
    "\n",
    "print('여기서 점수란 R-square값을 의미한다.')\n",
    "# RandomForest 회귀분석\n",
    "RFmodel = RandomForestRegressor()\n",
    "RFmodel.fit(train_X,train_y)\n",
    "# Get the mean absolute error on the validation data\n",
    "RFpredicted = RFmodel.predict(val_X)\n",
    "MAE = mean_absolute_error(val_y , RFpredicted)\n",
    "print('Random forest을 이용한 %s의 회귀분석 결과 :'%item)\n",
    "# print('Random forest validation MAE = ', MAE)\n",
    "print('훈련세트점수 : {:.3f}'.format(RFmodel.score(train_X, train_y)))\n",
    "print('검증세트점수 : {:.3f}'.format(RFmodel.score(val_X, val_y)))\n",
    "\n",
    "# XGBRegressor 회귀분석\n",
    "XGBModel = XGBRegressor(objective='reg:squarederror')\n",
    "XGBModel.fit(train_X,train_y , verbose=False)\n",
    "# Get the mean absolute error on the validation data :\n",
    "XGBpredictions = XGBModel.predict(val_X)\n",
    "MAE = mean_absolute_error(val_y , XGBpredictions)\n",
    "print('XGBoost을 이용한 %s의 회귀분석 결과 :'%item)\n",
    "# print('XGBoost validation MAE = ',MAE)\n",
    "print('훈련세트점수 : {:.3f}'.format(XGBModel.score(train_X, train_y)))\n",
    "print('검증세트점수 : {:.3f}'.format(XGBModel.score(val_X, val_y)))\n",
    "\n",
    "linReg = LinearRegression().fit(train_X, train_y)\n",
    "print('LinearRegression을 이용한 %s의 회귀분석 결과 :'%item)\n",
    "print('훈련세트점수 : {:.3f}'.format(linReg.score(train_X, train_y)))\n",
    "print('검증세트점수 : {:.3f}'.format(linReg.score(val_X, val_y)))\n",
    "\n",
    "ridge = Ridge(alpha=0.1, normalize=True, random_state=0, tol=0.001).fit(train_X, train_y)\n",
    "print('RidgeRegression을 이용한 %s의 회귀분석 결과 :'%item)\n",
    "print('훈련세트점수 : {:.3f}'.format(ridge.score(train_X, train_y)))\n",
    "print('검증세트점수 : {:.3f}'.format(ridge.score(val_X, val_y)))\n",
    "\n",
    "lasso = Lasso(alpha=0.1, max_iter=1000).fit(train_X, train_y)\n",
    "print('LassoRegression을 이용한 %s의 회귀분석 결과 :'%item)\n",
    "print('훈련세트점수 : {:.3f}'.format(lasso.score(train_X, train_y)) )\n",
    "print('검증세트점수 : {:.3f}'.format(lasso.score(val_X, val_y)) )\n",
    "\n",
    "columns_in_data = list(train_X.columns)\n",
    "customF = formulaGen(target='qty',ind_features=columns_in_data)\n",
    "olsModel = sm.OLS.from_formula(customF, data=trainXy).fit()\n",
    "print('OLS을 이용한 %s의 회귀분석 결과 :'%item)\n",
    "print('훈련세트점수 : {:.3f}'.format(olsModel.rsquared) )\n",
    "print('검증세트점수 : {:.3f}'.format( r2_score(val_y, olsModel.predict(val_X))   ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사람이 직접 식을 때려 박았을때 : 0.215\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    qty   R-squared:                       0.540\n",
      "Model:                            OLS   Adj. R-squared:                  0.536\n",
      "Method:                 Least Squares   F-statistic:                     141.6\n",
      "Date:                Fri, 19 Jul 2019   Prob (F-statistic):          1.46e-118\n",
      "Time:                        21:12:02   Log-Likelihood:                -5789.7\n",
      "No. Observations:                 732   AIC:                         1.159e+04\n",
      "Df Residuals:                     725   BIC:                         1.163e+04\n",
      "Df Model:                           6                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "================================================================================\n",
      "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------\n",
      "Intercept     -103.7622    157.556     -0.659      0.510    -413.083     205.559\n",
      "I(temp ** 2)     2.4426      0.104     23.556      0.000       2.239       2.646\n",
      "cloud           41.7243     15.421      2.706      0.007      11.448      72.000\n",
      "wind            51.4245     36.635      1.404      0.161     -20.499     123.348\n",
      "lgt_time        48.5913     12.199      3.983      0.000      24.642      72.540\n",
      "rain_or_not    107.1213     71.022      1.508      0.132     -32.313     246.556\n",
      "snow_or_not    -12.4969    136.750     -0.091      0.927    -280.970     255.977\n",
      "==============================================================================\n",
      "Omnibus:                       45.279   Durbin-Watson:                   0.539\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               53.416\n",
      "Skew:                           0.595   Prob(JB):                     2.52e-12\n",
      "Kurtosis:                       3.579   Cond. No.                     2.51e+03\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.51e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "# columns_in_data = ['temp', 'cloud', 'wind', 'lgt_time', 'rain_or_not', 'snow_or_not',\n",
    "#                     '공기상태_0', '공기상태_1', '공기상태_2']\n",
    "\n",
    "# formulaGen은 단순 1차 다항식을 제조해준다.\n",
    "# customF = formulaGen(target='qty',ind_features=columns_in_data)\n",
    "# customF = formulaGen(target='qty',ind_features=['temp', 'wind','lgt_time','rain_or_not'])\n",
    "customF = 'qty ~ I(temp**2) + cloud + wind + lgt_time + rain_or_not + snow_or_not'\n",
    "\n",
    "olsModel = sm.OLS.from_formula(customF, data=trainXy).fit()\n",
    "print('사람이 직접 식을 때려 박았을때 : {:.3f}'.format(r2_score(val_y, olsModel.predict(val_X))) )\n",
    "print(olsModel.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# col_list = ['temp', 'cloud', 'wind', 'lgt_time', 'PM10', 'rain_or_not_o', 'snow_or_not_o',\n",
    "#             '공기상태_0', '공기상태_1', '공기상태_2']\n",
    "col_list = ['temp', 'cloud', 'wind', 'lgt_time', 'PM10', 'rain_or_not_o', 'snow_or_not_o',\n",
    "            '공기상태']\n",
    "combined = Xy.loc[:,'temp':]\n",
    "target = Xy.loc[:,'qty']\n",
    "\n",
    "# 가장 좋다고 판명된 설정을 이용하여, 예측qty생산\n",
    "predictions = NN_model.predict(combined)\n",
    "# RandomForest 회귀분석 예측 qty생산\n",
    "RFpredicted = RFmodel.predict(combined)\n",
    "# XGBRegressor 회귀분석 예측 qty생산\n",
    "XGBpredictions = XGBModel.predict(combined)\n",
    "# linearRegression 회귀분석 예측 qty생산\n",
    "linPred = linReg.predict(combined)\n",
    "# Ridge 회귀분석 예측 qty생산\n",
    "ridPred = ridge.predict(combined)\n",
    "# Lasso 회귀분석 예측 qty생산\n",
    "lassoPred = lasso.predict(combined)\n",
    "# OLS 회귀분석 예측 qty생산\n",
    "olsPred = olsModel.predict(combined)\n",
    "\n",
    "result_df = pd.DataFrame()\n",
    "result_df['date'] = lv_day_w['date']\n",
    "result_df['qty'] = Xy.loc[:,'qty']\n",
    "\n",
    "# print(\"keras 신경망 predictions\",predictions.shape)\n",
    "result_df['keras_qty'] = predictions\n",
    "\n",
    "# print(\"randomforest 예상\",RFpredicted.shape)\n",
    "result_df['rf_qty'] = RFpredicted\n",
    "\n",
    "# print(\"XGBpredictions\",XGBpredictions.shape)\n",
    "result_df['xgb_qty'] = XGBpredictions\n",
    "\n",
    "# print(\"linearRegression 예상\",RFpredicted.shape)\n",
    "result_df['lin_qty'] = linPred\n",
    "\n",
    "# print(\"Ridge 예상\",RFpredicted.shape)\n",
    "result_df['ridge_qty'] = ridPred\n",
    "\n",
    "# print(\"Lasso 예상\",RFpredicted.shape)\n",
    "result_df['lasso_qty'] = lassoPred\n",
    "\n",
    "# print(\"OLS 예상\",RFpredicted.shape)\n",
    "result_df['ols_qty'] = olsPred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras 인공 신경망 모델 MAPE \t: 0.49\n",
      "Linear 모델 MAPE \t\t: 0.89\n",
      "Ridge 모델 MAPE \t\t: 0.91\n",
      "Lasso 모델 MAPE \t\t: 0.89\n",
      "OLS 모델 MAPE \t\t\t: 0.83\n"
     ]
    }
   ],
   "source": [
    "# 예측률 계산\n",
    "# https://yamalab.tistory.com/46\n",
    "\n",
    "# RMSE (Root Mean Squared Error) : \n",
    "# OLS 추정에서 일반적인 표준 오차이다. 예측 대상의 scale(단위 크기)에 주의해야하는 단점이 있다. \n",
    "# MSE는 root를 수식에서 제외, SSE는 root와 분모를 제외한 수식으로, SE가 붙은 척도들은 거기서 거기인 척도들이라고 보면 된다.\n",
    "# 다만 디테일한 사용법에 차이가 있을 뿐.\n",
    "\n",
    "# MAPE (Mean Absolute Percentage Error) :\n",
    "\n",
    "# 위 방법의 단점을 보완한 것이다. \n",
    "# At는 실제값, Ft는 예측값인데, 이를 At로 나누어서 오차를 절대적 크기로 보는것이 아닌\n",
    "# 비율의 크기로 보고자 하는 것이 핵심이다.\n",
    "# 이 방법은 At가 0에 가까울수록 비정상적인 값이 나온다는 단점이 있다.\n",
    "\n",
    "# MAPE가 0에 가까울수록 좋은 모델\n",
    "result_df['mape_keras'] = abs((result_df.qty - result_df.keras_qty) / result_df.qty )\n",
    "result_df['mape_rf'] = abs((result_df.qty - result_df.rf_qty) / result_df.qty )\n",
    "result_df['mape_xgb'] = abs((result_df.qty - result_df.xgb_qty) / result_df.qty )\n",
    "result_df['mape_lin'] = abs((result_df.qty - result_df.lin_qty) / result_df.qty )\n",
    "result_df['mape_ridge'] = abs((result_df.qty - result_df.ridge_qty) / result_df.qty )\n",
    "result_df['mape_lasso'] = abs((result_df.qty - result_df.lasso_qty) / result_df.qty )\n",
    "result_df['mape_ols'] = abs((result_df.qty - result_df.ols_qty) / result_df.qty )\n",
    "\n",
    "print('Keras 인공 신경망 모델 MAPE \\t: {:<.2f}'.format(result_df['mape_keras'].sum() / result_df.shape[0] ))\n",
    "# print('RandomForest 모델 MAPE \\t\\t: {:<.2f}'.format(result_df['mape_rf'].sum() / result_df.shape[0] ))\n",
    "# print('XGBoosting  모델 MAPE \\t\\t: {:<.2f}'.format(result_df['mape_xgb'].sum() / result_df.shape[0] ))\n",
    "print('Linear 모델 MAPE \\t\\t: {:<.2f}'.format(result_df['mape_lin'].sum() / result_df.shape[0] ))\n",
    "print('Ridge 모델 MAPE \\t\\t: {:<.2f}'.format(result_df['mape_ridge'].sum() / result_df.shape[0] ))\n",
    "print('Lasso 모델 MAPE \\t\\t: {:<.2f}'.format(result_df['mape_lasso'].sum() / result_df.shape[0] ))\n",
    "print('OLS 모델 MAPE \\t\\t\\t: {:<.2f}'.format(result_df['mape_ols'].sum() / result_df.shape[0] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA5kAAAG7CAYAAABJrVEyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nOzde3xT9f0/8FeSNilpCzT0RgtlKQhFwB+sTmWiY5PJ9KtVcYqoQ6b1hi1zIJuIAs5JUQQRs4nKplNQtyFevuqU8Z3gGDKk0sqtXENLaemFcumF9JLk90dIyMn15HJykvT1fDx8jHP/nM/5pMs75/35fBRWq9UKIiIiIiIiojBQyl0AIiIiIiIiih8MMomIiIiIiChsGGQSERERERFR2DDIJCIiIiIiorBhkElERERERERhwyCTiIiIiIiIwoZBJhERSaqhoQF1dXURveb+/fvR0dER0WtS8Do6OrB///6Aj1u3bh1MJpMEJSIiolAwyCQioqB0d3fjxIkTjv8aGhrQ3d3t2J6VlQUAePvtt/Haa6+F5Zrt7e2CazY1NcE+3fPWrVsxZcoUAMCcOXOwffv2sFyTgGPHjuHo0aMe/ztz5gwA4IEHHsA777zjdmxra6vgmZ09e9axzd5Gtm/fjjlz5giOe++99zBs2DDBfxdffDE2btzo2Oexxx7DiRMnpLhlIiIKQYLcBSAiotj0r3/9C88884xjubGxEenp6di6dSsAW0Doy/jx43H8+HGo1Wq3bT09PUhMTMTBgwcF619++WV88sknjuWDBw/ivvvuw+LFi9HV1YWurq5Qbom8ePjhh9HY2IgjR47g0ksvBQB8++23yMvLw913341HH33UY/0fOHAAl156KS655BLHuoqKCmzfvh0XX3yxzzZyxx134I477hCsmz9/Pv7zn/9g0qRJYbw7IiIKNwaZREQUlMmTJ2Py5MmO5aVLl2LPnj2ij9+3bx+MRiPS0tI8bk9IcP+/qMcffxyPP/64Y/l//ud/MHz48ABKHX67d+9GTU0Nrr/+elnLIaVPPvkEmzZtwu9//3t8/vnnAIAbbrgBJSUl+NnPfub1uMbGRnz/+9/Hpk2bHOsmTpyIxsZGXHzxxQGXw1Ob+MEPfgCVSoW3334bP/3pTwM+JxERhR+DTCIiCov33nsPTz/9dEDHKBSKoK/X0tKCzZs34+233w76HOGwY8cObNmyJa6DTDn84x//QGlpKXp6ehzr2tvbsWrVKsF+33zzDb73ve9FuHREROQL+2QSEVHItm3bhtbWVowZMwYrVqzAihUrJL/ma6+9hqlTp+LAgQNYsWIF1q1bJ/k1na1ZswaDBg3C7Nmz8e6772LQoEHIy8tDS0sLAFuf1ZKSEuTk5CAnJwcvvvgiAFsqcF5eHiZOnIipU6fCYDAgJycHS5cuBQA8++yzeOqpp3DDDTdg0KBBmDRpkqiBkw4fPuz2VvePf/wjHnnkEQCAxWLB7NmzMWTIEAwePBiXXHIJ6uvrw1klmDdvHgoKCvD888+HfK7t27dj2rRpgv6fTU1NuPXWWwX7bdiwAR9++CEaGhpCviYREYUHg0wiIgrZnDlzMHbsWCQkJDj+80ehUHjtQ9nd3e0Y0MeT5uZmlJWVobCwEEqlEgkJCVCpVEGXPxh33303amtrsXz5ckybNg21tbWoqamBTqcDACxcuBB5eXk4fvw4vvnmG6xatQpffvklEhIScOzYMTzzzDPo6enBN998g/LycixevBhmsxnd3d34wx/+gPvvvx+1tbW46aabcO+99/otz9ChQwEAVVVVjnUfffQRioqKAADvvvsu9u3bh/379+PYsWPYtGkTMjIyQq6Hrq4unDt3DgBQVlaGqqoq/OY3vxF17Llz5zB27FgUFxd73O78pttsNqO+vh5ff/013nnnHZw+fRoAsHPnTmzbts0R3BMRkfyYLktERCFZsmQJMjIycPjwYVRVVaGkpAQABH0nPbnmmmtw5ZVXOoLJI0eOQK/XQ6FQQKFQeO3rZ7FYcM899+D+++/HsmXL8J///AeXXXYZNm3ahBdeeCGgsnd1dWHo0KFuAa1arcaRI0cCOpczk8mEjz76CLt374ZCoUBubi5KS0uxZs0a/PjHPwZg60s4atQomM1mDBw4EH369HEESpdccgluuukmAEBpaSlefPFFHD161G9a6I033oh//OMfKCgoQHt7OyoqKhzXs1gsgvu0B8P+nDlzBjNnzkRDQwN27dqFW2+9FW1tbdixYwcOHz6M9PR0zJ8/P9AqAgD06dMHW7Zswb///W/84Q9/EGwbN24cSkpK8Pe//x1msxlKpRL9+/fHoEGDMHz4cPzkJz8BAPz2t79luiwRUZRhkElEREH78MMP8fbbb+Prr79GfX09brjhBnzxxRfIz8/3e6xremtSUhL27NmDpKQkn8fNnTsX/fr1wwsvvIDCwkLcdttt+Oc//xlU+dVqNY4dOxbUsb4cOnQIhw8fhl6vd6zr7u7G+PHjAQAqlQpJSUlQq9WOPodqtRqdnZ0AgMLCQsH5CgsLsWfPHr/B1A033IAlS5bg17/+Nf75z39i0qRJjtF777zzThw4cABjxozBrFmz8OCDD3oc2ddVamoqHn/8cZjNZqhUKvTp0wepqalIS0sTHP/ee+/5rxgPUlJS0KdPH7f1RUVFjrew3gwfPtzjsUREJC8GmUREFJQ33ngDy5cvx2effYa+ffuib9++WLVqFa677jrs3Lkz7Nczm814+OGH0dzc7JiPcdq0aTAajbjrrrtQWloa9msGq6enBwUFBaioqAjL+RISEmAymfzud9VVV+HOO+9ER0cHPvnkE9x8882ObSqVCs888wweeeQRLFq0CGPGjMEXX3zhN3BVKpUYM2YMAKCjowMajUZ0anJKSgoqKysFU5FUVFSgf//+oo4HgM7OTrzxxhv47LPPUFtbC7PZjNzcXEyePBnr169HSkqK6HMREVFksE8mEREFzGq1orKyEps2bcKQIUMc66+55hps3rwZWq027NdsaGjAgAEDsG7dOsHbzieeeMIt1TKSPL0NHDZsGA4dOhT0wDrffvutYHn79u0YOXKk3+MSEhIwceJEfPnll/jXv/6F6667zm2f7OxsrFq1CnfeeSdee+21gMo1Y8YMfPzxxx63FRYWCt7cAsDYsWOxbds2PPbYY47//vvf/2Ls2LGir3njjTfi22+/xeLFi/Hvf/8b27ZtwwsvvIDjx4/jqquuQkdHR0D3QERE0uObTCIiCphCofA6gmx2drbPY6dPn46tW7e6rR80aBBGjx7tcf2mTZuQk5ODsrIyr9d0HvAmkrKysrBv3z6YzWa0t7cjJSUFKSkpmDFjBh544AGsWbMG/fr1w3fffQe9Xo/U1FS/5/z222/xySef4IYbbsAf//hH5Obmip5X8sYbb8TixYsxatQowVu+2tpaJCcnIy0tDS0tLdiyZQtuvPHGgO7VYrHAbDZ73ObtTfKIESMCuoazhoYGbNmyBf/4xz8Eb08vvvhiPP/887j88svx3//+19HvlIiIogODTCIiiqi33npL7iKE1YQJE5CRkYG8vDwMGDAAmzZtgk6nw9KlSzF79mwMGzYMarUaubm5+PTTT5GamuoINJ1TT5OSkpCYmAgAKCkpwapVq/Dggw9iyJAhWLt2rejyXHfddbj//vvx6quvCtb/3//9H2bPng2VSgWNRoOf//znmDlzZkD3qlAoBPNWSi0jIwPDhw/HsmXLMHPmTEfQ3N7ejnfffRfNzc0BvRUlIqLIYJBJRESSWLZsGQAgMTHRETxJqaCgAPfff39ErwnYAsUPP/zQbX2fPn3wyiuv4JVXXnHbdurUKQC2QYzsnN/E9unTB5988klQ5UlLS0N7e7vb+nvuuQf33HNPUOe0+8lPfoKFCxfiySef9Lg9MTERe/bsgVIprjeOvzaiVCrx5ZdfoqysDD/84Q9x7tw5WK1WaDQaTJo0CVu2bEFaWlrwN0RERJJQWH1NREZERBQi+//NOM95KDWLxSI60Ik2zz77LBISEvDb3/5W7qJEVCw/MyIiEmKQSURERERERGHDnwyJiIiIiIgobBhkEhERERERUdjE1cA/dXV1cheBJJCeno7m5ma5i0G9GNsgyY1tkOTGNkhyYxuMTjk5OR7X800mERERERERhQ2DTCIiIiIiIgobBplEREREREQUNnHVJ9OV1WqFyWSCxWKJ6PxsFF4NDQ3o7Oz0u5/VaoVSqURSUhKfNxERERGRTOI6yDSZTEhMTERCQlzfZtxLSEiASqUStW9PTw9MJhP69OkjcamIiIiIiMiTuE6XtVgsDDB7mYSEBFgsFrmLQURERETUa8V1kMmUyd6Jz52IiIiISD5xHWSSOO3t7XIXgYiIiIiI4gSDzAhZtWqVYHnDhg3YunWr1/27urpQVVUl+G///v0wm81Yvny5YN+amhpUVlaisrIS1dXVAICysjIAQGlpqaAMd911F+666y784he/wH//+18AwKxZs8Jyj0RERERERAwyI+Srr74SLJ86dQpnz571uv+5c+dQWVmJX/3qV6isrMTzzz+Pzz//HF1dXdi9e7dg35kzZzqCzEceeQSALfAEbAPh2D300ENYu3Yt1q5diwcffBC7du0CYBuV9Z133sF3330XlnslIiIiIqLei6PiOKmurkZpaSlaWlqg0+lgMBiQl5cX8nm/+OILGI1GlJeXo7CwUNQx/fr1w9SpU/HFF19g6tSpqK2txeTJkx2jpvb09EClUkGhUCAzMxPTp08HAGzatMnrOd98800cOXIEAHDmzBncfPPNjm2XXXYZdDpdkHdIRERERERkwyDTSWlpKcrLywEARqMRJSUl+Pjjj0M6544dO7Bu3Tps2LABc+bMwZQpU/Czn/0s5LIuXrwYV199NSZOnOhxe1tbm+Ne7L766iv8+c9/9rj/woULcfPNN+O2224LuWxERERERNR7Mch00tLS4nM5UN3d3fjnP/8Jg8EAjUaDP/zhD/jrX/8Ki8UClUoFpdJ7tnJ1dTX+8pe/YP/+/XjmmWewf/9+NDQ0YPz48QCABQsW+Lz2uXPncOjQIcG6AQMGYPbs2TCbzTCbzVAoFLjssssAAGvXrg3pXomIiIiIiAAGmQI6nQ5Go1GwHIrExETMmzcPBw4cwObNmx3r//SnP0GlUuGaa67xeuyQIUOwYMECj8Hk//7v/wqWe3p6YDKZHP8GgIyMDEydOlWQPvvcc8/BZDIhKSlJEOA63zMREREREVEoGGQ6MRgMKCkpEfTJDIfc3FxMmjRJsO7TTz/FN998g2uvvdbnsS+//DKmTp2KzMxMx7rExETBPuPHj8fixYsBAFdffbXXcymVSphMJjz55JM4efIkLBYLEhMT8ctf/jLQWyIiIiKKalKNtRFt15ST8/0mJyfDarWio6OjV9w7+cYg00leXl7IfTA92bt3L5577jlotVrHuo6ODq/9KZ01NTWhs7NTsO7VV18VLD/88MOiy/Lcc8/h3nvvxejRowEAnZ2duPvuu3HppZc6BhUiIiIiinVSjLURjdeUk/P9OusN906+MciMAKPRiPvuuw/XXXddwMcOHDgQv/rVr9wCwOnTp2Py5Mlejxs8eLDH9RkZGSgvL8eQIUOg0Wiwd+9eWK1WqNXqgMtGREREFK3CPdZGtF5TTr7uL97vnXxjkBkBo0ePRllZGdasWSNYL2Y014cffjigN5V2TzzxBABg/vz5gvW//vWvsWbNGvzmN79BZ2cnLrroIrz88stQqVQBX4OIiIgonMKZbhrusTai6ZrRkpbrer+u26j3UlitVqvchQiXuro6wXJHR4cgRZViU0JCgmNAIzH43Cnc0tPT0dzcLHcxqBdjGyS5RaoNFhUVCdIvCwsLg065rKmpcRtrQ+pALFLXDGc9hcL5fqXuk8m/g9EpJyfH43q+ySQiIiKiqBDOdFOpxtqIhmtGS1quHHVMscH7RI1ERERERBHkmmLJlEvPWE8U7RhkEhEREVFUMBgMKCwshF6vR2FhYdimk4s3rCeKdkyXJdHa29uhVCr9TnVi74dAREREFAimX4rDeqJoxzeZEquvr0dlZSUqKytx7NgxAEBZWRkA29xCdlVVVdi6dSu2bt2Kbdu24cyZMwCABx54wOu5Dx486DhnIH7zm98Ilnft2oXt27c7lj/66CPcdddduOuuu3D33Xfjr3/9KwDgk08+webNmx37vf/++7j77rsd+/39738HADz22GOiyvHvf/8b//nPfxzLnurFbuPGjXjsscfw2GOP4ZtvvhF5p0REREREFGkMMiVWV1fnCDKLi4vR1dWFmpoaABCMmHr27Fk0NTWhqakJ27dvxxtvvOG2j6vVq1cLgkOxjhw5Ilg+fvy4YPjpm266CWvXrsXatWvx6KOPYv369fjrX//qFtxt2bIFK1euxNq1a7Fy5Ups3bpVdBmWLFmCQ4cOYefOnViyZAkAeKwXAHj88cfxxhtvoL6+HvX19Vi5ciU+++yzgO6ZiIiIiMKruroaRUVFmDBhAoqKihzf5ey2bt2K4cOHY8iQIRg+fDi2bdsmU0kp0pgu68TSVA/r6uVAWyuQkgpF8RwoM7JDOmdhYSEKCwsB2D5oarXa436XXXaZ49+7d+/GF1984fO8RqMRzc3N+PTTT/HjH/9YdHrqvn37sHv3bhw8eBAXXXSRz32tVitWr16N2bNno1+/fjhx4oTbdvv8miqVCs6z4bz++usYO3YsfvCDH7id12KxYP/+/Xj88ccBALfeeivmzp3rFvzaLVmyBD09PWhubsb777+Pw4cP49JLLxV1v0REREQkjdLSUsdUKkajESUlJYI03hkzZqC9vR2A7SXC9OnTceDAAVnKSpHFINOJdfVy4Mh+20Lj+eV5z4d0zjfeeAOHDx9GQ0MDdu3ahd/+9rceg6kNGzagvLwcVqsVDQ0NGDt2rGNbeXk5cnJyMHDgQAC2N5Hz58/HihUrYDKZMHv2bCxcuBB6vd73/VmteOGFF/DBBx+grKwMK1asQN++fT3u29XVhSeffBI/+tGPYDAYYLFYcOLECcydO1fUfY8fPx5ZWVket508eRIZGRmO5fz8fMyZMwdPP/20276HDx/G+vXrUVdXhwEDBsBsNkOhUGDVqlW47bbbMHLkSFHlISIiIqLw8jeVSmdnp89lil8MMp21tbosnw35lL/85S9htVoxc+ZMvP/++8jNzcXDDz/stt8777yDl156CQCgVCqRmprq2Hbo0CFoNBoMHDgQf/rTn7Bz504YDAYMGDAAAPDiiy9i2bJlyM/Px7333uuxHF1dXXj88cdx++23Y+TIkZg/fz4eeeQRvPrqq277fv7551izZg0eeughTJgwAdOmTQMAR99Mu/T0dNx3333QaDTo7OzE97//fce20aNHe62TlJQUR59TwPYH6dSpUzCZTIL9Tp48ierqanz/+9/HT37yE8G2jo4ONDc3c5AhIiIiIpnodDpBlyvX72QajUbQDUqj0USsbCQvBpnOUlKBRpflEJlMJjz55JO45ZZbkJub63U/pVKJfv36uR0LAFOnTnWsu/vuu3HfffcJ9ktLS8Pvf/97n+VQqVS4//77HW/+hg4dijfffNOR7ups+PDh+Mtf/uK2LSkpSZDu++STT3q81pgxY3yWpU+fPjCZTDh58iQ6OzvR0tKCzZs3u/361dbWhtbWViiVSrS1tXk8V2trK4NMIiIiIhkYDAaUlJQ4fvR3nUrlrbfewvTp09HZ2QmNRoO33npLppJSpDHIdKIonnO+T+ZZR5/MUK1YsQK33HILrrzySp/75eTkYPbs2QBsAWdnZ6ejL6ezYH8BUqlUGDlyJLZv3469e/dixowZjiBSqVQKAsr8/HxYrVa89NJL2LZtGxISEtDd3Y2rr74aM2fOFJy3tbUVCxcuRENDA5RKJSwWC4qLi/2WZ9GiRfjd734Hi8WCFStWYMiQIaisrBTsM2TIEJjNZixYsEDQ3xMAsrOzsWzZsqDqgoiIiIhC528qlSuuuIJ9MHspBplOlBnZIffBdGUf3MYfb28iv/rqK8e/N23ahNdff93neR544AH86Ec/8rq9p6cH3d3dgnXXXnutx+uaTCa8++67jnVlZWXYvHmz4PwGgwE333wzrr76agC2XPtf/OIXuOKKK3zOp6nX6x3pwb7k5+fjvffecxtxdsaMGX6PJSIiIiKiyGOQKYPBgwcHddzEiRMxceLEkK6dnp6Od955B5s2bRKsHz9+PEpKShzLmZmZOHToEI4fP46srCzU1dXh8OHDuOWWWwTH5eTkoLy8HJdccgm0Wi327NkDq9Ua1BvXQOpFqeTsO0RERERE0Uhhdc1DjGF1dXWC5Y6ODmi1WplK419tbS0GDRrkc5+amhrk5eVFqERC33zzDdatW4fGxkZkZ2fjtttuEwzuY7d+/Xp8+eWX6OjowEUXXYQZM2YgOzv4qV9c6yUhIcHtTea3337rsSxA9D93ij3p6elobm6WuxjUi7ENktzYBklubIPRKScnx+N6BpkU9TwFmb7wuVO48f/YSG5sgyQ3tkGSG9tgdPIWZMZ1zmEcxc8UAD53IiLqbaqrq1FUVIQJEyagqKgINTU1chcpZrEuiUIX10GmUqkM6A0Yxb6enh721yQiol6ntLQU5eXlMBqNKC8vF4yzQIFhXRKFLq4H/klKSoLJZEJnZycUCoXcxaEgaTQadHZ2+t3ParVCqVQiKSkpAqUiIiKKHq5zTbsuk3isS6LQxXWQqVAofE6jQbGBOfhERES+6XQ6GI1GwbKz6upqlJaWoqWlBTqdDgaDQbaBBaOdv7okIv+YV0hEREQU4wwGAwoLC6HX61FYWAiDwSDYzhRQ8fzVJRH5J+mbzI6ODixbtgwWiwUajQb33XcfFixYgKysLADAzJkzkZmZiTVr1mDv3r3Iz89HcXExAHhcR0RERETu8vLy8PHHH3vdzhRQ8fzVJRH5J2mQqdVqMX/+fCiVSlRUVGDz5s24/PLLMWPGDMc+NTU1sFgsWLx4MdatW4eqqipotVq3dQUFBVIWlYiIiChuMQX0AqYOE0lP8nRZ+wivVVVVSE9PR2VlJZ5++mm89957AICqqiqMGzcOK1euxNixY1FVVeVxHREREREFJ1pTQF2nC/n6668lnz6EqcOB4ZQuFAzJB/7Zvn07Xn/9dYwbNw633347fvjDH0KtVuNvf/sbduzYgba2Nseby+TkZLS1tcFisbit82Tjxo3YuHEjAGDJkiVIT0+X+nZIBgkJCXy2JCu2QZIb2yCFKj09HVu3bg36eKna4K233ory8nIAgNFoxIwZMxzf+4xGI379619j8+bNYb3mmTNn3Jb5+fLO9RlJ8UzE4N/B2CJ5kHnZZZfhsssuw44dO/DZZ5/hhhtuAACMGzcO+/btg1arRUdHBx599FEcOnQIWq3W4zpPJk2ahEmTJjmWOQJpfOLosiQ3tkGSG9sgyU2qNtjQ0CBYNplMbtvDfd1+/fq5LfPz5Z3rM5LimYjBv4PRKScnx+N6SdNlrVar498JCQk4e/asY/nrr7/GsGHDMGzYMOzcuRMAUFFR4XUdEREREcUX176hGo3G5/ZwiNbU4Wjl+gycl5lKS94orM6RYJjt3r0bf//736FQKNC3b19MmTIFq1evhkKhwLhx4zBlyhQAwJ///GccPXoUAwcOxIMPPgilUulxnT91dXVS3QrJiL9ckdzYBklubIMkN6naYE1NDUpKShyD8DzxxBNYvHgxB+WJIq7PyPmZFBUVOVJpAaCwsFCykXn5dzA6eXuTKWmQGWkMMuMT/6iQ3NgGSW5sgyQ3tkHyZMKECYJRi/V6PbZs2SLJtdgGo5Ms6bJEREREFPuMRmPE0iKZghk7fKXSUu/GIJOIiIiIfJoxY0bEpv3gFCOxg/1byRvJR5clIiIiotjmmqbY0tIi2bVczy3ltSg0eXl5kvXBpNjGN5lEREQkKaY/xj7X+QmlTItkCiZR7GOQSURERJJi+mN0CSbof/PNNyOWFskUTGnwxx6KJI4uS1GPo4mR3NgGSW6x3gYjOQIl+RfMtBOx3gYpstONSIFtMDpxdFkiIiKSBdMfowv7PPZOfO4USQwyiYiISFJMf4wukQr6mZ4pTqTqKZp+7GHbiH9Ml6Wox/QIkhvbIMmNbZDCqaamBiUlJWhpaYFOp4PBYEBeXp7PY4Jpg7GenhkpkaqnYJ67VJiyHT+8pctyChMiIiKiXiRS004wPVOcSNVTNE03wrYR/5guS0RERERhF03pmeEiRZpnPNaTJ85119jYKNgWTffMVN7wYLosRT2mR5Dc2AZJbmyDJLdg2mA0pWeGixSprfFUT9XV1SgtLfV4L651l5ycjMzMTElTtoPBNO/AMF2WiIiIiCImmtIzw0WKNM94qif7nLgAYDQaUVJS4rg317rKzMyMyqmMmMobHkyXJSIiIiISobektgbLV4AWK3UXK+WMdgwyiYiIiIhE4HQ8vvkK0GKl7mKlnNGOfTIp6rEvEsmNbZDkxjZIcmMbJDGk7F/KNhid2CeTiIiIiIgkE0/9Syk0TJclIiIiIqJegVOURAaDTCIiIiLyi1/OKR7YR8A1Go0oLy9HSUmJ3EWKSwwyiYiIiMgvfjmneMApSiKDQSYRERER+cUv597xLW/s4BQlkcEgk4iIiIj84pdz72LlLa+vYLi3BMqcoiQyOLosEREREfllMBjcpqcgm1h5y2sPhgHAaDSipKTEMRqsr23xhCPgRgaDTCIiIiLyi1/OvdPpdDAajYLlaOQrGI6VQJliA9NliYiIiIgQfMporKRg+kp5jsV06N6S4huLFFar1Sp3IcKlrq5O7iKQBNLT09Hc3Cx3MagXYxskubENktx6SxssKipypIwCQGFhYVy9va2pqXFLec7Ly/O7LRp4aoPx/rxiQU5Ojsf1TJclIiIiIkL8p4z6SnmOxXToeH9esYxBJhERERHFterqapSWlqKlpQXJycmwWq04c+YMTp06hbS0NGRlZcFgMPjtW+l8nmh82+dPrJffVaz0he2NmC5LUa+3pOhQ9GIbJNchiQcAACAASURBVLmxDZLcYr0NuqZVemLvS+krZTTW0zNjufye2mC0p/j2BkyXJSIiIqJeSUwaZUtLi9+U0VhPz4z18ruKxRTf3oKjyxIRERGRLCI1OqiYNMpg9om19MxYL78vHGk2ujBdlqJerKfoUOxjGyS5sQ1GRrz1VwsnqdqglOmbzs9Tq9VCoVCgvb3dZ59Mf89b7vTMUNuolOUP5+fH0lQP6+rlQFsrkJIKRfEcZI4c7bMNxnIqcCzzli7LIJOiHr9ckdzYBklubIORwS+p3knVBidMmCAYuEWv12PLli1hOXc8Ps9ovqdwls1cNhc4sv/CCk0SlLp0WPokQ1E8B8qMbLdjpGxL5J23IJPpskRERESIv/5qsUDK9M14fJ7RfE9hLVtbq3C50wRLfS1wZL/tDacH8ZwKHIsYZBIRERGBX1LlYDAYUFhYCL1e7xjdNVzi8XlKeU+h9mkMZ9k6E9XeN7ad9bhayrZEgWO6LEU9pomR3NgGSW5sg5Ehd3+7aBaLbdDT8xzUJ9Gtr5+n1MtoJWUbDTXdNZxlK765CPer2qBTJyAjKQGpCU4TYuSPgGre0qDOS+HHPpkUs2Lx/9govrANktzYBklu8dIG3fr65RdANe95+QoURaKpT6NzWQYlqbFyrB46dQI6lCqMWfFGTP0wEO/YJ5OIiIiIIiaY9Mvq6mpce+21yM/PR35+PiZPnhzeqShc+/p5Sb2MJ2KfQzSlFztfu9bUhSnb9mPiV3vwVGsiA8wYIembzI6ODixbtgwWiwUajQaPPPIIPvroI+zduxf5+fkoLi4GAKxZs0bUOn/4JjM+xcuvpxS72AZJbmyDJLdg2mAw6Zeux4g9zhvXaTXeK9RDU3vhbV1vSL0U+xyiKV3cXpaGhgbHNDODBg3Ciy++yBT2KOPtTWaCx7VhotVqMX/+fCiVSlRUVOCLL76AxWLB4sWLsW7dOlRVVUGr1YpaV1BQIGVRiYiIiCiMghlt1NM+oYxSWlpa6giwjEYjZimBVy8vsL3BPN8nM96JfQ55eXlRMx2Kp7Lwx7bYImmQCQBKpRI9PT2oqqqCSqXCuHHjsHLlSlx//fXYvXs3tFqtqHUMMomIiIhih06nE/TxE5N+6XqM2OO8cQ2oqppbel0fzGCeA1GoJA8yt2/fjtdffx3jxo1Ddna24y1lcnIy2traYLFYRK3zZOPGjdi4cSMAYMmSJUhPT5f6dkgGCQkJfLYkK7ZBkhvbYGwzGo2YMWMGmpubkZ6ejjfffBN6vV7uYgUkmDa4du1at/v2d461a9fijjvuwL59+wAAI0eOxNq1a4Nu/1lZWYIAKysrq9d9loJ5DtFIbBuMh89bPIjY6LI7duxATU0NLrroIowZMwaHDh3Cd999B61Wi9zcXL/rpkyZ4vca7JMZn5geQXJjGyS5sQ3GtlCnhogGsdoGo6mfIYVGbBuMh89bLJGlT6bVaoVCobBdKCEBVVVVaGtrw5gxY1BRUYHhw4dDq9Vi69atftcRERERxaJg+iZSeERTP0OKDH7eooOkU5js2bMHCxcuxKJFi/Cvf/0Ljz76KHp6erBgwQI0NTVh9OjRGDZsmKh1RERERLEo0Kkhgpn6g0gOwbZVS1M9zGVzYZ7/EMxlc2FpOhG2MkXTVCy9WcTSZSOB6bLxKVZTdCh+sA2S3NgGY1ugKZvRmO7HNkieBNtWzWVzgSP7L6zIL/A7IJPYNsgU6ciSJV2WiIiIqLcLNGWT6X4UKzRnT2P9+BHQJSagpbsHS5tPizuwrdVl+WzYysQU6eggabosERERxT+md4aXa3pfY2NjVNRpoM+Z7SL+LRrSH5empSA/JQmXpqVg0ZD+4g5MSfW97APbVWxguixFPabokNzYBklu0d4GozG9M5bV1NRg0qRJaG9vd6wLd51WV1ejtLRUdEpheno6fvjDHwb0nNku4p/pt/chsaXJsdyty0DSc3/ye5yl6QSsq5fb3mCmpEJRPAfKjGyfx9j/DrJdRRemyxIREZEkmN4ZXnl5ecjMzBTM7xjuOi0tLXV8UTcajSgpKfH7RT3Q58x2Ef8S++sApyAzsb+4QXaUGdmAnz6Y3rBdxQamyxIREVFIeuNojlKn7Eldp8F8UQ+0TL2xXfQ2iuI5QH4BkJkD5I+wLUuM7So28E0mERERhcRgMLiN5hjvgnkTGAgp67S6uhqNjY2CdWK+qAdapt7YLuwCTUeOVaG8kQyWa7v65S9/ieHDh6OzsxMajQZvvfUWrrjiioiWKZwsTfXnU4lbRacSRyP2yaSoF+19kSj+sQ2S3NgGo8+ECRME6ax6vR5btmyRsUTiufZpS05OxsaNG/32yWQbFI/9BsPPWxscPny4oP9ycnIyDhw4EMmihVUw07vIyVufTKbLEhEREQUollP2XFNjMzMz4/Itm5zYbzByOjs7fS7HHAmnd4kkBplEREQUd6ToM+l8TpPJhNGjR0Ov16OwsDCmUkGDDZAjNXVEPExR4a2O4+HewiGc9aDRaHwux5wQpneJJkyXpajHFB2SG9sgyY1tMHBSpCvGSwpkTU2NW19Jf28yg5nCJFjxUM/e6jge7i0cgqkHb38Ht23bhunTp8dRn8zAp3eRE6cwISIiol5DinTFeEmBzMvLCyqwidT9x0M9e6vjeLi3cAhnPVxxxRUx3QfTlRyDKUmB6bJEREQUd6ToMxnL/TDDIZT7DyQ9MhrrOVzpnVLcWyym4Lre99GjR5Gfn4/JkyfHRPnJP9WiRYsWyV2IcGltbfW/E8UcrVaLjo4OuYtBvRjbIMmNbTBwV155JSoqKpCUlIShQ4fCYDCgX79+UXfOWKHVajFu3Lig73/69OkoLy/H6dOnUV9fj4qKCkybNs3jvtFYz4GU3xcp7i1cZYskez20tLTAbDYDAMxmMxobG72Wn38Ho1Nqquc+o0yXJSIiorgTbEpopM8ZS0K5/0DSI6OxnsOV3inFvcViCq69HlynAgLkL3+8zFMpN6bLEhEREZGkojEFNhBiyy9H6qrYslma6mEumwvz/IdgLpsLS9MJycvmj6eyyt02rKuX2+apbKwDjuy3LVPAGGQSERERhSAW+8RFmsFgQGFhYUxO+VJdXe0YuVSj0WDUqFGC8js//5/+9KcoLy+H0WhEeXk5SkpKwl4W17bmXLejR4+GyWTy2BajMXgyGAwYNWqUo25Hjx7t1jbs9zxq1KjIfL7iZJ5KuXEKE4p6HLqf5MY2SHJjG4xuvWFait7cBv09X9ftzvR6PbZs2SJbWZy3m+c/ZAsw7TJzoHp2VdjK5kk4Uk8j/fkyl821BeN2+SOgmrdUsuvFOk5hQkRERCSBWOwTFwnx0rfN3/P19bzDnfoZaFkEyympQCOEyxJzvD0FgMbzywFOzxGuz5fY9qgonuM2TyUFjkEmERERUQh0Op1g8BK5+5RFi3AEGHKorq5GaWkpWlpaoNPpkJycLNienJyMoqIix3atVuu2PTMzEzqdLuxpwf7amq/t4QyeXOvIYDAgLy/PfccwpJ7a72lwkhovjdNjYGoKzGVzA/7RQmx7jJd5KuXGIJOIiIgoBAaDASUlJYIv3ISY7dtWWlrqSM80Go0YNWoUCgsLHc/XZDIJto8ePVqw3WvAFQb+2pqv7eEMnlzrqKSkxHMKaxjentrv6Zm+PRjd53zoYu9TGsj9xGh7jFUMMomIiIhCEI1TbkQFGdIzw8E1HbOjowMbNmxwLE+YMEGwvb29HV988UVEyuavrXnaLkXastgU1nC8PbXfk3XBTFjqay9sCDRIjNH2GKs4uiwRERERhZ2ieA6QXwBk5gD5IyLWty3U0X79TQkSDdOxBHKPUowqK7YOlBnZUM17HqpnV0E1b2lIwa2qb3/higCDRLnaY2/F0WUp6vXmEe0oOrANktzYBklusdQG/Y1G6u/NXk1NjVvKqXP6q7/tkRDIiKtSjCorRx307+nCyaVPCt6KxuJAUvGGo8sSERERUdzzl8rpbwCYYFJSIy2gEVclSBOVow4SsnOg4oA8MYPpskREREQUN/ymcsbBADCBpOzGS5qo0WgMKQ2aIotvMomIiIhinOgpJaKsTJ72sVqtotZ5uz9fI6xWV1ejrbYOBWqnA1ze7IVSl1I9B9fzPvHEE1i8eLGoEY1jeUoO59TmY8fr0LBnF2pNXb5HtA3zdZmaGxz2yaSoF0v9QCg+sQ2S3NgGyZ9A+ugFI5g2KKZMnvYBIGpdMPdXVFSEhj27sHKsHjp1ArrUSRj5wmuCACKUupTqOUj9fKOVuWzuhdRmADta2jBl234MTlLj1SsKMPp7QwC1BlAqAJMp4IDQWzDpel3kFzBV1wv2ySQiIiKKUwH10YsQMWUKZh9v68SWqdbUhSnbbAGEXq/HFpeAJJS6lOo5ROPzjQiX1Gad2ha6vDROj9HaROGARoDHPra+eO2fGwcp1XJjn0wiIiKiGOfaJy85OVn2/mti+g162kfsukiWyc7SVA9z2VyY5z8Ec9lcWJpO+D021ClVPJ03OTkZ1157LfLz85Gfn4/JkyfHZR/FzkS1YNmUqIZer8fA1BTvB51p8fmMBE67BOunT9r+13VwJM6pGTDVokWLFsldiHBpbW31vxPFHK1Wi46ODrmLQb0Y2yDJjW2Q/LnyyitRUVGBpKQkDB06FD09PaisrMTp06dRX1+PiooKTJs2LejzB9MGXctkMBjQr18/v/tcf/31butuHH8Zbms4gIf0WbhjaC5+Pn8R+mYPDPg+gi2TfR/Lyt/Z3ny1twKnTgLGg1Be9VOfx5aWlqK8vDykZ+Hp+e7ZswdmsxlmsxmNjY0hP+No9PCKVzCwsw0mswWH20344zkNPtzwT6Ts+9ZW/56Ye4DmhgvPaP8eKCf+zOOu1o/W2va3s1igvP42oOASwHgQSFQDWTlQFM+BItlHYNuLpaZ6DsCZLktEREQU41ynlJgwYYJguxzplWKmuXDdx95H7oMxOUDKiAt95Na+jGw1AKhsO372HvD/vh+RMgn4SaP0dGw4Ul39Pd9gzxvtqppbMMVodCzr9XoAthFzbX0pzwIqJXCyCejpARITga4u4UlOHPN+gZS+QKdJuIzYHiwpWjBdlogoCoQjnYqIolskP+ee0jb9pXpGA0cfucY64Mh+2zIgaR+5gJ5LEGmU4Ur19XeOcJw32mi1WgxOUmP9+BHYdPUovKLvB0vTCSgzsqGa9zxUz64C+iQDXZ2AxWwLGK0W8Rfol+Z7mYLGIJOIKArY06mMRiPKy8tRUlIid5GIKMwi+Tk3GAwoLCyEXq9HYWGhbRoQbwHceVHxY5drMFlz2BYMS9hHLpDnEsyck56eRagMBgNGjRoFjUYDjUaD0aNHh+W80UahUOClcXpcmpaC/JQkXJykgnXBI8IfSVzbjMolUTNnsPfzx8kcotGI6bJERFGg144cSNSLRPJz7ilt0+znbaA92AIQ9nkIRc87mJIKNDot93TDunq5MD3y/PHhEshzCSaNUkyKbqDy8vKwYcOGsJ4zGrW3t0On0wpX9nRf+JFk3vPubWbgYNu0JiLaCtNipcMgk4goCuh0Ohid+p3EY9oTUW8n++fc9cu4y9tAKYNgr1NFuFAUz4F1wSO2QMKu7aykwYDszyVKiP4hIIJ0Oh1autuQ72nj+R9JPP0AIXe5iUEmEVFUMBgMKCkpQUtLC3Q6XVymPRH1dnJ/zv29DQw02KqurkZpaangfvLy8jzvLLJPpTIjGx1ZudAcP+pY16nWQOtx7/CYN28e7rnnHnR2dkKj0eCJJ56Q8GqBc65nrVYLhUJx/g2fnzoPkOsPAaY/lOGOb43inm+Q/LUhg8GA380qgaajG8P7JEKjcDrY8SOJ9fx/nkVj8OxJrJRTLIXVavX+VGJMXV2d/50o5qSnp6O5uVnuYlAvxjZIcmMbpEioqalxC4LtX/g9tcGioiJHei0AFBYWek0LNZfNvRDAAED+CKjmLfW4b/HNRbhf1QadOgEt3T14vScFqz8Mb7qps0DuQw6u5XPmWtZQAhXz/Ids/XXPO94DjN8gbb0EUvf9e7pwcumTbm8s3dtWAVROb739bY8WsVJOVzk5OR7X800mEREREQXcdzCQ9NpA+lR6m7ZCKnL3ifcXGPoqj+s2sWnJHrmkU5/q6hZslqJeAqn7hOwcz0GXv7fkEo5MHFaxUk6RJA0ym5ub8frrr6OzsxOZmZm47bbbsGDBAmRlZQEAZs6ciczMTKxZswZ79+5Ffn4+iouLAcDjOiIiIiLyTUwaa0CprrANBHTXXXcJ9g8kvTaQPpWR7iMp9fX81bW/wDA5OdntnIOT1HhpnB4DU1NgLpt7ITANIVBx/SHg5f/uF2yX4jmEpe5dguPdR6vxVFHRhXr20xc5asRKOUVSLVq0aJFUJ1cqlRg/fjwmTZqEw4cPo1+/fgCARx99FBMnTkRycjJqampgNBoxe/ZsHDlyBEqlEh0dHW7r0tPT/V6vtbXV7z4Ue7RaLTo6OuQuBvVibIMkN7ZB8sfSVA/Lyt/B+vl61H30N7xTvgs1zSdRX1+PiooKTJs2TbD/9OnTUV5ejtOnT3vdx9mdd96Jb775RrC/wWBARUUFkpKSMHToUBgMBsd3vVBceeWVkpxXruv5q2vr5+uBdqfvsIlqKK+5wbH49ttvo6mpybHcp08fvH3FCIzt2wd9lQBOnQSMB6G86qewbt9sW7bLyoHyqmtFlVORnALlVT+F8poboLzqWoz9ofTPwV/dO7frrv9shPmiUVAkpwhPUnAJYDyI403NOHCmDTN3HML+Y7UX6vn8diSqgawcKIrnuJ8jGsRKOV2kpnoOhiV9k5mUlCT4t8ViQWVlJZ5++mmMGDECd9xxB6qqqjBu3DisXLkS119/PXbv3g2tVuu2rqCgQMqiEhEREcUs57dhBWpg5Vg9pmyzLXtKQQw0RdS1P2ZLS4skU3MA0kz5IcX1xPZ/9FvXft5guf7AlJ2djdHfGyLoP+lrpNVgiamXUAer8XcN53bd3VgHeEj/tb8lv3PCBMFbUXs9x8o0JbFSTrEi0iezvb0dzc3NuOmmm/Dcc89BrVbjb3/7G3bs2IG2tjZotVpYLBYkJyejra0NFovFbZ0nGzduxMaNGwEAS5YsEfW2k2JPQkICny3Jim2Q5MY2GHlGoxEzZsxAc3Mz0tPT8eabb0reNzAUTefaYXFa1qkvfMXLyspyaz9ZWVmCL+Se9nGWkZGBQ4cOid6/N2h54Ql0O6W5JvxlJXRLXnPbz19d98x9FmdXLIL57Gmo+vZH30cXIcFpu6fjE9N0tqDrvMQ0HXTp6UB6OrDsz+G8TZ/E1kGwXNu18lyb13YXaJsmaUk+umxPTw/efPNNTJ06VfA69eDBg9i3bx/UajVyc3MxZswYHDp0CN999x20Wq3builTpvi9FkeXjU8cVZHkxjZIcmMbDD9//eSifcRRV64jU1Z1AQ8e9t7f0tdIsp60tra69ckMx3QWsThtg73trOxvxmCN6sKGzByonl3ltn+gdS3m+EF91FExN6SnEWnvPBi+NuJpVGJF8WyPbSbUeqbgeBtdVtIgs6enB2+88QZuvPFGZGdnw2KxQKlUAgDeeustXHrppVCr1di6dSumT5+OdevWYfjw4dBqtW7rLrnkEr/XY5AZn/jliuTGNkhyYxsMP39B5ASX1Du9Xo8tW7ZEtIyBsDSdkDTo6N/TeX76CPHBoJgAMhanbbC3nfXjR+DSNKc+cz6mZYlXrs9vx6k2TPnathyOH2bMVbsAwzNAdzegVgOPPAl88FbMtRkgNn9QEUOWKUzWr1+PXbt24fjx4wCAUaNGobKyEgqFAuPGjcPFF18MAPjqq6+wYMECDBw4EFOmTIFSqXRbR0RERBQu/vrJRXqE01BJ3Z/r7IqnA54aQ9R0GkGMhir3l3V7W5m104iVY/XISu6DwSMvDqn/Y6xy7gO6+2g1Zu107xPpLOBn98FbQKfJ9m/TOeCDtyWf6kOq9hXS9DIxSNIg8/bbb8ftt98uWHfbbbe57XfvvfeKWkdEREQUDv6CSIPB4JZ6J1ag04PISWxZzWdPC1eI+GLffboFiYLlk1C57hTEtA1yf1m3t51aUxembNtve2PXy95g2jn/uPFUURFqTV2ObZ5+mHF9dt89+kssaE10a3eOQO/oIeEJag67nbOqtg6pNTVh+4xJ1r7ibB5MfyIy8A8RERFRNPEXRIYywmlpaakjFddoNOKZWSVYdfmIqEyTcy1rSUmJx/tW9e0PS33thRUigsHDJ5pQoBYuj3LZJ6jRUGX+sh7KDxDxTFS9uDy7frBgvroNWFgC8/ARjs+GINBz1tPt+Kepx4zdrecwa6cRWV7abVCkal9xNg+mPwwyiYiIqNeRcpoM1zTBkuTusL4ZCWc6n9ipTPo+uuh8n0zxweDC6tOYOyABOnUCWrp7sLS5B+tc9gkqzTeAL+tSpD5GeoqVSJF6OhIAbs9ugDoBeVqNbeHIflhXLQGeWuEe6ClVgEoFdF94U1pn6nb0/0z0MwWPM7/3KVEwGM7pZWIBg0wiIiIihC/N1TUVN02dKNwhxDcj4UznE9v3NCE7J+DBVbr69seUbcLBlcLB05d1b4GDlKm1sZQWLYYUdeVaR688swjZn72H4weqUN/ahtF9tcID6o7Z/tc10PveMCQmJqJ7/27HqpbuHgDA4CQ1Xh2qg+m39+HwiSYsrD6Nrr79vT4Pf/cpVTAYb/Ng+sMgk4iIiAjiU0f9cU0bTP+eHqi9EMiF/GYkjOl8UqZ+SnVuT1/WBaOcOgcOIuoq2Dd44Wov/kQsmJUgTdS1jh5+apGtjmpq8GxJCd5TeJ7kwlOg1zdN53ib3qnW4PUmI/R6PV4dqrOlZbfY0rPnDkjAlG3l3p+Hn/vsbcGgVBhkEhEREUF86qg/rmmDnqYXCUkY0/kG9UnEB+Od+ov2Ufs/SKSIppV6CxxE1FUgb/CcA9JnUrvxQJLaMdhNsO3Fn0gFs1KkiTrXyeAkNZ5J7YZ5/kPITUnFh396DdY/lgl/gMkeBMBzoJeQnu54m64FsPr8evPjxcDJCwXPTEp0u7ZAL+sbKRel3AUgIiIiigauqaLhmrZEmZEN1bznoXp2FVTzlobcJ1BRPAfILwAyc85PTh980OoIsBrrbH3iVi8PqWyycQ0UzrTAPP8hoKsLyMsX1FV1dTWKioowYcIEFBUVofu0SzDi4w2ec32N1iZi5Vi9Y5tU09w0NDT4XA6XcLYrO+c6eWmcHqO1iYK2ppg5T3jNmfMCOr+lqR5oaRKsS0tUuV3bmRT3Se74JpOIiIgIsTNqaFjT+WJwWgVP6a3119+B08ufRorVjAGJKmg7TbZgBgDyC6B6doXj+NKiIsGbwcNphYJRcH2+2XKpr4F9U6DX6yWd5ubUqVNuy1Kk0AbTrgTPQq0BlArAZHI8F+fP1MDUFOHBbWdDbsvW1csBqzDlttWiQGFhodfnwXTYyGCQSURERIT4HTXUpxhMHfSU3jrz6ypH4Ljp6lHIT0m6cIBL4OyaRrmw+jT+OvkKcenMLvWVm5yErz5YF/Db6UBSYNPS0tDe3i5YjlgKrR9epxo5/1zy5j3vKJeg3ywApKSGPvqv648kAHJGXuyYt1SK0YVJHAaZRERERL1UTE6r4OHtq3Pg2NLdg3zn7S6Bs+uIul19+zv6+tmCkmUwewlKFMVzYH16FtBpsq3oNMG64BGY8/IDCmAC6f+blZWF2tpawXK4+g+HzEOQ53Cmxf1NZ16+4E2ndfWy0Ea0df2RRJMkaMNSji5MvrFPJhEREVEvFe7+ooFy7R9ZU1Pj/yDXt60pqYL+d7N2GrGvCx773FVXV8NkMkGj0UCj0WD06NGCtErXPqrlj9yNyy+/3FE2ZUY20M+lr1+PbR5U69OzYJ7/EMxlc2FpOuHzFsT0/7XXTUNDA5KTkzFo0CBHGqjr/o2NjeLqzoewPAsn5uZGmJ965EJ91hrRabbill11+NGnX+Pm+x4IqD+sJ279KxeuxLGOTsd9HD/g8pY1BtLB44XCarV6Hjs4BtXV1cldBJJAeno6mpub5S4G9WJsgyQ3tkGSm1RtsMipfyRgm0vTX9qnp9F6a891ufWn9dRH0d/1zPMfutCXE8CRNhMmfrVHsK9b2qcn+QU+5xWtqanxW15fZa2pqcGkSZMEabRi6s6XkJ9FcwNgMfvc/3gPMH7DhWtsmOTSHzZ/BFTnU11diW2DzvexfvwIXJrm1BfUx/kpODk5OR7XM12WiIiIiGQRTNqnp4Fb8gBRAZbf67mkX7Z097jt60gxrjlse4vpiZ83ZmL6//oqa15eHjIzMwVpv6GmzIb6LMQE36e6hPUVUH9YP+ypuSv7m9EwfgRm7TRi1k4jXr2iAGO+N0T0+dmPMzwYZBIREREFSYpRPoHQv+gGc7xU9+Lr3K79I/1NAxJsGe3HuWa9uV5PUTwHex97AJouE1q6ezBrp6eyWW3/9e0PtLcCKX1tQZK9nybgNY3U/ly6T7fg8IkmLKw+ja6+/T3eh7+6CbTu/PF3Pn9tyrnuMpISkJrgFGYkJAJ5+Xj5v8Ig1Lk/bKjsqc6DNSoM1qRg5Vg9pmzbjwWtifj42VUBnwcA+3GGgOmyFPWYJkZyYxskubENRq9gUgzFcHsr5Cf9MhzH+7oXT20wkEDW27nFpI2KLWMg9+bcH9P1evYyNTQ04NSpU0hLS0NWVpZjX091qyie7ZbC66kuXI/d0dKGKdv2e7wPf3UTaN25cg3Yn3jiCSxevNjr+cS0qeOV3+L08kXoazWjf6IK6jQdEgZkOOojlDL7+ztofrwYOHnhNXRdlxnFJ3pgtVrR0dEh+nquKdPIzIEqgCC1t2G6LBEREVGYSTbKZ6jzVwZxfKD3EsgbH2/n9pQ26it4Dba+XffLycnxGpwOOMi/cwAAIABJREFU6pOID8aPANpyPAeMHupW9NyLLsfq1Akeywf4T6kNdcod12lQFi9e7Pt8ItpU9mfvIlsNACrbigGZgkBU0mmCXMqTk5oMzSlT4FO9xOC0PtGIQSYRERFRkMKdsgjYgiyc8dBXMBBBfFEO+F4CCGQDObev4DXY+g7X9QGEFoR46fMZjnYjhnMA/0xqNx5IUqPW1AUA0Jw9bXtb6e3NtJj79tEm3KYzUSps05k4/zuUPpDJqcKU5eRUtLQIsxzF/CgRk9P6RCFOYUJEREQE25dgc9lc0dNQAIDBYEBhYSH0er1jeolAuU4dYfrjEuGXZZe5/8Rwm9rB6Xhv9xnwvXiYSsSbgM7tI1AJtr5Dvb7zM5rx7++w12TGsU4zqrqAE9dPc+zqbxoQ+3Pp1mWgqgtY2twTdLvxxVs5nKdoGa1NxMqxescxi4b0F0zfYl293GPZPbUpB5c2sPtoteP61j8uEUxngpoj7v8+sh/WVUuCujf0dwnU++tETRXjSpmRjdo7HxFMtRLq9DC9EftkUtRjXySSG9sgyY1tMDLMT//K9oXXblA+VAtXSH5d1/6CX19biFznXLMw9wkLpr+m5z6Z7lOJhGMUTvfyBTbtRKiDJnm6/i1f7xc8I2fX/6AQqy4fAbS1oqq2Dvdu2eV4OxiuPrqB8tZ31bW/4fEe4M6Dtv6RfxuZgcSWpgsnCaLd2dvE8QNVqG9tw6ydRtSaulBYWIgPchO9j8brLCERqlfed1ttb4Pe7i2UqW1cSdXXOh6xTyYRERGRLydqXZaPReSyril8p7q6kZuQeGFFuPuEhdrf8zzR/RADFGq6Yqijg3q6fsunP/e6f0lyt+N6BWo4RjUFwthHN0Be+666pLzmDh+BLW/YAnhz2VzAOcj00O78B/C2kXctZuF8mS0tLUBuVii35H4vLsv29mgvo3XFIuSmpOLDP70W8I8fkvW17kUYZBL1cpwPiojCQcrpL6JRKPfr+ne3IF3YX/Dl9kS8OrpAuj5hAfQptN/nmTNn0K9fv4g815CDV9cg+uhBmMvmQlE8B8c6Ov0+N0/Xd+7TOThJjZfG6aFLTEBLdw8y1InCfdUJguPk4K0Pqq8AXkxw7y+A9zaNiE6nA3IG29Ji7dQaoP8A4FQz0N11YX32oKDuzVsZTX8owx3fGgP6rErR17q3YbosRT2miUkr1GHyewO2QZJbLLTBeEgvMz/zqPBLcF4+VE95TpcN5X5d/+52DtLjjvLAvgSHIpA011h8rm7/v2aXX4Bbvq7yez+efnx1Trtcnd8fF2kuDGtiSUiE0ikNtKoLePBw+J5lMD8Gi5kqJJjz+pvew3X7sU4zZp1WwWAwYFAftcd2J7Y92v8O+rs3TynB4zcE1oZDnR6mN2G6LBF5Fqa0KSLq3eIhvUzx0OOi0zRDul+Xv7uars6IBm6BvCmMyed6yy8Aw++FgycBQNtZUffj6W1d3rznHc/I/PCtgr6FSqvVNiDO+XYzsngOtoQxIyiY9F8xU4UElVbs7y24y/bBF12EDxISgVcXw+olgAz0zbXfe3Mpw6kuYT9QMW1Y0qlWegmOLkvU2wUwOiBJw99ohESxIJhRHKONMiMbqnnPQ/XsKtTeWYKb73vA6+cypPuV4O9uoCPjiv27I/VzDeXvn9d7/uBt9wATAFJSxd1PgD++dnZ345avq3D8wSegmrc0/F1ORJbHW13a119++eUYPnw4Lr/8chQVFaH7tEuwJeJHZn8jzLpuh8Xqc8RaKbiW4eV2l3TmGPzbFIsYZBL1cqKGJCdJ2SfENhqNKC8vR0lJidxFIgpYOKbyiCb+Ppeh3G+wf3d9BWTOU1OI+TIv9u+O/T6HDRsW8H2KCXx//6tSzFe34Y3BWsxXt+F3s8T//fN2z67BkxUAEmwjm77yzCKfz626uhpVtcLuV87TcACw9S10cuBsB8rLy1FcXIzainLsuacIR6f/D/bcU4Tjld+Kvh+vRP4o4e2Z2tfX1taivb0dtbW1KC8vx+ETTcITiPqxw3r+P3e29NtlwkyArk7hThHIljrW0Ylbvq7Cjzbvxi1f70fx40/E1d+mWMF0WaJeTqrRAUm8mExHI3IRb+ll/j6XodxvsH937cECABiNRpSUlFwoQ4Bv38T+3bHfZzD9gsWkY5Ykd2O0NgUAkA9A0yFiigs7L/d8+EQTCtQXVisAW3przRFkf/aeo87sfRLNTn0SS0tL0bBnF1aO1UOntg3sY5+Gw17f9rRq465KnOzqxqydtgFiDh06hDMvPn3+2ioAwL7li5D7l+DaiaPP5JlTgCYJSE4F+uu8/ijh7Zl6e7YLq0/jr5OvCGiAKV/P1OO2AAaZCpW9vhQH9mO+ug2z6o+j3GjE4sWL4+pvU6xgkElEJDOOYkcUfaLxc+kzMAzwy3xE7k9E4JvmNjJrots+Xnm554XVpzF3QAJ06gTk9FEjSeWUuOdUBk9BUUtLC2pNXY4pSJy5TpVxbX4+OjuFb+qSrWbYA0wASLEKp/IIhKB8AJD7PZ8D83l7pq7r7br69g98oD8fI/d6et6KRxeFNB1NIOz1lZsA5KZdGNmWP9zKg+myREQyi7c0Q6JIkbI/s7fPpZx9qH31Jww0BTcif3dEpHmmf0/vc9kXb/fc1bc/pmzbj4lf7cHusx3ey+AhKPIVbNfV1Qme+UUXXSTYftFFF6FdoRKsazrXGXw7CfDttLdnal//A30ePrpyJLZc8//w+U/Gol9PZ8DtuDNRLVxhMV9IVfbwvJ37OUvSX9WZS33Zp5Lx9Uwj+XnubeMvcAoTinqxMHQ/xTe2QZIb26BnckyvIeeUHnJOqxBMGxQzNYW56jvbSLDd3UBiIlDyFFQFY0Iqq3M9FaTrsHKcHpquTrcyuE/hNQLH7yp1HJucnAyr1YpDhw4J3ljan7mn56E61YxTyxchqbvTkUpba+oKqp14Kp9q3tKg68X1fDta2hxvbMWWr/jmItyvasMl/bVQK53eVWXmeHxrGc6g0l8bdL2/3R3deKo10efnJJKf51icDkgMTmFCREREcUWO/sxy9qGWs99rz4njMC99MqA5FUX1PXUeCbbTbFsOcZwAsfWkKJ5zIShKSgK6upD76mJ8MH6E4P4mTJggSDe1P3NP17H0SUR2wQgc27cXcJo6I5h2IihfOFJNvbzpC6R8Vc0tmGI04pMrC3BJv+QLG9Qa2cd4cK2vMcVz8LGfNhrJz3NvG3+BQSYRERFFperqapSWlnp9cxdKv0J/5/Ym3H0Zgy1HpK91dsXTgc+pKOL6uUHM1ewYECeAgNcT56CoY9EsaI4ftW1oBCp/NQML29QwGAwBPXN7v8DBGhUGay70CwymnYQ9aHPpw9rS3eP4t6/yOdf3q0N1uLf+ONQKhctOwfc9DZdg6iuSfa+jsZ+3lFSLFi1aJHchwqW1tdX/ThRztFotOjo6/O9IJBG2QZJbb22D06dPR3l5OU6fPo36+npUVFRg2rRpju1XXnklKioqkJSUhKFDh8JgMKBfv35hObc3oVwznOWI9LUsn78Pq3MAmKgGLimEZeXvYP18PazbNwMFl0CRnBLQ9e8YmgOcOnlhp6wcKK+61ndZVv7OFvC2t9qONR6E8qqfiroPb+r/8gr6OmV/tnd1o2xbJSoqKmAwGFD/XQVeGp6BkuGDMP1iPVSjxnm8V+vn623lOs+sVKFSlxtyOwmLgksA40EgUY3OtHQ8W9cBs8Z/O3au73QV8MPcLOQnJSDBOdA81wHlDVMlLb4UfwfD/XmOlmtFUmqq50HG+CaTiIiIopKU04gEm7oW7pTVWEnXU/XtD0t97YUVKamipijxd/2gUkKDePvpz6mubuQmXBjZ1v6Wr6WlBXl5eVh1+YgL91pr9H6vLm8LB4+8GB+H0I8SkObNrRbAarEHutT3yEE5QEuTbVoYu55uxyizkg7uE2aRTEGPt2me/GGQSURERJIINRXUV3qZlOcORLSUQ+pr9X10EU4ufVIQDFpXLBLu5CfYG5muw7JsNXSJtvknX+9JEZ3iKAi0zrgExympAT0HT/u+3J6I+01tgrkxAVsdVVdXQ3HANjWGt3u1n1N99jQWDemPYdkZSPQxp6Wo+7TXs2sw//QsmPvpJBlcxyNPU8WoNUCty7Qo9lFmA32ekboPiiiOLktRj6MqktzYBklusdoGQx1N0ddoqlKeOxBiyuErAIrkiLH+ruXri7+nNuhv9NPainKcefFpJFvNaFeoMCg7EyktF6KVzkF6aBe+JKrsbtfSJAFOgdbN9z3g8zk47u3MKXQ0NaL5nAmNXbZgMmvUGBgMBpSUlKChoQGnTp1CWloasrKyHOvnq9twaZpTeqzLvQbaHr21Cfc6LbAFtI1evuMmqoG0dLfnFY4gzl/gbF29HDh6UNgfMzMHqmdX+T23p/v0N2dnpP4ORrKfdDwIaXTZgwcPYsiQIWhpaUFHRwfy8/PDWjgiIiKKP6GmgvpKL5Py3IEQU47S0lJHAGI0GlFSUuK4djSl6wWa/uov1fXMi0+jQA0AtrkjO5sbBTO0a7o6IZprimw/nSCY8fccnO9NqwTykpOQlwysHKvHnIYWv21tVv1xrByrh06dgA6lCmNc7jXQ9ui1TXhKBXZ9k+isu8sWgLo8L2/PMpApY5zLOPmgPXD+04Ud5j3vHix6mAvVIwlSnsPF1+eVxBMVZFZWVmLAgAGorq7GiRMnGGQSEcUo/kJLkSRlKqjYcwf7RkfscWLKEQ1TF4i6nwC/+PtLdU22mmEPMG2sAJwGixEbkNj3dU3ZdOL3Objem30/dQJ0Ou+DFdnPVW40CueUdKm7QNu61zbh4T4Fwby3N5qA8Hl5e5aG3wunjDE8Axj+FlgZnQQ9zYqf5ymnaPi8xgOfQebevXuxadMmHD16FLW1tThz5gzOnTuH48ePIz8/H1dffTVee+01pP9/9s49Pqr6zvufuQ8zIZchCTEJyEQkQWIF4xZpU2231O76dPMqdF+2rl1ExeuGiKLbohWClIu6osTUQkWr9ubjY7WPu+2z67LPWpcC7iNiFSQoMiSEhFyYBEji3Of5YzIz5/zm3C8zZya/9+vFi5wz5/K7fH+/c77n972Ul+P73/9+tspMoVAoFIXQL7SUbNHd3Y1gMAiHwwEAmDt3Ljo7OzW7ftKMkfnBhAtyRefjB+5A8Sbxjyt8K0Hkh5r21rvh+NVPUyahpfe3Z1zLCKkLJLWDxi/+4yYLa7s3asIlcxsU5X1kKjNBmx1t7x5DV3Nzqu9F5YFnNTBkd6LzsfSxXB/ipMgaaW47MDCAlpYW3g95fDLBpbQxlfnopjVAzwnuRrI7EiuLPH6rABIrmEzIbQllZKI0zYrmOUA1xAjjtRAQ9MkcGxvD4CB7RMZiMcTjcZSUlOBf/uVfMG/ePPh8Pni9XjQ3N+teYCGoT2Zhkq++SJTCoZBkkEwq7vV6sXfv3hyWiCKFfJRBtT6TWhF9+C7W6s+JsQDWjjtFy0Keh8pqmNZswNEH7oQ9FEgFh3mh+fJJk9BJOHzL1Phd8q1Ayl2hldIOsaEz3AoOlMng6T+/j5Ht7ShiKOA1V1wp6xpcKJGtVN3O+RP1c08HJv0Lme2mVm6lnq9UJlh95HQCMQChQEKJjITZCijht2quqEK09Yb0SubkMRaelcxs+gtLIVvzoNHqbXQU+WQWFRWhqIhtQvD2228jGo3i61//Onw+H2699VbU19fjN7/5TYaSOTw8jOeeew7BYBCVlZW4++678atf/Qoff/wx6urqsGrVKgDAL3/5S0n7KBQKhaIO+oWWki0MY3LGkYBeUlk4VvXiu7cnFEq7E3VI+PNlmIRymJiq8bvkW1GV6z9J1qfCaUWHLcpKO6F0VYqPmiuuRM1L7OA7qZU2FRFFlclWPPHPYgVqLua9t1q5lXq+UpkQ6qPow3exdxB+qwCA1kcSJrIMn0w+plrKjSRTtd5aYxY74A9/+ANeeOGFVGNXVFRkrBjOmDEDIyMjGecWFRXhvvvuQ3t7OzweD7q6uhCLxbBlyxaUlpaiq6sLPT09kvZRKBQKRT2dnZ1oamqC1+tFU1OTpuaLFOPS3d2NlpYWNDc3o6WlBT09Pbrfk/yAka0PGsm6frt5Cd67YSlOHz2CsUgUPeMBvDcyhrZDPkllMa1am4jsWVkN1NUntgk/N4/dmmESqrlvGZ9vnUz/SdOqtTgaSqxgXohEMN1qxSyHJZ12QgFy5SqlGA/2qbov2X99fX2i95d6bz65lVpXl8sluK0rpOxxyGLvtGIs6wng2iNDWNYTwGlXSZYKJ09ecjFnUbRFNPDPf/7nf+KWW27B888/j5aWFlRUVKS+ypjNCR01HA7DbrdnnOt0Oll/nzx5EosWLUJHRweuv/56HD58GC6XS9K+hoYGrepMoVAoUxb6hXZqkgtfXKk+k1qTrOvrS+qxqCT9gv/JeBBrz4RS6SrE4FoxihKrgSG7M+GD+YdX9PMt41hRjQ318/vc8WCuqELxpkSfdNiimC6Q81EqsuVKo4iiSdk6fPgwgsEggsEgDh48KHx/iffmk1updTWZEoGNZjnt2LHIi6oie8KPMhYHQsFEfkmzCQgENM8PKcXPMZd++XLuzXXsvn37slJOijaIKpkOhwOXXXZZSmF0uVwIBBK23BaLBYFAACdOnMCsWbN4rzE+Po7h4WF4PB64XC7EYjG43W6MjY0hFotJ2sfFnj17sGfPHgDAtm3bUF5eLrsBKMbHarXSvqXkFCqDlFyjVgbPnTuXsa23TJeXl+fkpTBZV4+N/YpTOc2Brq4PVF078uBmnH+6HdHzo7AUl+LLa9phraoGvn6dquvKuWfxmnacf7odYaZfnXMaZjy4GVaRPk32if+HdyB87HBqv63MA4/IuVwyKFeu/GUehBl+oVLuy0WyHgsWLMDx48cl3V/qvfnkVmpdk+/IOxZ503k1+QL1DALWlzrg2fYz7t/lUl4OPPmC4CG5mAuU3JvrWPoszi8kpTBh4nQ6EZ6MRPVXf/VX2LBhA2KxGB544AHO4yORCH7zm9/gu9/9Lv70pz9hYmICa9aswfHjx+FyueByuSTt42Lp0qVYunRpajvfgiJQpJGPAS8ohQWVQUquUSuDJSUlGdtGkGk9Uuok6+oPR8BMuDYGi/o6W+3AA1tgQiLeyigAcFyTWS+Xy4VwOIzu7m4AiSi7u3fvll5PjntGR4hVzOIyjFrtnGXhInZzG8BY8Yrc3CbaNlwyKFeulNxXCDn3V3tvqfdKHkd+5OAjPOLHwYMHVY0DOUGg1MwFasfrvLISPL6kHh6bFf5wBM9FinjvzVXOSCRiiHmLj6maIowv8I9gdFkAePjhh7F582Zs2LABTU1NiMVi+PDDD7F+/XoAwOjoKBwOB6ZNm5ZxbiQSwc9//nP8zd/8DaqqqnD8+HHs27cPK1aswGuvvYZ58+bB5XJJ2veFL3xBtJI0umxhQl/wKbmGyiAl16iVQaNGS9QjAm2yrib/EH5U7Ua5044Jk1WzyKZJhF7syXqRqK1ndOuD6aA/AFBXD8u6JxRfTwpcMphNueJ6gQeQtftLrWvyuE3Tw2h02cQvXFePZfuPCY4DMSUyUx4yIxzLrQcXasfrxMZ74ehNB54L1nrh2rBDcjmvvPJKQz+LjRJRO9soii4LACtWrAAA3HbbbamIhLfeemvq99LSUt5zX3/9dXz00Uc4ffo0gMTKZyQSwfr163HRRRdh+fLlMJvNeOedd0T3USgUCoVCUYZRfXH1iECbrboKRXcVq4faeholx2A25YrPny9b95da1+RxrFQjo2cT/phJ7A6gdEaq7/y//1vWNUj5EI0kPErI0+hZzrLFhvpR86tn8Mbl1UBRvWx/ULXj1cFsA45tJkads4QwTERtgyCqZNbX1wNIdLbcr0M33HADbrjhBta+q6++OuM4ptIqtI9CoVAoFErhkK2UOnJzSkpCIJAMWS8StfXUOtVILpHaN/nyAp9RnzXtiD/dzs65WjqDlVpEdByIBS0avyC8PUmGsrqxDVEij6YQqscrRxCrQoKmCGMj2yeTQqFQKBQKRQv0jEDLetlnriQNAscfvAO3Hs80F5TlUyXwwsysl8vlQiQSwcmTJxGPx2E2mzEwMICWlhZV5p1q/L+6u7vx43tXo9UdRpndhvI5XjjvWadZlFM5cK3SxVbdl6F45ssLfHznY+lAP4NA1323Im6xJvKrJiGUK9FxIKacFRUDzEBQRcXchSOV1WAgofwOAh8/cAeKNwnLkNrxapQVeL346aZ2jG5vhzsexbjJkog8PYUR9MmMRqP4r//6L8RiMdELWSwWXHvttZoWTi7UJ7Mwof5wlFxDZZCSa6gMyifDT41BIBrDvH87BIDtNyXHp4plDilxJUhLny0112ppacHD9rF09FNA0I8PUC+DfCuW0YfvYq/yVVYnlCjCx/D0Ta058yuWstqaOoaQuWA0hq/98Qieb74c82urFa2ki8maVB/d6KY1vJFuA9EY7vWbsft30n1Bs43R50E5vrGFhGKfTFLBfPfddzF37lzMmDGDtV8kfhCFQqFQKBRK9iBXbZgw3lmYZpdyTDKVmKxqafKp5lp+vx+eWUTkfgk5K9UoHbx+hVyrdBzmobn00SNXJ+M7twGPPM0+hkPBBACryYTeQAh3febH3peUlV9M1iSvEMb439WdFjNa3WHWPlFfUAobjfLAFgqCSqbFYsE111yDaDQKIKFI9vb2YuHChRlfj2w2CRG0KBQKhUKhGIZCDrkftNnh4Pntk/G0aSHT7FJvk0wyJRtfijYpqCmrx+OBPzzGSvEixT9OldLB8wLOpSDFdz+ZU989clz8ttoKM/OAvlMACKXbP8R5rfDkBw21siSk4Ev+4EEE2onFAbMpve2xE+/yAkoT39xh5DlF97IVuM+pXERXMnfu3ImzZ9lRqric2a+55hp87Wtf065kFAqFQqFQdIUvYmch0PbBSdxuGYPHbsV4JAqny41La6sRtDvwkyEfvF5vhl+Znj6iAGAymQS35aCmrJ2dnXi0rRWOiTA8SZ9MKf5xEldquBQiOJ3sgya3uRSk6LIVQOcmIBwGbDZg2QrJddMCclyEK5rgMGcex7d6yaQ7FENTU5MqWYoN9SO+8d6036XSVUVSCXI4WIpn+Ryv8PEMpYlv7jDynKJ32Qrd51Quokpma2trNspBoVAoFAoly+RLxE4ldA37sZzxUdzr9WLvS2/CBWA3zzl6m2SOj48LbstBTVlnz57N8r2TjMSVGs4VT9JUUyjcxxsvpxWqYBR44xdZM9OMDfVj0/QwXNcsgD8cQdshH3pDYVziZKzyzZiZ+J9Uuq02oLg0Ed21qBgoKUPDqrV4U6UfY3z3dnZgH0CRKSapBJmXrUi07eQ2+aFBSGnimzuMPKfoXbZCivqsBaJKZjAYxPr161Mms0ni8Tjmz5+PVatW6VY4CoVCoVAo+pEvETuVYMS6GalMSvwrJa/USFjxPH3yBNDTw22umEPftvju7Wh02QDYUAegY6EXsBBmpI7JULHk6qzZnFA0ay7mbU9Ffq1kHkxAkSkmpxIkoBQJKU18smwkGScxctkKEVElc3x8HHPmzMHdd9+d8dvmzZt1KRSFQqFQKBT90ds8VCuU+FIZsW5GKpMS/0ohpYPZR7su8XCn7GCsgvZfGMNmPnNFFb5tqiOiEgpdbXERZlRWsHwuw2MXsKylBduKw6ifxlBAQ8FUShC+9iTbPfDD2+GLmFB6fztqrriSu0xk3kuTKeemmOvWrcPNN9+MYDAIh8OBhx56CICxZJxEatmM7FeaT0jKk2k2cxiiC+ynUCgUCoVifHIZsVMOSnypjFg3Q5VJ49VCZh/d2n86I2UHAHy45ha4Y9GUGartohpOpZC1Yup0AqFQItWJBKVRTHmODfUj/uw24ExvYkf1LJju+mH6moRCV+V2AqUelpL52ZkhHDx4ELZrFgDgCXzJ155EuzvMJjTYgaPb21HDF32WzIPpqchpKhEA2Lp1a8rcOxKJYMuWLXjzzTeNJeMEUstmZL/SfEKSlhgIBDA2Nsb6d/78eUQiEb3LR6FQKBQKZYpjZD+vvIVcHVQZCZPZJ8mUHZbNO2FZ9wTMFVUwV1Rh/QUbvvrOESzffwy9gRA8Hk9aKRzsA04cQ3z3dpgrqmBZ9zgsm3cmzE97fazfBRFRnuO7tyeuFwkn/vWcYF+zqJh9flFxQkmua0jk8Kyrx4bu0USdwwLvwXztybO/KB7l3A8AKCkT3s4isaF+RLc+iI7SKF5fUo9aZ2LJupDGJJ1vtEF0JbO4uBjBYBBPPvlkxm/z58/XpVAUCoWSb1DzGgpFP/T2pRIysWSObZfLBZPJhPHxcUOOcznzkJpImFz3kdJHpLniLbfcgpOv7cIcF8O2llwBlLviKmZqy5U/lXnNkjLg7CBrmzQTDu1vAQC0HfKhY6EXFxUXoWaON5EPJBAQbM9ku4eOd8HOWOoJmS28VVLSV2KyoPSZFfjJVjhOn8QshwWzHEXoWOjF8gPHCsq/Mde+m4XyPmGKx+P8mVkJPvzwQzQ0NMBut4sfnAP6+vpyXQSKDpSXl2N4eDjXxaBMYaTIYEtLS8q8BgCampqoeQ1FM6b6PNjT05PhS8X30qXEJy+69UF2Koq6BlgmlQpybDMx2jjXcx5iyiDXfbj83cRejOfNm4dffKEWV5UVpXfW1cOy7onUZmbfsH8niQ2dyVDImP2fcT3immLnA9LkUUwOJ350DxwDvant4MxauH78LH9jyURMFpTKSs8tLahhLFH5xoO4f8yRFUUoKYOq/W5FkDPf6EG+vU9UV1dz7pfkk5lk//79mDVrFqeSefbsWcyYMUNZ6SgUCiXPoeY1FIp+yPHzUhLQRmi1TGgsG22cZ2se4rqPEl+8YDCYWg3DbhyWAAAgAElEQVT02K0YCUdxlYw0GlyIpZEwrVqL+I5HgaSCZ3ew8nBKSUMhpa7xnY8BPScSG4NAfOc24JGnU7874uwcLuS2UpIKWEdpFANL6hMpWAIhUdmQKisjoTBqrGk/1HGTOesKkKIxLoNc+5UWyvuEoJI5MTGBF198MbV97NgxvPTSSykl02Kx4M477wQAPP3009i0aZN+JaVQKBQDk2vzmkKjUMyFKPrCJSc1SgLaCJhYkmObidHGebbmIa3u43A40Ds+juUHEgqD2+3GJ8SKlNa5B80VVYi63ekdoSCCr+zG9973SZ5vJM1PfaeEtwmZ6+rtw53NzapNW5MKmJg5q1gf8t3zmXEbbg+MwWO3wh+O4LlIEW/eWd3IYYqbbFAo7xOC5rKxWAwnT57k3G82m2E2mzFnzhwAwMMPP5zzlCbUXLYwmepmYpTcI0UGc21eU2jkm7mQ3tB5kBsuOXljSb0s80pA2ESSObaN7pOp5zzElEGt7nPgwAGsWLEilQbj5ZdfxtVXX61JeYWIPnxXIpDQJKcjwJK3pM83Uuan6N3fSQQWSmK1wfLT36Y2mTLX1duHW/d+hN5AiPN6cuZDsm6nglG0jVoy+kisD/numctnXVIG5ZpQ5xv59j6hyFzWbDajuLgYFosFZWWJSFbnz5/Hb3/7W9xyyy2sY00mk0ZFpVAolPwj1+Y1hUahmAtR9IVLTpQESRFaLcunsZ2tsnLdR4mf3NVXX41PPvlEz6Jy43SyNseIKLGO86MJRYanLpLmp6raRBRb5jYDpszd2dycUjClXF9wPiRWSGe5nXhjfh1M09iubmKywndPI4wHNUGrkujt16kGI7SxFoj6ZB4+fBh+vx8LFiwAAMTjcQwNDYmcRaFQKNmFmlcWFoViLkTRFy45UWJeSecP9WjlJ8d8+Q/a7Gj74CS6hjXul3CItem0pl+HZznteOGSUsG6SJmfTPesk6wIiV2P73fBHKM9n6XTtCRTv8joDyPPwVqYUAvJq5EV0HxCUuCfY8eOYXR0NLX9+eef61YgCoVCUQJNnlxYcEWqpFBItJITcv5YunQpKisrqcIpBw4/Oaby7na7EY/HMTExIdiuzJd/B4DbLWNY7vNJntf5FARmWd6qL4PDnLbAm+WwoKmpCX6/H7su8cBFZpEnfP6kyJ0cRUjseny/cylKlnWPA+sezzCbleu32NnZiU1trWh1h1Fmt6F8jhexoTOGVLb27duHlStXyjO7FvDr1Duw0FRBkpL5l3/5l1i8eHFq+4knCsfumUKhFAbUvLKwKBRzIYq+aCUn5HwxPj4OnwzFhgLO4ElM5Z2JYLsSL/+NxdPw9jUL4A9H8MTwaObxBHwKArMs8UtLAEZeynAkmipLhnKWrBsDUu5iQ/2C5rViiMkxn3lyKnptEqYiKZYvVEKZdi5m+Df3+gyrbK1cuRLj4+MAgEgkghUrVoibYQu1T4EHFsoWkpTMkydPwsmwXx8bGwMA/Ou//iv27duHeDye8tmkUCiUXGBk0x4KhWJshCLI0g9W0uDyk/P//m95j+dtV+Ll32m1oK7IgjoA7ZNBYblWK4F4Yt/J4+zrTSoIzPt9Mh7AF0rSEWZPBsO4LLlhd7DPt9lhWrVW0ISSS7GNrbpPV5PL+O7t7MBCAEtR0sJvMV+UrWAwKLjNhWD7qFTQKQkkKZmnTp1CNBpNbV+4kBC6pUuX4pprrgEAuFwuHYpHoVAo0qDmldmH+rHlF1O1v6TUmzl/DA4OplZFAP4PVmr8tpT2RfKe4VE/PjszhA3dowgVlxqiL7nMQ+eXe/BklR0eWyLdRTJnI8DfrsyX/9jQGZgZ+SPnlicWNAI/2QrH6ZOJnYNA4NmtcNjt7IijSSYVBOaHhLsOnkjl5sxIw2EmAlleVItTE0GMrV+NhmTsHNKEkkMZ093kkryn1cZSlJj9kZCbJxGQKzcaK1t6zUEOhwORSDp4U12xm7WyjGV/D7zxi8yxytMfmijoFOEUJgDwzjvvwOl04otf/GJq32OPPYYf/OAHuhdOLjSFSWFCQ/dTcg2VQW5ompHsoYUMTtX+kltvqekDMtMoNCT84XQoE9893/OPYfmBY1npSyUyOLHxXjgYEVY/DkRxt++cZAUj2noDEAykdzicMG3YgeC6O2Fn6IKnI0BNdTXbzNVsAebMTSkUUlPRZJjLVlZj2Ud9eNIdQF2Rk7Xfsnln4hyOlBoYu8C+jqcCKPVotrLJdU/Tqvs5P3wolRuh1D5KUDsH8ckgmQrnveXXwn12IH2A3QGEGKubMsYqRRxFKUwApFYqmdx7773qS0ShUCiUvIb6weYXU7W/5NZbsp+nClNCxX1B3NNjt8o7P8s4Qmyzxctmz8LeX/xe+gWKitlKZlEx4ru3sxRMABgJhVFDpCVB7cWs3IlC/cryqTxHtGXRdPj9fvjtdtQR+5NwrXzFdz/JXgUcvwD4J7MzaLCyyXtPrtVThXKjJIqr0Aq/XnMQmQonevd32AcQcmhUs99CQ5K5LImTHMgUCoVCmXJQP9j8Ihf9lS0TXaEXW7Leg4OD6OnpES2HqDmsClNCxX1B3NM/md/RsGNPQRsxZWbXJZ60iSoAlJRlKEyBSBTPjNuwK0YY5sWITak+lQDgcAIlntRxnv13oO3QRykT27jDiUtCocSq5+Qx5MpYjFACcW6EpTCfOnoEbS0tvGNCTP64FMAo34ePLMqNkJmwYZ4ZDDmcqm4E2cDS3t7enutCaEXSV5RSWLhcLkxMTOS6GJQpDJVBbr785S/jgw8+gNPpxCWXXILOzk6UlJTkulgFiRYymIv+WrFiBQ4ePIjR0VH09/fjgw8+wI033qj5fWIdjyZebMcvACNnAd+nMH/lGwAS9X7llVcQDieCpITDYUnl4LomGhoR63gU8X99HTCbgellgHMaMLM6kaPQXSSpvIr7ouELgO9ThE0mfHpuApv7JzDTW5eVvlQkg5Plhc0uuY2YMvOffWfxpZqZqLioOnU+Dh9M9MckxyNmXPdEJ4r/++1EXyVxToP5699KbQrJSPz3rwKfp/1wUeqBZevPYP7KdTC5i/DlL38Z77x3EP97eAz/HrHh624zKibOcV4ricldBPNXvgHz178F81euQ/z//Rer3J9emMDT//0RryzylTc21J+Swfh//xFo+EKqTeP//UfWPTCzGuavXJdVuYn/6+vsfrDZU/2gdg6SKoOB/W/DyihDcMZMWC+axSmH2ZqjCpnp07k/HilayaRQKBQKhaYZyS/40iDoGQFTK/M40XIKmK7Onj0blZWVrBUUSeUgr9nzGeLrW9kRPesaYNnwtOx61IxdwBtL6mW3d3L1ygJgAYDXJJ+ZG5SYWzrOj+JfvtyAeW4nYDKhOxSBaU17qp3IFcL5Sb9DsVVTIfNm0nyS2GaOnZaWFjjDgcRqJ9/5XCxbAXRuQvjzzxGIRbH7xBm8vqQeM11RRLc+KFmmM1YK1/8DorPrEooTT8CarMqNQD9k65nRduQ0breMpQM7DQG7f/cc57FT1Y0gG1Alk0KhUCiUKYreETClmseJKZGi5RRRMBSZ6ZHXJNNFALJ9u/I9ybveHyUAoP3iUpaJbP00M0uR4lNcRSOCkq5ezG3HNCLA0DTe8on5Z/LyxstAMACb2QSb2Yonr/DCbZ3M1XniGOI7twGPMD5Y8Mk0qXxGwonzd29PmOzmWJ6MEJm1a9iP5Yzx7vV6eY81jAlvAWLOdQEoFAqFQqHkCJ3z4HV2dqKpqQlerxdNTU28qYVSytdgX+qFWU45TavWAnUNQGX1ZJRN9out1HLwXtNq4z5Ioh9mKrAMTw7HJN3d3WhpaUFzczNaWlrQ09Mj6frZQrSfNOCSqorMnQxFig9zRRUs6x6HZfNOWNY9kan8cvhspvrl/Aj7t+DnvPfxeDxoO+TDe/4xnBgLoCsEaYoUIcPTLOxX8NjpHlbfn7n+Rm6Z5pG58OhZzv3ZRrQfVODz+SSND1JRFFIclcwNFGnQlUwKhUKhUKYqOicd1yxSq0g5xcwylZjpMa+ZkS7CagMmV9akkBFYJglRj9WrV6dSPPh8PrS2thrLJF3njxIAYCv1pKOwZtxfxf3ICKOhgEC/FPNeJplTde2AHx5PETof65SmSBEybDaxQ+SGwxFW39/9SDtn3ydXCoPHu+Bg6KmfnRnCAvFS5DUrV66UND7k5M2mbh/6QZVMCoVCoVCmKEYwbQMgqkTmupxc90/5CEoxISWVM0YORyaG9w/T+aMEMNnWz24DzpzKNFFWcz+uspP9ksRdlE5pQvSpmFLCJw+kDGF8HBjoTZ3XGwrj9SX18NgSfoRPDI9yXj/58WPFV6/BgzOsKb/DJ4Yjknwts2HyrBdkjky+8UEVR2NAlUwKhUKhUAoIOSH5lQRm0aMc/dd/D6PbN6IoHsW4yYLS629EDeP3UxNBrN7flb7WTSFkM8mAUDtJ8rMkFZw5c1k5HJPo7R+mNl1DNpR9c0UVMBlMKTZ0BoGfbMVwtw8joTCeefcY1ktIP8NVz1opuSwnV6gRCin2neWTB1KGYkNn0uWxO1Dd48MlzoRZdh2ADa4YWlpaePsqVFyK5QcOprabmppUlS8fKC8vx/HjaZPz5PigaUiMiSkej8fFD8sP+vr6cl0Eig6Ul5dnfL2iULIJlUFKrpEjgy0tLSmTMiDx8pmLr/pyyiF2rFHqxEX04bsSPopJKqth2byTdUxKoTjnTygV7ulAqSdjFamnpyfDzE/Ll2U17ciUwWyuhikps9RzWIoeox5S+pQPJedmmGMD6A3H8KV/P8RbB6WyklE+xqq60Vc0L1y4gJtuuimjzkaeH6YC1dXVnPvpSiaFQqFQKAWEUUwu5ZRD7Fij1IkTCSakyVWs6NYHgbODiUim/qGMVSS9zfy0asdsroYpKbPUc3hXqNWYBSs5l8NsdzQcZW2TdVAsK2T5YtF0UCXWSqsxzGqZ5Sgp8+B3z/8soxyGnh+mMDS6LIVCoVAoBYScyIpqEYqGKqccYsdms05yEYtsyyILgXOE0KwdJdYj2vUhoq03IHrnssT/XR/JvhVXmfft24d58+bh4osvxrx583DgwIHU793d3RgcHBS8hhhcfZqMRBt9+C5Etz6I2NAZTvmXJQ9JCEV0Igb800hMVR1E62a2sH8g+jAbkYSlwCxH+NhhznKIybXRozYnyZdySoWay1IMDzVVpOQaKoOUXCNHBvU2uWQiZKYmpxxix+pRJy1XaqReK8Mssq6e0zdTLx8zNe3IlEGp9Yi23kDkn3TC0vmq6jIvXboU4+PjqWPcbjc++eQTAGyZnOW0o7PpEjR6L4aNwzxZDpl1bsCy/V2yzTS5ZAUAPn7gDjhCAfjDEbQd8qHkkkvhdDp1G8difajGZFhLpJRDTK7zxZw2X8pJQs1lKRQKhUKZAmQzsqKQmZqccogdq2WdUi/5PSfS0UtVmnxKNR+VGjhHr1QmWrWj5ABA4bDwtgS4ylxhiuEXjEis932UXvFhyuCORV4sKnElUqJwmCfLgly97fkMHaVRDCypR9shH0wANk0PJ5QigQ8NXLJiWfc47vrMzwr6ZJuYwFtvvaWsrBIQ7cMsRBKWhIRyiMl1vpjT5ks5pUKVTAqFQqFQKLLRwiwxF1EheXMjqjFdlWg+KjWar9FfNsXqkVLkY2y/Qthsmtx/xxVzEsojEpFYd1wxJ/UbM0Kvx0a85qrpY1LZiYQxy2HBLEcROhZ6ARPQ6LIlVt2EPlrwyIrekYVJxPow12mDuMphK/MgcnNbxjFilgTZblul5Es5pUKVTAqFYhhoGHLaBpT8YfXq1Rkmi0JJz/muIWXFjtvEMK7M3JUvN6LWORgZyDXNFXvZNPo8wanIO5xA6yMA1Jsqz59VA5wfSW1fNiud8GbDP9yF+PPbUWo1o8JBKLUq+pildPmHWDk8Z7qnwWwR9nFklYFDVjo7OzNMPvVETIb0TG8kB2Y5PDxuA2KWBFxta8QxlG0Z0Jus+GT29/fj8ccfx3333QeXy4VHHnkEM2fOBADcc889qKysxC9/+Ut8/PHHqKurw6pVqwCAc58Q1CezMKH+cPmJkpcIo/ojZFMGjdoGlNxixHmwubmZpQh5vV7s3btXl2tw+cMB8Yx9Fp6XYtZ8dM7P9hOczI2ozieTOxWGUPn5ygoY08dMjgyK+dHJbY+M6wv4Ex65uQUN9vRPEzHAVVWtaYRUrvsDkOSnmpKV0bPA+AWgqBgoKct69NZ8fNbwyaAS/9F8rL9RyZlPZiwWw+9//3ssWrQIsVgMsVgMixcvxsqVK1PH9PT0IBaLYcuWLXjttdfQ1dUFl8uVsa+hoUHv4lIoFI1QEuLe6CZi2YC2ASVf0MK0S/I1pJijCphCZqysOZxAiUczxUN01UdmVFm9fMyylpZCzI+Ooz3klE3IlNMdjwJIryqeDUcxXeOANXz3l2Jeykpn4x9KfPA4O6hrGhguCupZo8B/tKDqb1B0T2FiNpuxatUqOJ1OAIDJZMKf//xnbNy4Ea+88goAoKurC4sWLUJHRwcWLlyIrq4uzn0UCiWPUBCq38hpCrIFbQOKUrId/r6zsxNNTU3wer1oampSZNoldo1knQ6f7GafWDQ980WyaDp/G5DzUYkHls07YVn3RHZWjzjKqgZyXhgcHJTU31LTUqiVJdE0HhztwVU2vnKYK6pgWfc4Zx+Om9hmq+S2nLpxpS3hu79QmTghZfKcn/NeepGPzxqfz8fZd/3Xfw9HQ8CpYBRdIeDM9TeKXkuo/oWWSiRXZC2FyauvvoovfvGLuPjiixEOh2G32/Hqq6+irq4OPT09uOKKK/DP//zP+O53v4v/+I//gMvlytj3/e9/n3XNPXv2YM+ePQCAbdu2IRQKZaMqlCxjtVoRiURyXQyKTPw/vAPhY4dT27b6Rni2/UzwHJ/Ph5UrV2J4eBjl5eV48cUX4fV69S6qKNmUQaO2ASW3SJHBa6+9lpUv8Oqrr8Yf//hHvYumK8k61Trt6FjoRXVJES6+rBHFa9oBAOefbkf0/CgsxaUoXtOOr3/3Rs42UDIfaUnkTF9GWa1V3CZmUvD5fLjqqqswNjaW2ielv4fuuQGx/t7UtvmiWlQ8m5lShEuW/vSnP2k2D3K1x8ijazLK9rdHBjLK8R//89c4//RG3rY8+f/eRc/G++CORzFusmD2hqcw5y8Wc9ZtltOOF75yOebPruW81uDqv0O892Rq21Q7B5XP/FqTNiBlEs5pQODz1KbeMpqPz5qvfvWr2L9/f2o7KfNK5j6h+hfiXKondrudc3/WA/+YTKZUYRYtWoSjR4/C5XJhYmICa9aswfHjx+FyuTj3kSxduhRLly5NbRvNX4WiDUb0RaKIE7u5DWCYDkVubhPtx+nTp+O3v/0ta58R+j6bMmjUNqDkFikyODAwkLGd77KTrFNvIITlB44lfDZf2ILR5AEPbIEJQAzAKPjbQMl8pClWO/DAFsSH+hHevR1nN7SpMledPn06KioqWEqmlP6OTXNnbHOdw9WOkUhEuzabbA9m33GVjascZ5/4Ucr0Odbfi7NP/Ijlz1nkvQSXvcg2NWaWm3nNHYu8qLclrhPr78XZ1Tey/HOZCiYAxHtPatYGpExi1M9SMsMjfl1lNB+fNUNDQ6ztpMwrmfuE6l+Ic6me8Plk6m4uSxKLxVJ/79+/H3PnzsXcuXNx6NAhAMAHH3zAu49CoegLn2mQEmSbDmUBagJDKWTUmr9xjQ+9x4zY9eXWie94tfORVu0Q3/kY2yR05zZF1wGU9beoGauKa6uFq2yc5VDgipFxjeTfZIqTSDjRL89uS/hMykCujJyaCGLZ/i5c+8fDWLb/GIKuIvYBCk2qC/k5V15eztpO9iUpJ263W1Ub5KMpsRHJmrnsa6+9hi9+8YuIxWLYvXs3TCYTFi1ahOXLlwMAXnjhBZw8eRIXXXQR7rzzTpjNZs59QtDosoUJXcnMHmoj/hkdpdHkqAxSco0UGRSLSCoG1/gAoHkERmaAl67ePty69yP0BkKc15dbJ+bxbrcb8XgcExMTqlMUaBWJMnr3d1ipL2C1wfLT3/KfIIDa/pZ77SuvvBIHDx7MatoHrnLU/OoZSVFcpVzzp3WluMzB8W5ptbH7KYndActP/lfG7u7ubnzjG99gpfQRkxFSpv76L5qwa3EDb4RiqRRy1NQLFy7gpptuypA/Uk4CgQCOHDmSOk9uG+g5tgoRvpXMrCmZ2YAqmYUJfcHPHkrCgOcTSlMuUBmk5JpsyCDX+ACgOk0JCfkx6z3/GJYfOKbZ9ZNo+bItd+7gi5SqpZKZbcrLy/GlL30p5wqMWLoYOaz6dgtut4yhscQFp4WhbHIpmZN5Pi0Nl2dch5Q1QFxGtEgBlM3rGgGp82Aht4ERyVkKEwqFkkcoCAOeT2iRcoFCKVT4xofmY4Ywd/TY068iWo5JqSkKpKTOkDt38KZwqqoFetPXQVWtjBppi5J0JkZI+yCaLkYGXcN+LPf5UoGlZrqnYdYlc9kfWwHR1VK/349ZTjt2LPLCY7PCH47guUgR7/GAfs8j+pyjbWAUsu6TSaFQjItUf518RYuUCxRKocI1PnQZM8THq9FIDA6HA42NjZqOSal+VWTqjI8fuCPDl0tqqpXkeeFRQvma9Bs03bOOPcfes06j2vLD52svNZ0JE6P5qqn1P0yWPxlYqm3UgmA8DoSCqWNidofos9Dj8WDHIi+uKitCXZETV5UVoWORcKRWPplSWyf6nKNtYBSouSzF8FBTRUquoTJIyTWFJINJc8fTn3Sh/8IY2g750BsIaW56KdWvinQTODEWwFffSfhzSS0TaS751tImNDCj+sv0G9QSPl97ue4R5eXleP/99w3lqybFJFpoxZZLRrChFTUMO7/TEWD2z4VloKenJ+M8pe4mhexTqZZCmgcLCWouS6FQKBQKJavwvuCvexx/R/hNaW16OXv2bGkv54SbwFg0iteX1MNjs2LCHEZs6IxsM9IN3aP4n9+8muU3mDP4orEqcI+Q3KZZQor5bobp8rPbELXbgLELqCmajt89/zNW//45FEaN1ZbaHgmFIaZGz549G9F59WxlXqG7iRFMkikULaDmshQKhUKhUHRByCTTKKaXTDeBrhBgiiNl9tjosikyIw0Vl+YkhROnqSWp7ExuF4J7hCQZIpXsM6cEzYSfGbfhPf8YTowF8N7IGJ4Zt4EPZnvf+e4xBGu9qttT6rjQMuWYkWG28bXXXltQKVkKHbqSSaFQKBQKRR8Echp2dnZmmirmAGYgmemTZo8sJORhNEpdVq9enTK19Pl8aG1txe+e/1lGNNYE8cl/+YukdidXbEmI/l3fMXnNAfG+JNv7ezGoXumVKku8waUKDC6ZNtJqOoUfqmRSKBQKhVJAKIkaqhsCJplGM70ElJs9GqUuXKaWfNFYC0FJkdLuplVrWUo2ImGg50T6gHP+yVXAOOK7t6Nm7ALeWFKfs2i7kmVJ4ANOIUHNh/MXai5LoVAoFEoBoSRqqF5wmWSqjZ6pN/lsRirLBDkPlBQpJqFi8mSuqGKZLpvu+mEi52WSYADx3dvzL9qu3SG8XSAYxayeIh8aXZZieGg0MUquoTJIyTVyZFBu1NBsk4vomUKru4Za+VWJ1Ii6AFfUWeEIuOXl5Rg8+pEmbdXd3Y3Vq1eLR/7dtIa96ji7DpZHnmYdo0SeuMYIANa+U8Eo2kYtgm3IbG+XywWTyYTx8fGsRN4l2+azMHDrcfF+l9r2RoHZxjNnzsRTTz1l6PJORfiiy9KVTAqFQqFQCgmeQC9GIRfmb0KrVEZa+VVL0tRy7969ePPNNwVfxpWs2GrVVkk/O5/Ph4MHD6K1tZX7wL5TwttQKE9cY4TYNzDxuXDZwG5vp9OJw4cPi9dJKwIB1qYpGJB0b8ltbxCYbfzHP/6RKph5BPXJpFAoFAqlgCB90LQ291S78ufxeFipS7Ji/kaahvZ8lljNKpoOnBshjjWe2aga+PqLz1dTEI1MbLX80KBEnvjGSHz3dpw6egQDE5+j7ZBPctliQ/3YND0M1zUL4A9H0HbIp//HE8Lf2R+OpP8WuHfyt1lOO3Ys8mKmK4ro1gfzegWfYkyokkmhUHJCvpmo5ZuJkRTU9kEhtkkhoEh5kIHagDE5icRKBiCKhBOrcYNg++cljy0gxPpL1jhWkFuTCy7FkKscNVW1QG/6OFTVso5zuVwIhUJwOBL+iJdeeik6OztF5zbeMbLucbS1tODgwbQZsZDSmrpPzwk0umwAbKgD0LHQi83hIkVtIxWmotzV25dSisXKnGz7HYu8uKpssozJVek8C/xEMTbUJ5NieKg/XGGS6Q/UAItBH3Dl5eX40pe+lHU/Mr2R0wdcL23fvu2OgmsTo2KkedDoPp9cxIbOpFeu/EMJJTOJpwIoncFa1VL7wctIH9HE+kuqT2PCJ/Nwxgqgknpx+Y62trZmlIMr/Qo57zBJnLML8Y33AkGGOamM54sqv9ZJTkcAbMzeRzc5ZU4e21EaxSyHJf1DHoxjI82DlDR8Ppl0JZNCoeSGPIhsyKQgw6jL6AOu1ZCCbBOKOBqtZukNn6KXoRiUejT/wGWo9CAi/SVnHGu1Ss6VpkNq+hUxU9D47u1sBROQ9XyRlY6GnEMnqXE7gV1bEM3SBwY5ZU4emzEODDqOKfkLDfxDoVByg8GDk5AUZBh1OX3AoZAWZJtQRBELGCMl7UQ2IIPUfPzAHWhubsad7x5DsNarb4oSA31ES/WXpyJhGnxuhNUveoxjJWlquMrBJUtipqCcih8xt5Hl279/v7K0OuScabUl2jgYMHwgKaWperROQWT0lEYU5VBzWYrhoeYRhQnLfM3gPpnl5eV4//33JZsj5Qty+oAr3cHpm1YXXJsYlXyaB7NpCi9klkqaiZ4YC+Cr7xwBoEhG4qoAACAASURBVL9pt9z0INmAr1+kmlrKkUElaUW4ylHzq2cyynz6plbBtCEZ5zicMG3oYM1tZPncbjfGx8dllRfgnkPjT7fnnTm5HLROQSTnevk0D04lqLkshUIxFHoHJ9EaWSZUeYKcPuCKxji7oqrg2oSiAVlcxRM0S1UYfVML9I7wqwieftFjblNiSp8sR+rDwa4tCf9ZJmPnRcsb42h78uMZWZ5gMCi7vAD3HBrNE3NypWjtJkHdLgoXqmRSKJScoEdkUhrtVD/kfhRQ0hdyzsnnvtai7EarP2tF8RzxkqjnS7aAQqs0+qYWGPIjmgTlR6uARVLTinDdj/XhgKsOIkhpe7J8DocDkUiE9bsUuMqfyw8M2ZgXtE5BRF5vcHAQPT09rHIn63Xu3DmUlJTkfL6jSIOay1IMDzWPyC16RUnU2uRGr2sCVAaVoKQv5JyjV18n0fNlTUnZSRnUqv5aje8MU0yHEyjx6GIKz+ybXZd40GBn/MhjlipkEtrd3Y0f37sare4wyuw2lM/xwnnPOl3N93MRfVaKebyQqbOceVCqCS7X/TB2nmVuGowDg6Eoxk0WlN7fjkjpDNX9RZbvoYcewpYtW2SP94n2NjhOn0yXtdYL14YdksuhNXrPi4C8SLZSr7d06VJBc+Vs1IuiHGouS6FQFKFXlEQ9TGSo2Y1xUNIXcs7Ru69Xr16deqnx+XxobW3V7KVGi7JrVX/Nxje5olji0c0Pjdk3t/afxvPNl2N+bTXvqlFsqB81v3oGb1xeDRTVZyhXq1evxsP2MTS6JnMG9vp0jwabi+izklZXRUydpSrHkk1wue5HrLgeOz+OUCwOj82K0e3teOoccLtVXX9xlU/J+B7uPokaxpv08EkflKhbWn10yMYzUGvz6tmzZ6OyspK1milWD/pszw9odFkKhSKMTv5VekQ0pNFOpaN3BFAlfSHnHL37Ws+XGi3Krln9VY7vpBxl+M7paCLL7IveQAh3feaHZfNOWNY9wXoxT5Ytvr6VFWWWjPbp9/vhsRHf3PWOBmug6LMsyH7zD7HmBzJir9LIqUJyw4x6engiDFMcuKqsCHVFTjTYgVZ3OPv9xcNIKCy4LRWt2jVfn4Fi5c7Xek11qJJJoVCE0SnVSGdnJ5qamuD1etHU1ITOzk5DXDMfwqlrUUatXmr4UNIXcs7RQ36Y6PlSo0XZNau/yvGdkqPI5Mu11aZLWhCmzA8ODrJ+6+vr4xwHGWVLQigkHo+HFRQIgKZKMud4Ja7f1dvHKn+u5qGUgme1JXZEwuz5QSPlOPCTray+iVmsKbkxV1TBsu5xWDbvxD8Ox+C2Wljneuw2XfuLiVg/PDNuw3v+MZwYC+C9kTE8M26TfC4LjdpV73lRL8TKnfx97ty5eVWvqQ71yaQYHuoPl1vyKdWIFnD5fuzbt89QMqiFfwqZ3kFNmP1c+JfpjdZ+R2rRax5UO761lCMhuFJORCIRVlRQchxklC0J4bfZ09ODR9taEytkOvhk3v7tFqyyjsFjs8IfjuC5SBF+9tzP8PEDd8ARCsAfjqDtkA8zF1yeKn+ufdC4+nXmrtcwsPYWTVKz9NzSwjIzPR0BZv88s37XXXcdNhVHcFVZUWpfsNaLtkM+xf0lZ74S6weheUJOHxox5Y0Roe+DxoT6ZFIoFEUYMkqijuSD74cmZdQwzH4u/Mv0phBT1nChenxnKV0DKeOVlZUAIOjHlVE2qw2YXZexyjp79mzs/p1+fd3qDqf8B+sAOCbCMFdUYWP3KB4ot8Jjs6JjkRdPDI+mzsn5PMTTr1pFTh0JhVFjtbG2uT7hTExMoO2z0+hY6IXHbsWE2YLL71mH3YRZdHz3k4hK/MglZ74S6weheUJOHxoy5Q2FohKqZFIoFAoDrcOz64EWZdT0pYbD1EvL6KxGS9eRr+jRjkJypOX9SJnv6+uD1WrNOEasbEzlI1tyVWa3sbY9k9vtF5emIuPWAWh3s+ui5zwktprH169afXR8ZtyG2wNj8NgTq7sPfHwaZS0tGX3g8Xhw0OfD8gMJpbCpqQlvVlRlpswJBhInDCZMcb/3vi/Vr+vWrcPWrVsxMDCAkZER/NvVczHbwZAdAdNUNf0g59yp9jGXMjWg5rIUw0PNIyjZhMv86corrzSUDBrNlJPL1GvZ/mOamfvlc7oSrdBiHlTbjnLNornMRMkVQ6nXTMr84cOHWSaybrcblZWVivotWyapExvvhaM3rWwk01wEfnAbbIzAN2FPBZyPPQ9A+RiX2p5CqUr40PJZzNefUs1RM8rP4HQEWPIW27SamR7j9SX1LPNbIdNUOf1Atv2Z62/E3Y+0G2peyYe5Tgj6PmhM+MxlqZJJMTx0UqHkGiqDwnD59V2z7G9ZX/G9Xi/27t2r6PrNzc2aXYuLXPu/SUELGVTbjnIVkz/f9NdodKVX8cajMbgvqmUpP3KvqaUs6C1XSfj8XvXILSq1PZX40uoxDyrtA15/WwCHJ8K4/u0PU9tWqxWRSDpQUK3Tjo6FXsx0T8Os+Zdp5kOuRHHPNvkw1wlBn8XGhE/JpNFlKRRKwZEPEWLloqRO2WoHZjTIZBoJLaOz5nO6EiOhuh1lRsAkzUTdFnNmNGOZ1yTLPDg4qFi+s5UWgWt8AGCl6oDDmTD5VBvtWWp76hQ1XC5K+iA21J8wkWXicCbasa6eFeEVABwOB2u7NxDC8gPH0DZqQe/fteLbt92hzRxp1LQ0DKbKXEcxBlTJpFCmEEZSvvQsSzJZu8/nw8GDB9Ha2qrZtXOFkjrlsh20DKWfz+lKjITqdpSpmJTP8fL/mHwBl3lNZh2SZpBJ+V66dKms+STX6R6YyidKCJlTqqBIbE+WgqtRyhmxOZ3rdyV9EN+9Pe2DCQAOJ0wbOlJK/PoO9jVffvllNDU1oba2Fm63G7W1tViwYAGCwSC+9rWvaTdHGkRxF2KqzHUUY0DNZSmGh5pHaIeRTGWk+GspRWszOCPIoJI6ZcscMN8xmo8rF0aQQbnpTljHM4OzACk/OLFrCvkYkvLNJN/MALVKYaFnyikxGRR7vnD9/rvnd8lOf6RF2hyyLEm8Xi/eeeN/KUrJlA/pvvJhrhPCCPMgJROawoRCoRjKVIYrrL9WzC/34MkqO0uBzXeURDnMh0i5RmCqpCtRi9wImMzjuV7ApVxTKN2Ex+NBpP80dizypsZ62yEfegOhvDMD1Cracy6jlIo9X7i2FaU/0iBtDp98eDwexSmZ8iFCLJ3rKNmEKpkUyhTCSEoHX1h/LdixyJuK5lgH4PJaAbO9PKGzszPjC7SSc7IZXVDsXvke6VALjNIGepeD6wVcUiRUAT+3zs5OXHiklZUGpGOhF8sPHMu7Dyr5oKCIIfZ84fxdxI+RSy5rNVDIybI4HA40NjYm5tVdWwTLRKFQpEHNZSmGh5pHaIeRTGX4wvprgRbmVEwKSQazaTKtxHxuqn1ll9oGestgLvpCSjROMTNScqyfCkbRNmqRNLfJTcky1RGTQbHnC9fvNb96RrB/9ZJLobJqZbpM0Z5CehYXEtRclkKhGMpUxnnPOtbXaKcGgSdSaGBOVahk02RaifncVMMobaCkHKqVNAnROEXNSImxPmv+ZXhTokKg1CySwo3Y84Xr95hI/+o1PoTKypI5pxMIhRIfM+iHCApFFlTJpFAoouhhSqeneZhW/k1Aou7f+c53MDAwkPPVXy3Ipsm02L3cbrfgttZkyzRVzn2MYsKupBxqlbSgzQ5mcomg3QEXcYzYPME11ns/OIhzT22EOx7FuMmC0vvbUXPFlZkn50HKiUKD68MEuXodG+pHfOdjQN8pvFXvwbFqB+46eAK9gRA8Ho/sjxtyx725ogqxVfcl7tFzAohMxgsQkXGp7gEDAwMYGRlBWVkZZs6cmffPFAqFD2ouSzE81Dwi9+SzWaPa1RYldRe7Zy7N9LJpMi12r+uuuw5HjhxJbS9YsABvvfWWLmUBsifHcu4jtT/0ngeVyIVas/RV327B7ZYxeOzaRpg+cnNLyk8TAI6GgMaXMq9byGaReswxWsigIhNpAB9NhLH+go3HxDZxDT4lT8m45yoDAEEZl+seIKc8lAT0fdCYUHNZCoWiGKOY9ClB7WqLkrqL3TOXZnrZNJkWu9fExITgttZkS47l3IfThJBDQUB5uS5lFSqHKE6n8LYIXcN+LCdS7PAhR2lyx6MALKntoniU8zglFg/54sfJN8eoLX82TKQzjgFw+ZyL8eakchc9N8L+8VxifCXzAgOAz+dDa2sr3nzzTWXjnqMMAARdL5S6A+TT85RCkYM51wWgUCjGJ68TOKs0ieOqe2yoH9GtDyL68F2Ibn0QsaEz8u5JzfQAZF+usnU/tfdJKQiDfcCJY4ltIxIjDKFi8k6X005y2mTcZBHcTmKuqIJl3eOwbN4Jy7onJClLevWN6JwiF545Rm35VdefVNK4lDaxfcR8GR0eROAHt2HT9DBqnekl7KTypmg8kmWw2oC6esEPEWL34btvXj1PKRQZZEXJ7O/vx3333Yeenh4AwC9/+Us89NBD2L17d+oYqfsoFEr26ezsRFNTE7xeL5qamiSlzzAMUl5qBOjs7MTVV1/Nqrvoi5bYPUW2u7u70dLSgubmZrS0tKTmzkIjW3KVbM+BgQG43W7U1taqvp9QH6muVxY/QqiStVCQ2A7IuresdpLRJqX3t+NoKBFptiuU2BZCVhvo1DeaK698c4za8o8Sq26jZ1N/SmlH06q1QF0DUFnNq7SZVq0FZtclFDurDaj1so9zs+tmMQE2/xAaXTZ0LEyvhieVNylyRpb9zPU3ssv56E9SHyL4PgiI3Sf5e21trWbzUL4xVZ5tlAS6+2TGYjG88MILsNvtuOaaa2A2m/H2229jxYoVeO2119DY2AiXyyVpX0NDg+C9qE9mYUJt8Clq4EoCL9e8jZRBMV80sXuK/Z7PPrBMpJrW6W2CqEd76tlHXL6CM5/8uS7zoJp6aOHTKLXv9fSflNMGepVD67RLfHOMmvKXl5dj4Ht/CQQZHxMcTlg6XwWQvXmL118SwOkI8Hefyvc3VycDCZ/QfDGlziVqZYS+DxqTnPlkms1mrFq1Cq++mpiEurq6sGjRInR0dOD666/H4cOH4XK5JO0TUzIpFAqFRJcotiIpUsTuKfZ7PvvAMhHzPU29lMmI4KgEPdpTzz7SMjoyE66XYDX10KKcUv2Tue6l9KWePM9+fpT1u1Ab6NU3Wqdd4ptjVLdjUTFbySwqTv2p97yVKueoH2ORKPyhCGbYrXBb0+bQNXO82Ptz6UpL8podpVEMLKlH2yEfegMh4bKLmSIDNCUOD4XybKNII+uBf8bGxuByuRCLxeB2uzE2NoZYLCZpH8mePXuwZ88eAMC2bdtQrnNgBEpusFqttG91xOfzYeXKlRgeHkZ5eTlefPFFwQAcUxFSBiMPbsb5p9sRPT8KS3Epite0w6pARvnafubMmax0EjNnzjT0GOCrx9Dn4yw3PfPnY6x6+P/pIYQ5ViTI49SipD3FxoWufVReDjz5AmuXFvMgq70HAetLHYrqETlzGuef3ojw2WF82n8G7afOI1o6Ay+2uuGVWcahsfNsGRk7x31/jjbx//COjPp4tv1MtO/Idnh0Tim+8SmjTENDuHDhAvc8yFEOLdBqTgl8dBDntvwjEA4BNjtKHvonOC9flD5ARjuSWK1W2MorET6b1oZt5ZU4d+ECVq5cmWFNpvW8xey3IqsFXec/x7lQBJeXMlIfDfWjNBKCtSq9spKU12Tbnv/Obbj5gX/E8PAwfuotQb0NmOWwYJajCB0LvVh+4Jhg2f1lHoQZq862Mg885eWi8x1F/bxJ3wfzi6wrmS6XCxMTE1izZg2OHz8Ol8sleR/J0qVLsXTp0tQ2XUIvTKh5hL7cdNNNKfOV48eP46abbspL00w9yZBBqx14YAtMSMQ6GQUABTLK1/ZPPfUUK53EU089ZegxwFeP2DR23svYNDfb7HiE+ys2eZxalLSn2LjIdh9JmQfFVqTI9g6P+BXVI/rEj4ATx2AGUG8D1paasfzAAUVzR4yIFBo7NyK5HbnqMzw8LNp35Hl1MyvgdrsxPj4OIPExPNvzYGzkLOLhMBCNIRYOwz/ih9lqFz+RILr5wfRKY/RznNu8FmOT5qy85/C0I0l5eTkiN7cBjJXQyM1trPYGAIfDgcbGRs3HBFlOj53jFTYYwNknfsRKi5KUVwCI9ffiZPt9OHAgUV5b9QLAlo6KPNM9DU1NTYJlj3G0wfDwsOh8R1E/b9L3QWNimBQmc+fOxb59+3D55Zfjgw8+wLx58+ByuSTto1Ao2mMU85Wp6M/C1/bZTDOiBXz1EDUtJE0ErTZgdp12JoiTKGlPsXFhxD4SNdfjMMlUVA/CXDD5si9l7iDHORzT2OaXbhlmojwmpqJzGnGerdSDyspK1gpLNufB2FA/4hvvTbeDgKml6DwZDrNPILe5ruUfYv8gYKrLZYZLtlV1dbU+Y4PoN384AgCoI49jBDOKDfUnzPGZl2GktPGHI6zzZ82/DG+K+KjKMUWmsDHivEnRj6ylMDGbzTCbzZg7dy4ikQjWr1+PoaEhNDY2St5HoejFVI54RoZPHxwczEk7yImuaPT+klo+takujNIOfPUQSxGREWmSEcEx1+Rl2h6RyKFke/df/z1l8kMoIdXT7Hh9ST0aysXbiBznCH7OPqCUfQ0hGWfWJ1gzB3e+ewzNzc0YHBxkXYPsO64Ip8ljZjkTdfn1pZ5U5FDN04sQxHdvZyvaAMKMqK0ZxwrNkzZbxjZfG6aulfSHlpCmg4tsjZVkv4U9FTh0bgJth3xoO+TDhUiEfSBDPuO7t6frNwkzpU3bIR+OhiAY7VYqSlLiUCiFjO7RZbMJjS5bmGTDPKJQonkqoaenJ2W+Mjg4mDIZA7LbDnKiK2a7v+TKoNTyMdtebjREOffRG7X1MCJa1am7uxurV69WfR0pMig3cigpP9f/RRN2Lq5PrzIuWwG88XLGqlkycmms+zjM0fQLfrDWC9eGHcJlJMf5jEqgxKM60jJ5nNvtRmVlpeQ2T/b3pulhNLoYilpdA4A4ZzRRrchoEwBdIWDBS5n1FJsno10fAZ2bEiuYNhvQ+giW/ePDnG0oN6ItlwzGhvoReHYbhk/6MBIK45lxG9Z3aDf+uVZuv33bHan6zHLaseuqubisbDrMJhNQPQumu36YkiGyjqE4cPS796D9mWcLar6aKlBzWWNiGHNZCsWIGMVkNBfUTrPhjSWJF8vDJ7txx4Eu9AZCALLcDjKiKxqpv9RE7FRrOmSUdihEEyiuOikx6V69enXqhdjn86G1tVW3tpJrrkfKS6s7zDK3RecmThPOlLkg8QLvIPNmgsM81ulkH+AuAhDnPWdbcQTBLzegyGKBPxzBE8PsSLB8damsrMTevXsF688k2d8ZihdXHkmt85YSc9+FSAQbusfwmoRjyXnS0nA5QPhg8s4TGkS0je/eDkevDzVWoMZqw67GBlg0VNi4TMCZ9dmxyIvG4mlA8mOH1c4ek0QdPxwdw+Znni24+YpCMSJUyaRQkDDvYfrj5IVpnEYwH+LJZNbLDyS2s9EOyZUe+/lRtF9cirlVFbCVegRfkI3UX1wvQdkqn5HaYSqgJEVBNj8EyE3XQ8pPmZ0wtST9+UjlilRSzvkRGzrDeskn2wy1dYnVwUlFGKFQZpsyVg7rp1mBaYlXlToA7ezYKrx14RsLLKXX7gDMJiAQSCvldgf7BLsDsNslK2NKPkSYVq3Fxw/cAUcogPFIFHETsN1biujWBzPOV+L3x9s2y/4e6PxxetVz2QrRa2UgYqKtGo7rM+vjsVkzfmdiWrUWXffdiovtZiAeh91sykhZQ6FQ9IEqmRQKgM7OzgzTuCkD8RC/qLgIXq83a+3AXOn55qdJU67nBc9R0l9amS1mQL4EnfPjlSYvhmeAZT6mBr6yG1luo10fsl9gWx9B77TiVD3cbjcCgQBOnToFALj00kvx3HPP5dRsTVRGFLxQG/lDACk/5XO8QG+6rLDZgGA6SAqpRJpWrUV8Y1t6tTMYQHxjG6IlnrQCRLZZKADLhqdTm9GH72L/LtKm7ngELS0tGX0jdSywlF4mSQXXbGLvN5tkKXZKPkSYK6pQvClR/keLQviCezKq7IljOLJ2Fe4+MQqPx4N169Zh69atbPkUUGCTCu+r8yvwWVkTNnSPIlRcmm6bN37B6LtoYluuGbDG+T3Frn/o0+Po7U3MH2VlZQjZnZnHMzBXVCFuscI56Yb5hRI32qdpW0QKhcIN9cmkGB5qg68vcv24tKa5uZn1Eu71emWZuUlFjf+ikAxmtJ/DyQ7ioYH/llF8L+UQbb2B3Q4OJ5b1BFj1IMl1vcTaWclY0cq3MxvzYNLXMrXKuGwF22QWyJBnLn/CFLV1wFAfcT67zbjaFAC3IgjgvZExLN9/TLGsCJa3ctKvSIafouj1ZZ7fc0sLahif/0+MBfDVd44AACvNCiA+XjLbVqTvFPlknslQwOUEvBFb+Y0NnUmt8vrDEbQd8qXcOZqamvC7538mev/AD26DjRFBN+ypgPMx4Q+ZFGNC3weNCfXJpFAonLC+0judQCiUePnIUhqRbK306GW2SK5yYNTPfqnWwHzMKL6XsuBIpSBW7lzXS6ydlZgq5pO/Kpe5bbTEI+yjSJqXMjlzih3Z0+HMaDO+NmXNSTGg78SnmG6Oo9JuxetL6nl9M0UhV97I3wB1K3MqV/ZGQmHUWNNmy8k0HQAQDLJ9XkXHi9jKuwarkHJNtEnEVn7NFVW46zM/6xmRxO/3S7q/rdTDStNiK5X/jJmKKbYoFLVQJZNCyXPUmoEyH9KsL98STb3Uki2TTyXKbPLFYujzccSmuTlfLMiXnOjWB1kvNF29fbizuZnVN1x9Fo/HeftRStl1MwdWSMxqgTkUZWxbM+pBkitT0mTbkdYwZHnUvlDLLQ+zL8vLyzW7liy5EFNESPNSIUo8ouMnBbHv/M0tqLYC061WzHYnfDOV+j+mFFgun0xA9ocE3usrOP+ZcRtuD4zBY7emVu6SOBwORBjpOkTHi0jf9V//PYxu3wh3PIKzgRA2/X4v4vszTZGFkCJfgsdIMEGfX+7Bk1V2eGxW1mpmX18fp+n0vn37sHLlSgSDQTgcDvx22yZcdrpb0PeUlKX+67+Hex7ZmCrzK01eOJKm5Fl6NlIo+Q41l6UYHmoeIczt327BKutY6gH8XKQIu3+nbOVEramXkVFitihmbsYF03ysq7cPt+79iGXe9eabb3KaZQLgNdU8/ef3Mbq9He54FOMmC0rvb0fNFVey7ms0k9ofLG/BuuIIHBYzgrEYtp6z4h+eTn9QMJJPJtl2DocDjY2NOVPUufpy3759iuZBtXIhZg6ZMWdYbYCnIqHQRMJAz4n0bypM8blMHm2lHs7xmctVJyX3Zp4TtDvQdsiHc6OjWD9rOootJoyGo3hm3IZVP3wIW7ZskTyHifUdKRtJ+GSE61ksRb6EnlFSTNAnNt6bVvAAHBwZx7L9Xbz3nDdvHsus+H9/eT4WlbgY98icx8lyHA0B39yTrtf+65pYZsyF9GzMJ+j7oDGh5rIUSoHS6g6j0VUEIBF90TERFj5BCL2DOOQQRWaLCgK9MFdm7mxuTimYQNq8TYr5K3Nf1R9+gyo7AExGr/jDKwChZBrNpPZPg34seJfta/uYQU1Hybaqrq7OaTm17EvmubOcdmyaHpZlDi+6ekvOGbPrUkoCl5KjFE6TR57xqST4jlYouTfzHAeAXYvZuTlrbWbsKnMC//wi3lhSL1lpFus7PrmSI29SZFXoGSVl5ZdMjVPpYgf7Ie9JmhWXWs3sC3KmpWHLUlE8ytomzZgL6dlIoeiFWfwQCoUiRnd3N1paWtDc3IyWlhb09PRk7d5k2gEPmYZABqZVaxPpBSqrgbp6VS+FuWwTzSBfJCS8WDDrPTjIdv5KmreRZm4ej4dzXwoJyq7g+TnAaOXho7u7m7efsk1sqB/RrQ/i15d68PqSetQ67bzlkTq+mOfuWORFo8uWWHk8cWwyXYg0uO63b98+LP3173FwZBy+iSCOfB7Bd//t3dTv5ooqWNY9DsvmnbCse0LVaiLX3BS02VnHfNxzCs3NzTj9CRE0SKZfdLIfog/fhejWBxEbOsP6vfeDgzhycwtOrvgfOHJzC07/+X3GvYix2vMZ73WEzsEooawFA4r6TQg+OZcj/1LGOfmMmo54So56Pw8JykjvBwcx0X+ate8C2Cba5D0dDraf8EgkxtoO2h0ZfUz6Fg8H2IrqM+M2zZ6NFMpUgZrLUgxPPphH5NJU8fNH7oH9TG9qO1RVi2mbns3KvYUwmvmmEpIrMebPx3h9MknIervdblRWVrLM27hMdwHwmvNKMSnTKoqpVuhdHq1MIrn6a8+ePTlpO7KfD46M4/sfnsLLL7+Mb33rWxg8+lGqznym2CTMfvj1pR7FJn9c47mrq4tllsiELA9Xf8XPDmakubE0XM66jlA/r/p2C263sP0XewMhvL6kHleVFaUvItNMN2O8WW3A7LrUvY/c3IIGhn57NAQ0vsRj/smEx9ye8xybHQiHMo4FoImpZmyoH4Fnt2H4pA8XQiFEo1FMt9swYbJmmOMn+8DM4ZsuZZyT5q7JCMGA+HOBbOsL4QhWD0RwzubkveeBAwewYsWKlE/mwlnVWFtqTsnJc5Ei7Fpcz27z2XU4evwEK4rtiMWWMXdTcks+vA9ORai5LGVKki3fnFyaKtqtNmLbznNkdjGa+aYSkuZmch5sZD0rKyszUrLwme7yvWxJMSmTag6crTGhd1RVrUwiuforZy+TxIpWmc2C8fFxbNmyBd/61rdYdW6wAx0LvVh+ILHNN76Y/ZChzMgw+eMaz6RZotDxnP11+iQ7UeU2vgAAIABJREFUT2PnJqDzVfHzJvv53OgoUJ75GtN2yIddVzfg8jkXC5rp8o4FcmUxEk6vIK57HO54FCnTdbBNK1lj1T/Ejq7Ls6JqWrUW8R/dDcQYJpqMAD8ZaGCqGd+9HY5eX+KjA/nMIMzxk30QY25P9oGUce68Z12qTQ6f7GYFMxJ7LpBtPRSMwHdhAnv3vsV7ztVXX41PPvkktd3c3IzlB9im+xl9HAhkRLH1emt0SadFoUwVqLkspaBJvaBobGZEklPTQMJfBaEA93FZJl/MJbVGj3praXaYrTGhOwr8ZbkwlJwSykMyfUXqRZyos8eeVrCklFuNOTxXO5FmiULHc/YXR5qbDAT6uf3iUlxVVoS6IieuKitCx0IvAKA3EML6CzbR8cI7FviUuMl7j5ssrN3MbeZYxew69vn+IU6zWXNFVWIll1U4toln4kCLdqaaZLuyfiPGksqxxmyTRy7YWH7qYnJLtrU/HJE9RjnHOIcrhKHmAgqlAKBKJqWw0ehFVIzOzk40NTXB6/WiqalJtzQcnMjwG8ymn2RO20QBYn5YUpFS71z6q4YJX6/w6Nms3VtTFPjLcsHsr8bGRgQCAcX9wtevXPu59iWVwNORhElhcsUn9bJL1DFkd6bk7Keb2kXlV8nHimQ5BwYG4Ha7UVtbm2qnoqIimM1mWCwWOJ1O1NfX88s9Ufau3j5MkEolqWhxnMfcvqSqgvVT1XSXvPmG5/mQUsYJK5HkvUvvb8fREHAqGEVXKLHNOX8s+3vA4UTKJ2lyRTTw7FaOehazty0chmZz5gr2GylT+/fv559nhMYL47fu7m509bJdkbp6+7B48WLMmzcPixcvFpRpgD23vtLkxV//hfTnQun97fg0EEUgGkMgGkOJy4WfbmrnrTPXmE2O8draWrjdbgwMDODOd48hWOtlfXBR+8wqiDgEFIqGUJ9MiuFRY4MvxZct3xELU8+kEPwk9UIoXYnWfiC57AfSx6krBCx4yTgyINWcV47cS0Vtv/CdLzdlDZef25VXXonBo4d566wk3Y7SOgmVnQ+u1D5VThte+ou5cFqtsDmdPD6ZXBFq44l9PSfY5qhqfS+J8+XIWHTTGna6ltl1CSWVwz9zIAJU/5zwV914b9p0OHk+APQlUvygqhame9YJyjiXfzHTZ5bZT6y6ceQLTd6npaUFA0c+QsdCLzx2K85FY/iHg5+xViOT1wa45UKtbAqdL2fM6j3v0uer/lCfTGNCfTIpUxK1ibHzATkJ4gvBT1I3srTqDeS2HzZ0j+LBGdZUEIwnhiN4LWt3F0eqr6UcuZeK2n7hO19uyho+PzfBOuskv3LLzgdXap/eQAgL/v3P8Hq9Kd83ro8MYjkNAQAOJ7BshZyqiT4fZMlYUhlkbnsqOA8tMiVMYVN1JZVlhxOmu34o+6OJ4/woXl9Sn8pHed9HPWCGZWL2k9S6+f3+RCzXyYCusRj3uoSgXKiVTYHz5YxZvedd+nylUNhQc1lKQaOlL1shkE2fEyHTIUOaFXGY5SVTFRz8H4szUxVIgK+eZLv39fVxtoOcdpJ6bKi4FMsPHMNX3zmC5fuPIVRcKqtOWsJZ5iwq+yRqxwff+bJT1iggaGI/zkNmbR7vasvO1cdC50vyGebyJwwGgM5Nsszd1T4fmGagLCUxCY9J6oV4om9SdSXPLfEoelaRPqo7rpjD+l2JjHk8HuxY5E1dt6nMjY6FXsxy2vH6knq8fc0CvL6kHg3lHswv92TsA6DatJ1MVRNkpBuRI4tCx8p9JsmVawplKkLNZSmGp9DMI/SM7il2baVpJZSUWch0KBdmRWJ14DKNO/rAHbypCqTAV89kPxw+fJgVoZNsBz1MwYyU6oSrzG8sqc+ZibvatuE7X27KGi7E5sFjN7dgLkNWPw0BDSKyKj4m0mkuRkJhPDNuw/qOdNkd50fRfnEpLqmqgK3UwzkvJPt4ltOOHYu8uGh6EcrneNF2yIeuYY50PQ/flVAwk8yoBErK2KlPdj/JnyYkCY9Jppbzr2C6klovTJNRVWO+T2BmBPIJzqyF68fPZtY1icMJlHhkly/wg9tg8w+lt4vLcOOnI6rGek9PD7ChlZX65nQE8AdDuNydFrhgrRcIh+EYSKfTStZTzOxYrE/IVDXPRYqw+3f8puV8dRQ6Vu4ziev4zs5Ow8ythUqhvQ8WCtRclkIxCFqlXlBy7dpptsRLfPJhPk1auhMlZRYyHcqFWZFYHbjMx4RSFUiBr55Jc8jm5mZWyHyxdtHCFEzv1CJy4CpzLk3c1bYN3/lyU9YowUHIqlOCrIqNCWaaixqrDbsaG2CZfGlm+dr5hwD/EOe8kOzj5GoYAKDXh12LefzyiqYDg4ztsfPA2UFWGVMy0vMZ9woiAJxjyxanaara+ZdcUbXaEiayTEVp3eMA4a/pcNi562q1ARZLYlV2sC9RvvX/gCgjR6cQtlJPoi8mcZZX4s0nX1JWt0lmz56N6Dz2h5+aefWoGbvAUpAdZ3oz+sJxdgBAem5N9kH86XZEGW0kJoddw34s9xEpSBjlkzqOhJ5/cp9JXMcbaW6lUIwANZc1KIY0J8xDmO143XXX4Zvf/GZO27S7uxunPyG+fMswBxSVCxFTQ6XpK5REJBUyHZJiVqT5GFBghimUqoAPZrkHBwdZvyXrmTyGtL7weDyIdn2IaOsNiN65DP+n3oOrSt2858sx1TLinMJVZqOZuBux3bhQIquiY0Lt72CYDNvY37T55hAyzQrchGnl2PmUjJge/Un6WJNJsCy8pqlqzLFJs8/ZdZxyGybaKbmdkVLm0Z8kVjCZMHN0iiAlRY2SKNrJ65ovqk1fl6w7n7LPgO/5I/Z80coMVej5J/ce1DSWQhGHrmQalNWrV6dMMXw+H1pbW+kXMgUw25FJrtp09erVeNg+hprkF31Aln+KmFwEbXYwM9cF7Q64mBeQoWh1d3dj9erVGBgYQMcsd3oVAsBnZ4awQKSsXKZDYr8xzabGevswcOQj9AZC2vQXuWpQND1VRz7zptL723F0ezumI4oxWFB6fzurbbjOI2XO7XajsrIydVx3dze+8Y1vsKI+OhwONDY2Jtrh8QdSUSZdZuDlL16KL/zfw3A4HHjooYcy7pFsG6H25jsn13MKV5nF+iTb5KLduNqgvLxc8JykrBbFoxg3pWVVEHJMnPMnTDiTK8gcY0bwfI65LNnHo5EJ1n6+OYS0KIhufZC1Ose8B/PY6A9uYx9HKKfhUT84EqQkIt0uXoyRkRGU/X/23j06jupKF//63erWs62XJVl2yw/JWOal5MYknsBaw8ANyehih2SSMLFJkB0PyArBcAfB2JbjYBMIDtiCxMEkIYTcPAiwmMlkYHEzgcvPmBkbA37JNrbcsqyn3ZIstdTP6t8f1VVd59SpR7daUtuuby2WKXXVeeyzz6mz63x776IilJWV6dY5vafup/oGCdq90HcWeyJGy1QAtVZzg72IP/sY0Jegp1bMgWndQ5pRW4PPbIfj3Bn+YgAIPrsdrs1Pqz4jtFNKVeSkffcPso3MkjIASX3eWRjDHIfk40eiTyz55ErmgMvlQn19PQKBAHNtE6C5dqi8/7TWTxqp3m/AwJUIw8jMUhhRyjKDVOiF0wG/34+W3nNiOPhxswVLU6ADaulFy4dnSN+VwU7skd6gY1MoQLq5bjlvF9usNyKpGnVI6TcpbarODuy81ouV+44z+5oqWBvC9XevVTUgKq+5HpUvvC7zA1EzPOh2lpaWipEzAd6XR2pgArw/g/B8jModaDebEI1GEY1GsW3bNrz++utpUbWycU1h0ddu1xiT6cZUyE3LB42lX3v37lUtU9DVVEDMiRE/SdOU0lIVjCg9RpYwxj3HjmI0GsVQOIaBUER3VGO1Ogg5BigDopA8WaINmXAcOB0Bvv3uITEdRyAQQHd3t26d0xuhNZWIzopUYGqtju/ZAXQnKaToOi2jmbL07LzvDOFfef5MJ9L5hEMY+Eq+qYmAPYI+999QizkO+QdWlnzC1Me6hoYGvPHGG6pt0vwgpPL+S5XqalBjDRjQhmFkZik8Hg/hq2VQMdIDLUf6t+mGx+PBgc5O0XBqaGjA6ynQAbX0Qs13BUgtpYt0My0NYQ8AhYVTFJGU+tLssSeXqMmOF2tDmK4Bofac1hix6iDusdmAUNKfLsQlA4YIz6azPmTjmsLyxco2Y3gq5KblgzZ9Mogn/gMQo3w4E7RUNSNKj5El9LUicYJ1/GIQK/cdF/MqakGtDkKO4gNm3rih0pmwDJm+KCfL9whkXt58RGd5rlEWkv6LrPygErAi7CpRhAFRz4bCEVRak2e6Q+FIWkamFOJ75cxJgJPoUZBnZAjybDnYiZ3XelHmzsGcxVeJfWLJJ505INwjBJkqc8UQ2/6g+BHnSkhpZsBANsEwMrMUBhUjM5DK0eVywWQyaVJupqs96bRB6XmBJsTy8ZNCa1MopRv19SV9daRBO2oALK3yKpSgD0q0JpruG7Ta4PV6ZbJSej5VqiVtQPh8PnzmM59Rpcz5fD5FX0tAe4zdbjdxnZOTQ9wz8NW1yH1hJ2yII8RxWP1fn4ibpll2G46sbkTb+nvQtuvZlPSotbUVq1evRigUIqi30n4pyc7n82HNmjX45JNPAAALFy7Ec889h6oc26QiddIUxsjwBaZRN50UWrquhx9+GJs3b8bJkycBAMFgEF1dXZOrX4O2vrjYgyfL7WK+w+eiuZgKMI00AXYH+++pguprmTsHS5YsQSgUwvLly5m6pnesmRRYjuNPZF99kVjrWIaMB2B+hMz0B5h01n1NA55Fq81VpwhHhi9gV8CGNUEqUqvkHtbp59nxENavX4+RkREUFBTIxkRoq+xEM9EeYU53B8PiB4bXExGjucFe/LbBi/Oz+Ii13zvUhf7+fgwNDRF9SeVDGhFkSvC9bH18SnLrCsg2mr8BA9kAI4WJgayHEbJaG3Q4damPn9aLTrqp6OjuIehjAv76+SWoyXUm/1BaAcujP81Ye4Vw8Wqh6vU8n2oY+q6uLtx8880y+ir9rFQH6Trcbjfeeust3RuKW265BUeOHBGvlyxZgjfffFOxb263Gy9dU43rC5PetammUmGVm0q6lMbGRgwcOYSnr/MShs/u67wkZa+qBpbNT+lu05HVjQSFsSMM5G2Vb8ibm5unLeUNSw4AMlq/bDNOpWkZ3/JdOCRyDVV5Ub3rpYyvg4opNAA+iM3Gp9JK+UE8I9BwBdTUYsV7xzOS3ojWHwLUGqWWRkYwalL1yZxJcIN9CZ/Ms/wfEj6Z0rHRO7+kfZXrZh1WvNeha0yUUpWopQ6h69vvHxOZPrQ/u9aYCPXIfD8n+b7Sg5lIy3UlwtgPZieMFCYGDFzGoKlEUh8/Laj5QYrlR6Kokf4hxWTaNKTtneO0Y2teBLFH1mG9O4K1+zpFI5em+7Kel16nSrGqrq5GaWkp8zSDflbYOO8sjKH/hlq0HOTbWVpamtKGdHx8XDyZ9Nh4v1xusE/cHLJ8OktyyFOlVFOpsMpN5drv98tOsx3jkWTQEQHChlcnmL5qDF+n6aTQ6qkr0/7BWLGK32wnDDnH+BhxvyMcUihpklAKMgOIVMd00hfJTkipvI/+P91B3J9ueqPNvmH83JsHt5URSZdaozKZRoY2vLHim/zJ6RTkPlaCuaQc0Pigo3d+EWCcsusdE6WTQlX/RRUXCdqfXQtCPUonqlOJbKP5GzCQDTCMTAOXNC4Xispk+zEZvzGaUiV9yQtoOdiJ9ob5KHE6+MiVt30dlbprUG/v09d5Ue+yAQM9qHfZCCNX2g+pjJToqunQDJX8dqXpQr785S9jk3Mc9S4b5jgsmOPIFds5MDCgSJ9knQK53W481lCDqwuStNn4s4+JG0bWWAao7Axa6Sm6PzyAkR9vgVsSaZQu1+VyobGxUdQ5l4uIQyxLOeOxBYnfi2wWnpooQSgcxtcaG3Xrr15fNTX99lFRKGlKfKrrgVJdk/HLZM5vOoKqxJCDw0kWMEWbZGbgH7rONFL/yJ4p8BAnSWrjqfQbS4bh/EKcHgtgqSTNT9xigWnuApm/XSbfFfGf/jCZ93IA4HZ+H+ZIWLymI7ZOtm7p8263G/F4HOPj45plpeILKoL+8OB0Yvd8D+xzXPBHomg52JlZOjFVnz8SFf9fbezV5DcTvpfZ6PNuwMBMw6DLGsh6qNEjLheKymT7oUZH0gJNqTo4Mo77eoLEZmZgYACBQEA8gZudl4vKRbVpf7GXtvc3Cz1EtMNzUeAbJ+X9YNFIaSoVi2aoFZ5faIsSZU6ol6YMnx4L4qZ3eNqr0nixqGdf+M8P8WqlDU7p6YvVBstP/iiTjdA3y9B5DFHpKSqvuZ6oS2rQjvf1wCXJgnwsDORTNLlQKITDhw+L99TX18PhcDB1qKurC/0PfBvXFyQN0aMhDlfl5QCSU7bxaAxHRyd064eW3gp9ipwfQGR4CMPRGC6C7D+tF1Kksx6o0Sq15pcStVRrfstoq7NK+ZM/ySa5dHH9lNLElKiOWtReFrSeURt3pd9YMmxvb0ekdS3muZIL2LkoUP0LfRT7157fnZZPceyfvkxEfuXigFnyIYhuw2TX93R1PJ33Aq0HCIcJSrywlmTqY660vpDdgZaDneg4T7Z3ze2NaLKOodRuRZHDinFYUTaJ989UYDLvYAP6YdBlsxMGXdbAZYlsoaik47ckxWT7MZlw6ixKlZSixA324tB934aLi6HEaUWeNbFsSAIqpAoidQV1glLpduLtG+vFlBYCtFKDAHJaoR6aod7UHzRlWPrFXXG8GKdABeEgbBbloCrM9lRXE+kpYh0fI9b8VSAS4aPRNm8EfvNToJenq0oNTICn19LlLl++nLgnEAgopgiorq7G/QNhPBjjCD353bJy4ELyGMJiMjEDbqTU1wS4wV7Et3wXCAVhA2AzAy67BRUA8O+/BRJGpp40RanMz8nQKpWopZrzmz49cudCjPo6TVCiOhKnQnYHEI0QuTRZctQ6SUonvZFS2p6PQB7zK0VLZT2fDhWYjTik4bfpNkx2fU83FVc67wVZntJH1hG/L66qgCWDxpO0PudgL3ZL52li/W92R1DvSrJS8gDm+jLZ9/BkYKQ0MWBADrP2LQYmC5/Ph8bGRixfvhyNjY3o6uqa6SZdMvD5fLjxxhuZstOK8jmdEDcrAz3Jl18KoNs9nf3gKVXHcdM7R7DyveMI55PpSeJ7dqDeZUNNrjNpYArQQ51jIPjM9qS8QkFwdgdQWsHTBIVcfZQcdcmIlSxegnTmolBPy8FO7PeP4VyUD6DRclAHNYqq/+DJT/BgsQ0WE8V/rZij2Q4C7T/g5cTFePnt+j64HmV/SBa9NlWdY+pJQRFxj81M9StF/ZCOz7EHvkPSN6UY8Yv3dnd3s+9Bsk+TnZ+6oUAt1ZK1qWkDUFPHz4GaWv5oTKW90/lOMZeUw9L6OE93tdt5mqhCu7jBXsS2P4j4U20A4jDd1wZL6xMZ2egryXBXwIb9/jGcHgti/9AYdgVk8WaZ74qBgQGcPXaUvFGvvpZXEZddEZNqGxYXe/DKDbX46+eX4JUbalFXnNr6rjY39bwrJqUvGmtqJsGapz6fD7lKH1yUUrYknj/6wNpp3XcZez0DBkgYRuY0QEgQ3NnZiQMHDqC5uXmmm3TJYP369di3bx9TduvXryeigrrd7plL9ZKO35IE7e3taGhogNfrFWlg0wWtuiPDKl/d09xwnPedIa57x0P8JraA2jBJ5KhHRvRm3dS0gXjx/93f/V3Kc7G9vR3Lli2DbXYlHo3kAlvakbe1HWVLlmqOV+9tX8MHI+M4PRbExyMBWONxLC3IIe7hLFbgK99GbPuDiD2yDrHtD4Ib7GOWJyISIS5joRDok694HDgbiqEjDBTe38bsVyo6x7pfkDdn4T8+mGnjOUX9kK6V9rCCgQkAYxfFeyOULEwmE6qqqsg+acxP1uYwrQ2jwoZcS9ZSQ87S+gRABf7B8AXiUs87RTD4Yg81Idb8VcT++W6ZbqXcRw056jXmhXq/ctPncWR1I4JU21jtUpLhpp3teDSSi2+dHcej4Vxs2inXY/pdYTabEQgE0D8+Qd6oU19N97QS64zz/jbVNghBs2pynfhUUS6+m8/JZL53714sWrQIc+fOxaJFi7Bv3z7x+dbWVrjdblitVuTk5GDhwoUpvSsmsweRrqm22vqp9W9k6Nf69etxPiTPZQpAPl7U845wULPPmTQMjb2eAQMkDLrsNCBbKJ2XIrQiXkqRapTPyUIWpl+KFDfXM0m10ar7VN8g4bM5zgGu8opJBVRQTAhO0wYlctQjIxblb72KP5OeuVhdXY23335b5geiZ7zu2bgFBw4cAwC8ckNtkkoqbfPc+XxkylRoezYbEEpGmI1wHEJxDrmSk2aT3Y55e15W7Rfhk/bSLnBp0EjR+jhA+xSaLcA8efAVLRDzm45oLIU7D34/2wc/Ho+jrKyMbKuKXgHJzSHAB/hpbm5GmRl4xD4GzxwX/JExfL+lmZlORwolmmjK8zswqnqt550ii/AaCgL+QUK3WP1WbaeGHPV+bBPqfeWGWn5t8Q8SbVNqF6ttemRLy8dsNoPjOLQc7MTOa70oc+dgzuKrdOsrvc5UQn09oGn7zkgYnZ2dRN/uuusu0RCORqNYtWoVTpw4AQD4+Q+348Wrq4iAZlq6KMVk9iDSvnqm2h+OoV9+vx8tveew81ovSh1WzHLa4S4tBwqK5OOlEkRIqc8pzwEVGHs9AwZIGCeZ04CZpEJe6lCT3UzLlfhqHwoCJhO/uXY4gRWrprUtU4nNvmGCCvatU8PiiYsaDU48SWGczu0K2PDxcADBaAzBGIccmw3cYB/zJHKyUHvRT7XOSOv22MhvepE4kn1M9SS8eSOvZwl9+8GwGav+6xOMRqIIcxzGOQAtmzXbp3bypDZ+MtDGhs0GjI0ivudJ7VNZCaTj0XKwE8fCSNKopSj0qI6d3+8n2o9oBKiqATwlfFkjQ0SfWJvDZneEOH1qdkc0ZUKfSArzQ/ChjX1nBf9vxyF1QeTmq157PB7McdpFCubu+R65nGmdEv+e1K1UN8Wa81MntVKoh54TQtsyvVmndcXh4H2iu4NhrNx3HC3DlozRepmg5MAyfkIh0hCVXrN0MRXM9LtSL1j65fF4xHFa/vYR/ON5MyyP7WGOl/R5vS4NmdS1S0XOBgxMF4yTzGmAkEycjlZoQBvt7e343ve+h/7+fpnsZlyu9CYuHgfiMf6E6dUXxa+/dPj11tZWbN++PaNR6LRCvKv9rvXsqCMHK/clo5Dm5ORg+fLlmm1nBdXwfeNerF+/Hv39/YjNzRMjrM638H6at+89hk8++QQcx2GeOwdPHToEj8OO4nle+G9fhXs2bkm5j3RoeToq7VRCWjd9MsfN8YoRN2MKJ0RidNVhP071DWKzbxjh/EK+b+2/F2+/NxHZ8EufJPuep0enVIzbVIKiCCd4keELiJwfgEvwq2Wkc1ADPadH17VixfbtsF8cRtvcQiwoL4Gt0ANT0wa03xkWowL39PSAk6RT8Xg88pO8mjrA7uFPzUJB4MIAjj6wFvlb25npB4rsIOCx23TLRMpyCNns4M6eQY7wSTcUA9q3ApLxo3X3tw1eEKGhKN/X9vZ2jG5sJhgGsrYo5cD0DyK2/UGYmjaknPJHKTiQgN7bvobhHVuSUZAVUh0J9VY4Kf/JhN7rTQfBmvNVOTY+JZCQw7ViDn6ytQ3/tLFNvO/hhx/Gtm3bJv3uUEstIl3n64o92HmdF45wCB3dPTLjx+fzEfoLJA1hACiyk3Ly2OV+p2qY8XelTgj6Jcr1T3fA7XZjwYIFOHuW9zkPhUKKKaOk+pnX1YWy5mYgETW8v78fjYz0SplMPaIl58sl5ZoBA3phpDAxkPXI1pDVsjD9UpRWiHnhWKk3pP5BmUi7ohUiX/idlYLk9rvXqj57yy234MiRI8x61douS8tQWoEVh3rEuuiUIOeiwA1vJttB00uPhYFb35K3U9jQnztxHL2jY2g52InuYFj8fbKh5bnBXlhf2IXIYD9PW8zNF6laWicf0rqlG0068iE32If4Tx8DhOA95VUw3dOK+J4nCR3b7x/Dyn3HM5aqR6bDDifvF5ubB4wMEZFjpTqthMbGRjzpDsrGlZVSQg/0pn5gjXHl7m0y/QNA/O30WBAbAk7m5rD4F0/K0uE4wiFZmSyZxLbel8yjCICLx0l/VbMFlt2vKvbzC59uwO7P1KmmMIk91ESOz6xSWB7bk6xTSA0x4ufLiUT4QFECauoQCod0p/zRE7lT73jRqYY4ixXmufPFMvXOWVZ9r95QK1+Xa+pgSStqrDrUUosorfOsvjU3NxPlmM1m/OEPf8CyZcsAyOWlJzXTVGC63sWZfGdq6eR0ph65XFKuzSSydT94pcNIYWLAQIahK5E55PQbmhaVCb8NLcqPcC0EoAAg0iO1nh0fH9ddLwEF/xrxWepkbyhMUsBoKl1uPEZcC2UJp0uVVqCyKBc7r/Vi5b7j4u+T9XeN79mBCO3bdmFA1ylWZW4eXnv+Z5rGqLmkHDGrLZl7r7szuaGXwGPnZZJOag5WOxGNAIJvrMmUjOw7ADlFVYefsd/vh99ul41ruls2vVQ21hgrnQ7TPltCKgz6ee6eVl62wxeAwCgcEwE5jVlJJlSkXxP9u408iaL71XHer20U0W2hrpmpKKQG8thF0Il0HH3d4Ab7mDqk5xRX73jRPormWaVEHk29c5ZZH4smnGYU7FTrl6LExOHFG2rFU+Inzg8DYPeNLmfu3LmigQkATkEXEx8dnFMZfGcKoXe9yuQ7U0snpzMeguGzaeBKg+GTaSDjSDdaWzrPzWTIcKn/lWnzTsWopvQJu43aYLrdbs26tPopUHwEP63fLPRBKZ4yAAAgAElEQVQQPmPC7ywfKC0/knTD5yv51wggfO5qamVh/6V+S4A8DYdYloIhRrct7QiiOnzbpEg7XQaLuqrgyyXoDJEK5vRxBJ/dziya1c/gM9v507ZoBIhGZBu5iCMHx8LJCLV9t31dswsej0dM9aKUziGVOUvPDbfbzXye5Ssp1b9Q5Tx85/3j+Ic33hej/e4f4k+9PR4P83lhfqPQI35YQCjIG98p+gyHubjEXzbO+9QmsP8//oQny+1ieosqp10fZc+dp35Ng9Klju4ejNLmbzSirK8M/aTlRqfm0Jva5/AZn6IuqOmLy+Ui7nW5XEzDP2SzT8l7Qm2cnr5mHuFH2Ta3UPFerTX37HgIK97rwI1vH8aK946jeyI8Ze++qXyn6l0b6f7X5LuJFDAm/2DKKaiUrrWQSXkYPpsGrjQYdFkDGUe6lBCl59ToEZmin0xFEme6bQ6HA/X19cgJXMT9RWbxC3d7wIoX//ymaps+6e7BxHgAbquFGV1QoPxszYug3iXZ1CdoYsq/1+LcnetV6UJSOhHtd5QqtUiNmtTV1YWmpibRJ3OuOwdPXTMXsxI+mUO3ryb8qoRnacrn4fEINo7aZG1j6QoADBw5hKev88JjsyJsd2Lxj8iTR0VadE0tcfoi3s+gCWvRTJn1JIyY+J4d6D5+FH1j4yIVeMmSJXjzzTfR9a1GVEq+GyhRU1l9b58F4tlgjIPTkvzu2BEGbmHQk9XQ1dWFNWvW4OTJkwCABQsWYM+ePZrjIJRLz8O73vkIf/k4SdVesmQJnE6nNkWSokey6HdSv9zKl3YpPi8bT6sNpu8/o7o+xLZ8F5DQGz8eCeBL/1+H2Ic330zO9/1fvRnXFSSNpf1DY5i945eyeUWvgyx9YemjAG6wD0cfWAtHOIixWAymODDLacNshw0mKZVXiQLMolbHYsnTd/A0zq8d6IRD8KEt8cAaHOcN4IQvrbmkXKTynjvRwaS4S7Hm9kY0WceYkVVX3XYr7nVFkmvpuA0vvPBCwiczcZpcMQffOXAaf/7vzNMU1dbG/7OwCM6LQ+K9EU8JnD98XrMc1rqqtHZNBfVSbX5Olqqod22k5fGrpZXIGzgn/p6K28Bk6bCZpLhOJzX3coVBl81OGHRZA9OGdCkh6TyXKfpJKkFO9IJuS0VFBV5//XV8dOcXREOvBsAGBztSoLRNC+wA7G7xGcc4+YxA+WFR4qS/i35aEl+v6pJy5ktT2PBXDvvxarUTuKpOty+iEpLtSBgTu7chJrSjuprYfNNwgZ0mgE4bsbRpA17XQcFiUoghH3tT0wZYX9jJ9MlkgqZpjvgVKYhq/RDl3Po47ly+nAhOIVCYFVPB6Oj7WH4+IEl5ciYQRMRqw9J5c4HcPGx+433VMliorq7GG2+8oXqP2pyl5+EGjwV/AURf4jKXDSOxCNY67egOhpPPa0TnZaU7evfdd8XrmNrz9HgKp30q64NJQm88fMaHdQeS/pk0/bzQShKKZtmtujaeSulSlGAuKce6U350dnYqptMBIDsJFOfqsJ83LHPz+Tql7gEJOMIhfh0SDFIhtROVPkXQ629Qes3SsWZ3BPUuvq302rehyEz8tsER4cve/BRRRsfy5cR1pmiKalTL2PYHAYmRaStUPrXSomzqec9lqk9TSunUSoGTAC2P2CPriN9ptwE1TJYOm0l5zGSqMgMGZgLTbmSeP38eGzduRFlZGQDgnnvuwZtvvomjR4+ipqYGTU1NAIBf//rXsr8ZuDSQbrS2dJ7LWGS4VFNI6IC0bXOcduye70HskXVY6NQXKTAy7IdSDEHF6IIaL3Gt6JBSMPPsqfgipoJMGvV6+6SkKx4btVlm+LZ5HvuZ7q+npqYNiLWth1nwOwsFFSOs6j1BV4oCuitgw5rgGDx2ySmPzr5bSPYxwlwcm0dteO2+zYjv2YEd3kL0FteKp0yZonYpzQvk5vGGjAQldhteuaEW9Xk5YiTiObCIfrdCeVp6T9f5VIUTZ1Z9kY+Aen8bylWeNzVtQHzTvcSJndb6INXJjY2NokEMAAMDA0R0zECMJBPR13rq0AtBDjLafAIhDjJ/P9k6UDkPsFjJj1kCBLnppJjrWb/pyKp1OTYxOq7eqKuZjCCqF6l+BKAhjUQ6MECGCRbaPxV9mkpZpS0ThfyX0zGOM6E7BgxcLph2I5PjOHzmM5/BXXfdBYCnD3Ach23btuHll19GR0cHXC6X7G91dXXT3VQDaSLdcOnCc2b/IP6lwo1ZziiOrG7E3LYfI9c7P6N1yaDzC6sUWuHIpW3bPd/DpxsY6IGD8oQunudlln+qb5BIUaDnGaWXuN4UJlLK128Wegg6pYiuU7pO5mhI65GVzdi0Zzrcu5KujG5sJm/UMfZa7YwHJlBlSw70YOcpzGU8yzK2uabvyQzPp6/zitElawAsreLHf9PORJ/61UPm9/f3w+12o6ioCGVlZWhvb0fpM1v4dB4JeNw5aH+yXRZIafeyOmxK0I919T0e1z0vfr7Ag/k2JIMN2clQNKUuB8oZOjg7Pxder1cs35RjV928Sut8qsJJ0FOP7WjD7B/9TPY88QHARPku2h2qHwjoOeVwOESf10AggDVr1ognvl7vPOBCf7Jou00xRZBQrkBHnS9J6ULPR9bYCHIImMJgotorn9eUwXj22BEETBZybbLagOoaUe4hm10WVAiAbG7pWb+L53kJ6rHNBNGfj/5NaV2U1uNyuRAKhXSlYZoMzCXlYsomv98Pz3trU6pr/fr1qhRvACm/+/SsqVOZ7iSdDyM+nw9b3z+OZncERTYLLnLAE+ejPOV/ilKx0PN3yZIlhIuIAQMG9GHafTIHBwexbds2FBYWora2Fh6PB7Nnz8Z//ud/4rbbbsPhw4fhcrlkf7v99ts1yzZ8Mi8PHFndSGxgjkeAq345tRQTFo1Uy4hKxVeD5dcFT4lqXXfc9Hk8OMsKj92KsVgMDrsDtXOr0/IZVfNrUgrDr0qpSyMlgLQeWdkMf7LpCveuZ+xT9Qve6BjH9YVJQ+aD4XF8+g9vyZ5l+SghN0+e33HsYsp+gUptE2So5NOXik8pXf5tn27AfQWAPRyEPxJFy8FOlC1Zqjwv/unL5AmhxcLPjUiEj8Ca4+aju9KoroFl41Pyv+vA2dVfRIU9eYzbE45hzgt/krdNLUVRdQ3fTgU/TlouJpMJ0letw+HA6dM8hZaWdzAaQ08wIpunxcXF+OxnP4sDBw4w5o98PqqNfdPtjVhjGUOpw4oihxXjsKIskdKI1ilaDkLApOeXL8XiqgrmnBHLd9pQZLMgYLKiXKF8LYjz88xJMgWL2QJUzQU4AOHglKzbk8Vk6lpOUYm9Xi9B8Z7u9gAz4w83E2k/jFQj2QvDJzM7kTU+mcXFxfjhD38Iu92O3//+9xgZGcH8+fPBcRzcbjfGxsbAcZx4min8jYW33noLb73Fb9wee+wxFBcXT2dXDEwRchEDkNwEuuOxqR/b4mLgyZ+n9MjIyIjsWqmd/iIPIpKNpG1+LTyP/Uy1/PisEqzct0+8XrZsGd7e/XJKbRTQnBtFfU7Sd8k5ERXbSvdDQMvBTvzshsWor64EBgcAJDfJ5omxlMdEWo9Q9tU182ByuoA4h9jDa4DRizDnF8JSNAvOwEXZ81OiBzrG3mq1KtbN0oP7B/vwo8WVIo31gaPncIzxvEwvijyIXRyGNC27eWIMFuo+RCOwvrBTU4dYbSuMhnDxqS2IjQ4DzhxR3vn3tcFaXMxsk0dn35tzo6izWwG7EzUAdl7rxf8+zx63aN85XIiSEYQR44BYgr4cislPEBOwWCximdG+c3x/Lg7Dkl/I96Oc/cIDgFEryRMutFqY7RucCBDjIIU5EgYiYdk4Kc0p1rdc4V5a3k6rBTW5Ftk8tVqtYrk03ZU1H9XWp5NDI1j5ySfibwsWLMCRf/0Fs6/RBx/Fxafa0HnoI/QFJkT69L1nRnDkT3uZz2iVn9KYJean/6G1iBw/nPw7FwO6TsNWWw/Prl+zn2UglXV7sphMXWVlZYSRWVZWNul2TrbvauvgVGE6x2sm6zSgDzOhgwbSx7QbmSaTCXY7f0x13XXX4cMPP8T4+Djuu+8+fPLJJ3C5XHC5XLK/sXDzzTfj5ptvFq+NrxuXB8ZAbgIDJktWjm1BQYHsWqmd3OoWIHFaFrLZ8Z13D6Ojrk6VrvXjH/+YoC39+Mc/1pSDEh2qiNqUFtmsYll0PwR0B8PYeNGK17c9JzvN4HLcKY+JtB6x7O8/i/G2FjjOnUmWHZwAN9CLjRVu/M8O8nmhToGqGBn241TfIDb7hnHR7oTJZEIgEFClGtKy0UP5fOmll5CXx6bRsvQg6HBg5T4yKipLXlK9QG4eoqtbEN/zJHlPjhvx1S0A5Rd4+uOP8KXPfla1H4uKCvC4JFffc9FcXHjiX4ix/O++83jgyF/xzEcfYWFFOTi7A11hwBmPYTQOPP6XA+hU0FWnk8+lKQTmqXWSc7c+PwfPO6J4+4ufReH9bai85nrxt9gT/wLphwsAgNlMnFb1jU1gMBxBXY4VNonBGRwZFuUZk/SH6+3GhSf+BZbWxxXH21ZYRAVkKWKOzYTZyqZ8AuBs9mR+UeFvkjlB60ROTg4mJibE6wULFiR1WaID4f4e2CV2tXSeFhcXi+XSOWZZ81FtfUpl7YLVDjywDesbG3HgQFJvent78cEHHzDXLq3y6TF79+47sO4Um8IpjKM9QRGuc5ph4pLmfWTIn9JaRLdNrR8spELjZ8lh4NghJs2aLvfhhx/Gtm3bUlr/tZDSuDOQyilSptwdJtvmdDATdRrQB+MkMzuhdJI57XRZjuNgNvO+Sr/61a/wqU99Cvv378eqVavw8ssvY9GiRXC5XNi7dy/xt6uvvlqzbIMue3ng3EcfYGhHG3LjMQRMFlWfzJlEuuHIp5KKo1T2+Jbvij59AJ9qQAhEoydFSTp0YhpK8jr3rUam3113hMN6v5kpXxmFLxHSXgparkqyYVGJBzgyPcCyZcvwxz/+UXe/ALm/lN4NlpKsWbTFle8lw/iz+vfbq6vg6O8W/xYqq4IjzhH0zNNjPLVVSr9kyZMl01tuuQVHjhxRp1YncCwM1L9ARYykKeTlVYSPndBHuvyOMLAkUZYSvVdpvPWm/hAonxU5dpQ7bTBLT1XLqgCHHehJpMkor4LpnlZxTtA6QRsMSvqgNk+Li4vxwQcfoLm5WTS4Fqj4ZGqlC0pVP7u6unDzzTcjEAjIZMq6V6l8brAX8U3NxAeTMMfh45FxJr2aHsc3b24g/UE1UrdMph8spLJ+s+SglC5nOiiak02hkcoGP1P9mYm0H0aqkeyFYWRmJ7KGLtvV1YU9e/bAZDLhuuuuw1VXXYV9+/Zh06ZNmD17NlauXAmz2Yx33nmH+JuBKweV11yPSslmNFsXlXTDkU9liHilsp2SlArIzSMiSOrpRzoBG2go1VNg4gCYZX8fjsTw+uv/xi6MCkYihLSXQkvOwjUrRUKzjyxfTf+U+pXuBlFJ1kJQp7PHjqB/nKctSvvB6p/jAnna5ujv5tNQSO+LRGX0S5Y8WXUI6Thk0UrNFoSiUTjMScMsNx4j76GDbSUCx0hTfwh9bDnYiZ3Xegn/ZDEiLRUsSAguozTeeiNcjgwPA8VWlNEGJsAH6pH6ktodhJHH0gk9+qA2T5XKVYLavdLfBFZATCPCcXV1NUpLSzVTjmjVHd+zg5QdALvZjE8V5WLntV5s6Feft5t9w/jdrcvSjtrK6ofj4jD/8UFHnuRU1m+WHJTS5Uxp6hCV9kwVMtWfmUj7YaQaMWAgM5h2I3PevHn4wQ9+QPzt29/+tuw+1t8MzCwyHe3zSsVUhkRXKlswXMQx/NMdmmOoN71GuvcLsJhIA5OLx/HBcICZjqP7wwMY+fEWeK1xwoDxR6IiZZNO88GSjZDGonPVbVjgICmeHrtNJkc9PiDS+eFyuWAymTA8PIyhoSEiqms6c0Yq24DJIvrFCf2i+yf9uwyhIGAyIcLFEYxFse1YNx5eXEXQL4UUATToMoU6x2KkAdkxNoGJSJSI4howkXJWygsqROQ8fPg4QiG+j93BsHiy+soNtbg6xypGpA1xHCJcHCOxOEZNVhTe9nVUqsiDZcQLeuVOsCcK72/jqZkK0Z1D4TChf5zvE3zn9kYc6u3XPd6K82WSH3MEqK3XUrp55PwgXMIU1EgnRMu0s7MTixYtwq9+9SssW7ZMX8OU0puA/7jh8SjPWwAI5xemHHRMCp/PJ0sJ0ja3kJlSiSXDVNZv1vPFVOTdkN2BQUabWOXqWWOz5T2dTak/skUmBgxcaZh2uuxUwqDLTi1mKuJatp5kpouppOJolZ1SRFwZrVA9omyq9wuIrFsJcyxp1ARjHJb+9SgWLFiAPXv2EO2nIw+HuDiOjk7g3gOnsPM6L0GplFINAVI2dBoLKUJVXpz/1gZCjmo+mQKUovRKkeqcETeVXaeJ059jYch82JjUvBcSz6rgwHAAG45049mGBbxPpisXLQc78ZePD4tpNwA+hcJbb71FjIdQ59accdTnJ+X58XAA6z44jfaG+ShxOkTDTeqTqQRajg6HAwsXLkQ8Hkew24c/L1sIp0V+8i1QfAUZa80F6YZ9oq8HOZIiT4aBeeUlsElSvIjPxeM4MTqBunxSf9Qo2yzjIL7nyZTmS6rrYEqRhaVQiSYsyPSDDz4gghm53W6cOHFCV7vU6u4IA3lb25k6lqn1kpaL2+3Gxyv+hhxrFco1K8WHUntYz5eagTUWMrctTc9nzTVA3xo7le/pVHQwmyinRrTYyweX237wckHW0GUNXLpwXBzGK5IgIk+cH57pJk0a4uZv2A8ERoHcfKCgKC2fQ8Wyqa/OU0nF0Spbi8JEtJneYGskoJedUGjdn4C5spowhE6OTqDUFMfW/CiwuRkxSeoDd5yMPDwQ4XBfTxDdwbCMsukIh4hrqWzOrPoi8ZuQNmLcbMHSe1pRXVJOyFHPi42eHy0HO2ECiNNVvXNGybgUsNhlw9s31vN6lWOX9U8sZ91DiXJOMcsBgIZFC/H//vB/ib/tgTyFQmlpqWyTKNRJy3NRXg5+/T8WYtxsQfWTz4tziZ4TWPFN4NUXiTlC62RFRYWYU/KjO7/ANDAB4OpCF165oVaUsRYlVJqjNIcqstoah63QI58DAMwmE+a5nYjF47BIaLRqlG1WPtR054teqM51ldNEpTyx3GAvKl/ahVeXVuCAPYD1B0+Lp+nSjxFaMDVtQHxLC3+iLiCRZ3MxY92tyrHh1RtqkzqSo3C8rAKp3m3Ni2Ct0y62vbS0VD7WKpTrVNZv1vN+ACup1CQ0WHMNgC6dmQ7arR5kE+U0W2RiwMCVBsPINKAbUvpYDYA294w2JyMgNn8Av/G5MKBKGUur7MTGkmv6HuI//aFiwJCpBovCRGz8R/zk5k8Khc0n8fsAdQ1tipdJMIQSfnjf+eA0eSqZSLyO1sdllMuAySL2iY64qdZeupzDoxNiEJ3XEJf5Z0EHXZaeHzuv9QImiP1IZc7I9JJGNCLSRdV0VaBfEsGE6DFWkFMqdDdank6LGTW5vO9nfEsLYgUevp5wOBnYZwBA+w+SbUn0RU1Ha3NIH1MpBL8+lox1GXnSskwmhMYDYpTdUpsFDokhyjJ0S5xWvHvjEhQ5rBgKxzAQiiQp2yzjQGG+ZAqq40fVPRqNYjAYRdjuxGIFH0epDBuK3Nh5rVc8uXU4lOLwymEuKQe3eafuQGLMsUtxbZaWUe+yEW33eDyKfrqTpXwqPa/3bzLo0JlsoqlmCwyZGDAwM2B/EjZggIH55SXE9QLq+pKE0kZz7CJ8Ph8aGxuxfPlyNDY2oqurK7WyR4bI6zMnEN/y3eTpVDQCdHfym5tpQnt7OxoaGuD1ekXql7gBG+iRG5hWG1BaAdTUKgbY4AZ7eaNsZIgPKuMpAWpqMfC5W3BkdSOCD61Nln/6OIKta/HRnV9A0+28TM0l5bC0Pg7Loz/F/z7PMU8lhS/2hfe34VgYOBuKoSPMXwt9+uVwDOMcEDeb+XasWKUoB6GcrlAUB0fGsa1vgi0PwcAFNPWBnh/leS6UusggO2pzpvvDAziyuhFnVn0R4VNsAzMOyFJn6DkB6zl3Dh0dHTh79iw+GQ0iXF6lOa7t7e247dMN+PebrsZ7tzTgtw1ecIN9zHul8gzGqOySoaAoS673LNmfSJi8d/gCftvgxXu38PV+4dPkmNjYaTMJMGWsZOQpwGQCHH3dGBkbw+f+74c4NMLO1cxZrEBpBTi7A3lWK6rdTv5flwOfKsrFT8qt/NxgBCcyNW0Aaur4+eJwAiNDGG9rQdPt6a05Pp8Pt956K2pqalBTU4ORkRHU19cTc13sX6LuiKcEHWGgqXMMGwJO5G1tZ/r4NTY24uyxo8Tfi512mM1mmM1m5OfnE+3du3cvFi1ahLlz52LRokXYJ8n36/P5cPvda3Hjn/ZixaEenLtzvfpHtkyc+FJlzM7PJeRydjyEFe914Ma3D2PFe8fRPcHrJWu91IJ0nQgGg7IxEMqsqqqC2+1Gf38/QqEQlixZolmPqDMqczedNqeCSb8XpwBabZpqmRgwYIANwyfTgG7oDf2faUwlB1/RP6imFiveO87049Ab4CbW/FXlU0EpVHygpgOyFBBS6BhjJT8h2n+Sxn7/GB6N5OpLiVFTC1PT/apyT8cnlOkr91SbLCVG2e6X8dnPflbVr0dWv8MJxGIkTVVFnlryAoC+KFC+qFY2D7VkQ5ctpBMh+u90AlwcCIfS9htkykGCcBxEHshxDsmgMwAvM+mcSdQn01Gzhc+pyaIAM2TMWruI06vhC3y/KZweC+Kmd46gymnHzmu9qM/PgdNqIcqxtD6hPocA3sgUcjtS7AW1dDxSHdNaB2m/szlOO55fvhR1VRWS07l4ysG5hHJlc9LhxHe6g/jzf8vnxKJFi4gUIVKfzVT949TeO7rXYo13FyuN0Z7X0qN66u3fpegnWFxcrLkOzgQuRVkaSA+GT2Z2wvDJNDBp6A39fylB7NPwBZlPpv9PdxD3qvpXsTbe7jx9RqaKD5S4gbI7ALMJCAbTzlOpWr+UguVwAgl6ozDGqps5hZMG2n+ShsduhZ9KVyCkxBBSVpS5czBn8VVyg4cl9zROPGRjuaUFKKMWS6cT/ofWYmdhDP031GL7sW60Lq5CmSuG2PYHRVkQ84OmpCZ8ztROg73WOAD1o7rz4QhmM+ahTDZbWsBt3imOET0WNdY4bxgp0aMn4TeoJofOYBSjE0Ex6Mkvh2No/9vPJE8WR4bI9gj10To6bwH/r9RwoGQsmz/VNfL5k9AfJSNRiLIrRLcVjM0ydw7mzF8ARCNJOapBasAO9pK/qaTjScV3zO/3ExGWS5xW5FlB0qoR17V2sXwYWw524o2/WYw8gWUQCqLZHcGfqTYAch9N6XWq/nFq7x29a7HWu4uVxihd6O3fpeonmI3tzsY2GTBgwDAyDaSATIbXzxao9UnRj0PnxjuU44YD8sAhslMNHT5QBAaA+KZ7EUtsqM0l5WmnDwGUU0kotmUA+Pi+b2HTqI2PYKrgJ0T76XFx3k4WUOK0oq7YQ4SXt434ieA5P7howZ7EiYNSfjmi3hR93CLDfhDk01AQoVAYjpq6pOETDiNy/DDmOCyY48jFLz+9ILnRPn0cwWe242sfdJJRXZ/ZQhpL+YWJ08YnieAz4slS12kiJQaNeDyOsVgMv5mwYf25cxg6egQ5sSiGIjHsXL0azy2tkvVDuuGmx8JhNqmfvAFsv0H/IGFYa6XhIHxBc/Ow4/3j+PN/J3W6oaEBltbHsXfvXtx111349dVz0FAkcapMjKGSkaCmt7L5U1MHy6NPiZdCnaFQCH/8zEIy2rDVhlB5FZ4b7ITD4RCNJMHYbGhowKt2u/zk2p3Hf6yKRoEYOw0MPTa0jKXpY3p6etDY2MinvtDwC/Z4PHik3E6eNkrBWKciwxdw26234uTJkwAgRnSufGkX04dxMBRN6j6AIhupVwMDA+jq6oLD4UA0muyHw+EQ5znNOBoYGMDy5csVI5CeHQ9h/Xsdyfl1ZxjiHTrXYq13VzHVjxKb8scxLbhcLtVrAfT7RZDddEZglc4Bh8OhKxVNNvo3ZmObDBgwYNBlDVwCmCl6hFIIdr204abbG7HGMoZShxVFDivGYUWZJFKqFjQpeECSTqiTKpquMUq3RaARNjQ04LXnf8bc7J/76AMM7WhDbiL3oOfuFhT/bjfMklOdUJUXXzvQKVKdaEqeNA0Jm/J4P3laFYsAg/387xVzYFr3kGr/WBTVc1Gg+hcSGizV9wgXh01iEPZHgbOjJNVudxVF+3Q4gcq5sjEiTpZ0IFTlRefpTqLN+/1jyM3NlVNtJTRs6ViU2S0EZVURUkopHZ02Rb0ToDSnBHqlcFJY7LRjXv3SSZ3Yy+YPRUuXUjqrnHa0N8zH9QsXyOZFV1cX1qxZIzfEdm9TLJ8wrgd7Afo1q3BvyO5gpo9paGjA3r17VdfBrq4uxDfdgyqbQqiFmlr+X8l4dYSBW94i0+40NDTg1aUVRN/ORYFvnJSn/jka4vDlfScQCATEU9TZebnIr6jEitffxumLAdF42bZtmyw1jdVqJWi1LJpjSqlY0nThGP3238NlSU6K8VgceT//15TLAYBbb70Vhw8fFq/r6+vF6MhSdHV14eabb9bs/1RCjdbMQnFxMT744IOsSU0iIJvSpRiYWhh02eyEQZc1YCBFKIVg10sb7jjvl4Wqf/cXKWyA6FMkFoQv9/QX/TMniRMnAWlHalQ4bfH7/YqnBJXXXI/KF0j5xd54mdi8OsIhgtqkloaEJXeZz6DDmTSGuk5r9m+zbxh7vLnIsybrHQpHQGxPqL7bcnIIAzLPxBERZB3jESC3lDQyQ0G5MTjT+f4AACAASURBVKlFPbXa+BNvLpbsXjgko7567Fa0+obxu/pyxaixlddcj/LWH5DRXMVCnTh7MYDhiSDiAHKtFoybLahfsYqXLys4lpLeafRJKR0FfVJotVrhe+k/mGXo/lCicbItNeK6g2Hc8f5JdD7zIuLPPsYzBQCgYg6q1j3ENBJiKuUTVNyHmoAL1ERWuNcFdvoYPfS/6upqxGoXy+cDRX2XzqHNb7wvK8fv9wO5tUTfKhfV4t1fPIE7bvo8HoxxIt35ifNRlJaWorOzE09LI0IPnMNb3/gS8cFB6INgjJa5cjAS47B2X4eYToTVTzUqZKZcOIajHFwWC3GdbqxfqdHGuhZQXV0tyk7AdNM81WjNSsim1CQCsrFNBgwYMIxMA1cwpDTNVL5+6qUNp0vhEdplvziMtrmFWFBeApsrl+ea9pwlT5SEzSq94eVifGRUSfoIU9OGtCM1Cpu5cyc60Ds6hpaDnWKfUpIj1c6O7h6CgRCIxojbj/u68OPbG/H0dV7e4MzNg+m+NvScO4eRB9ZivpU8VYyHgoRX49ljR7D2lltgMpkQCARk7QvnF+LWdw5h57VeIjn6nsTzPp8PW98/jvW5URTZrCie54XjH5oSuR35je3FE8chJcR57DagoEhuWLBkASh+SNg/yEcnlp7sBnu7UWQhT8XGYjGE8wthYqSFIMAwMEOV89Dy4Rn85eNjspOzV1/9leIpa0d3D/K6uhSp0kpQ+sjBolfqLuPZxxCz22RGp9QACdnsaHn/OA595jMYGhpCUVEROI6MgutwOPj7u5NzFl2nEdr5feRsfRYAuWZ481z43yV25CGOgMmCwtu+jkpWg2ldcDg1jaF01w491Hfp2jX611tlZfT09OA77x/HTumcS7Q3nF+IlfvIU0UP+PQbShGh6T5JjdE5sMjSidBQk4UqlTYFXDRZUEFdp4tUxm4maZ4+n485BwwYMGAgUzDosgayHlNFj9CKSDcZP0cgNQqPtK6O7h58+91D4td9abtoHzehTbGOj9mnVFKw6Jkp0stYfWpubtYd2S/WcQho3wpEIhiPxvCP+zqwf5j/0u9wOPDnv6nHAgntMxTjEI5zxEkjaurQ0dGhGYkVAILRGA6PTqDlYCdTnl1dXWhqasInn3wCAFi4cCGee+45cZyUdEQ6XtzwBYICzFmsMFdWAxyA7tPyRpVWsE+WEsGdzp0+TRjyO6/1or4gB04Le+N7+OIEip54XvMDSew7K4hTUZgtWNEbk1EY6+vreb9Sig7KxYFonEOI47D6vz5BfH6djCqNFd9MGOAKEYD/+W4y6b2nBJYfPo99+/Zh1apVunzDZDRYq41J5ZWCjh4q6IOQgkOo89P/+ksZRZ2LA+b5PHX4O2vWMssBlPVeqvOw2YDmjbDULWX2TQBrnl1//fUZXweFaM4ssPrDahcANDc3Y2teBPUuiWcwtbYIz+7IDcHrThozZ8bDWO0bU1wj1dbRTEUVpan9hfe3ofKa61MuR6u9k7k306BlZzab8Yc//EHVJ9OgKhqYaRg6mJ1QossaRqaBrMdULSpfuenzeKDYKm4Ynzgfxct/fUf8PZ2UGOlCLY2B1+vFu+++m9LzTFhtQH6hLIruZKPU0tQ+tfZq9fPtz9WSRggLpRU4e/Ys5jiSRleY48DFAaeF7Y/28XAAX9rbgTlOO3Yvq0P9vLm6Phwo9U1fupI64NwZmW+mpf33qt2j6wSAv35+CWpyncz7Q1wcjvJKzf7E7v0KGeXU7sCNH/Uqjp2aTu33j2FDf1g2zlpzRpbWhyEPrY87sjpoI5OREuijO79AGEDCxwfNOS9FTR0OHz5ElDMaiWIwFGWuH3plohdTsQ6ydE2AnnVHCqUPYDTosTg8HsE1L/1Zdp8epLL2GCCRjuyMDb6BmYahg9kJJSNTIUKAAQOXP9rmFuJTRbmoyXXiU0W5aJtbSN6QiSTgeqGSxkAXhWqY9uUxgbNTR33RCG/AhYJAgQeW1icykgaFbp9qexn9nOO045UbavGbhR5gSMfLIzdPFi3145FxHL44rvhIbV4OAODp67z8Bnegh6cT79mhWpVi32jdKPAAnhLyb2MXgeaNvAFqtvD/Nm9UrY9VJ0BGHKUhRoo9fZz3Jdz+ILjBPvmNRSWya7WxIxK/W23kfXYre5w1IwDnq19DQodVGCM6IT0q5pAFjPgRe2QdIYciO9l+p9XCnPOmpg2YIBmERF/ocvJsVuX1Q3xuGteRFKFF5UwF5pJyWFofh+XRn6quLbsCNuz3j+H0WBD7h8awK2Bj3qcHKa09BggYsjNgwMBUw/DJzCKk6yNoID3MLy8hTs0WlFObcAV/sykZJ6qusN0Jr9dLUNJUEaA2sg4H/qk7iDWWMXjsVlTk2MlTvrGLk6YDCxAoszSFjglGP3cvq0uebCgQKzi7A+bCWWI7Y+/8FWP/9iLsZhNCHIefDUzA5CnB0irejyw+0EP4ZtrMJni9fORLAiN+xLbex/u6AnxKmXtaRTkIfRsZGUFBQQHa29vh8/kw1t1D0nVZ/pW5eTwtMsWTuvb2dnzzm9/EqVOnEI/HYTKZsPnMELaazSiyWjAWjcFkMiHfYUO53UpGio1GkoYZdVoWiYSINCeRSAg/2dqG4R1tcEtoggKI4DXUaVy5y4nfV5eIwaXOjoewfv16OWWS9tGk/RPHLoIb7CP6Hzk/QLbzfD+6VeZc90cHMLxjC3LjMcyyWeAKBcXckEcfWIt1p/x4dl4+Kq3y192C8hLZfG5bfw/sv34WNdY4kVZmrOcsZplMUPo2K10/pGXunu9h60oWQDp3XS6XzHd5KnD3P7fim6tXE9TodJHS2sPAlfzOnazs0gFL3vF4/IobgytZ7wxcWTDoslmETPmXXG5Qo0dMxlDSCn+vRP+ainHSSzVT7AsdwXJWKW58t0OkQ9GpQVjpDFTTnjz7GNDXzf+BSg2SyhiI/Ry+kKTtjgyRdEcprDZAkg9UAJ165FgYqJdEso2tW0nmKbRYYfnpK7xB2SXxk7TZgUiYrJMhB6kONjY2ov9IMlhQ2O7E4h/9DIB63kaxbTrok4JMz504LvpndgfDMl1TpHcyKKO0zDrCQF1drU4dkOjniJ+kvNbUYcV7HThw4ICYgmR2fi4qGel6uME+xLe0yJ6X1jl6dyNcEjtunAPuHITinJPOR5pWLKTaEdpVX+AiP7bU1GLd+8cJP8vnornY89rrYp/PnehAPqKEX3AwGkMEccpXOLl+SNtU5bTj+eVLsbhK6osbV50zrDlVurj+sqCJZdN7LpvacilgslRFlrwB5bl9ucLQu/Rh0GWzE0YKk0sAaqHaDbCRdkoOaIe/V4oiOxXjpDdirSLoE6KCIiJyYcvBTtlGN/5UG1mGAo2PFXEzvulexBLGX2pjEOf/uzjMG5asQEVU2gWWoUan8ciNk1FpMXsO2ebZc/jgSF1UIB7awAQ06Yx+v19MtQEkfJmENurITYqRIc36BJlWWoHKolzsvNaL737Yia15ET7wTUI2ovzPnCSD+tjlUSI3+4bx4CwrkX7id1WpJ7OXBd4ZuyjOAUEuyul64rzvqkqdw9EYXHYLce33jxD3SOec4+IwXrmhFh6bFSVO8pUm0IyFdgnGZpk7B3MWXwVT0wY0H/4W6l1UChpJn7+xfDlenOsmDMqBcBRf23cCu5fVYanEv5fVvu5gGOtO+fHuCwofBxhzhjmnnvy5XJyTRKbYDKkgm95z2dSWKwF65H0ljIGhdwauFBhGZhZhJsOZX4rgBnvlRoOKgcDaUKUTgIM1TjNNf2EZzO13hgk6VP7WdlgkbVLL80eAlSdRSstMweeM2DxLYbXxPo2JtvecO4fxp7ag6qE1AICuSBw7e0Zxb2UB5peXYJaN9MmkfTR7b18lUigDJgsKb1+N8vYfKLZLipDdQaQkoVGT78aTCaPGH4mifVzdp4w2GOCgAviw5M7wXSX8SQeAj+/7FjaN2tDe3o7i5x6DQzhpBhCORpBDFclKP6GVS5KFkM0OqQkbsjuYc4Ib7EXw6a0w9XUjHo/jbNSEOXOq4KBPrXPziLlZaCXH8iIssvIHBgawfPlyeDwePDonD1c5k8+Mc4CrvAId3T1ihF4BgrHpcDhQP2xB+51hmZ+lh772eFBkJ31ii2wWvqz3jqM+MQbVEuNMcy3XmjNp+HGmswYpfSCayvUs0+85oa39/f1iepqCggLFtEV62jLT6/nlCiV5X2n7HmOvZ+BKgUGXzSLMZDjzbIYSPYJJFVRJyZGpKI+TTeORLdBL0VWNuJlIx6E3LYrsFEzhmRN3NWI+ZbuNRknK4jgHDEdiKLRZYC/ywDqrhElpnpOgK+pJeRKIxnD/kAV7XiPHTqqDh775RcKoORqMYemLf1IsU9ZnTwlQOEtV7rTMD49HUGS3oVLyWVCggjY0NKB9FojfzkWB6l9op5+oyrGnTNNuur1R9PUV6KWbdsr9uypf2iXTmxAHOKQujVYbTN9/BvE9TxL3jnPAhUjSTzRWVCyWPzAwQCS4f//vrsNsW7LQSH4RnE++QPTX7XYjHo8j2O3DE1dVEtTYnfVVcPQnDfRQWRVcP3iWkBv38BrMyUma1l2BIJa/nUz9Qc93rbVci6rP+r3syV+o0sTSoeDJdDNBs55KOl+m33N0W1lQar9SWww6IxuTpSqqpcC5kvY9xl4vfRh02eyEQZe9BFBdXW28yFIB/bXfalNPcp6hKI+scboU6S96Kbqmpg34+N5/xEK3A3aLGWaTJNKMQL1VoR0ToE/OJD6XUlRZ4gARugdwmMmAK67yCrjsDp4WO+IHRvy87+jmpwj5P32dV9PADMY4HL44jpaDnbDNrhT/LpywDU4EwOW4YWragDyyWbJrzT4XerQ/bqz4Jp/3NJFbsX7Do8CrvyIMD4EK6vf7MZSXh0pJBNihcESWlF5xfUnxQ0vHeT9WUqkPWGXHWCfgoMa1uobP80rd6yqvQB7lUyqUT6deKKDi8NhCE3zRjDZJ02fUAFgc4+A4T0bidThIZamursZHcTOkMWwHwyTll57vWmu51pxJaU4ptEFtDRJPjqUUewBwOlMuK1Vk+j2np21K9yi15VJczy8FKMn7Stv3GHs9A1cKDCMzSzETvjLTiYzQkejNe2LDqvv+3LyM0aIuRfqL3r6bS8rx1Q+7EAgERJ+2Yqcd8+qXJvVSSrH70x2K5bE2z2fHQ1h/91rixOnVKjtoIzPEcbBLDc3cPHC+U0SsT663CxYALleS8OqxMZY5u4NP6RHn0NHdg2+/ewTdQd4/c4nLhcbGRiIyqJDVIr5nB8Jmks7JmS2IbX8QkWE/TvUNYrNvGOH8QrH/6RgMod/ugUPwVw3FEPrdHjjvaUV8zw70nehALqJYmu/CiVuvwznOjOcvAiuD5OniHs1aSOjVB926Ts838LTnqMmUpDHf9nVUsu5Voe3S9Y/GzSS9mZEWRUAhRbN2W8xkgCgACMr9hH/kj6E5GBLl++Ax8jTe5/Nh3759qonspdD6wGMuKYfvG/cmx+O9tXjppZeQl6csl8XFHjxZbidOaZWgSFtPKDot456eHjQ2NqK1tRXbt2/PqhMYuq1K90ymzEthPTdgwICBbINBl81SZIrama1IhY6kRI/gBvsQ/+ljiuknmPdTm/3b716bEVrUpUh/SWUM9u3bh1WrVhFpB+gNdSrlST+i8EbeIdHIA4B/+1wdri5wi9cTXBwP+i7i3soCLCgvga3QA1PTBoRa1xIpPMJxIGfP67j11ltx+PBhAOzIulJqIj12oVBIfJaOVgqrDRzHwSwJssPZ7DBLAgjt949h5b7jk6LYdX2rUZH+Or7lu3B0k5vqUJUXXzvQOSn90zt+enWdG+xDaOf3Ee/tBhI+mT8YCOIvH8tppqlEV6br/22Dl5SHCl2bpjozwXheqk8AUFtbi5MnT4Ljkkk13W43Tpw4oV52CqDHY9myZfjjH/+oeD+tF6EqL1ybn2beq0hbT9BlBRkfPnwYoVBI/NntdhNU5WygkQptTccnU6vMS2k9nw4YVEUDMw1DB7MTBl32UkMWJ/AGJn/Smgk6krmkHDGrLZn+ortTNbIp6/QgU7SoS5H+kkrf/8f8uTj2rf+VHO/58zTLc1wc5j+WMHREepJSZwd2XusVo7UCwLoDp4kooK6mDfgJQ786g1HU5liJ66sAYiPccrBTMQooN9iLypd24dWlFUAun3LjH77yVcVopYhGZFkSzVS0VI/dypRHKhgKRxTpr45wSHa/IxyatP7p1Qe9um4uKUfO1qRvYy2AzuXLmXWkEl2Zrp9loCphy9lRMcJuidNKpiBRoG4DpD4BQDgchtlsJoxMqTGWCUij5vojUTw5dEH9fkovWHoignHKLP4dSRnT1GS6j9lAI52KtfdSXM8NGDBgINtgGJnZijSiPk4nJpM6BMggHWmY2uQMq2/EpqwdlyBS6bue8abLa5tbqPwMI3qqFEIU0IaGBryucCoFADvGrFgzIaeJStvSHQxj06gNr1M+fkr9aptbSPhwxuKApbQMGPKz83nabEAoaWgKvpKT0aVdARvWKNFfWQZCBtYHNX3QypWaiTrShR4DVfgotsNbiN7RMfzjf50EAFlaH6X+sNo9MDCAaDRJtXU45GljJgOpHtYAaFNmv/JQeGewPgiKFG5pvtqCIpmBTffb4XAQfb6S1ksDBgwYMJAaDCMzS5GOH5cSpsK/MzLsh424vgANEhqB1tZWrF69WqRfPvzww4rtjT74KGBViNwSGFW/1oAQGVagWvX396OxsfGSo0el41sq9J2O9Mcq23TiOEHflJ6sS1MIuN1uFBUVYZGnAF4rFeRF8gydBiNos8Pr9Yo+mSMjI8zxoHVjy5Y2/NPGNvj7yT78ZGsbhne0wR1PRihlgsEYmF9eAvgHxT9ZTIDNU4JIXiFJYU+cfGHFKuDVFxEZvoBTfYN44nyUj/iaaAs9Nj/Z2obyf/8/wNgoQjY7Wj48g0O9/bhw4QKi0SjMZjPmzJmDTU4nQfcTYGrakDD4EjTxijkwNW3QrQNK96npQ/CZ7XCcO5MspOt0yh+WAPV5T0M61oKcOs6nR1+k847+50316IyaUHh/GyzXXJ92u2kKuV5ojZXP50OuiQMk5+YLZ6uv2UrvDNaHlPdvvB13/eI1Vfo7IF8jHn74YWzbto1o92T82o1UIQYMGDBw+cLwybwCMBX+nUdWNxKnPR1hYMkL+ulFD61sxEMFUTjMZoQ4DttHrNi+eze/Ieo6TZ4YOXOA/CKmgRx7qImMkDirFJbHUg15kl74/6lCOh8FprL9jY2NeMQ+pujXyKp7exHkEV0lz7DSYEjThij1R68up39fLf8vFRTFPLsK8fWbUk73werLmzc3ELIRfDhppDqGenUgHV2hfUQBiP57qSCVuumxkcopVdkop85RXgvV/IYnO7+05MCac7baenAPbEu5LlaaksV/+AtBAZ6MP+lk1p5sWncNaMPwhzMw0zB0MDth+GReyZgC/87NvmHRt8kfieKJ81G8nPhNj5H0SCEHl4VXP7vZjEcKOeWIh8EJ/j8WTbOgiDQyC4rS6k82haxPh4o8le33+/1o6T2Hndd64bFbMW62YKnkZJ1Vt7uwAJCcbYe4OJySZ1hpMNTaL17r1WWd9yme/mxpAULJKKOW/EJwCVqmoN/xp9oQ02Fs0n1xx2OQyqa+wIW/fn4JAtEY4iYg12JJzKlhxTL11KOkA+noCu0jCiAtim5KdatQqlPWbyUfRJW1UM1veLLzS0sOrDl3431tSE0jEmDQaGnfysn4k05m7cmmddeAAQMGDGQWdAwLA5chQjbySClkn7zvUDi/ECv3HcdN7xzByveOI5xfKP4mbs4GeoDTx/lrCjYq56HdbJYbBixQm8Le276GY2HgbCiGjjDQd9vX0+oP7Vs0GV8jbrAXse0PIvbIOsS2PwhusE/7ISkoOZw9dgSNjY3o6upi3u7z+TAwQO6gM+kr5fF4RB/Jm945gq/89yl0T4SJ3+n7AyaSPH10dAKfX3GH2A8leQuy+81CD165oRZVTjtZB23YKBg6+nU+nvgvCXNJOUybdwI1dYh4StARBu74817ccsstuPXWW3Hovm8T+h18ZjsaGxvxlZs+jyOrGxH857uJcaf7OkqlZnFazKjJdWJpoRtXF7hRk+vEp4pyeZ/WFODNc+GVG2rx188vwSs31MKb52LeR7dnYGAAy5cvV9WxXQEbPh4OIBiNIRjjcCqCtCj8WvPM5/OhsbERy5cvR0c3efIo+LqyntOCqWkDUFPHU5ylUDOUVYxcIaWHkry0oCUHes5tHLXBWs7+UqwFse+lFUANH9yK9h9V8ieVjodSfyezdmZy3TVgwIABA9kFgy57BUCLmpgO1EK8s+hZNK0ucu9XYJZEP+TsDpir5hEnmcEYh0icIyNAUukFMkW3ymTI+snSk2U0waExrHxPOSUGLQO324233norY75NXV1duPnmmxVTF7BkZxk6j6EdbciNx3A+GMK9B04RVEOW/191dbWs74fGI9g0apP4ZPYpBiyRniYq6Tx9yo5wGCDSX5BjRcsWkKc1ORcFbnjzACNVCl8WLZ/5XBCbS6xwmM2wmEywmEijU0DEUwLnD5/XPU6HVn0JVzmSH2+Ohjgs/dW/ye6TtmdgYEBXSopMzQ+tcqTyrnLaxcA8IbsDLQc70/bJFJBKqhRaFzvCwN//PzKlx1StN6zfr7/++ozRxPSkJAL0ra+T0Q0jVcilBYOqaGCmYehgdsKgy17B0KImpgPVEO86IuOa128C2rcCkQhgs8HcvBGmWSWI79mBs8eOoH98Ai0H+Tb/7IbFqJ9bzQyANBMpSDTpwJOkJwsUTloOeumPpaWlGd2oVVdXo7S0lIgyKa2TKbvqalQmfHT/cflyIgem3+9Xljclu6Xz5hJRYYVIorHtD/LBeUJB4MKAjFKspPM0FVl2skWNFUvm/kgUNZLroTDvP+yxUctpoiy6rx/d+QXyw4kCbIWpnerkUSey9LUAaXvoFBWTTVuiBa1ypPV3B8NYd8qPd194HS4AqXtay5FKqhSaSr24aQMqVtyhS15a0JLDVKfQWLZsmS4fTD3r62TaaqQKMWDAgIHLFwZd9grAdFOSWPQsGpa6pbC0/x6W3a/y/9YthbmkHJbWx9EybMHK946jOxhGdzCM70/kwPLoT2FpfUJ26jATdKvgM9tJuuSz24nf06End394AEdWN+LMqi/i2ANr0Xfb1wg5AMq0xnToj6kiHTkLVDuaYUC3T40iqUhn1DDkldoboVLeSPMcAvKxYvWz5WAn9vvH0BkIoSMM/MjPpy+R0jnV2l5oI6nEIS7Oz5XqGqCqRnXeKMHn8+F8kPSroynLLOgdVz20yUw8Nxk9y7TOC+uRdO25FOmdWvJR+/1S7K8BAwYMGMgOGHTZacBUpBBJBZcaJYlu70svvYS8PPaGfSb6RkfaPBcFqn+R/BqfDj2ZjtZ7LAzkb23XRWtMh/6YKtKRM021czgcsFqtsvYBYFIk1eYKKyqslEat1F5azkdGJzARiSmOlVDOyMgIHA4HTCYTTp48SVAm6+vr4XA4YL84jLa5hVhQXgJboUex7Ye++UVc5UwagEeDMSx98U+qstRCY2Mj+o8cEgPFjMQ4zH7kcVRqpOfQO67p0tJTfS4TejaVEUpnci1NlyamJ5Kt0u+X2rvDwNTCoCoamGkYOpidMOiyMwi1aKGEAWp3AGYTEAxm1Bi91ChJdHvVFpWZ6BsdaXMoHIF025UOPZmOOJobj+mmNaZDf0wV6ciZrltYhNTaJ6VIqkErj6xSe+moyN871AXf2IT4Oz1WQjlSHaRlHAgE8MYbb6i2V4qf9I5h2xy3mL7n2d4AfqL7aTb8fr8YKEbox7s68j/qHdd0aempPpcJPZvKCKWX2loK6Itkq3R9KfbXgAEDBgxkBwwjczqgQu1TTNuhM3WFgenHroANa4LUSaXkd4/HQxgheihmNLWRvtZbZjp1Zwr0iX1dsbwtZWbgyXI7PLak7AY4pNzmVHzrpOCjIpNBkqTQU/dkZXxvZQHyEiuv3WzGvZUFKT0/FW2aqvKnQx9nUucvBWjJx5CfAQMGDBiYClja2traZroRmcLoqI4UGDOA+H+9DQxdSP6hrALmv7mF/+0/XuGjZLJgs8P8t1+ahhZmN1wuF8bHx2e6GSKu/ezn0Ppvb+G3/Rex316AH+5qR0FB0lD43Oc+hw8//BBOpxPz589He3s7hoeHsWrVKjzzzDN47bXX8LnPfY54JlJTi7Pv/hXBaAy9nBmF97chv3y2apnS51O9byow8cQjsHad4vV56AJu8lbifUsu0Za/7/oIXi6EIrsVFTl23OStxN9u2q67zT6fT1WOWhDkY7FYEIvFkJ+fj3g8jrKyMixcuBDt7e3IC4+D2/l9xP/jFX7u1l0Nd0mpqIPpylhoe6MzigJr0h2+sKQE1r/7X7r7oNavqRp3veXT4/Pwww/j1KlTU6qPM6nz04l010Et+Vwp8jMweWTbu9jAlQdDB7MTSi5thk/mNEAtbL7Mt0wKys/sSsXlwMGfTr+xmYKWr6ree9SQKTmqlcNKQVP25M/T1kHhhPfciePoHR2D3WzC1QWSE9TLaJ5fCXo+U7gc1kEDlzYMHTQw0zB0MDth+GTOINSofYRvGcMn08Dlgen0G5spaPmq6r1HDZmSo2o5k0xBQ0OgxFdagcqiXHw8HMB+/xjK3DmYs/iqy2qeXwl6bsCAAQMGDBjQhpHCZIZxdjyEFe914Ma3D2PFgU6cW32/YroOA5curoRUALsCNuz3j+H0WBD7h8awK2BL6x41ZEqOauWkk4JGFZTRmmu1YOW+42gZtlx28/xK0HMDBgwYMGDAgDYMI3OGsX79ehw4cACdnZ04a+zOhgAAB6dJREFUcOAAmpubZ7pJBqYA7e3taGhogNfrRUNDA9rb22e6SRnHpp3teDSSi2+dHcej4Vxs2invo5571JApOaqV0/LhGcIQbjnYqVKSDlD5MsfNlstWB64EPTdgwIABAwYMaCOrfTJ//etf4+jRo6ipqUFTU5Pm/dnqk6kGOh2C1+vFu+++O4Mtyj4YHHwD0wnWnOzo6JiET6ayT7YBA3phrIMGZhqGDhqYaRg6mJ1Q8snM2pPMrq4ucByHbdu2obCwEB0dHTPdpCmBQS8zYCC7kOk5aS4ph6X1cYMGb8CAAQMGDBi4YpC1RmZHRweuu+467Pz/27ufkCj6OI7jn512U0YNXbawCImYDoEHlZSCrBb2tnXq0M1AvEQE9ufQJXe99fcihIGHLoVhEHToJgsdWsiVFDLbg2UIUeBmZttmte0+h4ekP8/z+ETj/Hb1/QJhV2bgO/jZgY/z25m+PjU1Na3aksnyMqC08JkEAAD4MyV7d9lsNivbtlUoFFRVVaVsNvvLNsPDwxoeHpYknT9/XqFQyOsx/1goFFIymTQ9Rknz+/1l+bdFefqnzyQZhGlkEKaRQZhGBstLyZbMbw9c7e7u1tTUlGzb/mWbSCSiSCSy9J512qsTa/BhGhmEaWQQppFBmEYGS1PZfSfTcRyNjY1JksbHx+U4juGJAAAAAADLKemSmc/n1dPTo9nZWTU2NpoeCQAAAACwjJJdLitJnZ2dpkcAAAAAAPyGkr2SCQAAAAAoP5RMAAAAAIBrKJkAAAAAANdQMgEAAAAArqFkAgAAAABcQ8kEAAAAALiGkgkAAAAAcA0lEwAAAADgGkomAAAAAMA1lEwAAAAAgGt8xWKxaHoIAAAAAMDqwJVMlLyzZ8+aHgFrHBmEaWQQppFBmEYGywslEwAAAADgGkomAAAAAMA1lEyUvEgkYnoErHFkEKaRQZhGBmEaGSwv3PgHAAAAAOAarmQCAAAAAFzjNz0A8E9evXqlixcv6uTJk2poaJAk3bhxQ5OTk9q+fbu6uroMT4i1gtzBlJ/Pg2QRXspkMhoYGNCnT5+0adMmHTt2TDdv3iSD8Ewul9OVK1dUKBRUUVGh48eP6+7du2SwTKyLx+Nx00MA3ysUChoaGtLWrVvV0NCg2tpazczMaHp6WqdOndLz589lWZZCoZDpUbHKkTuY8vN5cGFhgSzCU5Zlac+ePYpEInr27Jn8fr9evnxJBuGZQCCg9vZ2hcNhVVdXK5VK6fPnz2SwTLBcFiXHsix1dXWpsrJy6XfpdFrNzc3q6+tTU1OT0um0wQmxVpA7mPLzeZAswmuVlZVL+ausrNSLFy/IIDxnWZby+bzS6bSKxSIZLCMsl4Vx9+7dUyqVWnrf2tqqaDT6wzbZbFa2batQKKiqqkrZbNbrMbEGkTuUCrIIUz58+KBMJqNgMEgG4bmRkRENDAyoublZ9fX1ZLCMUDJhXDQa/aVU/sy2beVyOXV3d2tqakq2bXs0HdYycodSQRZhQj6f1+DgoI4cOaIHDx6QQXiura1NbW1tGh0d1czMDBksIyyXRVlwHEdjY2OSpPHxcTmOY3girAXkDqWCLMJr+Xxe169f18GDB1VTU0MG4bnvn7Lo9/uVTqfJYBmhZKJkWZYly/o7oo7jKJ/Pq6enR7Ozs2psbDQ8HdYCcgfTvp0HySK8dufOHT1+/FjXrl1TPB5XJpMhg/DUkydPFIvFFI/HlUgk1N3dTQbLiK/4/b8JAAAAAAD4A1zJBAAAAAC4hpIJAAAAAHANJRMAAAAA4BpKJgAAAADANZRMAAAAAIBrKJkAAAAAANdQMgEAWCGjo6NaWFgwPQYAAJ6iZAIAsEIePnyoubk502MAAOApX7FYLJoeAgCA1WRyclKDg4N6/fq16urqVFFRoc7OTuVyOd26dUsfP35UNBpVOBzW7du3NT09rXw+L8dxlEqldPr0ac3PzyuRSGh2dlYLCws6dOiQDhw4YPrQAABYFiUTAIAVcvXqVUWjUW3btk25XE69vb2KxWIKBAI6d+6czpw5o0QiofXr1+vr16/68uWLtmzZorm5Oe3YsUOXL1/WpUuXFAwG1dvbqxMnTigUCpk+LAAA/hPLZQEA8MCjR4/U0tIi27YVCAS0e/dujY+PS5Lq6+tVV1en6upqBYNBvXv3TpK0c+dOhUIhWZal9vZ2jY6OmjwEAAD+F7/pAQAAWAsymYySyaSePn0qSVpcXFQ4HJYkWZYly7Lk8/nk8/n0bZFRMBhc2n/jxo2amJjwfnAAAH4TJRMAgBXi8/mWXtfW1mrfvn06fPjwD9sMDQ396/7z8/NLr9++fasNGza4PyQAAC5juSwAACvEtm29f/9ektTS0qJkMrn0SJPFxcVl95+YmNCbN29UKBR0//597dq1a0XnBQDADVzJBABghezdu1f9/f2qqalRR0eHjh49qgsXLiwtj43FYvL7/fL7/Vq3bt0PP5LU2tqq/v5+zc3Naf/+/dq8ebPhIwIAYHncXRYAgBKUTqc1MjKijo4O06MAAPBbKJkAAAAAANfwnUwAAAAAgGsomQAAAAAA11AyAQAAAACuoWQCAAAAAFxDyQQAAAAAuIaSCQAAAABwzV+fDJl3fDlHUAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1116x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 독립변수 Xy의 col번호: 0=qty\n",
    "# ['qty', 'temp', 'cloud', 'wind', 'lgt_time', 'rain_or_not','snow_or_not', \n",
    "#                                                   '공기상태_0', '공기상태_1', '공기상태_2']\n",
    "\n",
    "# 1~9 : 1 temp ~ 9 공기상태_2\n",
    "n= 1\n",
    "# alpha 값 0~1\n",
    "alp = 1\n",
    "# scatter plot 점 크기\n",
    "dot_size = 20\n",
    "\n",
    "matplotlib.rcParams['font.family'] = 'NanumGothicCoding'\n",
    "plt.figure(figsize=(15.5,7))\n",
    "plt.style.use('ggplot')\n",
    "plt.title('%s - %s vs 판매량' % (item, Xy.columns[n]) )\n",
    "plt.scatter(Xy.iloc[:,n],result_df.qty, label = '실 판매량', s=20, c='k')\n",
    "plt.scatter(Xy.iloc[:,n],result_df.keras_qty, label = '케라스 신경망 예측', alpha=alp, s=dot_size)\n",
    "# plt.scatter(Xy.iloc[:,n],result_df.rf_qty, label = 'RandomForest 예측', alpha=alp, s=dot_size)\n",
    "# plt.scatter(Xy.iloc[:,n],result_df.xgb_qty, label = 'XGBoosting 예측', alpha=alp, s=dot_size)\n",
    "# plt.scatter(Xy.iloc[:,n],result_df.lin_qty, label = '선형 예측', alpha=alp, s=dot_size)\n",
    "# plt.scatter(Xy.iloc[:,n],result_df.ridge_qty, label = 'Ridge 예측', alpha=alp, s=dot_size)\n",
    "# plt.scatter(Xy.iloc[:,n],result_df.ols_qty, label = 'OLS 예측', alpha=alp, s=dot_size)\n",
    "\n",
    "# X axis\n",
    "plt.xlabel('{}'.format(Xy.columns[n]))\n",
    "\n",
    "# y axis\n",
    "plt.ylabel('판매량')\n",
    "\n",
    "# 범례\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실험 구간"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# # 2016~2017 : 훈련 / 2018 검증 2:1\n",
    "# # 1~106 / 106~156\n",
    "# trainXy = gs_week_w.loc[:cut_line]\n",
    "# testXy = gs_week_w.loc[cut_line:]\n",
    "# train_X =pd.DataFrame(trainXy.loc[:,'temp'])\n",
    "# train_y = trainXy.loc[:,'qty']\n",
    "# val_X = pd.DataFrame(testXy.loc[:,'temp'])\n",
    "# val_y = testXy.loc[:,'qty']\n",
    "\n",
    "\n",
    "\n",
    "# print('여기서 점수란 R-square값을 의미한다.')\n",
    "# # RandomForest 회귀분석\n",
    "# RFmodel = RandomForestRegressor()\n",
    "# RFmodel.fit(train_X,train_y)\n",
    "# # Get the mean absolute error on the validation data\n",
    "# RFpredicted = RFmodel.predict(val_X)\n",
    "# MAE = mean_absolute_error(val_y , RFpredicted)\n",
    "# print('Random forest을 이용한 %s의 회귀분석 결과 :'%item)\n",
    "# # print('Random forest validation MAE = ', MAE)\n",
    "# print('훈련세트점수 : {:.3f}'.format(RFmodel.score(train_X, train_y)))\n",
    "# print('검증세트점수 : {:.3f}'.format(RFmodel.score(val_X, val_y)))\n",
    "\n",
    "# # XGBRegressor 회귀분석\n",
    "# XGBModel = XGBRegressor(objective='reg:squarederror')\n",
    "# XGBModel.fit(train_X,train_y , verbose=False)\n",
    "# # Get the mean absolute error on the validation data :\n",
    "# XGBpredictions = XGBModel.predict(val_X)\n",
    "# MAE = mean_absolute_error(val_y , XGBpredictions)\n",
    "# print('XGBoost을 이용한 %s의 회귀분석 결과 :'%item)\n",
    "# # print('XGBoost validation MAE = ',MAE)\n",
    "# print('훈련세트점수 : {:.3f}'.format(XGBModel.score(train_X, train_y)))\n",
    "# print('검증세트점수 : {:.3f}'.format(XGBModel.score(val_X, val_y)))\n",
    "\n",
    "# linReg = LinearRegression().fit(train_X, train_y)\n",
    "# print('LinearRegression을 이용한 %s의 회귀분석 결과 :'%item)\n",
    "# print('훈련세트점수 : {:.3f}'.format(linReg.score(train_X, train_y)))\n",
    "# print('검증세트점수 : {:.3f}'.format(linReg.score(val_X, val_y)))\n",
    "\n",
    "# ridge = Ridge(alpha=0.1, normalize=True, random_state=0, tol=0.001).fit(train_X, train_y)\n",
    "# print('RidgeRegression을 이용한 %s의 회귀분석 결과 :'%item)\n",
    "# print('훈련세트점수 : {:.3f}'.format(ridge.score(train_X, train_y)))\n",
    "# print('검증세트점수 : {:.3f}'.format(ridge.score(val_X, val_y)))\n",
    "\n",
    "# lasso = Lasso(alpha=0.1, max_iter=1000).fit(train_X, train_y)\n",
    "# print('LassoRegression을 이용한 %s의 회귀분석 결과 :'%item)\n",
    "# print('훈련세트점수 : {:.3f}'.format(lasso.score(train_X, train_y)) )\n",
    "# print('검증세트점수 : {:.3f}'.format(lasso.score(val_X, val_y)) )\n",
    "\n",
    "# customF = formulaGen(target='qty',ind_features=['temp'])\n",
    "# olsModel = sm.OLS.from_formula(customF, data=trainXy).fit()\n",
    "# print('OLS을 이용한 %s의 회귀분석 결과 :'%item)\n",
    "# print('훈련세트점수 : {:.3f}'.format(olsModel.rsquared) )\n",
    "\n",
    "# combined = pd.DataFrame(gs_week_w.loc[:,'temp'])\n",
    "# target = gs_week_w.loc[:,'qty']\n",
    "\n",
    "# # 가장 좋다고 판명된 설정을 이용하여, 예측qty생산\n",
    "# # predictions = NN_model.predict(combined)\n",
    "# # RandomForest 회귀분석 예측 qty생산\n",
    "# RFpredicted = RFmodel.predict(combined)\n",
    "# # XGBRegressor 회귀분석 예측 qty생산\n",
    "# XGBpredictions = XGBModel.predict(combined)\n",
    "# # linearRegression 회귀분석 예측 qty생산\n",
    "# linPred = linReg.predict(combined)\n",
    "# # Ridge 회귀분석 예측 qty생산\n",
    "# ridPred = ridge.predict(combined)\n",
    "# # Lasso 회귀분석 예측 qty생산\n",
    "# lassoPred = lasso.predict(combined)\n",
    "# # OLS 회귀분석 예측 qty생산\n",
    "# olsPred = olsModel.predict(combined)\n",
    "\n",
    "# result_df = pd.DataFrame()\n",
    "# result_df['week'] = gs_week_w['week']\n",
    "# result_df['qty'] = gs_week_w.loc[:,'qty']\n",
    "\n",
    "# # print(\"keras 신경망 predictions\",predictions.shape)\n",
    "# # result_df['keras_qty'] = predictions\n",
    "\n",
    "# # print(\"randomforest 예상\",RFpredicted.shape)\n",
    "# result_df['rf_qty'] = RFpredicted\n",
    "\n",
    "# # print(\"XGBpredictions\",XGBpredictions.shape)\n",
    "# result_df['xgb_qty'] = XGBpredictions\n",
    "\n",
    "# # print(\"linearRegression 예상\",RFpredicted.shape)\n",
    "# result_df['lin_qty'] = linPred\n",
    "\n",
    "# # print(\"Ridge 예상\",RFpredicted.shape)\n",
    "# result_df['ridge_qty'] = ridPred\n",
    "\n",
    "# # print(\"Lasso 예상\",RFpredicted.shape)\n",
    "# result_df['lasso_qty'] = lassoPred\n",
    "\n",
    "# # print(\"OLS 예상\",RFpredicted.shape)\n",
    "# result_df['ols_qty'] = olsPred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ============================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_graph = result_df.loc[:,['week','qty','keras_qty','rf_qty','xgb_qty','lin_qty','ridge_qty','lasso_qty','ols_qty']]\n",
    "# for_visual_col = ['week','temp','cloud','wind','lgt_time','snow','rain','PM10']\n",
    "# df = pd.merge(df_graph, gs_week_w[for_visual_col], on='week', how='left')\n",
    "# # df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2016, 온도\n",
    "# df_graph = df.loc[df.week <= 53]\n",
    "# plt.figure(figsize=(15.5, 10))\n",
    "# plt.scatter(df_graph.temp,df_graph.qty, ls='-', label='실제', color='green', alpha=0.5, lw=8)\n",
    "# plt.scatter(df_graph.temp,df_graph.keras_qty, ls='-', label='keras예측', color='r')\n",
    "# plt.scatter(df_graph.temp,df_graph.rf_qty, ls='-', label='rf예측', color='cyan')\n",
    "# plt.scatter(df_graph.temp,df_graph.xgb_qty, ls='-', label='xgb예측', color='b')\n",
    "# plt.scatter(df_graph.temp,df_graph.lin_qty, ls='-', label='linear예측')\n",
    "# plt.scatter(df_graph.temp,df_graph.ridge_qty, ls='-', label='ridge예측')\n",
    "# plt.scatter(df_graph.temp,df_graph.lasso_qty, ls='-', label='lasso예측',color='yellow')\n",
    "# plt.scatter(df_graph.temp,df_graph.ols_qty, ls='-', label='ols예측', color='violet')\n",
    "# plt.legend()\n",
    "# plt.title('{}년도 {} 판매량 실제/예측'.format( '2016',item ))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qty_columns = list(df_graph.columns)[1:9]\n",
    "# weather_columns = list(df_graph.columns)[9:]\n",
    "# print(qty_columns)\n",
    "# print(weather_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_temp = pd.DataFrame()\n",
    "# # x_temp['temp'] = list(range(-10,35,1))\n",
    "# x_temp['temp'] = np.arange(-9,35,0.5)\n",
    "# combined = x_temp\n",
    "# # RandomForest 회귀분석 예측 qty생산\n",
    "# RFpredicted = RFmodel.predict(combined)\n",
    "# # XGBRegressor 회귀분석 예측 qty생산\n",
    "# XGBpredictions = XGBModel.predict(combined)\n",
    "# # linearRegression 회귀분석 예측 qty생산\n",
    "# linPred = linReg.predict(combined)\n",
    "# # Ridge 회귀분석 예측 qty생산\n",
    "# ridPred = ridge.predict(combined)\n",
    "# # Lasso 회귀분석 예측 qty생산\n",
    "# lassoPred = lasso.predict(combined)\n",
    "# # OLS 회귀분석 예측 qty생산\n",
    "# olsPred = olsModel.predict(combined)\n",
    "\n",
    "# # 2016~2018, 일조시간\n",
    "# df_graph = df.copy()\n",
    "# plt.figure(figsize=(15.5, 10))\n",
    "# plt.scatter(df_graph[weather_columns[0]],df_graph['qty'], ls='-', color='k',label='실 판매량', s=100, alpha=0.7)\n",
    "# plt.plot(x_temp, RFpredicted, label = 'rf')\n",
    "# plt.plot(x_temp, XGBpredictions, label = 'xgb')\n",
    "# plt.plot(x_temp, linPred, label = 'line')\n",
    "# plt.plot(x_temp, ridPred, label = 'ridge')\n",
    "# plt.plot(x_temp, lassoPred, label = 'lasso')\n",
    "# plt.plot(x_temp, olsPred, label = 'ols')\n",
    "# plt.plot()\n",
    "# plt.legend()\n",
    "# plt.title('{}년도 {} 판매량 실제/예측'.format( '2016~2018',item ))\n",
    "# plt.xlabel(weather_columns[0])\n",
    "# plt.ylabel('판매량 (단위 : 1개)')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 실험"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intercept_lin = linReg.intercept_\n",
    "# coef_line = linReg.coef_\n",
    "# # list_col\n",
    "# linePredict = list()\n",
    "# x_temp = list(range(-10,38,1))\n",
    "# for temperature in x_temp:\n",
    "#     linePredict.append(intercept_lin + coef_line[0]*temperature)\n",
    "\n",
    "    \n",
    "# # 2016~2018, 일조시간\n",
    "# df_graph = df.copy()\n",
    "# plt.figure(figsize=(15.5, 10))\n",
    "# plt.scatter(df_graph[weather_columns[0]],df_graph['qty'], ls='-', color='k',label='실 판매량', s=100, alpha=0.3)\n",
    "# # for q_name in qty_columns:\n",
    "# #     plt.plot(df_graph[weather_columns[0]],df_graph[q_name], ls='-', label=q_name)\n",
    "# #     plt.scatter(df_graph.lgt_time,df_graph[q_name], ls='-', label='실제', color='green', alpha=0.5, lw=8)\n",
    "# #     plt.scatter(df_graph.lgt_time,df_graph.keras_qty, ls='-', label='keras예측', color='r')\n",
    "# #     plt.scatter(df_graph.lgt_time,df_graph.rf_qty, ls='-', label='rf예측', color='cyan')\n",
    "# #     plt.scatter(df_graph.lgt_time,df_graph.xgb_qty, ls='-', label='xgb예측', color='b')\n",
    "# #     plt.scatter(df_graph.lgt_time,df_graph.lin_qty, ls='-', label='linear예측')\n",
    "# #     plt.scatter(df_graph.lgt_time,df_graph.ridge_qty, ls='-', label='ridge예측')\n",
    "# #     plt.scatter(df_graph.lgt_time,df_graph.lasso_qty, ls='-', label='lasso예측',color='yellow')\n",
    "# #     plt.scatter(df_graph.lgt_time,df_graph.ols_qty, ls='-', label='ols예측', color='violet')\n",
    "# plt.plot(x_temp, linePredict, 'r--', label='linear회귀, 온도만')\n",
    "\n",
    "# plt.legend()\n",
    "# plt.title('{}년도 {} 판매량 실제/예측'.format( '2016~2018',item ))\n",
    "# plt.xlabel(weather_columns[0])\n",
    "# plt.ylabel('판매량 (단위 : 1개)')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 시간의 경과에 따른 예측량 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 2016\n",
    "# df_graph = result_df.loc[result_df.week <=53]\n",
    "# plt.figure(figsize=(15.5, 10))\n",
    "# plt.plot(df_graph.week,df_graph.qty, ls='-', label='실제', color='green', alpha=0.5, lw=8)\n",
    "# plt.plot(df_graph.week,df_graph.keras_qty, ls='-', label='keras예측', color='r')\n",
    "# plt.plot(df_graph.week,df_graph.rf_qty, ls='-', label='rf예측', color='cyan')\n",
    "# plt.plot(df_graph.week,df_graph.xgb_qty, ls='-', label='xgb예측', color='b')\n",
    "# plt.plot(df_graph.week,df_graph.lin_qty, ls='-', label='linear예측')\n",
    "# plt.plot(df_graph.week,df_graph.ridge_qty, ls='-', label='ridge예측')\n",
    "# plt.plot(df_graph.week,df_graph.lasso_qty, ls='-', label='lasso예측',color='yellow')\n",
    "# plt.plot(df_graph.week,df_graph.ols_qty, ls='-', label='ols예측', color='violet')\n",
    "# plt.legend()\n",
    "# plt.title('{}년도 {} 판매량 실제/예측'.format( '2016',item ))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 2017\n",
    "# df_graph = result_df.loc[(result_df.week >=53)&(result_df.week <=105)]\n",
    "# plt.figure(figsize=(15.5, 10))\n",
    "# plt.plot(df_graph.week,df_graph.qty, ls='-', label='실제', color='green', alpha=0.5, lw=8)\n",
    "# plt.plot(df_graph.week,df_graph.keras_qty, ls='-', label='keras예측', color='r')\n",
    "# plt.plot(df_graph.week,df_graph.rf_qty, ls='-', label='rf예측', color='cyan')\n",
    "# plt.plot(df_graph.week,df_graph.xgb_qty, ls='-', label='xgb예측', color='b')\n",
    "# plt.plot(df_graph.week,df_graph.lin_qty, ls='-', label='linear예측')\n",
    "# plt.plot(df_graph.week,df_graph.ridge_qty, ls='-', label='ridge예측')\n",
    "# plt.plot(df_graph.week,df_graph.lasso_qty, ls='-', label='lasso예측',color='yellow')\n",
    "# plt.plot(df_graph.week,df_graph.ols_qty, ls='-', label='ols예측', color='violet')\n",
    "# plt.title('{}년도 {} 판매량 실제/예측'.format( '2017',item ))\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 2018\n",
    "# df_graph = result_df.loc[(result_df.week >=105)]\n",
    "# plt.figure(figsize=(15.5, 10))\n",
    "# plt.plot(df_graph.week,df_graph.qty, ls='-', label='실제', color='green', alpha=0.5, lw=8)\n",
    "# plt.plot(df_graph.week,df_graph.keras_qty, ls='-', label='keras예측', color='r')\n",
    "# plt.plot(df_graph.week,df_graph.rf_qty, ls='-', label='rf예측', color='cyan')\n",
    "# plt.plot(df_graph.week,df_graph.xgb_qty, ls='-', label='xgb예측', color='b')\n",
    "# plt.plot(df_graph.week,df_graph.lin_qty, ls='-', label='linear예측')\n",
    "# plt.plot(df_graph.week,df_graph.ridge_qty, ls='-', label='ridge예측')\n",
    "# plt.plot(df_graph.week,df_graph.lasso_qty, ls='-', label='lasso예측',color='yellow')\n",
    "# plt.plot(df_graph.week,df_graph.ols_qty, ls='-', label='ols예측', color='violet')\n",
    "# plt.title('{}년도 {} 판매량 실제/예측'.format( '2018',item ))\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 2016~2018\n",
    "# plt.figure(figsize=(15.5, 10))\n",
    "# plt.plot(result_df.week,result_df.qty, ls='-', label='실제', color='green', alpha=0.5, lw=8)\n",
    "# plt.plot(result_df.week,result_df.keras_qty, ls='-', label='keras예측', color='r')\n",
    "# plt.plot(result_df.week,result_df.rf_qty, ls='-', label='rf예측', color='cyan')\n",
    "# plt.plot(result_df.week,result_df.xgb_qty, ls='-', label='xgb예측', color='b')\n",
    "# plt.plot(df_graph.week,df_graph.lin_qty, ls='-', label='linear예측')\n",
    "# plt.plot(df_graph.week,df_graph.ridge_qty, ls='-', label='ridge예측')\n",
    "# plt.plot(df_graph.week,df_graph.lasso_qty, ls='-', label='lasso예측',color='yellow')\n",
    "# plt.plot(df_graph.week,df_graph.ols_qty, ls='-', label='ols예측', color='violet')\n",
    "# plt.title('{}년도 {} 판매량 실제/예측'.format( '2016~2018',item ))\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def r2_score(v_true, v_pred):\n",
    "#     ssr = np.sum(np.square(v_pred - np.mean(v_true)))\n",
    "#     sst = np.sum(np.square(v_true - np.mean(v_true)))\n",
    "#     return ( ssr / sst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checked_for = '2016~2017'\n",
    "# combined = aaaaa.loc[:106,'temp':'PM10']\n",
    "# target = aaaaa.loc[:106,'qty']\n",
    "\n",
    "# # 가장 좋다고 판명된 설정을 이용하여, 예측qty생산\n",
    "# predictions = NN_model.predict(combined)\n",
    "# # RandomForest 회귀분석 예측 qty생산\n",
    "# RFpredicted = RFmodel.predict(combined)\n",
    "# # XGBRegressor 회귀분석 예측 qty생산\n",
    "# XGBpredictions = XGBModel.predict(combined)\n",
    "# # linearRegression 회귀분석 예측 qty생산\n",
    "# linPred = linReg.predict(combined)\n",
    "# # Ridge 회귀분석 예측 qty생산\n",
    "# ridPred = ridge.predict(combined)\n",
    "# # Lasso 회귀분석 예측 qty생산\n",
    "# lassoPred = lasso.predict(combined)\n",
    "# # OLS 회귀분석 예측 qty생산\n",
    "# olsPred = olsModel.predict(combined)\n",
    "# qty = target\n",
    "\n",
    "# print(checked_for)\n",
    "# print('RF R2값  \\t: ','{:<.5f}'.format(r2_score(qty, RFpredicted)) )\n",
    "# print('XGB R2값  \\t: ','{:<.5f}'.format(r2_score(qty, XGBpredictions)) )\n",
    "# print('KerasNN R2값\\t: ','{:<.5f}'.format(r2_score(qty,predictions )) )\n",
    "# print('LinReg R2값\\t: ','{:<.5f}'.format(r2_score(qty, linPred)) )\n",
    "# print('Ridge R2값  \\t: ','{:<.5f}'.format(r2_score(qty, ridPred)) )\n",
    "# print('Lasso R2값\\t: ','{:<.5f}'.format(r2_score(qty, lassoPred )) )\n",
    "# print('OLS R2값\\t: ','{:<.5f}'.format(r2_score(qty, olsPred )) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checked_for = '2018'\n",
    "# combined = aaaaa.loc[106:,'temp':'PM10']\n",
    "# target = aaaaa.loc[106:,'qty']\n",
    "\n",
    "# # 가장 좋다고 판명된 설정을 이용하여, 예측qty생산\n",
    "# predictions = NN_model.predict(combined)\n",
    "# # RandomForest 회귀분석 예측 qty생산\n",
    "# RFpredicted = RFmodel.predict(combined)\n",
    "# # XGBRegressor 회귀분석 예측 qty생산\n",
    "# XGBpredictions = XGBModel.predict(combined)\n",
    "# # linearRegression 회귀분석 예측 qty생산\n",
    "# linPred = linReg.predict(combined)\n",
    "# # Ridge 회귀분석 예측 qty생산\n",
    "# ridPred = ridge.predict(combined)\n",
    "# # Lasso 회귀분석 예측 qty생산\n",
    "# lassoPred = lasso.predict(combined)\n",
    "# # OLS 회귀분석 예측 qty생산\n",
    "# olsPred = olsModel.predict(combined)\n",
    "\n",
    "# qty = target\n",
    "\n",
    "# print(checked_for)\n",
    "# print('RF R2값  \\t: ','{:<.5f}'.format(r2_score(qty, RFpredicted)) )\n",
    "# print('XGB R2값  \\t: ','{:<.5f}'.format(r2_score(qty, XGBpredictions)) )\n",
    "# print('KerasNN R2값\\t: ','{:<.5f}'.format(r2_score(qty,predictions )) )\n",
    "# print('LinReg R2값\\t: ','{:<.5f}'.format(r2_score(qty, linPred)) )\n",
    "# print('Ridge R2값  \\t: ','{:<.5f}'.format(r2_score(qty, ridPred)) )\n",
    "# print('Lasso R2값\\t: ','{:<.5f}'.format(r2_score(qty, lassoPred )) )\n",
    "# print('OLS R2값\\t: ','{:<.5f}'.format(r2_score(qty, olsPred )) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checked_for = '2016~2018'\n",
    "# combined = aaaaa.loc[:,'temp':'PM10']\n",
    "# target = aaaaa.loc[:,'qty']\n",
    "\n",
    "# # 가장 좋다고 판명된 설정을 이용하여, 예측qty생산\n",
    "# predictions = NN_model.predict(combined)\n",
    "# # RandomForest 회귀분석 예측 qty생산\n",
    "# RFpredicted = RFmodel.predict(combined)\n",
    "# # XGBRegressor 회귀분석 예측 qty생산\n",
    "# XGBpredictions = XGBModel.predict(combined)\n",
    "# # linearRegression 회귀분석 예측 qty생산\n",
    "# linPred = linReg.predict(combined)\n",
    "# # Ridge 회귀분석 예측 qty생산\n",
    "# ridPred = ridge.predict(combined)\n",
    "# # Lasso 회귀분석 예측 qty생산\n",
    "# lassoPred = lasso.predict(combined)\n",
    "# # OLS 회귀분석 예측 qty생산\n",
    "# olsPred = olsModel.predict(combined)\n",
    "\n",
    "# qty = target\n",
    "\n",
    "# print(checked_for)\n",
    "# print('RF R2값  \\t: ','{:<.5f}'.format(r2_score(qty, RFpredicted)) )\n",
    "# print('XGB R2값  \\t: ','{:<.5f}'.format(r2_score(qty, XGBpredictions)) )\n",
    "# print('KerasNN R2값\\t: ','{:<.5f}'.format(r2_score(qty,predictions )) )\n",
    "# print('LinReg R2값\\t: ','{:<.5f}'.format(r2_score(qty, linPred)) )\n",
    "# print('Ridge R2값  \\t: ','{:<.5f}'.format(r2_score(qty, ridPred)) )\n",
    "# print('Lasso R2값\\t: ','{:<.5f}'.format(r2_score(qty, lassoPred )) )\n",
    "# print('OLS R2값\\t: ','{:<.5f}'.format(r2_score(qty, olsPred )) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = 'D:/project/contest/data/result/'\n",
    "# result_df.to_csv(path+item+'_'+grouped_by+'_predict(lowVIF07).csv', encoding='utf-8', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
