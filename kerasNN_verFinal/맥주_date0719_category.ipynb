{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인공신경망관련 패키지\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "\n",
    "# 회귀분석 관련 패키지\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error \n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from scipy import stats\n",
    "\n",
    "# R2 값, 결정계수 계산\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# OLS회귀분석\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# 시각화 패키지\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sb\n",
    "\n",
    "# 데이터 처리를 위한 패키지\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# 다중공선성(multicollinearity) 처리를 위한VIF 확인 패키지\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# 한글 처리\n",
    "from matplotlib import rc, font_manager\n",
    "font_name = font_manager.FontProperties(fname='C:/Windows/Fonts/NanumGothicCoding.ttf').get_name()\n",
    "rc('font',family=font_name)\n",
    "\n",
    "# from matplotlib import rcParams\n",
    "# rcParams['font.family'] = 'NanumGothicCoding'\n",
    "\n",
    "# - 마이너스 사인 처리\n",
    "matplotlib.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# DeprecationWarning경고 무시\n",
    "# 향후 안쓰일 함수들을 이용해서 만들어져 있기 때문에 필요하다 없으면, 사방이 붉어진다.\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "# MAD 기반 예제코드\n",
    "def mad_based_outlier(points, thresh=3.5):\n",
    "    if len(points.shape) == 1:\n",
    "        points = points[:,None]\n",
    "    median = np.median(points, axis=0)\n",
    "    diff = np.sum((points - median)**2, axis=-1)\n",
    "    diff = np.sqrt(diff)\n",
    "    med_abs_deviation = np.median(diff)\n",
    "    modified_z_score = 0.6745 * diff / med_abs_deviation\n",
    "    return modified_z_score > thresh \n",
    "\n",
    "# 출처: https://pythonanalysis.tistory.com/7 [Python 데이터 분석]\n",
    "#########################################################################\n",
    "\n",
    "# 소셜 데이터 처리를 위한 함수\n",
    "# 1. 모든 소셜 데이터 column들의 첫번째는 : 날짜다.\n",
    "# 2. 각 소셜데이터는 social_키워드.블로그/트위터/뉴스/총합 으로 되어 있다.\n",
    "def changeColNames(d,before, after) : \n",
    "    # 컬럼이름 시리즈로 만들어 반환\n",
    "    # 통합하기 쉽게, 모든 데이터들의 날짜컬럼 이름을 date로 통일\n",
    "    new_col_names = ['date']\n",
    "    new_col_names.extend(list(d.columns)[1:])\n",
    "    d.columns = new_col_names\n",
    "    return pd.Series(d.columns).apply(lambda x : x.replace(before,after))\n",
    "\n",
    "#########################################################################\n",
    "# modeling 함수로 만들어 처리하기\n",
    "def linReg(df, item, cols_using):\n",
    "    cols = cols_using\n",
    "    X = df.loc[df['category']==item, cols]\n",
    "    y = df.loc[df['category']==item,'qty']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=0)\n",
    "\n",
    "    model = LinearRegression().fit(X_train, y_train)\n",
    "  \n",
    "    print('LinearRegression을 이용한 %s의 회귀분석 결과 :'%item)\n",
    "    print('훈련세트점수 : {:.2f}'.format(model.score(X_train, y_train)))\n",
    "    print('검증세트점수 : {:.2f}'.format(model.score(X_test, y_test)))\n",
    "\n",
    "    \n",
    "def ridgeReg(df, item, cols_using):\n",
    "    cols = cols_using\n",
    "    X = df.loc[df['category']==item,cols]\n",
    "    y = df.loc[df['category']==item,'qty']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=0)\n",
    "\n",
    "    ridge = Ridge(alpha=0.1, normalize=True, random_state=0, tol=0.001).fit(X_train, y_train)\n",
    "    \n",
    "    print('RidgeRegression을 이용한 %s의 회귀분석 결과 :'%item)\n",
    "    print('훈련세트점수 : {:.2f}'.format(ridge.score(X_train, y_train)))\n",
    "    print('검증세트점수 : {:.2f}'.format(ridge.score(X_test, y_test)))\n",
    "\n",
    "\n",
    "def lassoReg(df, item, cols_using):\n",
    "    cols = cols_using\n",
    "    X = df.loc[df['category']==item,cols]\n",
    "    y = df.loc[df['category']==item,'qty']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=0)\n",
    "\n",
    "    lasso = Lasso(alpha=0.1, max_iter=1000).fit(X=X_train, y=y_train)\n",
    "  \n",
    "    print('LassoRegression을 이용한 %s의 회귀분석 결과 :'%item)\n",
    "    print('훈련세트점수 : {:.2f}'.format(lasso.score(X_train, y_train)) )\n",
    "    print('검증세트점수 : {:.2f}'.format(lasso.score(X_test, y_test)) )\n",
    "\n",
    "    #사용한 특성수\n",
    "    print('사용한 특성수 : {}'.format(np.sum(lasso.coef_ != 0)) )\n",
    "#########################################################################\n",
    "\n",
    "# 자료가 1일 1행이라는 전제하에\n",
    "# df길이를 이용하여 날짜수를 계산, 이후 2016년 1월1일을 1번째주 1일이라 기준하에\n",
    "# 몇번째 주인지 알려주는 컬럼 추가. 향후 주단위로 종합할때 스인다.\n",
    "def addDayWeek(df):\n",
    "    df_work = df.copy()\n",
    "    df_work['day'] = pd.Series(range(1,df_work.shape[0]+1)).astype('int64')\n",
    "    df_work['week'] = df_work['day'].apply(lambda x : math.ceil(x/7))\n",
    "    return df_work\n",
    "#########################################################################\n",
    "# 자료를 병합해주는 함수, 어떤 item인지 어느 컬럼을 기준으로 할지 받아서 병합\n",
    "def mergeForAnalysis(df1, df2, df3, item, on_what='date'):\n",
    "    merged_df = pd.merge(df1.loc[df1.category==item], df2, on=on_what, how='left')\n",
    "    merged_df = pd.merge(merged_df, df3, on=on_what, how='left')\n",
    "    return merged_df\n",
    "\n",
    "\n",
    "#########################################################################\n",
    "def lowVIF(df, n=7, cols_using =['temp', 'cloud', 'wind','humid', 'hpa', 'sun_time', 'lgt_time', \n",
    "       'SO2', 'CO', 'O3', 'NO2', 'PM10', 'PM25'] ):\n",
    "    col_to_use = cols_using\n",
    "    vif = pd.DataFrame()\n",
    "    vif[\"VIF_Factor\"] = [variance_inflation_factor(\n",
    "        df[col_to_use].values, i) for i in range(df[col_to_use].shape[1])]\n",
    "    vif[\"features\"] = col_to_use\n",
    "    vif.sort_values(\"VIF_Factor\")\n",
    "    lowest_vif = vif.sort_values(\"VIF_Factor\")[:n].reset_index()\n",
    "    lowest_vif.drop(columns='index', inplace=True)\n",
    "    return lowest_vif\n",
    "\n",
    "#########################################################################\n",
    "# ols모델용 formula 생성\n",
    "def formulaGen(target, ind_features):\n",
    "    '''\n",
    "    formulaGen(목표컬럼명,[변수컬럼명1, 변수컬럼명2,...])\n",
    "    '''\n",
    "    custom_formula = target + \" ~ \"\n",
    "    for f in range(len(ind_features)):\n",
    "        custom_formula += ind_features[f]\n",
    "        if f!=(len(ind_features)-1):\n",
    "            custom_formula += \" + \"\n",
    "    return custom_formula\n",
    "#########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기 (전처리 된 GS, 랄라블라, 날씨)\n",
    "gs = pd.read_csv('d:/project/contest/data/processed/p_gs.csv', parse_dates=['date'])\n",
    "lv = pd.read_csv('d:/project/contest/data/processed/p_lavla.csv', parse_dates=['date'])\n",
    "# w = pd.read_csv('d:/project/contest/data/processed/p_wUVair_seoul_category.csv', parse_dates=['date'], index_col=0)\n",
    "w = pd.read_csv('d:/project/contest/data/processed/날씨_ver071915.csv', parse_dates=['date'], index_col=0)\n",
    "sns_all = pd.read_csv('d:/project/contest/data/processed/social_all.csv', parse_dates=['date'])\n",
    "\n",
    "# GS/lv 서울시만\n",
    "gs_seoul = gs.loc[gs.pvn_nm =='서울특별시']\n",
    "lv_seoul = lv.loc[lv.pvn_nm =='서울특별시']\n",
    "w_seoul = w.loc[w['loc']==108]\n",
    "\n",
    "cols_to_keep = ['date','bor_nm','gender','age_cd','category','qty']\n",
    "\n",
    "# 일일, 구단위, 상품별 판매량 종합\n",
    "gs_grouped = gs_seoul[cols_to_keep].groupby(by=['date','bor_nm','category']).sum().reset_index()\n",
    "\n",
    "# 일단위로 자료 종합(qty는 일일 합계)\n",
    "day_gs_grouped = gs_grouped.groupby(by=['date','category']).sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '맥주'만 빼서 df생성\n",
    "item = '맥주'\n",
    "grouped_by = 'date'\n",
    "day_gs_grouped_w_item = pd.merge(day_gs_grouped.loc[day_gs_grouped.category==item],w_seoul,on='date',how='left')\n",
    "# day_gs_grouped_w_item.head(3)\n",
    "day_gs_grouped_w_sns_item = pd.merge(day_gs_grouped_w_item, sns_all,on='date',how='left')\n",
    "\n",
    "# 일단 uv = 자외선 지수는 결측치가 많아서 제외\n",
    "selected_cols = ['date', 'category', 'qty', 'temp', 'rain', 'cloud', 'wind','humid', 'hpa',\n",
    "                 'sun_time', 'lgt_time', 'snow','rain_or_not','snow_or_not','미세', '초미세', '공기상태',\n",
    "                 'SO2', 'CO', 'O3', 'NO2', 'PM10', 'PM25',\n",
    "                 'pm_blog', 'pm_twitter', 'pm_news', 'pm_total',\n",
    "                 'health_blog', 'health_twitter', 'health_news', 'health_total',\n",
    "                 'date_blog', 'date_twitter', 'date_news', 'date_total',\n",
    "                 'br_blog', 'br_twitter', 'br_news', 'br_total',\n",
    "                 'hobby_blog', 'hobby_twitter', 'hobby_news', 'hobby_total']\n",
    "gs_day_w = day_gs_grouped_w_sns_item[selected_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAD적용\n",
    "gs_day_w['outlier'] = pd.DataFrame(mad_based_outlier(gs_day_w['qty']))\n",
    "gs_day_w = gs_day_w.loc[gs_day_w.outlier==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VIF_Factor</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.239620</td>\n",
       "      <td>snow_or_not</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.479988</td>\n",
       "      <td>rain_or_not</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.114369</td>\n",
       "      <td>공기상태</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.013218</td>\n",
       "      <td>temp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.725926</td>\n",
       "      <td>cloud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8.084050</td>\n",
       "      <td>lgt_time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9.334878</td>\n",
       "      <td>wind</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VIF_Factor     features\n",
       "0    1.239620  snow_or_not\n",
       "1    2.479988  rain_or_not\n",
       "2    3.114369         공기상태\n",
       "3    4.013218         temp\n",
       "4    6.725926        cloud\n",
       "5    8.084050     lgt_time\n",
       "6    9.334878         wind"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list_col = ['temp', 'cloud', 'wind', 'lgt_time', 'PM10'] # +,'rain_or_not','snow_or_not'\n",
    "list_col = ['temp', 'cloud', 'wind','lgt_time',\n",
    "            'rain_or_not', 'snow_or_not', '공기상태'] #+'rain_or_not', 'snow_or_not'\n",
    "lowVIF(w,20,list_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data = gs_day_w.loc[gs_day_w.date.between('2016-01-01','2017-12-31')]\n",
    "test_data = gs_day_w.loc[gs_day_w.date.between('2018-01-01','2018-12-31')]\n",
    "\n",
    "# 3년치 데이터 분리 : 종속변수('qty': 판매량)와 독립변수(판매량 제외 나머지 전부)\n",
    "# 날씨 데이터만\n",
    "combined = gs_day_w.loc[:,list_col]\n",
    "target = gs_day_w.loc[:,'qty']\n",
    "Xy = pd.concat([target,combined], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cols_with_no_nans(df,col_type):\n",
    "    '''\n",
    "    Arguments :\n",
    "    df : The dataframe to process\n",
    "    col_type : \n",
    "          num : to only get numerical columns with no nans\n",
    "          no_num : to only get nun-numerical columns with no nans\n",
    "          all : to get any columns with no nans    \n",
    "    '''\n",
    "    if (col_type == 'num'):\n",
    "        predictors = df.select_dtypes(exclude=['object'])\n",
    "    elif (col_type == 'no_num'):\n",
    "        predictors = df.select_dtypes(include=['object'])\n",
    "    elif (col_type == 'all'):\n",
    "        predictors = df\n",
    "    else :\n",
    "        print('Error : choose a type (num, no_num, all)')\n",
    "        return 0\n",
    "    cols_with_no_nans = []\n",
    "    for col in predictors.columns:\n",
    "        if not df[col].isnull().any():\n",
    "            cols_with_no_nans.append(col)\n",
    "    return cols_with_no_nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "수치형 자료 컬럼 갯수 : 7\n",
      "오브젝트형 자료 컬럼 갯수 : 0\n"
     ]
    }
   ],
   "source": [
    "num_cols = get_cols_with_no_nans(combined , 'num')\n",
    "cat_cols = get_cols_with_no_nans(combined , 'no_num')\n",
    "\n",
    "print ('수치형 자료 컬럼 갯수 :',len(num_cols))\n",
    "print ('오브젝트형 자료 컬럼 갯수 :',len(cat_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x720 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "combined = combined[num_cols + cat_cols]\n",
    "combined.hist(figsize = (12,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data = train_data[num_cols + cat_cols]\n",
    "train_data['Target'] = target\n",
    "\n",
    "C_mat = train_data.corr()\n",
    "fig = plt.figure(figsize = (15,15))\n",
    "\n",
    "sb.heatmap(C_mat, vmax = .8, square = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분류형(category형) 컬럼 수정 전, 총 7 개의 columns이 있었습니다.\n",
      "분류형(category형) 컬럼 수정 후, 총 10 개의 columns이 있었습니다.\n"
     ]
    }
   ],
   "source": [
    "def oneHotEncode(df,colNames):\n",
    "    for col in colNames:\n",
    "        # 해당 컬럼의 데이터 타입이 object란 소리는 숫자가 아니다 = 분류형 데이터\n",
    "        if( df[col].dtype == np.dtype('object')):\n",
    "            # 더미 컬럼 생성\n",
    "            dummies = pd.get_dummies(df[col],prefix=col)\n",
    "            # 원본 데이터에 이어 붙이기 axis=1 컬럼방향으로 \n",
    "            df = pd.concat([df,dummies],axis=1)\n",
    "\n",
    "            # 기존의 str형 컬럼 삭제\n",
    "            df.drop([col],axis = 1 , inplace=True)\n",
    "    return df\n",
    "    \n",
    "\n",
    "print('분류형(category형) 컬럼 수정 전, 총 {} 개의 columns이 있었습니다.'.format(combined.shape[1]))\n",
    "combined = oneHotEncode(combined, cat_cols)\n",
    "#### 내가 '공기상태'라는 컬럼이 사실은 category형이라는것을 알기에 직접 dummy컬럼 생성\n",
    "airCondition_dummies = pd.get_dummies(combined['공기상태'],prefix='공기상태')\n",
    "combined = pd.concat([combined, airCondition_dummies], axis=1)\n",
    "combined.drop(['공기상태'],axis = 1 , inplace=True)\n",
    "######################################################################################\n",
    "print('분류형(category형) 컬럼 수정 후, 총 {} 개의 columns이 있었습니다.'.format(combined.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temp</th>\n",
       "      <th>cloud</th>\n",
       "      <th>wind</th>\n",
       "      <th>lgt_time</th>\n",
       "      <th>rain_or_not</th>\n",
       "      <th>snow_or_not</th>\n",
       "      <th>공기상태_0</th>\n",
       "      <th>공기상태_1</th>\n",
       "      <th>공기상태_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   temp  cloud  wind  lgt_time  rain_or_not  snow_or_not  공기상태_0  공기상태_1  \\\n",
       "0   1.2    7.0   1.6       2.1            0            0       0       0   \n",
       "\n",
       "   공기상태_2  \n",
       "0       1  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 공기상태_0,공기상태_1,공기상태_2가 전부 0이면,   공기상태_3이 1이란 소리고\n",
    "#                                                               공기상태가 '매우나쁨' 임을 추정할수 있다.\n",
    "# 그런이유로 공기상태_3삭제\n",
    "combined.drop(['공기상태_3'],axis = 1 , inplace=True)\n",
    "combined.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xy = pd.concat([target,combined], axis=1)\n",
    "# Xy.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(732, 9)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 첫 2년 : 732 일\n",
    "cut_line = 732\n",
    "def split_combined():\n",
    "    global combined\n",
    "    train = combined[:cut_line]\n",
    "    test = combined[cut_line:]\n",
    "\n",
    "    return train , test \n",
    "  \n",
    "train, test = split_combined()\n",
    "\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 128)               1280      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 166,145\n",
      "Trainable params: 166,145\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 신경망 모델 생성\n",
    "NN_model = Sequential()\n",
    "\n",
    "# The Input Layer :\n",
    "NN_model.add(Dense(128, kernel_initializer='normal',input_dim = train.shape[1], activation='relu'))\n",
    "\n",
    "# The Hidden Layers :\n",
    "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "\n",
    "# The Output Layer :\n",
    "NN_model.add(Dense(1, kernel_initializer='normal',activation='linear'))\n",
    "\n",
    "# Compile the network :\n",
    "# optimizer에 여러 방식이 있다.\n",
    "NN_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
    "NN_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인공 신경망에 의해 생성된 weight 자료를 저장하기 위해서\n",
    "checkpoint_name = item+grouped_by+'-Weights-{epoch:03d}--{val_loss:.5f}-cat02-vf05.hdf5' \n",
    "\n",
    "# save_best_only값이 저장되어, 모든 weight값을 저장하지 않고, val_loss값이 줄어들때마다(적을수록 좋다.) 저장\n",
    "checkpoint = ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose = 1, save_best_only = True, mode ='auto')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 585 samples, validate on 147 samples\n",
      "Epoch 1/500\n",
      "585/585 [==============================] - 0s 566us/step - loss: 11601.3567 - mean_absolute_error: 11601.3567 - val_loss: 11578.3776 - val_mean_absolute_error: 11578.3776\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 11578.37761, saving model to 맥주date-Weights-001--11578.37761-cat02-vf05.hdf5\n",
      "Epoch 2/500\n",
      "585/585 [==============================] - 0s 80us/step - loss: 11056.9085 - mean_absolute_error: 11056.9085 - val_loss: 9554.1973 - val_mean_absolute_error: 9554.1973\n",
      "\n",
      "Epoch 00002: val_loss improved from 11578.37761 to 9554.19731, saving model to 맥주date-Weights-002--9554.19731-cat02-vf05.hdf5\n",
      "Epoch 3/500\n",
      "585/585 [==============================] - 0s 78us/step - loss: 5293.4258 - mean_absolute_error: 5293.4258 - val_loss: 3061.3435 - val_mean_absolute_error: 3061.3435\n",
      "\n",
      "Epoch 00003: val_loss improved from 9554.19731 to 3061.34352, saving model to 맥주date-Weights-003--3061.34352-cat02-vf05.hdf5\n",
      "Epoch 4/500\n",
      "585/585 [==============================] - 0s 80us/step - loss: 2314.1899 - mean_absolute_error: 2314.1899 - val_loss: 1695.0003 - val_mean_absolute_error: 1695.0003\n",
      "\n",
      "Epoch 00004: val_loss improved from 3061.34352 to 1695.00033, saving model to 맥주date-Weights-004--1695.00033-cat02-vf05.hdf5\n",
      "Epoch 5/500\n",
      "585/585 [==============================] - 0s 78us/step - loss: 1903.4773 - mean_absolute_error: 1903.4773 - val_loss: 1575.1054 - val_mean_absolute_error: 1575.1054\n",
      "\n",
      "Epoch 00005: val_loss improved from 1695.00033 to 1575.10539, saving model to 맥주date-Weights-005--1575.10539-cat02-vf05.hdf5\n",
      "Epoch 6/500\n",
      "585/585 [==============================] - 0s 73us/step - loss: 1836.2385 - mean_absolute_error: 1836.2385 - val_loss: 1597.2014 - val_mean_absolute_error: 1597.2014\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1575.10539\n",
      "Epoch 7/500\n",
      "585/585 [==============================] - 0s 82us/step - loss: 1833.0006 - mean_absolute_error: 1833.0006 - val_loss: 1636.9796 - val_mean_absolute_error: 1636.9796\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1575.10539\n",
      "Epoch 8/500\n",
      "585/585 [==============================] - 0s 85us/step - loss: 1855.6663 - mean_absolute_error: 1855.6663 - val_loss: 1669.1482 - val_mean_absolute_error: 1669.1482\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1575.10539\n",
      "Epoch 9/500\n",
      "585/585 [==============================] - 0s 104us/step - loss: 1844.2043 - mean_absolute_error: 1844.2043 - val_loss: 1688.0034 - val_mean_absolute_error: 1688.0034\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1575.10539\n",
      "Epoch 10/500\n",
      "585/585 [==============================] - 0s 72us/step - loss: 1796.7191 - mean_absolute_error: 1796.7191 - val_loss: 1886.6886 - val_mean_absolute_error: 1886.6886\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1575.10539\n",
      "Epoch 11/500\n",
      "585/585 [==============================] - 0s 94us/step - loss: 1902.4854 - mean_absolute_error: 1902.4854 - val_loss: 1729.4960 - val_mean_absolute_error: 1729.4960\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1575.10539\n",
      "Epoch 12/500\n",
      "585/585 [==============================] - 0s 84us/step - loss: 1786.9912 - mean_absolute_error: 1786.9912 - val_loss: 1818.4310 - val_mean_absolute_error: 1818.4310\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1575.10539\n",
      "Epoch 13/500\n",
      "585/585 [==============================] - 0s 84us/step - loss: 1804.0255 - mean_absolute_error: 1804.0255 - val_loss: 1637.1758 - val_mean_absolute_error: 1637.1758\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1575.10539\n",
      "Epoch 14/500\n",
      "585/585 [==============================] - 0s 82us/step - loss: 1800.5808 - mean_absolute_error: 1800.5808 - val_loss: 1553.8617 - val_mean_absolute_error: 1553.8617\n",
      "\n",
      "Epoch 00014: val_loss improved from 1575.10539 to 1553.86171, saving model to 맥주date-Weights-014--1553.86171-cat02-vf05.hdf5\n",
      "Epoch 15/500\n",
      "585/585 [==============================] - 0s 78us/step - loss: 1759.9900 - mean_absolute_error: 1759.9900 - val_loss: 1580.6657 - val_mean_absolute_error: 1580.6657\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1553.86171\n",
      "Epoch 16/500\n",
      "585/585 [==============================] - 0s 68us/step - loss: 1786.3868 - mean_absolute_error: 1786.3868 - val_loss: 1568.6331 - val_mean_absolute_error: 1568.6331\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1553.86171\n",
      "Epoch 17/500\n",
      "585/585 [==============================] - 0s 80us/step - loss: 1750.7106 - mean_absolute_error: 1750.7106 - val_loss: 1639.5021 - val_mean_absolute_error: 1639.5021\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1553.86171\n",
      "Epoch 18/500\n",
      "585/585 [==============================] - 0s 78us/step - loss: 1747.7228 - mean_absolute_error: 1747.7228 - val_loss: 1611.5103 - val_mean_absolute_error: 1611.5103\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1553.86171\n",
      "Epoch 19/500\n",
      "585/585 [==============================] - 0s 72us/step - loss: 1744.0918 - mean_absolute_error: 1744.0918 - val_loss: 1607.1205 - val_mean_absolute_error: 1607.1205\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1553.86171\n",
      "Epoch 20/500\n",
      "585/585 [==============================] - 0s 89us/step - loss: 1742.8208 - mean_absolute_error: 1742.8208 - val_loss: 1550.2614 - val_mean_absolute_error: 1550.2614\n",
      "\n",
      "Epoch 00020: val_loss improved from 1553.86171 to 1550.26137, saving model to 맥주date-Weights-020--1550.26137-cat02-vf05.hdf5\n",
      "Epoch 21/500\n",
      "585/585 [==============================] - 0s 78us/step - loss: 1749.9250 - mean_absolute_error: 1749.9250 - val_loss: 1517.6898 - val_mean_absolute_error: 1517.6898\n",
      "\n",
      "Epoch 00021: val_loss improved from 1550.26137 to 1517.68981, saving model to 맥주date-Weights-021--1517.68981-cat02-vf05.hdf5\n",
      "Epoch 22/500\n",
      "585/585 [==============================] - 0s 73us/step - loss: 1712.4989 - mean_absolute_error: 1712.4989 - val_loss: 1607.1133 - val_mean_absolute_error: 1607.1133\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1517.68981\n",
      "Epoch 23/500\n",
      "585/585 [==============================] - 0s 87us/step - loss: 1744.7742 - mean_absolute_error: 1744.7742 - val_loss: 1501.4872 - val_mean_absolute_error: 1501.4872\n",
      "\n",
      "Epoch 00023: val_loss improved from 1517.68981 to 1501.48723, saving model to 맥주date-Weights-023--1501.48723-cat02-vf05.hdf5\n",
      "Epoch 24/500\n",
      "585/585 [==============================] - 0s 77us/step - loss: 1765.2220 - mean_absolute_error: 1765.2220 - val_loss: 1535.5568 - val_mean_absolute_error: 1535.5568\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1501.48723\n",
      "Epoch 25/500\n",
      "585/585 [==============================] - 0s 73us/step - loss: 1760.7463 - mean_absolute_error: 1760.7463 - val_loss: 1569.9280 - val_mean_absolute_error: 1569.9280\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1501.48723\n",
      "Epoch 26/500\n",
      "585/585 [==============================] - 0s 78us/step - loss: 1700.4188 - mean_absolute_error: 1700.4188 - val_loss: 1524.2398 - val_mean_absolute_error: 1524.2398\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1501.48723\n",
      "Epoch 27/500\n",
      "585/585 [==============================] - 0s 87us/step - loss: 1706.3494 - mean_absolute_error: 1706.3494 - val_loss: 1541.2732 - val_mean_absolute_error: 1541.2732\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1501.48723\n",
      "Epoch 28/500\n",
      "585/585 [==============================] - 0s 87us/step - loss: 1698.9041 - mean_absolute_error: 1698.9041 - val_loss: 1516.5456 - val_mean_absolute_error: 1516.5456\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1501.48723\n",
      "Epoch 29/500\n",
      "585/585 [==============================] - 0s 78us/step - loss: 1722.0880 - mean_absolute_error: 1722.0880 - val_loss: 1536.7366 - val_mean_absolute_error: 1536.7366\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1501.48723\n",
      "Epoch 30/500\n",
      "585/585 [==============================] - 0s 89us/step - loss: 1726.3142 - mean_absolute_error: 1726.3142 - val_loss: 1531.0670 - val_mean_absolute_error: 1531.0670\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1501.48723\n",
      "Epoch 31/500\n",
      "585/585 [==============================] - 0s 77us/step - loss: 1666.4433 - mean_absolute_error: 1666.4433 - val_loss: 1727.8505 - val_mean_absolute_error: 1727.8505\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1501.48723\n",
      "Epoch 32/500\n",
      "585/585 [==============================] - 0s 92us/step - loss: 1716.3496 - mean_absolute_error: 1716.3496 - val_loss: 1473.1423 - val_mean_absolute_error: 1473.1423\n",
      "\n",
      "Epoch 00032: val_loss improved from 1501.48723 to 1473.14229, saving model to 맥주date-Weights-032--1473.14229-cat02-vf05.hdf5\n",
      "Epoch 33/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "585/585 [==============================] - 0s 90us/step - loss: 1759.9145 - mean_absolute_error: 1759.9145 - val_loss: 1563.7600 - val_mean_absolute_error: 1563.7600\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1473.14229\n",
      "Epoch 34/500\n",
      "585/585 [==============================] - 0s 82us/step - loss: 1752.9506 - mean_absolute_error: 1752.9506 - val_loss: 1561.5924 - val_mean_absolute_error: 1561.5924\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1473.14229\n",
      "Epoch 35/500\n",
      "585/585 [==============================] - 0s 80us/step - loss: 1712.5009 - mean_absolute_error: 1712.5009 - val_loss: 1494.5241 - val_mean_absolute_error: 1494.5241\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1473.14229\n",
      "Epoch 36/500\n",
      "585/585 [==============================] - 0s 78us/step - loss: 1736.4870 - mean_absolute_error: 1736.4870 - val_loss: 1534.6829 - val_mean_absolute_error: 1534.6829\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1473.14229\n",
      "Epoch 37/500\n",
      "585/585 [==============================] - 0s 75us/step - loss: 1689.9898 - mean_absolute_error: 1689.9898 - val_loss: 1508.8884 - val_mean_absolute_error: 1508.8884\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1473.14229\n",
      "Epoch 38/500\n",
      "585/585 [==============================] - 0s 78us/step - loss: 1656.1991 - mean_absolute_error: 1656.1991 - val_loss: 1509.7310 - val_mean_absolute_error: 1509.7310\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1473.14229\n",
      "Epoch 39/500\n",
      "585/585 [==============================] - 0s 85us/step - loss: 1662.8058 - mean_absolute_error: 1662.8058 - val_loss: 1462.6066 - val_mean_absolute_error: 1462.6066\n",
      "\n",
      "Epoch 00039: val_loss improved from 1473.14229 to 1462.60656, saving model to 맥주date-Weights-039--1462.60656-cat02-vf05.hdf5\n",
      "Epoch 40/500\n",
      "585/585 [==============================] - 0s 82us/step - loss: 1675.5824 - mean_absolute_error: 1675.5824 - val_loss: 1471.5267 - val_mean_absolute_error: 1471.5267\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1462.60656\n",
      "Epoch 41/500\n",
      "585/585 [==============================] - 0s 82us/step - loss: 1651.7719 - mean_absolute_error: 1651.7719 - val_loss: 1496.2262 - val_mean_absolute_error: 1496.2262\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1462.60656\n",
      "Epoch 42/500\n",
      "585/585 [==============================] - 0s 77us/step - loss: 1672.4018 - mean_absolute_error: 1672.4018 - val_loss: 1606.3259 - val_mean_absolute_error: 1606.3259\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1462.60656\n",
      "Epoch 43/500\n",
      "585/585 [==============================] - 0s 87us/step - loss: 1722.2141 - mean_absolute_error: 1722.2141 - val_loss: 1540.6982 - val_mean_absolute_error: 1540.6982\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1462.60656\n",
      "Epoch 44/500\n",
      "585/585 [==============================] - 0s 89us/step - loss: 1644.6731 - mean_absolute_error: 1644.6731 - val_loss: 1500.4359 - val_mean_absolute_error: 1500.4359\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1462.60656\n",
      "Epoch 45/500\n",
      "585/585 [==============================] - 0s 89us/step - loss: 1630.2124 - mean_absolute_error: 1630.2124 - val_loss: 1516.0601 - val_mean_absolute_error: 1516.0601\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1462.60656\n",
      "Epoch 46/500\n",
      "585/585 [==============================] - 0s 77us/step - loss: 1711.1469 - mean_absolute_error: 1711.1469 - val_loss: 1497.9868 - val_mean_absolute_error: 1497.9868\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1462.60656\n",
      "Epoch 47/500\n",
      "585/585 [==============================] - 0s 84us/step - loss: 1627.5417 - mean_absolute_error: 1627.5417 - val_loss: 1449.7883 - val_mean_absolute_error: 1449.7883\n",
      "\n",
      "Epoch 00047: val_loss improved from 1462.60656 to 1449.78834, saving model to 맥주date-Weights-047--1449.78834-cat02-vf05.hdf5\n",
      "Epoch 48/500\n",
      "585/585 [==============================] - 0s 87us/step - loss: 1626.3421 - mean_absolute_error: 1626.3421 - val_loss: 1532.9320 - val_mean_absolute_error: 1532.9320\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 1449.78834\n",
      "Epoch 49/500\n",
      "585/585 [==============================] - 0s 92us/step - loss: 1618.7879 - mean_absolute_error: 1618.7879 - val_loss: 1470.7690 - val_mean_absolute_error: 1470.7690\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1449.78834\n",
      "Epoch 50/500\n",
      "585/585 [==============================] - 0s 95us/step - loss: 1679.4825 - mean_absolute_error: 1679.4825 - val_loss: 1710.6328 - val_mean_absolute_error: 1710.6328\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1449.78834\n",
      "Epoch 51/500\n",
      "585/585 [==============================] - 0s 87us/step - loss: 1717.8271 - mean_absolute_error: 1717.8271 - val_loss: 1558.1898 - val_mean_absolute_error: 1558.1898\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 1449.78834\n",
      "Epoch 52/500\n",
      "585/585 [==============================] - 0s 89us/step - loss: 1660.6631 - mean_absolute_error: 1660.6631 - val_loss: 1445.6274 - val_mean_absolute_error: 1445.6274\n",
      "\n",
      "Epoch 00052: val_loss improved from 1449.78834 to 1445.62737, saving model to 맥주date-Weights-052--1445.62737-cat02-vf05.hdf5\n",
      "Epoch 53/500\n",
      "585/585 [==============================] - 0s 87us/step - loss: 1673.1830 - mean_absolute_error: 1673.1830 - val_loss: 1469.8988 - val_mean_absolute_error: 1469.8988\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 1445.62737\n",
      "Epoch 54/500\n",
      "585/585 [==============================] - 0s 89us/step - loss: 1659.0620 - mean_absolute_error: 1659.0620 - val_loss: 1606.7818 - val_mean_absolute_error: 1606.7818\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 1445.62737\n",
      "Epoch 55/500\n",
      "585/585 [==============================] - 0s 95us/step - loss: 1663.4499 - mean_absolute_error: 1663.4499 - val_loss: 1505.0735 - val_mean_absolute_error: 1505.0735\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 1445.62737\n",
      "Epoch 56/500\n",
      "585/585 [==============================] - 0s 99us/step - loss: 1623.3562 - mean_absolute_error: 1623.3562 - val_loss: 1426.2215 - val_mean_absolute_error: 1426.2215\n",
      "\n",
      "Epoch 00056: val_loss improved from 1445.62737 to 1426.22154, saving model to 맥주date-Weights-056--1426.22154-cat02-vf05.hdf5\n",
      "Epoch 57/500\n",
      "585/585 [==============================] - 0s 82us/step - loss: 1662.5113 - mean_absolute_error: 1662.5113 - val_loss: 1477.9661 - val_mean_absolute_error: 1477.9661\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 1426.22154\n",
      "Epoch 58/500\n",
      "585/585 [==============================] - 0s 87us/step - loss: 1604.5859 - mean_absolute_error: 1604.5859 - val_loss: 1467.3231 - val_mean_absolute_error: 1467.3231\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 1426.22154\n",
      "Epoch 59/500\n",
      "585/585 [==============================] - 0s 78us/step - loss: 1686.6387 - mean_absolute_error: 1686.6387 - val_loss: 1433.1978 - val_mean_absolute_error: 1433.1978\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 1426.22154\n",
      "Epoch 60/500\n",
      "585/585 [==============================] - 0s 82us/step - loss: 1629.8922 - mean_absolute_error: 1629.8922 - val_loss: 1458.2259 - val_mean_absolute_error: 1458.2259\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 1426.22154\n",
      "Epoch 61/500\n",
      "585/585 [==============================] - 0s 82us/step - loss: 1613.8105 - mean_absolute_error: 1613.8105 - val_loss: 1482.2848 - val_mean_absolute_error: 1482.2848\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 1426.22154\n",
      "Epoch 62/500\n",
      "585/585 [==============================] - 0s 95us/step - loss: 1610.5942 - mean_absolute_error: 1610.5942 - val_loss: 1573.3495 - val_mean_absolute_error: 1573.3495\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 1426.22154\n",
      "Epoch 63/500\n",
      "585/585 [==============================] - ETA: 0s - loss: 1546.8342 - mean_absolute_error: 1546.834 - 0s 80us/step - loss: 1612.4989 - mean_absolute_error: 1612.4989 - val_loss: 1450.5465 - val_mean_absolute_error: 1450.5465\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 1426.22154\n",
      "Epoch 64/500\n",
      "585/585 [==============================] - 0s 84us/step - loss: 1598.5459 - mean_absolute_error: 1598.5459 - val_loss: 1496.9922 - val_mean_absolute_error: 1496.9922\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 1426.22154\n",
      "Epoch 65/500\n",
      "585/585 [==============================] - 0s 85us/step - loss: 1602.8650 - mean_absolute_error: 1602.8650 - val_loss: 1479.7838 - val_mean_absolute_error: 1479.7838\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 1426.22154\n",
      "Epoch 66/500\n",
      "585/585 [==============================] - 0s 102us/step - loss: 1595.7228 - mean_absolute_error: 1595.7228 - val_loss: 1453.4685 - val_mean_absolute_error: 1453.4685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00066: val_loss did not improve from 1426.22154\n",
      "Epoch 67/500\n",
      "585/585 [==============================] - 0s 87us/step - loss: 1573.3811 - mean_absolute_error: 1573.3811 - val_loss: 1454.2465 - val_mean_absolute_error: 1454.2465\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 1426.22154\n",
      "Epoch 68/500\n",
      "585/585 [==============================] - 0s 101us/step - loss: 1635.8877 - mean_absolute_error: 1635.8877 - val_loss: 1400.9757 - val_mean_absolute_error: 1400.9757\n",
      "\n",
      "Epoch 00068: val_loss improved from 1426.22154 to 1400.97568, saving model to 맥주date-Weights-068--1400.97568-cat02-vf05.hdf5\n",
      "Epoch 69/500\n",
      "585/585 [==============================] - 0s 92us/step - loss: 1584.6891 - mean_absolute_error: 1584.6891 - val_loss: 1398.3172 - val_mean_absolute_error: 1398.3172\n",
      "\n",
      "Epoch 00069: val_loss improved from 1400.97568 to 1398.31718, saving model to 맥주date-Weights-069--1398.31718-cat02-vf05.hdf5\n",
      "Epoch 70/500\n",
      "585/585 [==============================] - 0s 94us/step - loss: 1608.3510 - mean_absolute_error: 1608.3510 - val_loss: 1533.4877 - val_mean_absolute_error: 1533.4877\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 1398.31718\n",
      "Epoch 71/500\n",
      "585/585 [==============================] - 0s 97us/step - loss: 1581.1815 - mean_absolute_error: 1581.1815 - val_loss: 1440.0332 - val_mean_absolute_error: 1440.0332\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 1398.31718\n",
      "Epoch 72/500\n",
      "585/585 [==============================] - 0s 94us/step - loss: 1573.5381 - mean_absolute_error: 1573.5381 - val_loss: 1499.1885 - val_mean_absolute_error: 1499.1885\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 1398.31718\n",
      "Epoch 73/500\n",
      "585/585 [==============================] - 0s 101us/step - loss: 1584.3335 - mean_absolute_error: 1584.3335 - val_loss: 1569.2375 - val_mean_absolute_error: 1569.2375\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 1398.31718\n",
      "Epoch 74/500\n",
      "585/585 [==============================] - 0s 90us/step - loss: 1613.4198 - mean_absolute_error: 1613.4198 - val_loss: 1478.2504 - val_mean_absolute_error: 1478.2504\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 1398.31718\n",
      "Epoch 75/500\n",
      "585/585 [==============================] - 0s 95us/step - loss: 1602.1072 - mean_absolute_error: 1602.1072 - val_loss: 1406.8951 - val_mean_absolute_error: 1406.8951\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 1398.31718\n",
      "Epoch 76/500\n",
      "585/585 [==============================] - 0s 97us/step - loss: 1567.2942 - mean_absolute_error: 1567.2942 - val_loss: 1440.2818 - val_mean_absolute_error: 1440.2818\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 1398.31718\n",
      "Epoch 77/500\n",
      "585/585 [==============================] - 0s 82us/step - loss: 1570.1559 - mean_absolute_error: 1570.1559 - val_loss: 1455.5840 - val_mean_absolute_error: 1455.5840\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 1398.31718\n",
      "Epoch 78/500\n",
      "585/585 [==============================] - 0s 90us/step - loss: 1567.9905 - mean_absolute_error: 1567.9905 - val_loss: 1416.9773 - val_mean_absolute_error: 1416.9773\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 1398.31718\n",
      "Epoch 79/500\n",
      "585/585 [==============================] - 0s 90us/step - loss: 1555.7015 - mean_absolute_error: 1555.7015 - val_loss: 1454.8578 - val_mean_absolute_error: 1454.8578\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 1398.31718\n",
      "Epoch 80/500\n",
      "585/585 [==============================] - 0s 95us/step - loss: 1583.5571 - mean_absolute_error: 1583.5571 - val_loss: 1453.0815 - val_mean_absolute_error: 1453.0815\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 1398.31718\n",
      "Epoch 81/500\n",
      "585/585 [==============================] - 0s 92us/step - loss: 1585.8706 - mean_absolute_error: 1585.8706 - val_loss: 1438.3073 - val_mean_absolute_error: 1438.3073\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 1398.31718\n",
      "Epoch 82/500\n",
      "585/585 [==============================] - 0s 101us/step - loss: 1572.7864 - mean_absolute_error: 1572.7864 - val_loss: 1410.2456 - val_mean_absolute_error: 1410.2456\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 1398.31718\n",
      "Epoch 83/500\n",
      "585/585 [==============================] - 0s 92us/step - loss: 1548.2991 - mean_absolute_error: 1548.2991 - val_loss: 1442.3679 - val_mean_absolute_error: 1442.3679\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 1398.31718\n",
      "Epoch 84/500\n",
      "585/585 [==============================] - 0s 107us/step - loss: 1554.5762 - mean_absolute_error: 1554.5762 - val_loss: 1439.5864 - val_mean_absolute_error: 1439.5864\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 1398.31718\n",
      "Epoch 85/500\n",
      "585/585 [==============================] - 0s 92us/step - loss: 1581.4154 - mean_absolute_error: 1581.4154 - val_loss: 1449.3004 - val_mean_absolute_error: 1449.3004\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 1398.31718\n",
      "Epoch 86/500\n",
      "585/585 [==============================] - 0s 94us/step - loss: 1554.6356 - mean_absolute_error: 1554.6356 - val_loss: 1436.2975 - val_mean_absolute_error: 1436.2975\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 1398.31718\n",
      "Epoch 87/500\n",
      "585/585 [==============================] - 0s 118us/step - loss: 1551.0398 - mean_absolute_error: 1551.0398 - val_loss: 1481.0636 - val_mean_absolute_error: 1481.0636\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 1398.31718\n",
      "Epoch 88/500\n",
      "585/585 [==============================] - 0s 101us/step - loss: 1589.2919 - mean_absolute_error: 1589.2919 - val_loss: 1503.4426 - val_mean_absolute_error: 1503.4426\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 1398.31718\n",
      "Epoch 89/500\n",
      "585/585 [==============================] - 0s 119us/step - loss: 1616.4853 - mean_absolute_error: 1616.4853 - val_loss: 1704.2439 - val_mean_absolute_error: 1704.2439\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 1398.31718\n",
      "Epoch 90/500\n",
      "585/585 [==============================] - 0s 97us/step - loss: 1673.1639 - mean_absolute_error: 1673.1639 - val_loss: 1432.5366 - val_mean_absolute_error: 1432.5366\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 1398.31718\n",
      "Epoch 91/500\n",
      "585/585 [==============================] - 0s 102us/step - loss: 1581.7018 - mean_absolute_error: 1581.7018 - val_loss: 1406.1419 - val_mean_absolute_error: 1406.1419\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 1398.31718\n",
      "Epoch 92/500\n",
      "585/585 [==============================] - 0s 111us/step - loss: 1538.0524 - mean_absolute_error: 1538.0524 - val_loss: 1488.0848 - val_mean_absolute_error: 1488.0848\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 1398.31718\n",
      "Epoch 93/500\n",
      "585/585 [==============================] - 0s 95us/step - loss: 1631.5094 - mean_absolute_error: 1631.5094 - val_loss: 1385.5521 - val_mean_absolute_error: 1385.5521\n",
      "\n",
      "Epoch 00093: val_loss improved from 1398.31718 to 1385.55206, saving model to 맥주date-Weights-093--1385.55206-cat02-vf05.hdf5\n",
      "Epoch 94/500\n",
      "585/585 [==============================] - 0s 101us/step - loss: 1535.2192 - mean_absolute_error: 1535.2192 - val_loss: 1428.2298 - val_mean_absolute_error: 1428.2298\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 1385.55206\n",
      "Epoch 95/500\n",
      "585/585 [==============================] - 0s 101us/step - loss: 1574.1998 - mean_absolute_error: 1574.1998 - val_loss: 1425.3245 - val_mean_absolute_error: 1425.3245\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 1385.55206\n",
      "Epoch 96/500\n",
      "585/585 [==============================] - 0s 97us/step - loss: 1561.9741 - mean_absolute_error: 1561.9741 - val_loss: 1403.2169 - val_mean_absolute_error: 1403.2169\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 1385.55206\n",
      "Epoch 97/500\n",
      "585/585 [==============================] - 0s 99us/step - loss: 1545.9599 - mean_absolute_error: 1545.9599 - val_loss: 1516.8314 - val_mean_absolute_error: 1516.8314\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 1385.55206\n",
      "Epoch 98/500\n",
      "585/585 [==============================] - 0s 101us/step - loss: 1558.9008 - mean_absolute_error: 1558.9008 - val_loss: 1445.2809 - val_mean_absolute_error: 1445.2809\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 1385.55206\n",
      "Epoch 99/500\n",
      "585/585 [==============================] - 0s 111us/step - loss: 1530.9055 - mean_absolute_error: 1530.9055 - val_loss: 1427.0801 - val_mean_absolute_error: 1427.0801\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 1385.55206\n",
      "Epoch 100/500\n",
      "585/585 [==============================] - 0s 111us/step - loss: 1535.5169 - mean_absolute_error: 1535.5169 - val_loss: 1485.0111 - val_mean_absolute_error: 1485.0111\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 1385.55206\n",
      "Epoch 101/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "585/585 [==============================] - 0s 124us/step - loss: 1534.3285 - mean_absolute_error: 1534.3285 - val_loss: 1556.2697 - val_mean_absolute_error: 1556.2697\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 1385.55206\n",
      "Epoch 102/500\n",
      "585/585 [==============================] - 0s 94us/step - loss: 1534.0559 - mean_absolute_error: 1534.0559 - val_loss: 1395.1881 - val_mean_absolute_error: 1395.1881\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 1385.55206\n",
      "Epoch 103/500\n",
      "585/585 [==============================] - 0s 95us/step - loss: 1555.3177 - mean_absolute_error: 1555.3177 - val_loss: 1575.7112 - val_mean_absolute_error: 1575.7112\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 1385.55206\n",
      "Epoch 104/500\n",
      "585/585 [==============================] - 0s 94us/step - loss: 1564.9818 - mean_absolute_error: 1564.9818 - val_loss: 1400.0996 - val_mean_absolute_error: 1400.0996\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 1385.55206\n",
      "Epoch 105/500\n",
      "585/585 [==============================] - 0s 102us/step - loss: 1526.8206 - mean_absolute_error: 1526.8206 - val_loss: 1408.1707 - val_mean_absolute_error: 1408.1707\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 1385.55206\n",
      "Epoch 106/500\n",
      "585/585 [==============================] - 0s 116us/step - loss: 1516.3545 - mean_absolute_error: 1516.3545 - val_loss: 1444.4748 - val_mean_absolute_error: 1444.4748\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 1385.55206\n",
      "Epoch 107/500\n",
      "585/585 [==============================] - 0s 113us/step - loss: 1556.9830 - mean_absolute_error: 1556.9830 - val_loss: 1404.0007 - val_mean_absolute_error: 1404.0007\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 1385.55206\n",
      "Epoch 108/500\n",
      "585/585 [==============================] - 0s 121us/step - loss: 1528.6178 - mean_absolute_error: 1528.6178 - val_loss: 1406.9969 - val_mean_absolute_error: 1406.9969\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 1385.55206\n",
      "Epoch 109/500\n",
      "585/585 [==============================] - 0s 130us/step - loss: 1527.3883 - mean_absolute_error: 1527.3883 - val_loss: 1399.1479 - val_mean_absolute_error: 1399.1479\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 1385.55206\n",
      "Epoch 110/500\n",
      "585/585 [==============================] - 0s 111us/step - loss: 1539.3338 - mean_absolute_error: 1539.3338 - val_loss: 1554.7112 - val_mean_absolute_error: 1554.7112\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 1385.55206\n",
      "Epoch 111/500\n",
      "585/585 [==============================] - 0s 114us/step - loss: 1566.5000 - mean_absolute_error: 1566.5000 - val_loss: 1470.3526 - val_mean_absolute_error: 1470.3526\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 1385.55206\n",
      "Epoch 112/500\n",
      "585/585 [==============================] - 0s 133us/step - loss: 1537.1348 - mean_absolute_error: 1537.1348 - val_loss: 1449.1392 - val_mean_absolute_error: 1449.1392\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 1385.55206\n",
      "Epoch 113/500\n",
      "585/585 [==============================] - 0s 113us/step - loss: 1544.0528 - mean_absolute_error: 1544.0528 - val_loss: 1441.0956 - val_mean_absolute_error: 1441.0956\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 1385.55206\n",
      "Epoch 114/500\n",
      "585/585 [==============================] - 0s 116us/step - loss: 1527.3805 - mean_absolute_error: 1527.3805 - val_loss: 1592.7190 - val_mean_absolute_error: 1592.7190\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 1385.55206\n",
      "Epoch 115/500\n",
      "585/585 [==============================] - 0s 114us/step - loss: 1567.5807 - mean_absolute_error: 1567.5807 - val_loss: 1414.9337 - val_mean_absolute_error: 1414.9337\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 1385.55206\n",
      "Epoch 116/500\n",
      "585/585 [==============================] - 0s 121us/step - loss: 1666.9417 - mean_absolute_error: 1666.9417 - val_loss: 1484.5331 - val_mean_absolute_error: 1484.5331\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 1385.55206\n",
      "Epoch 117/500\n",
      "585/585 [==============================] - 0s 113us/step - loss: 1559.9736 - mean_absolute_error: 1559.9736 - val_loss: 1393.2273 - val_mean_absolute_error: 1393.2273\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 1385.55206\n",
      "Epoch 118/500\n",
      "585/585 [==============================] - 0s 106us/step - loss: 1539.5177 - mean_absolute_error: 1539.5177 - val_loss: 1657.9830 - val_mean_absolute_error: 1657.9830\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 1385.55206\n",
      "Epoch 119/500\n",
      "585/585 [==============================] - 0s 116us/step - loss: 1538.6269 - mean_absolute_error: 1538.6269 - val_loss: 1415.9787 - val_mean_absolute_error: 1415.9787\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 1385.55206\n",
      "Epoch 120/500\n",
      "585/585 [==============================] - 0s 130us/step - loss: 1516.9681 - mean_absolute_error: 1516.9681 - val_loss: 1417.5353 - val_mean_absolute_error: 1417.5353\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 1385.55206\n",
      "Epoch 121/500\n",
      "585/585 [==============================] - 0s 119us/step - loss: 1528.3312 - mean_absolute_error: 1528.3312 - val_loss: 1415.6632 - val_mean_absolute_error: 1415.6632\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 1385.55206\n",
      "Epoch 122/500\n",
      "585/585 [==============================] - 0s 118us/step - loss: 1531.5195 - mean_absolute_error: 1531.5195 - val_loss: 1400.5137 - val_mean_absolute_error: 1400.5137\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 1385.55206\n",
      "Epoch 123/500\n",
      "585/585 [==============================] - 0s 131us/step - loss: 1505.5771 - mean_absolute_error: 1505.5771 - val_loss: 1415.4009 - val_mean_absolute_error: 1415.4009\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 1385.55206\n",
      "Epoch 124/500\n",
      "585/585 [==============================] - 0s 119us/step - loss: 1562.8020 - mean_absolute_error: 1562.8020 - val_loss: 1576.4582 - val_mean_absolute_error: 1576.4582\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 1385.55206\n",
      "Epoch 125/500\n",
      "585/585 [==============================] - 0s 142us/step - loss: 1607.2754 - mean_absolute_error: 1607.2754 - val_loss: 1393.5045 - val_mean_absolute_error: 1393.5045\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 1385.55206\n",
      "Epoch 126/500\n",
      "585/585 [==============================] - 0s 119us/step - loss: 1548.7547 - mean_absolute_error: 1548.7547 - val_loss: 1428.4075 - val_mean_absolute_error: 1428.4075\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 1385.55206\n",
      "Epoch 127/500\n",
      "585/585 [==============================] - 0s 106us/step - loss: 1492.7309 - mean_absolute_error: 1492.7309 - val_loss: 1466.2618 - val_mean_absolute_error: 1466.2618\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 1385.55206\n",
      "Epoch 128/500\n",
      "585/585 [==============================] - 0s 109us/step - loss: 1535.9179 - mean_absolute_error: 1535.9179 - val_loss: 1398.7396 - val_mean_absolute_error: 1398.7396\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 1385.55206\n",
      "Epoch 129/500\n",
      "585/585 [==============================] - 0s 114us/step - loss: 1560.8144 - mean_absolute_error: 1560.8144 - val_loss: 1414.7416 - val_mean_absolute_error: 1414.7416\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 1385.55206\n",
      "Epoch 130/500\n",
      "585/585 [==============================] - 0s 119us/step - loss: 1499.4387 - mean_absolute_error: 1499.4387 - val_loss: 1490.2496 - val_mean_absolute_error: 1490.2496\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 1385.55206\n",
      "Epoch 131/500\n",
      "585/585 [==============================] - 0s 113us/step - loss: 1522.4925 - mean_absolute_error: 1522.4925 - val_loss: 1386.5498 - val_mean_absolute_error: 1386.5498\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 1385.55206\n",
      "Epoch 132/500\n",
      "585/585 [==============================] - 0s 133us/step - loss: 1494.4611 - mean_absolute_error: 1494.4611 - val_loss: 1504.4361 - val_mean_absolute_error: 1504.4361\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 1385.55206\n",
      "Epoch 133/500\n",
      "585/585 [==============================] - 0s 111us/step - loss: 1563.1793 - mean_absolute_error: 1563.1793 - val_loss: 1411.8644 - val_mean_absolute_error: 1411.8644\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 1385.55206\n",
      "Epoch 134/500\n",
      "585/585 [==============================] - 0s 107us/step - loss: 1565.2246 - mean_absolute_error: 1565.2246 - val_loss: 1388.6967 - val_mean_absolute_error: 1388.6967\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 1385.55206\n",
      "Epoch 135/500\n",
      "585/585 [==============================] - 0s 109us/step - loss: 1545.0928 - mean_absolute_error: 1545.0928 - val_loss: 1540.2145 - val_mean_absolute_error: 1540.2145\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 1385.55206\n",
      "Epoch 136/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "585/585 [==============================] - 0s 130us/step - loss: 1540.8972 - mean_absolute_error: 1540.8972 - val_loss: 1458.0963 - val_mean_absolute_error: 1458.0963\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 1385.55206\n",
      "Epoch 137/500\n",
      "585/585 [==============================] - 0s 131us/step - loss: 1566.6165 - mean_absolute_error: 1566.6165 - val_loss: 1400.4946 - val_mean_absolute_error: 1400.4946\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 1385.55206\n",
      "Epoch 138/500\n",
      "585/585 [==============================] - 0s 118us/step - loss: 1602.1645 - mean_absolute_error: 1602.1645 - val_loss: 1522.3356 - val_mean_absolute_error: 1522.3356\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 1385.55206\n",
      "Epoch 139/500\n",
      "585/585 [==============================] - 0s 124us/step - loss: 1568.1299 - mean_absolute_error: 1568.1299 - val_loss: 1421.0281 - val_mean_absolute_error: 1421.0281\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 1385.55206\n",
      "Epoch 140/500\n",
      "585/585 [==============================] - 0s 121us/step - loss: 1500.2373 - mean_absolute_error: 1500.2373 - val_loss: 1413.8583 - val_mean_absolute_error: 1413.8583\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 1385.55206\n",
      "Epoch 141/500\n",
      "585/585 [==============================] - 0s 121us/step - loss: 1490.1960 - mean_absolute_error: 1490.1960 - val_loss: 1411.5570 - val_mean_absolute_error: 1411.5570\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 1385.55206\n",
      "Epoch 142/500\n",
      "585/585 [==============================] - 0s 130us/step - loss: 1553.3873 - mean_absolute_error: 1553.3873 - val_loss: 1404.1233 - val_mean_absolute_error: 1404.1233\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 1385.55206\n",
      "Epoch 143/500\n",
      "585/585 [==============================] - 0s 124us/step - loss: 1528.1440 - mean_absolute_error: 1528.1440 - val_loss: 1491.9760 - val_mean_absolute_error: 1491.9760\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 1385.55206\n",
      "Epoch 144/500\n",
      "585/585 [==============================] - 0s 123us/step - loss: 1491.3170 - mean_absolute_error: 1491.3170 - val_loss: 1431.9734 - val_mean_absolute_error: 1431.9734\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 1385.55206\n",
      "Epoch 145/500\n",
      "585/585 [==============================] - 0s 135us/step - loss: 1536.2740 - mean_absolute_error: 1536.2740 - val_loss: 1403.9396 - val_mean_absolute_error: 1403.9396\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 1385.55206\n",
      "Epoch 146/500\n",
      "585/585 [==============================] - 0s 135us/step - loss: 1560.3887 - mean_absolute_error: 1560.3887 - val_loss: 1676.7944 - val_mean_absolute_error: 1676.7944\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 1385.55206\n",
      "Epoch 147/500\n",
      "585/585 [==============================] - 0s 116us/step - loss: 1513.5334 - mean_absolute_error: 1513.5334 - val_loss: 1446.4074 - val_mean_absolute_error: 1446.4074\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 1385.55206\n",
      "Epoch 148/500\n",
      "585/585 [==============================] - 0s 138us/step - loss: 1488.5836 - mean_absolute_error: 1488.5836 - val_loss: 1451.1924 - val_mean_absolute_error: 1451.1924\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 1385.55206\n",
      "Epoch 149/500\n",
      "585/585 [==============================] - 0s 135us/step - loss: 1526.5611 - mean_absolute_error: 1526.5611 - val_loss: 1433.2938 - val_mean_absolute_error: 1433.2938\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 1385.55206\n",
      "Epoch 150/500\n",
      "585/585 [==============================] - 0s 130us/step - loss: 1541.4946 - mean_absolute_error: 1541.4946 - val_loss: 1420.6568 - val_mean_absolute_error: 1420.6568\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 1385.55206\n",
      "Epoch 151/500\n",
      "585/585 [==============================] - 0s 119us/step - loss: 1500.9873 - mean_absolute_error: 1500.9873 - val_loss: 1420.4687 - val_mean_absolute_error: 1420.4687\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 1385.55206\n",
      "Epoch 152/500\n",
      "585/585 [==============================] - 0s 123us/step - loss: 1486.9466 - mean_absolute_error: 1486.9466 - val_loss: 1429.0866 - val_mean_absolute_error: 1429.0866\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 1385.55206\n",
      "Epoch 153/500\n",
      "585/585 [==============================] - 0s 111us/step - loss: 1485.5029 - mean_absolute_error: 1485.5029 - val_loss: 1484.9303 - val_mean_absolute_error: 1484.9303\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 1385.55206\n",
      "Epoch 154/500\n",
      "585/585 [==============================] - 0s 121us/step - loss: 1497.4735 - mean_absolute_error: 1497.4735 - val_loss: 1402.8880 - val_mean_absolute_error: 1402.8880\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 1385.55206\n",
      "Epoch 155/500\n",
      "585/585 [==============================] - 0s 119us/step - loss: 1483.5133 - mean_absolute_error: 1483.5133 - val_loss: 1381.3278 - val_mean_absolute_error: 1381.3278\n",
      "\n",
      "Epoch 00155: val_loss improved from 1385.55206 to 1381.32784, saving model to 맥주date-Weights-155--1381.32784-cat02-vf05.hdf5\n",
      "Epoch 156/500\n",
      "585/585 [==============================] - 0s 114us/step - loss: 1473.7828 - mean_absolute_error: 1473.7828 - val_loss: 1401.2764 - val_mean_absolute_error: 1401.2764\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 1381.32784\n",
      "Epoch 157/500\n",
      "585/585 [==============================] - 0s 123us/step - loss: 1512.9112 - mean_absolute_error: 1512.9112 - val_loss: 1395.2744 - val_mean_absolute_error: 1395.2744\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 1381.32784\n",
      "Epoch 158/500\n",
      "585/585 [==============================] - 0s 118us/step - loss: 1482.6083 - mean_absolute_error: 1482.6083 - val_loss: 1372.4986 - val_mean_absolute_error: 1372.4986\n",
      "\n",
      "Epoch 00158: val_loss improved from 1381.32784 to 1372.49859, saving model to 맥주date-Weights-158--1372.49859-cat02-vf05.hdf5\n",
      "Epoch 159/500\n",
      "585/585 [==============================] - 0s 111us/step - loss: 1474.2332 - mean_absolute_error: 1474.2332 - val_loss: 1414.9247 - val_mean_absolute_error: 1414.9247\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 1372.49859\n",
      "Epoch 160/500\n",
      "585/585 [==============================] - 0s 119us/step - loss: 1500.2417 - mean_absolute_error: 1500.2417 - val_loss: 1479.0001 - val_mean_absolute_error: 1479.0001\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 1372.49859\n",
      "Epoch 161/500\n",
      "585/585 [==============================] - 0s 128us/step - loss: 1475.3409 - mean_absolute_error: 1475.3409 - val_loss: 1396.2788 - val_mean_absolute_error: 1396.2788\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 1372.49859\n",
      "Epoch 162/500\n",
      "585/585 [==============================] - 0s 111us/step - loss: 1513.1124 - mean_absolute_error: 1513.1124 - val_loss: 1561.3792 - val_mean_absolute_error: 1561.3792\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 1372.49859\n",
      "Epoch 163/500\n",
      "585/585 [==============================] - 0s 113us/step - loss: 1506.8500 - mean_absolute_error: 1506.8500 - val_loss: 1596.1666 - val_mean_absolute_error: 1596.1666\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 1372.49859\n",
      "Epoch 164/500\n",
      "585/585 [==============================] - 0s 109us/step - loss: 1521.7297 - mean_absolute_error: 1521.7297 - val_loss: 1465.5129 - val_mean_absolute_error: 1465.5129\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 1372.49859\n",
      "Epoch 165/500\n",
      "585/585 [==============================] - 0s 107us/step - loss: 1475.4705 - mean_absolute_error: 1475.4705 - val_loss: 1434.4719 - val_mean_absolute_error: 1434.4719\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 1372.49859\n",
      "Epoch 166/500\n",
      "585/585 [==============================] - 0s 106us/step - loss: 1467.0984 - mean_absolute_error: 1467.0984 - val_loss: 1453.9049 - val_mean_absolute_error: 1453.9049\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 1372.49859\n",
      "Epoch 167/500\n",
      "585/585 [==============================] - 0s 101us/step - loss: 1526.6829 - mean_absolute_error: 1526.6829 - val_loss: 1422.8355 - val_mean_absolute_error: 1422.8355\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 1372.49859\n",
      "Epoch 168/500\n",
      "585/585 [==============================] - 0s 124us/step - loss: 1679.7233 - mean_absolute_error: 1679.7233 - val_loss: 1371.4067 - val_mean_absolute_error: 1371.4067\n",
      "\n",
      "Epoch 00168: val_loss improved from 1372.49859 to 1371.40668, saving model to 맥주date-Weights-168--1371.40668-cat02-vf05.hdf5\n",
      "Epoch 169/500\n",
      "585/585 [==============================] - 0s 116us/step - loss: 1497.5780 - mean_absolute_error: 1497.5780 - val_loss: 1449.0963 - val_mean_absolute_error: 1449.0963\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 1371.40668\n",
      "Epoch 170/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "585/585 [==============================] - 0s 116us/step - loss: 1464.9288 - mean_absolute_error: 1464.9288 - val_loss: 1387.7712 - val_mean_absolute_error: 1387.7712\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 1371.40668\n",
      "Epoch 171/500\n",
      "585/585 [==============================] - 0s 109us/step - loss: 1501.2234 - mean_absolute_error: 1501.2234 - val_loss: 1379.2324 - val_mean_absolute_error: 1379.2324\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 1371.40668\n",
      "Epoch 172/500\n",
      "585/585 [==============================] - 0s 107us/step - loss: 1506.3907 - mean_absolute_error: 1506.3907 - val_loss: 1533.2484 - val_mean_absolute_error: 1533.2484\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 1371.40668\n",
      "Epoch 173/500\n",
      "585/585 [==============================] - 0s 130us/step - loss: 1505.9339 - mean_absolute_error: 1505.9339 - val_loss: 1623.7842 - val_mean_absolute_error: 1623.7842\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 1371.40668\n",
      "Epoch 174/500\n",
      "585/585 [==============================] - 0s 136us/step - loss: 1512.7193 - mean_absolute_error: 1512.7193 - val_loss: 1405.9920 - val_mean_absolute_error: 1405.9920\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 1371.40668\n",
      "Epoch 175/500\n",
      "585/585 [==============================] - 0s 142us/step - loss: 1491.3628 - mean_absolute_error: 1491.3628 - val_loss: 1421.0028 - val_mean_absolute_error: 1421.0028\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 1371.40668\n",
      "Epoch 176/500\n",
      "585/585 [==============================] - 0s 118us/step - loss: 1505.9463 - mean_absolute_error: 1505.9463 - val_loss: 1480.7194 - val_mean_absolute_error: 1480.7194\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 1371.40668\n",
      "Epoch 177/500\n",
      "585/585 [==============================] - 0s 126us/step - loss: 1510.5190 - mean_absolute_error: 1510.5190 - val_loss: 1406.5374 - val_mean_absolute_error: 1406.5374\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 1371.40668\n",
      "Epoch 178/500\n",
      "585/585 [==============================] - 0s 119us/step - loss: 1507.0805 - mean_absolute_error: 1507.0805 - val_loss: 1429.5848 - val_mean_absolute_error: 1429.5848\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 1371.40668\n",
      "Epoch 179/500\n",
      "585/585 [==============================] - 0s 124us/step - loss: 1528.9545 - mean_absolute_error: 1528.9545 - val_loss: 1684.7454 - val_mean_absolute_error: 1684.7454\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 1371.40668\n",
      "Epoch 180/500\n",
      "585/585 [==============================] - 0s 140us/step - loss: 1508.2549 - mean_absolute_error: 1508.2549 - val_loss: 1470.2247 - val_mean_absolute_error: 1470.2247\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 1371.40668\n",
      "Epoch 181/500\n",
      "585/585 [==============================] - 0s 135us/step - loss: 1487.4562 - mean_absolute_error: 1487.4562 - val_loss: 1406.5746 - val_mean_absolute_error: 1406.5746\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 1371.40668\n",
      "Epoch 182/500\n",
      "585/585 [==============================] - 0s 135us/step - loss: 1479.3440 - mean_absolute_error: 1479.3440 - val_loss: 1406.7725 - val_mean_absolute_error: 1406.7725\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 1371.40668\n",
      "Epoch 183/500\n",
      "585/585 [==============================] - 0s 126us/step - loss: 1471.6343 - mean_absolute_error: 1471.6343 - val_loss: 1446.9071 - val_mean_absolute_error: 1446.9071\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 1371.40668\n",
      "Epoch 184/500\n",
      "585/585 [==============================] - 0s 136us/step - loss: 1521.4936 - mean_absolute_error: 1521.4936 - val_loss: 1392.8808 - val_mean_absolute_error: 1392.8808\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 1371.40668\n",
      "Epoch 185/500\n",
      "585/585 [==============================] - 0s 145us/step - loss: 1531.3487 - mean_absolute_error: 1531.3487 - val_loss: 1450.5989 - val_mean_absolute_error: 1450.5989\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 1371.40668\n",
      "Epoch 186/500\n",
      "585/585 [==============================] - 0s 145us/step - loss: 1474.2407 - mean_absolute_error: 1474.2407 - val_loss: 1396.0090 - val_mean_absolute_error: 1396.0090\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 1371.40668\n",
      "Epoch 187/500\n",
      "585/585 [==============================] - 0s 131us/step - loss: 1474.7133 - mean_absolute_error: 1474.7133 - val_loss: 1372.0199 - val_mean_absolute_error: 1372.0199\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 1371.40668\n",
      "Epoch 188/500\n",
      "585/585 [==============================] - 0s 140us/step - loss: 1488.0853 - mean_absolute_error: 1488.0853 - val_loss: 1431.4821 - val_mean_absolute_error: 1431.4821\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 1371.40668\n",
      "Epoch 189/500\n",
      "585/585 [==============================] - 0s 136us/step - loss: 1473.0110 - mean_absolute_error: 1473.0110 - val_loss: 1459.9521 - val_mean_absolute_error: 1459.9521\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 1371.40668\n",
      "Epoch 190/500\n",
      "585/585 [==============================] - 0s 138us/step - loss: 1497.7183 - mean_absolute_error: 1497.7183 - val_loss: 1372.3038 - val_mean_absolute_error: 1372.3038\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 1371.40668\n",
      "Epoch 191/500\n",
      "585/585 [==============================] - 0s 133us/step - loss: 1480.5416 - mean_absolute_error: 1480.5416 - val_loss: 1401.3129 - val_mean_absolute_error: 1401.3129\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 1371.40668\n",
      "Epoch 192/500\n",
      "585/585 [==============================] - 0s 136us/step - loss: 1478.8858 - mean_absolute_error: 1478.8858 - val_loss: 1395.2780 - val_mean_absolute_error: 1395.2780\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 1371.40668\n",
      "Epoch 193/500\n",
      "585/585 [==============================] - 0s 138us/step - loss: 1469.0005 - mean_absolute_error: 1469.0005 - val_loss: 1447.4110 - val_mean_absolute_error: 1447.4110\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 1371.40668\n",
      "Epoch 194/500\n",
      "585/585 [==============================] - 0s 131us/step - loss: 1463.3382 - mean_absolute_error: 1463.3382 - val_loss: 1476.6057 - val_mean_absolute_error: 1476.6057\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 1371.40668\n",
      "Epoch 195/500\n",
      "585/585 [==============================] - 0s 135us/step - loss: 1527.2535 - mean_absolute_error: 1527.2535 - val_loss: 1401.6468 - val_mean_absolute_error: 1401.6468\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 1371.40668\n",
      "Epoch 196/500\n",
      "585/585 [==============================] - 0s 123us/step - loss: 1499.8115 - mean_absolute_error: 1499.8115 - val_loss: 1390.6854 - val_mean_absolute_error: 1390.6854\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 1371.40668\n",
      "Epoch 197/500\n",
      "585/585 [==============================] - 0s 111us/step - loss: 1521.6160 - mean_absolute_error: 1521.6160 - val_loss: 1512.6789 - val_mean_absolute_error: 1512.6789\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 1371.40668\n",
      "Epoch 198/500\n",
      "585/585 [==============================] - 0s 123us/step - loss: 1505.3055 - mean_absolute_error: 1505.3055 - val_loss: 1381.6742 - val_mean_absolute_error: 1381.6742\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 1371.40668\n",
      "Epoch 199/500\n",
      "585/585 [==============================] - 0s 124us/step - loss: 1500.5287 - mean_absolute_error: 1500.5287 - val_loss: 1407.8157 - val_mean_absolute_error: 1407.8157\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 1371.40668\n",
      "Epoch 200/500\n",
      "585/585 [==============================] - 0s 135us/step - loss: 1543.6611 - mean_absolute_error: 1543.6611 - val_loss: 1495.1154 - val_mean_absolute_error: 1495.1154\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 1371.40668\n",
      "Epoch 201/500\n",
      "585/585 [==============================] - 0s 133us/step - loss: 1548.1216 - mean_absolute_error: 1548.1216 - val_loss: 1440.0607 - val_mean_absolute_error: 1440.0607\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 1371.40668\n",
      "Epoch 202/500\n",
      "585/585 [==============================] - 0s 147us/step - loss: 1485.8070 - mean_absolute_error: 1485.8070 - val_loss: 1380.6116 - val_mean_absolute_error: 1380.6116\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 1371.40668\n",
      "Epoch 203/500\n",
      "585/585 [==============================] - 0s 133us/step - loss: 1458.9282 - mean_absolute_error: 1458.9282 - val_loss: 1386.3215 - val_mean_absolute_error: 1386.3215\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 1371.40668\n",
      "Epoch 204/500\n",
      "585/585 [==============================] - 0s 130us/step - loss: 1481.1787 - mean_absolute_error: 1481.1787 - val_loss: 1375.6413 - val_mean_absolute_error: 1375.6413\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 1371.40668\n",
      "Epoch 205/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "585/585 [==============================] - 0s 147us/step - loss: 1464.2185 - mean_absolute_error: 1464.2185 - val_loss: 1546.2513 - val_mean_absolute_error: 1546.2513\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 1371.40668\n",
      "Epoch 206/500\n",
      "585/585 [==============================] - 0s 123us/step - loss: 1455.6775 - mean_absolute_error: 1455.6775 - val_loss: 1488.9243 - val_mean_absolute_error: 1488.9243\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 1371.40668\n",
      "Epoch 207/500\n",
      "585/585 [==============================] - 0s 142us/step - loss: 1466.4609 - mean_absolute_error: 1466.4609 - val_loss: 1392.8842 - val_mean_absolute_error: 1392.8842\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 1371.40668\n",
      "Epoch 208/500\n",
      "585/585 [==============================] - 0s 147us/step - loss: 1477.5273 - mean_absolute_error: 1477.5273 - val_loss: 1506.4635 - val_mean_absolute_error: 1506.4635\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 1371.40668\n",
      "Epoch 209/500\n",
      "585/585 [==============================] - 0s 162us/step - loss: 1518.9448 - mean_absolute_error: 1518.9448 - val_loss: 1426.2263 - val_mean_absolute_error: 1426.2263\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 1371.40668\n",
      "Epoch 210/500\n",
      "585/585 [==============================] - 0s 140us/step - loss: 1479.7396 - mean_absolute_error: 1479.7396 - val_loss: 1386.4417 - val_mean_absolute_error: 1386.4417\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 1371.40668\n",
      "Epoch 211/500\n",
      "585/585 [==============================] - 0s 147us/step - loss: 1459.4399 - mean_absolute_error: 1459.4399 - val_loss: 1457.2888 - val_mean_absolute_error: 1457.2888\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 1371.40668\n",
      "Epoch 212/500\n",
      "585/585 [==============================] - 0s 133us/step - loss: 1463.4599 - mean_absolute_error: 1463.4599 - val_loss: 1410.9999 - val_mean_absolute_error: 1410.9999\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 1371.40668\n",
      "Epoch 213/500\n",
      "585/585 [==============================] - 0s 147us/step - loss: 1499.7480 - mean_absolute_error: 1499.7480 - val_loss: 1407.8765 - val_mean_absolute_error: 1407.8765\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 1371.40668\n",
      "Epoch 214/500\n",
      "585/585 [==============================] - 0s 142us/step - loss: 1473.7177 - mean_absolute_error: 1473.7177 - val_loss: 1407.7772 - val_mean_absolute_error: 1407.7772\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 1371.40668\n",
      "Epoch 215/500\n",
      "585/585 [==============================] - 0s 140us/step - loss: 1459.8063 - mean_absolute_error: 1459.8063 - val_loss: 1477.2277 - val_mean_absolute_error: 1477.2277\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 1371.40668\n",
      "Epoch 216/500\n",
      "585/585 [==============================] - 0s 131us/step - loss: 1473.7992 - mean_absolute_error: 1473.7992 - val_loss: 1411.4720 - val_mean_absolute_error: 1411.4720\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 1371.40668\n",
      "Epoch 217/500\n",
      "585/585 [==============================] - 0s 145us/step - loss: 1460.5442 - mean_absolute_error: 1460.5442 - val_loss: 1400.2264 - val_mean_absolute_error: 1400.2264\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 1371.40668\n",
      "Epoch 218/500\n",
      "585/585 [==============================] - 0s 126us/step - loss: 1507.4598 - mean_absolute_error: 1507.4598 - val_loss: 1417.0579 - val_mean_absolute_error: 1417.0579\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 1371.40668\n",
      "Epoch 219/500\n",
      "585/585 [==============================] - 0s 142us/step - loss: 1464.1553 - mean_absolute_error: 1464.1553 - val_loss: 1422.4161 - val_mean_absolute_error: 1422.4161\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 1371.40668\n",
      "Epoch 220/500\n",
      "585/585 [==============================] - 0s 148us/step - loss: 1478.6884 - mean_absolute_error: 1478.6884 - val_loss: 1442.6386 - val_mean_absolute_error: 1442.6386\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 1371.40668\n",
      "Epoch 221/500\n",
      "585/585 [==============================] - 0s 133us/step - loss: 1476.8519 - mean_absolute_error: 1476.8519 - val_loss: 1371.4861 - val_mean_absolute_error: 1371.4861\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 1371.40668\n",
      "Epoch 222/500\n",
      "585/585 [==============================] - 0s 143us/step - loss: 1457.3938 - mean_absolute_error: 1457.3938 - val_loss: 1466.8361 - val_mean_absolute_error: 1466.8361\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 1371.40668\n",
      "Epoch 223/500\n",
      "585/585 [==============================] - 0s 143us/step - loss: 1471.3299 - mean_absolute_error: 1471.3299 - val_loss: 1534.7272 - val_mean_absolute_error: 1534.7272\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 1371.40668\n",
      "Epoch 224/500\n",
      "585/585 [==============================] - 0s 135us/step - loss: 1487.3765 - mean_absolute_error: 1487.3765 - val_loss: 1419.7847 - val_mean_absolute_error: 1419.7847\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 1371.40668\n",
      "Epoch 225/500\n",
      "585/585 [==============================] - 0s 142us/step - loss: 1459.8972 - mean_absolute_error: 1459.8972 - val_loss: 1406.2971 - val_mean_absolute_error: 1406.2971\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 1371.40668\n",
      "Epoch 226/500\n",
      "585/585 [==============================] - 0s 142us/step - loss: 1459.8671 - mean_absolute_error: 1459.8671 - val_loss: 1520.7880 - val_mean_absolute_error: 1520.7880\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 1371.40668\n",
      "Epoch 227/500\n",
      "585/585 [==============================] - 0s 140us/step - loss: 1480.2898 - mean_absolute_error: 1480.2898 - val_loss: 1452.3812 - val_mean_absolute_error: 1452.3812\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 1371.40668\n",
      "Epoch 228/500\n",
      "585/585 [==============================] - 0s 131us/step - loss: 1457.4388 - mean_absolute_error: 1457.4388 - val_loss: 1454.0836 - val_mean_absolute_error: 1454.0836\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 1371.40668\n",
      "Epoch 229/500\n",
      "585/585 [==============================] - 0s 147us/step - loss: 1475.9526 - mean_absolute_error: 1475.9526 - val_loss: 1407.9623 - val_mean_absolute_error: 1407.9623\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 1371.40668\n",
      "Epoch 230/500\n",
      "585/585 [==============================] - 0s 133us/step - loss: 1478.9741 - mean_absolute_error: 1478.9741 - val_loss: 1609.9620 - val_mean_absolute_error: 1609.9620\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 1371.40668\n",
      "Epoch 231/500\n",
      "585/585 [==============================] - 0s 124us/step - loss: 1539.0392 - mean_absolute_error: 1539.0392 - val_loss: 1814.3893 - val_mean_absolute_error: 1814.3893\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 1371.40668\n",
      "Epoch 232/500\n",
      "585/585 [==============================] - 0s 145us/step - loss: 1594.0038 - mean_absolute_error: 1594.0038 - val_loss: 1594.3857 - val_mean_absolute_error: 1594.3857\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 1371.40668\n",
      "Epoch 233/500\n",
      "585/585 [==============================] - 0s 126us/step - loss: 1476.1454 - mean_absolute_error: 1476.1454 - val_loss: 1386.5839 - val_mean_absolute_error: 1386.5839\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 1371.40668\n",
      "Epoch 234/500\n",
      "585/585 [==============================] - 0s 143us/step - loss: 1525.5217 - mean_absolute_error: 1525.5217 - val_loss: 1426.8790 - val_mean_absolute_error: 1426.8790\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 1371.40668\n",
      "Epoch 235/500\n",
      "585/585 [==============================] - 0s 124us/step - loss: 1481.4940 - mean_absolute_error: 1481.4940 - val_loss: 1428.4400 - val_mean_absolute_error: 1428.4400\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 1371.40668\n",
      "Epoch 236/500\n",
      "585/585 [==============================] - 0s 147us/step - loss: 1454.6029 - mean_absolute_error: 1454.6029 - val_loss: 1467.4967 - val_mean_absolute_error: 1467.4967\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 1371.40668\n",
      "Epoch 237/500\n",
      "585/585 [==============================] - 0s 124us/step - loss: 1443.2709 - mean_absolute_error: 1443.2709 - val_loss: 1425.2047 - val_mean_absolute_error: 1425.2047\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 1371.40668\n",
      "Epoch 238/500\n",
      "585/585 [==============================] - 0s 138us/step - loss: 1472.0351 - mean_absolute_error: 1472.0351 - val_loss: 1380.8801 - val_mean_absolute_error: 1380.8801\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 1371.40668\n",
      "Epoch 239/500\n",
      "585/585 [==============================] - 0s 133us/step - loss: 1478.2799 - mean_absolute_error: 1478.2799 - val_loss: 1407.6582 - val_mean_absolute_error: 1407.6582\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 1371.40668\n",
      "Epoch 240/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "585/585 [==============================] - 0s 133us/step - loss: 1479.8301 - mean_absolute_error: 1479.8301 - val_loss: 1389.1696 - val_mean_absolute_error: 1389.1696\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 1371.40668\n",
      "Epoch 241/500\n",
      "585/585 [==============================] - 0s 128us/step - loss: 1499.6077 - mean_absolute_error: 1499.6077 - val_loss: 1389.1775 - val_mean_absolute_error: 1389.1775\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 1371.40668\n",
      "Epoch 242/500\n",
      "585/585 [==============================] - 0s 130us/step - loss: 1455.4799 - mean_absolute_error: 1455.4799 - val_loss: 1416.2581 - val_mean_absolute_error: 1416.2581\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 1371.40668\n",
      "Epoch 243/500\n",
      "585/585 [==============================] - 0s 142us/step - loss: 1461.9749 - mean_absolute_error: 1461.9749 - val_loss: 1394.0233 - val_mean_absolute_error: 1394.0233\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 1371.40668\n",
      "Epoch 244/500\n",
      "585/585 [==============================] - 0s 133us/step - loss: 1463.2158 - mean_absolute_error: 1463.2158 - val_loss: 1398.4754 - val_mean_absolute_error: 1398.4754\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 1371.40668\n",
      "Epoch 245/500\n",
      "585/585 [==============================] - 0s 143us/step - loss: 1467.7144 - mean_absolute_error: 1467.7144 - val_loss: 1693.2279 - val_mean_absolute_error: 1693.2279\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 1371.40668\n",
      "Epoch 246/500\n",
      "585/585 [==============================] - 0s 140us/step - loss: 1504.4561 - mean_absolute_error: 1504.4561 - val_loss: 1458.6163 - val_mean_absolute_error: 1458.6163\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 1371.40668\n",
      "Epoch 247/500\n",
      "585/585 [==============================] - 0s 133us/step - loss: 1449.6473 - mean_absolute_error: 1449.6473 - val_loss: 1462.3439 - val_mean_absolute_error: 1462.3439\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 1371.40668\n",
      "Epoch 248/500\n",
      "585/585 [==============================] - 0s 131us/step - loss: 1459.3345 - mean_absolute_error: 1459.3345 - val_loss: 1474.0587 - val_mean_absolute_error: 1474.0587\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 1371.40668\n",
      "Epoch 249/500\n",
      "585/585 [==============================] - 0s 140us/step - loss: 1471.5659 - mean_absolute_error: 1471.5659 - val_loss: 1414.0974 - val_mean_absolute_error: 1414.0974\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 1371.40668\n",
      "Epoch 250/500\n",
      "585/585 [==============================] - 0s 140us/step - loss: 1497.4762 - mean_absolute_error: 1497.4762 - val_loss: 1389.2186 - val_mean_absolute_error: 1389.2186\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 1371.40668\n",
      "Epoch 251/500\n",
      "585/585 [==============================] - 0s 145us/step - loss: 1445.4120 - mean_absolute_error: 1445.4120 - val_loss: 1419.6382 - val_mean_absolute_error: 1419.6382\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 1371.40668\n",
      "Epoch 252/500\n",
      "585/585 [==============================] - 0s 131us/step - loss: 1457.2325 - mean_absolute_error: 1457.2325 - val_loss: 1478.2332 - val_mean_absolute_error: 1478.2332\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 1371.40668\n",
      "Epoch 253/500\n",
      "585/585 [==============================] - 0s 142us/step - loss: 1456.5365 - mean_absolute_error: 1456.5365 - val_loss: 1428.9499 - val_mean_absolute_error: 1428.9499\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 1371.40668\n",
      "Epoch 254/500\n",
      "585/585 [==============================] - 0s 131us/step - loss: 1444.5809 - mean_absolute_error: 1444.5809 - val_loss: 1393.7534 - val_mean_absolute_error: 1393.7534\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 1371.40668\n",
      "Epoch 255/500\n",
      "585/585 [==============================] - 0s 147us/step - loss: 1492.0423 - mean_absolute_error: 1492.0423 - val_loss: 1414.4919 - val_mean_absolute_error: 1414.4919\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 1371.40668\n",
      "Epoch 256/500\n",
      "585/585 [==============================] - 0s 138us/step - loss: 1529.6004 - mean_absolute_error: 1529.6004 - val_loss: 1601.4428 - val_mean_absolute_error: 1601.4428\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 1371.40668\n",
      "Epoch 257/500\n",
      "585/585 [==============================] - 0s 135us/step - loss: 1491.3712 - mean_absolute_error: 1491.3712 - val_loss: 1383.8798 - val_mean_absolute_error: 1383.8798\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 1371.40668\n",
      "Epoch 258/500\n",
      "585/585 [==============================] - 0s 147us/step - loss: 1460.6251 - mean_absolute_error: 1460.6251 - val_loss: 1390.7371 - val_mean_absolute_error: 1390.7371\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 1371.40668\n",
      "Epoch 259/500\n",
      "585/585 [==============================] - 0s 152us/step - loss: 1468.2585 - mean_absolute_error: 1468.2585 - val_loss: 1401.2434 - val_mean_absolute_error: 1401.2434\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 1371.40668\n",
      "Epoch 260/500\n",
      "585/585 [==============================] - 0s 142us/step - loss: 1485.9215 - mean_absolute_error: 1485.9215 - val_loss: 1389.9701 - val_mean_absolute_error: 1389.9701\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 1371.40668\n",
      "Epoch 261/500\n",
      "585/585 [==============================] - 0s 140us/step - loss: 1453.1291 - mean_absolute_error: 1453.1291 - val_loss: 1413.4766 - val_mean_absolute_error: 1413.4766\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 1371.40668\n",
      "Epoch 262/500\n",
      "585/585 [==============================] - 0s 136us/step - loss: 1465.6659 - mean_absolute_error: 1465.6659 - val_loss: 1565.4390 - val_mean_absolute_error: 1565.4390\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 1371.40668\n",
      "Epoch 263/500\n",
      "585/585 [==============================] - 0s 150us/step - loss: 1515.6271 - mean_absolute_error: 1515.6271 - val_loss: 1404.2893 - val_mean_absolute_error: 1404.2893\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 1371.40668\n",
      "Epoch 264/500\n",
      "585/585 [==============================] - 0s 150us/step - loss: 1484.9346 - mean_absolute_error: 1484.9346 - val_loss: 1430.1015 - val_mean_absolute_error: 1430.1015\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 1371.40668\n",
      "Epoch 265/500\n",
      "585/585 [==============================] - 0s 136us/step - loss: 1450.4443 - mean_absolute_error: 1450.4443 - val_loss: 1434.2021 - val_mean_absolute_error: 1434.2021\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 1371.40668\n",
      "Epoch 266/500\n",
      "585/585 [==============================] - 0s 131us/step - loss: 1476.0008 - mean_absolute_error: 1476.0008 - val_loss: 1404.8763 - val_mean_absolute_error: 1404.8763\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 1371.40668\n",
      "Epoch 267/500\n",
      "585/585 [==============================] - 0s 135us/step - loss: 1468.1395 - mean_absolute_error: 1468.1395 - val_loss: 1452.2115 - val_mean_absolute_error: 1452.2115\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 1371.40668\n",
      "Epoch 268/500\n",
      "585/585 [==============================] - 0s 152us/step - loss: 1516.0164 - mean_absolute_error: 1516.0164 - val_loss: 1429.1474 - val_mean_absolute_error: 1429.1474\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 1371.40668\n",
      "Epoch 269/500\n",
      "585/585 [==============================] - 0s 133us/step - loss: 1492.7574 - mean_absolute_error: 1492.7574 - val_loss: 1409.0923 - val_mean_absolute_error: 1409.0923\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 1371.40668\n",
      "Epoch 270/500\n",
      "585/585 [==============================] - 0s 143us/step - loss: 1471.2403 - mean_absolute_error: 1471.2403 - val_loss: 1402.7324 - val_mean_absolute_error: 1402.7324\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 1371.40668\n",
      "Epoch 271/500\n",
      "585/585 [==============================] - 0s 155us/step - loss: 1441.0898 - mean_absolute_error: 1441.0898 - val_loss: 1530.7968 - val_mean_absolute_error: 1530.7968\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 1371.40668\n",
      "Epoch 272/500\n",
      "585/585 [==============================] - 0s 128us/step - loss: 1476.0524 - mean_absolute_error: 1476.0524 - val_loss: 1410.0238 - val_mean_absolute_error: 1410.0238\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 1371.40668\n",
      "Epoch 273/500\n",
      "585/585 [==============================] - 0s 128us/step - loss: 1467.6901 - mean_absolute_error: 1467.6901 - val_loss: 1387.2898 - val_mean_absolute_error: 1387.2898\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 1371.40668\n",
      "Epoch 274/500\n",
      "585/585 [==============================] - 0s 136us/step - loss: 1499.7746 - mean_absolute_error: 1499.7746 - val_loss: 1400.3850 - val_mean_absolute_error: 1400.3850\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 1371.40668\n",
      "Epoch 275/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "585/585 [==============================] - 0s 148us/step - loss: 1452.6149 - mean_absolute_error: 1452.6149 - val_loss: 1412.0227 - val_mean_absolute_error: 1412.0227\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 1371.40668\n",
      "Epoch 276/500\n",
      "585/585 [==============================] - 0s 119us/step - loss: 1450.9061 - mean_absolute_error: 1450.9061 - val_loss: 1390.2610 - val_mean_absolute_error: 1390.2610\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 1371.40668\n",
      "Epoch 277/500\n",
      "585/585 [==============================] - 0s 143us/step - loss: 1482.8234 - mean_absolute_error: 1482.8234 - val_loss: 1444.2791 - val_mean_absolute_error: 1444.2791\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 1371.40668\n",
      "Epoch 278/500\n",
      "585/585 [==============================] - 0s 135us/step - loss: 1527.8577 - mean_absolute_error: 1527.8577 - val_loss: 1413.7474 - val_mean_absolute_error: 1413.7474\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 1371.40668\n",
      "Epoch 279/500\n",
      "585/585 [==============================] - 0s 147us/step - loss: 1451.5804 - mean_absolute_error: 1451.5804 - val_loss: 1424.4715 - val_mean_absolute_error: 1424.4715\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 1371.40668\n",
      "Epoch 280/500\n",
      "585/585 [==============================] - 0s 147us/step - loss: 1470.6421 - mean_absolute_error: 1470.6421 - val_loss: 1420.2308 - val_mean_absolute_error: 1420.2308\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 1371.40668\n",
      "Epoch 281/500\n",
      "585/585 [==============================] - 0s 140us/step - loss: 1455.5565 - mean_absolute_error: 1455.5565 - val_loss: 1408.6281 - val_mean_absolute_error: 1408.6281\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 1371.40668\n",
      "Epoch 282/500\n",
      "585/585 [==============================] - 0s 148us/step - loss: 1464.3816 - mean_absolute_error: 1464.3816 - val_loss: 1435.5418 - val_mean_absolute_error: 1435.5418\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 1371.40668\n",
      "Epoch 283/500\n",
      "585/585 [==============================] - 0s 147us/step - loss: 1468.3930 - mean_absolute_error: 1468.3930 - val_loss: 1400.2209 - val_mean_absolute_error: 1400.2209\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 1371.40668\n",
      "Epoch 284/500\n",
      "585/585 [==============================] - 0s 143us/step - loss: 1454.8937 - mean_absolute_error: 1454.8937 - val_loss: 1466.5552 - val_mean_absolute_error: 1466.5552\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 1371.40668\n",
      "Epoch 285/500\n",
      "585/585 [==============================] - 0s 142us/step - loss: 1470.8765 - mean_absolute_error: 1470.8765 - val_loss: 1648.8455 - val_mean_absolute_error: 1648.8455\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 1371.40668\n",
      "Epoch 286/500\n",
      "585/585 [==============================] - 0s 143us/step - loss: 1506.8203 - mean_absolute_error: 1506.8203 - val_loss: 1449.7535 - val_mean_absolute_error: 1449.7535\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 1371.40668\n",
      "Epoch 287/500\n",
      "585/585 [==============================] - 0s 160us/step - loss: 1459.3524 - mean_absolute_error: 1459.3524 - val_loss: 1496.7604 - val_mean_absolute_error: 1496.7604\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 1371.40668\n",
      "Epoch 288/500\n",
      "585/585 [==============================] - 0s 135us/step - loss: 1445.5552 - mean_absolute_error: 1445.5552 - val_loss: 1416.4941 - val_mean_absolute_error: 1416.4941\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 1371.40668\n",
      "Epoch 289/500\n",
      "585/585 [==============================] - 0s 152us/step - loss: 1492.6236 - mean_absolute_error: 1492.6236 - val_loss: 1385.8756 - val_mean_absolute_error: 1385.8756\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 1371.40668\n",
      "Epoch 290/500\n",
      "585/585 [==============================] - 0s 138us/step - loss: 1495.3384 - mean_absolute_error: 1495.3384 - val_loss: 1387.8187 - val_mean_absolute_error: 1387.8187\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 1371.40668\n",
      "Epoch 291/500\n",
      "585/585 [==============================] - 0s 143us/step - loss: 1463.8204 - mean_absolute_error: 1463.8204 - val_loss: 1477.4767 - val_mean_absolute_error: 1477.4767\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 1371.40668\n",
      "Epoch 292/500\n",
      "585/585 [==============================] - 0s 142us/step - loss: 1467.2328 - mean_absolute_error: 1467.2328 - val_loss: 1410.3759 - val_mean_absolute_error: 1410.3759\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 1371.40668\n",
      "Epoch 293/500\n",
      "585/585 [==============================] - 0s 150us/step - loss: 1461.3488 - mean_absolute_error: 1461.3488 - val_loss: 1419.6896 - val_mean_absolute_error: 1419.6896\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 1371.40668\n",
      "Epoch 294/500\n",
      "585/585 [==============================] - 0s 165us/step - loss: 1453.9155 - mean_absolute_error: 1453.9155 - val_loss: 1402.0985 - val_mean_absolute_error: 1402.0985\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 1371.40668\n",
      "Epoch 295/500\n",
      "585/585 [==============================] - 0s 152us/step - loss: 1444.4080 - mean_absolute_error: 1444.4080 - val_loss: 1406.0745 - val_mean_absolute_error: 1406.0745\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 1371.40668\n",
      "Epoch 296/500\n",
      "585/585 [==============================] - 0s 162us/step - loss: 1482.3910 - mean_absolute_error: 1482.3910 - val_loss: 1514.3512 - val_mean_absolute_error: 1514.3512\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 1371.40668\n",
      "Epoch 297/500\n",
      "585/585 [==============================] - 0s 152us/step - loss: 1497.8091 - mean_absolute_error: 1497.8091 - val_loss: 1458.6756 - val_mean_absolute_error: 1458.6756\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 1371.40668\n",
      "Epoch 298/500\n",
      "585/585 [==============================] - 0s 153us/step - loss: 1472.5724 - mean_absolute_error: 1472.5724 - val_loss: 1412.8588 - val_mean_absolute_error: 1412.8588\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 1371.40668\n",
      "Epoch 299/500\n",
      "585/585 [==============================] - 0s 147us/step - loss: 1442.8519 - mean_absolute_error: 1442.8519 - val_loss: 1392.9715 - val_mean_absolute_error: 1392.9715\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 1371.40668\n",
      "Epoch 300/500\n",
      "585/585 [==============================] - 0s 147us/step - loss: 1450.5507 - mean_absolute_error: 1450.5507 - val_loss: 1392.4075 - val_mean_absolute_error: 1392.4075\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 1371.40668\n",
      "Epoch 301/500\n",
      "585/585 [==============================] - 0s 133us/step - loss: 1459.5782 - mean_absolute_error: 1459.5782 - val_loss: 1398.7229 - val_mean_absolute_error: 1398.7229\n",
      "\n",
      "Epoch 00301: val_loss did not improve from 1371.40668\n",
      "Epoch 302/500\n",
      "585/585 [==============================] - 0s 140us/step - loss: 1475.9108 - mean_absolute_error: 1475.9108 - val_loss: 1501.0775 - val_mean_absolute_error: 1501.0775\n",
      "\n",
      "Epoch 00302: val_loss did not improve from 1371.40668\n",
      "Epoch 303/500\n",
      "585/585 [==============================] - 0s 142us/step - loss: 1494.7984 - mean_absolute_error: 1494.7984 - val_loss: 1426.3538 - val_mean_absolute_error: 1426.3538\n",
      "\n",
      "Epoch 00303: val_loss did not improve from 1371.40668\n",
      "Epoch 304/500\n",
      "585/585 [==============================] - 0s 148us/step - loss: 1435.1387 - mean_absolute_error: 1435.1387 - val_loss: 1402.6855 - val_mean_absolute_error: 1402.6855\n",
      "\n",
      "Epoch 00304: val_loss did not improve from 1371.40668\n",
      "Epoch 305/500\n",
      "585/585 [==============================] - 0s 138us/step - loss: 1446.7068 - mean_absolute_error: 1446.7068 - val_loss: 1464.3970 - val_mean_absolute_error: 1464.3970\n",
      "\n",
      "Epoch 00305: val_loss did not improve from 1371.40668\n",
      "Epoch 306/500\n",
      "585/585 [==============================] - 0s 147us/step - loss: 1447.7840 - mean_absolute_error: 1447.7840 - val_loss: 1414.5202 - val_mean_absolute_error: 1414.5202\n",
      "\n",
      "Epoch 00306: val_loss did not improve from 1371.40668\n",
      "Epoch 307/500\n",
      "585/585 [==============================] - 0s 150us/step - loss: 1447.6977 - mean_absolute_error: 1447.6977 - val_loss: 1432.9015 - val_mean_absolute_error: 1432.9015\n",
      "\n",
      "Epoch 00307: val_loss did not improve from 1371.40668\n",
      "Epoch 308/500\n",
      "585/585 [==============================] - 0s 140us/step - loss: 1441.8980 - mean_absolute_error: 1441.8980 - val_loss: 1515.8396 - val_mean_absolute_error: 1515.8396\n",
      "\n",
      "Epoch 00308: val_loss did not improve from 1371.40668\n",
      "Epoch 309/500\n",
      "585/585 [==============================] - 0s 138us/step - loss: 1457.6886 - mean_absolute_error: 1457.6886 - val_loss: 1396.2077 - val_mean_absolute_error: 1396.2077\n",
      "\n",
      "Epoch 00309: val_loss did not improve from 1371.40668\n",
      "Epoch 310/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "585/585 [==============================] - 0s 128us/step - loss: 1466.5522 - mean_absolute_error: 1466.5522 - val_loss: 1485.0849 - val_mean_absolute_error: 1485.0849\n",
      "\n",
      "Epoch 00310: val_loss did not improve from 1371.40668\n",
      "Epoch 311/500\n",
      "585/585 [==============================] - 0s 157us/step - loss: 1499.3167 - mean_absolute_error: 1499.3167 - val_loss: 1459.1241 - val_mean_absolute_error: 1459.1241\n",
      "\n",
      "Epoch 00311: val_loss did not improve from 1371.40668\n",
      "Epoch 312/500\n",
      "585/585 [==============================] - 0s 155us/step - loss: 1442.4095 - mean_absolute_error: 1442.4095 - val_loss: 1406.0620 - val_mean_absolute_error: 1406.0620\n",
      "\n",
      "Epoch 00312: val_loss did not improve from 1371.40668\n",
      "Epoch 313/500\n",
      "585/585 [==============================] - 0s 143us/step - loss: 1450.8715 - mean_absolute_error: 1450.8715 - val_loss: 1434.1714 - val_mean_absolute_error: 1434.1714\n",
      "\n",
      "Epoch 00313: val_loss did not improve from 1371.40668\n",
      "Epoch 314/500\n",
      "585/585 [==============================] - 0s 159us/step - loss: 1482.0195 - mean_absolute_error: 1482.0195 - val_loss: 1388.7375 - val_mean_absolute_error: 1388.7375\n",
      "\n",
      "Epoch 00314: val_loss did not improve from 1371.40668\n",
      "Epoch 315/500\n",
      "585/585 [==============================] - 0s 138us/step - loss: 1463.6788 - mean_absolute_error: 1463.6788 - val_loss: 1478.9328 - val_mean_absolute_error: 1478.9328\n",
      "\n",
      "Epoch 00315: val_loss did not improve from 1371.40668\n",
      "Epoch 316/500\n",
      "585/585 [==============================] - 0s 131us/step - loss: 1485.2708 - mean_absolute_error: 1485.2708 - val_loss: 1610.1910 - val_mean_absolute_error: 1610.1910\n",
      "\n",
      "Epoch 00316: val_loss did not improve from 1371.40668\n",
      "Epoch 317/500\n",
      "585/585 [==============================] - 0s 155us/step - loss: 1478.1053 - mean_absolute_error: 1478.1053 - val_loss: 1421.1643 - val_mean_absolute_error: 1421.1643\n",
      "\n",
      "Epoch 00317: val_loss did not improve from 1371.40668\n",
      "Epoch 318/500\n",
      "585/585 [==============================] - 0s 145us/step - loss: 1482.7645 - mean_absolute_error: 1482.7645 - val_loss: 1538.6232 - val_mean_absolute_error: 1538.6232\n",
      "\n",
      "Epoch 00318: val_loss did not improve from 1371.40668\n",
      "Epoch 319/500\n",
      "585/585 [==============================] - 0s 126us/step - loss: 1485.0683 - mean_absolute_error: 1485.0683 - val_loss: 1636.4155 - val_mean_absolute_error: 1636.4155\n",
      "\n",
      "Epoch 00319: val_loss did not improve from 1371.40668\n",
      "Epoch 320/500\n",
      "585/585 [==============================] - 0s 131us/step - loss: 1447.9216 - mean_absolute_error: 1447.9216 - val_loss: 1615.4553 - val_mean_absolute_error: 1615.4553\n",
      "\n",
      "Epoch 00320: val_loss did not improve from 1371.40668\n",
      "Epoch 321/500\n",
      "585/585 [==============================] - 0s 133us/step - loss: 1553.2869 - mean_absolute_error: 1553.2869 - val_loss: 1454.1244 - val_mean_absolute_error: 1454.1244\n",
      "\n",
      "Epoch 00321: val_loss did not improve from 1371.40668\n",
      "Epoch 322/500\n",
      "585/585 [==============================] - 0s 148us/step - loss: 1513.8794 - mean_absolute_error: 1513.8794 - val_loss: 1419.0823 - val_mean_absolute_error: 1419.0823\n",
      "\n",
      "Epoch 00322: val_loss did not improve from 1371.40668\n",
      "Epoch 323/500\n",
      "585/585 [==============================] - 0s 140us/step - loss: 1479.9963 - mean_absolute_error: 1479.9963 - val_loss: 1428.0514 - val_mean_absolute_error: 1428.0514\n",
      "\n",
      "Epoch 00323: val_loss did not improve from 1371.40668\n",
      "Epoch 324/500\n",
      "585/585 [==============================] - 0s 126us/step - loss: 1450.2238 - mean_absolute_error: 1450.2238 - val_loss: 1383.8481 - val_mean_absolute_error: 1383.8481\n",
      "\n",
      "Epoch 00324: val_loss did not improve from 1371.40668\n",
      "Epoch 325/500\n",
      "585/585 [==============================] - 0s 136us/step - loss: 1466.8819 - mean_absolute_error: 1466.8819 - val_loss: 1396.1442 - val_mean_absolute_error: 1396.1442\n",
      "\n",
      "Epoch 00325: val_loss did not improve from 1371.40668\n",
      "Epoch 326/500\n",
      "585/585 [==============================] - 0s 126us/step - loss: 1524.0274 - mean_absolute_error: 1524.0274 - val_loss: 1650.9178 - val_mean_absolute_error: 1650.9178\n",
      "\n",
      "Epoch 00326: val_loss did not improve from 1371.40668\n",
      "Epoch 327/500\n",
      "585/585 [==============================] - 0s 164us/step - loss: 1526.5587 - mean_absolute_error: 1526.5587 - val_loss: 1434.8407 - val_mean_absolute_error: 1434.8407\n",
      "\n",
      "Epoch 00327: val_loss did not improve from 1371.40668\n",
      "Epoch 328/500\n",
      "585/585 [==============================] - 0s 135us/step - loss: 1459.5194 - mean_absolute_error: 1459.5194 - val_loss: 1401.5689 - val_mean_absolute_error: 1401.5689\n",
      "\n",
      "Epoch 00328: val_loss did not improve from 1371.40668\n",
      "Epoch 329/500\n",
      "585/585 [==============================] - 0s 138us/step - loss: 1437.9756 - mean_absolute_error: 1437.9756 - val_loss: 1394.3313 - val_mean_absolute_error: 1394.3313\n",
      "\n",
      "Epoch 00329: val_loss did not improve from 1371.40668\n",
      "Epoch 330/500\n",
      "585/585 [==============================] - 0s 126us/step - loss: 1465.3417 - mean_absolute_error: 1465.3417 - val_loss: 1438.2426 - val_mean_absolute_error: 1438.2426\n",
      "\n",
      "Epoch 00330: val_loss did not improve from 1371.40668\n",
      "Epoch 331/500\n",
      "585/585 [==============================] - ETA: 0s - loss: 1472.5907 - mean_absolute_error: 1472.590 - 0s 140us/step - loss: 1456.6399 - mean_absolute_error: 1456.6399 - val_loss: 1393.2635 - val_mean_absolute_error: 1393.2635\n",
      "\n",
      "Epoch 00331: val_loss did not improve from 1371.40668\n",
      "Epoch 332/500\n",
      "585/585 [==============================] - 0s 133us/step - loss: 1443.2162 - mean_absolute_error: 1443.2162 - val_loss: 1392.7561 - val_mean_absolute_error: 1392.7561\n",
      "\n",
      "Epoch 00332: val_loss did not improve from 1371.40668\n",
      "Epoch 333/500\n",
      "585/585 [==============================] - 0s 142us/step - loss: 1432.3390 - mean_absolute_error: 1432.3390 - val_loss: 1486.6269 - val_mean_absolute_error: 1486.6269\n",
      "\n",
      "Epoch 00333: val_loss did not improve from 1371.40668\n",
      "Epoch 334/500\n",
      "585/585 [==============================] - 0s 126us/step - loss: 1472.5647 - mean_absolute_error: 1472.5647 - val_loss: 1394.7212 - val_mean_absolute_error: 1394.7212\n",
      "\n",
      "Epoch 00334: val_loss did not improve from 1371.40668\n",
      "Epoch 335/500\n",
      "585/585 [==============================] - 0s 126us/step - loss: 1479.1953 - mean_absolute_error: 1479.1953 - val_loss: 1408.4085 - val_mean_absolute_error: 1408.4085\n",
      "\n",
      "Epoch 00335: val_loss did not improve from 1371.40668\n",
      "Epoch 336/500\n",
      "585/585 [==============================] - 0s 152us/step - loss: 1484.6335 - mean_absolute_error: 1484.6335 - val_loss: 1565.1560 - val_mean_absolute_error: 1565.1560\n",
      "\n",
      "Epoch 00336: val_loss did not improve from 1371.40668\n",
      "Epoch 337/500\n",
      "585/585 [==============================] - 0s 138us/step - loss: 1448.4593 - mean_absolute_error: 1448.4593 - val_loss: 1433.4995 - val_mean_absolute_error: 1433.4995\n",
      "\n",
      "Epoch 00337: val_loss did not improve from 1371.40668\n",
      "Epoch 338/500\n",
      "585/585 [==============================] - 0s 140us/step - loss: 1448.7624 - mean_absolute_error: 1448.7624 - val_loss: 1410.4886 - val_mean_absolute_error: 1410.4886\n",
      "\n",
      "Epoch 00338: val_loss did not improve from 1371.40668\n",
      "Epoch 339/500\n",
      "585/585 [==============================] - 0s 140us/step - loss: 1453.4292 - mean_absolute_error: 1453.4292 - val_loss: 1378.4930 - val_mean_absolute_error: 1378.4930\n",
      "\n",
      "Epoch 00339: val_loss did not improve from 1371.40668\n",
      "Epoch 340/500\n",
      "585/585 [==============================] - 0s 133us/step - loss: 1457.2495 - mean_absolute_error: 1457.2495 - val_loss: 1383.7283 - val_mean_absolute_error: 1383.7283\n",
      "\n",
      "Epoch 00340: val_loss did not improve from 1371.40668\n",
      "Epoch 341/500\n",
      "585/585 [==============================] - 0s 131us/step - loss: 1438.5668 - mean_absolute_error: 1438.5668 - val_loss: 1394.6044 - val_mean_absolute_error: 1394.6044\n",
      "\n",
      "Epoch 00341: val_loss did not improve from 1371.40668\n",
      "Epoch 342/500\n",
      "585/585 [==============================] - 0s 130us/step - loss: 1457.5344 - mean_absolute_error: 1457.5344 - val_loss: 1538.2984 - val_mean_absolute_error: 1538.2984\n",
      "\n",
      "Epoch 00342: val_loss did not improve from 1371.40668\n",
      "Epoch 343/500\n",
      "585/585 [==============================] - ETA: 0s - loss: 1487.7887 - mean_absolute_error: 1487.788 - 0s 135us/step - loss: 1491.2101 - mean_absolute_error: 1491.2101 - val_loss: 1386.4883 - val_mean_absolute_error: 1386.4883\n",
      "\n",
      "Epoch 00343: val_loss did not improve from 1371.40668\n",
      "Epoch 344/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "585/585 [==============================] - 0s 140us/step - loss: 1509.5495 - mean_absolute_error: 1509.5495 - val_loss: 1423.1286 - val_mean_absolute_error: 1423.1286\n",
      "\n",
      "Epoch 00344: val_loss did not improve from 1371.40668\n",
      "Epoch 345/500\n",
      "585/585 [==============================] - 0s 142us/step - loss: 1450.1490 - mean_absolute_error: 1450.1490 - val_loss: 1391.6390 - val_mean_absolute_error: 1391.6390\n",
      "\n",
      "Epoch 00345: val_loss did not improve from 1371.40668\n",
      "Epoch 346/500\n",
      "585/585 [==============================] - 0s 152us/step - loss: 1444.3869 - mean_absolute_error: 1444.3869 - val_loss: 1551.1040 - val_mean_absolute_error: 1551.1040\n",
      "\n",
      "Epoch 00346: val_loss did not improve from 1371.40668\n",
      "Epoch 347/500\n",
      "585/585 [==============================] - 0s 143us/step - loss: 1444.5642 - mean_absolute_error: 1444.5642 - val_loss: 1409.8635 - val_mean_absolute_error: 1409.8635\n",
      "\n",
      "Epoch 00347: val_loss did not improve from 1371.40668\n",
      "Epoch 348/500\n",
      "585/585 [==============================] - 0s 159us/step - loss: 1460.4178 - mean_absolute_error: 1460.4178 - val_loss: 1407.4908 - val_mean_absolute_error: 1407.4908\n",
      "\n",
      "Epoch 00348: val_loss did not improve from 1371.40668\n",
      "Epoch 349/500\n",
      "585/585 [==============================] - 0s 143us/step - loss: 1469.9192 - mean_absolute_error: 1469.9192 - val_loss: 1402.7239 - val_mean_absolute_error: 1402.7239\n",
      "\n",
      "Epoch 00349: val_loss did not improve from 1371.40668\n",
      "Epoch 350/500\n",
      "585/585 [==============================] - 0s 164us/step - loss: 1436.9823 - mean_absolute_error: 1436.9823 - val_loss: 1413.4861 - val_mean_absolute_error: 1413.4861\n",
      "\n",
      "Epoch 00350: val_loss did not improve from 1371.40668\n",
      "Epoch 351/500\n",
      "585/585 [==============================] - 0s 145us/step - loss: 1426.4722 - mean_absolute_error: 1426.4722 - val_loss: 1413.9753 - val_mean_absolute_error: 1413.9753\n",
      "\n",
      "Epoch 00351: val_loss did not improve from 1371.40668\n",
      "Epoch 352/500\n",
      "585/585 [==============================] - 0s 147us/step - loss: 1440.7449 - mean_absolute_error: 1440.7449 - val_loss: 1405.7925 - val_mean_absolute_error: 1405.7925\n",
      "\n",
      "Epoch 00352: val_loss did not improve from 1371.40668\n",
      "Epoch 353/500\n",
      "585/585 [==============================] - 0s 136us/step - loss: 1427.9385 - mean_absolute_error: 1427.9385 - val_loss: 1409.4041 - val_mean_absolute_error: 1409.4041\n",
      "\n",
      "Epoch 00353: val_loss did not improve from 1371.40668\n",
      "Epoch 354/500\n",
      "585/585 [==============================] - 0s 148us/step - loss: 1421.0733 - mean_absolute_error: 1421.0733 - val_loss: 1378.6562 - val_mean_absolute_error: 1378.6562\n",
      "\n",
      "Epoch 00354: val_loss did not improve from 1371.40668\n",
      "Epoch 355/500\n",
      "585/585 [==============================] - 0s 130us/step - loss: 1465.2984 - mean_absolute_error: 1465.2984 - val_loss: 1453.9945 - val_mean_absolute_error: 1453.9945\n",
      "\n",
      "Epoch 00355: val_loss did not improve from 1371.40668\n",
      "Epoch 356/500\n",
      "585/585 [==============================] - 0s 150us/step - loss: 1429.3796 - mean_absolute_error: 1429.3796 - val_loss: 1380.0673 - val_mean_absolute_error: 1380.0673\n",
      "\n",
      "Epoch 00356: val_loss did not improve from 1371.40668\n",
      "Epoch 357/500\n",
      "585/585 [==============================] - 0s 142us/step - loss: 1451.0880 - mean_absolute_error: 1451.0880 - val_loss: 1429.5491 - val_mean_absolute_error: 1429.5491\n",
      "\n",
      "Epoch 00357: val_loss did not improve from 1371.40668\n",
      "Epoch 358/500\n",
      "585/585 [==============================] - 0s 155us/step - loss: 1426.1206 - mean_absolute_error: 1426.1206 - val_loss: 1460.9735 - val_mean_absolute_error: 1460.9735\n",
      "\n",
      "Epoch 00358: val_loss did not improve from 1371.40668\n",
      "Epoch 359/500\n",
      "585/585 [==============================] - 0s 140us/step - loss: 1438.7905 - mean_absolute_error: 1438.7905 - val_loss: 1384.3579 - val_mean_absolute_error: 1384.3579\n",
      "\n",
      "Epoch 00359: val_loss did not improve from 1371.40668\n",
      "Epoch 360/500\n",
      "585/585 [==============================] - 0s 133us/step - loss: 1435.6274 - mean_absolute_error: 1435.6274 - val_loss: 1387.0961 - val_mean_absolute_error: 1387.0961\n",
      "\n",
      "Epoch 00360: val_loss did not improve from 1371.40668\n",
      "Epoch 361/500\n",
      "585/585 [==============================] - 0s 140us/step - loss: 1506.7780 - mean_absolute_error: 1506.7780 - val_loss: 1471.6062 - val_mean_absolute_error: 1471.6062\n",
      "\n",
      "Epoch 00361: val_loss did not improve from 1371.40668\n",
      "Epoch 362/500\n",
      "585/585 [==============================] - 0s 142us/step - loss: 1533.7610 - mean_absolute_error: 1533.7610 - val_loss: 1436.3321 - val_mean_absolute_error: 1436.3321\n",
      "\n",
      "Epoch 00362: val_loss did not improve from 1371.40668\n",
      "Epoch 363/500\n",
      "585/585 [==============================] - 0s 143us/step - loss: 1525.0775 - mean_absolute_error: 1525.0775 - val_loss: 1454.5561 - val_mean_absolute_error: 1454.5561\n",
      "\n",
      "Epoch 00363: val_loss did not improve from 1371.40668\n",
      "Epoch 364/500\n",
      "585/585 [==============================] - 0s 143us/step - loss: 1491.5776 - mean_absolute_error: 1491.5776 - val_loss: 1479.0338 - val_mean_absolute_error: 1479.0338\n",
      "\n",
      "Epoch 00364: val_loss did not improve from 1371.40668\n",
      "Epoch 365/500\n",
      "585/585 [==============================] - 0s 128us/step - loss: 1470.4371 - mean_absolute_error: 1470.4371 - val_loss: 1375.6682 - val_mean_absolute_error: 1375.6682\n",
      "\n",
      "Epoch 00365: val_loss did not improve from 1371.40668\n",
      "Epoch 366/500\n",
      "585/585 [==============================] - 0s 153us/step - loss: 1446.6101 - mean_absolute_error: 1446.6101 - val_loss: 1387.2980 - val_mean_absolute_error: 1387.2980\n",
      "\n",
      "Epoch 00366: val_loss did not improve from 1371.40668\n",
      "Epoch 367/500\n",
      "585/585 [==============================] - 0s 138us/step - loss: 1474.0131 - mean_absolute_error: 1474.0131 - val_loss: 1558.7084 - val_mean_absolute_error: 1558.7084\n",
      "\n",
      "Epoch 00367: val_loss did not improve from 1371.40668\n",
      "Epoch 368/500\n",
      "585/585 [==============================] - 0s 155us/step - loss: 1459.8832 - mean_absolute_error: 1459.8832 - val_loss: 1399.9141 - val_mean_absolute_error: 1399.9141\n",
      "\n",
      "Epoch 00368: val_loss did not improve from 1371.40668\n",
      "Epoch 369/500\n",
      "585/585 [==============================] - 0s 138us/step - loss: 1460.0797 - mean_absolute_error: 1460.0797 - val_loss: 1430.6326 - val_mean_absolute_error: 1430.6326\n",
      "\n",
      "Epoch 00369: val_loss did not improve from 1371.40668\n",
      "Epoch 370/500\n",
      "585/585 [==============================] - 0s 160us/step - loss: 1464.0313 - mean_absolute_error: 1464.0313 - val_loss: 1373.5893 - val_mean_absolute_error: 1373.5893\n",
      "\n",
      "Epoch 00370: val_loss did not improve from 1371.40668\n",
      "Epoch 371/500\n",
      "585/585 [==============================] - 0s 143us/step - loss: 1488.3151 - mean_absolute_error: 1488.3151 - val_loss: 1445.2335 - val_mean_absolute_error: 1445.2335\n",
      "\n",
      "Epoch 00371: val_loss did not improve from 1371.40668\n",
      "Epoch 372/500\n",
      "585/585 [==============================] - 0s 155us/step - loss: 1485.4091 - mean_absolute_error: 1485.4091 - val_loss: 1392.5769 - val_mean_absolute_error: 1392.5769\n",
      "\n",
      "Epoch 00372: val_loss did not improve from 1371.40668\n",
      "Epoch 373/500\n",
      "585/585 [==============================] - 0s 143us/step - loss: 1479.5262 - mean_absolute_error: 1479.5262 - val_loss: 1449.6922 - val_mean_absolute_error: 1449.6922\n",
      "\n",
      "Epoch 00373: val_loss did not improve from 1371.40668\n",
      "Epoch 374/500\n",
      "585/585 [==============================] - 0s 148us/step - loss: 1462.4067 - mean_absolute_error: 1462.4067 - val_loss: 1585.4658 - val_mean_absolute_error: 1585.4658\n",
      "\n",
      "Epoch 00374: val_loss did not improve from 1371.40668\n",
      "Epoch 375/500\n",
      "585/585 [==============================] - 0s 147us/step - loss: 1437.2945 - mean_absolute_error: 1437.2945 - val_loss: 1400.5699 - val_mean_absolute_error: 1400.5699\n",
      "\n",
      "Epoch 00375: val_loss did not improve from 1371.40668\n",
      "Epoch 376/500\n",
      "585/585 [==============================] - 0s 130us/step - loss: 1428.2894 - mean_absolute_error: 1428.2894 - val_loss: 1455.3889 - val_mean_absolute_error: 1455.3889\n",
      "\n",
      "Epoch 00376: val_loss did not improve from 1371.40668\n",
      "Epoch 377/500\n",
      "585/585 [==============================] - 0s 142us/step - loss: 1423.7680 - mean_absolute_error: 1423.7680 - val_loss: 1409.5803 - val_mean_absolute_error: 1409.5803\n",
      "\n",
      "Epoch 00377: val_loss did not improve from 1371.40668\n",
      "Epoch 378/500\n",
      "585/585 [==============================] - 0s 133us/step - loss: 1428.5050 - mean_absolute_error: 1428.5050 - val_loss: 1383.9992 - val_mean_absolute_error: 1383.9992\n",
      "\n",
      "Epoch 00378: val_loss did not improve from 1371.40668\n",
      "Epoch 379/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "585/585 [==============================] - 0s 136us/step - loss: 1456.3295 - mean_absolute_error: 1456.3295 - val_loss: 1546.8787 - val_mean_absolute_error: 1546.8787\n",
      "\n",
      "Epoch 00379: val_loss did not improve from 1371.40668\n",
      "Epoch 380/500\n",
      "585/585 [==============================] - 0s 145us/step - loss: 1485.5716 - mean_absolute_error: 1485.5716 - val_loss: 1373.2940 - val_mean_absolute_error: 1373.2940\n",
      "\n",
      "Epoch 00380: val_loss did not improve from 1371.40668\n",
      "Epoch 381/500\n",
      "585/585 [==============================] - 0s 136us/step - loss: 1451.5675 - mean_absolute_error: 1451.5675 - val_loss: 1419.1176 - val_mean_absolute_error: 1419.1176\n",
      "\n",
      "Epoch 00381: val_loss did not improve from 1371.40668\n",
      "Epoch 382/500\n",
      "585/585 [==============================] - 0s 155us/step - loss: 1427.2519 - mean_absolute_error: 1427.2519 - val_loss: 1397.8539 - val_mean_absolute_error: 1397.8539\n",
      "\n",
      "Epoch 00382: val_loss did not improve from 1371.40668\n",
      "Epoch 383/500\n",
      "585/585 [==============================] - 0s 164us/step - loss: 1435.1207 - mean_absolute_error: 1435.1207 - val_loss: 1410.7995 - val_mean_absolute_error: 1410.7995\n",
      "\n",
      "Epoch 00383: val_loss did not improve from 1371.40668\n",
      "Epoch 384/500\n",
      "585/585 [==============================] - 0s 165us/step - loss: 1428.6265 - mean_absolute_error: 1428.6265 - val_loss: 1387.9899 - val_mean_absolute_error: 1387.9899\n",
      "\n",
      "Epoch 00384: val_loss did not improve from 1371.40668\n",
      "Epoch 385/500\n",
      "585/585 [==============================] - 0s 160us/step - loss: 1440.1319 - mean_absolute_error: 1440.1319 - val_loss: 1420.0911 - val_mean_absolute_error: 1420.0911\n",
      "\n",
      "Epoch 00385: val_loss did not improve from 1371.40668\n",
      "Epoch 386/500\n",
      "585/585 [==============================] - 0s 148us/step - loss: 1435.0908 - mean_absolute_error: 1435.0908 - val_loss: 1395.4694 - val_mean_absolute_error: 1395.4694\n",
      "\n",
      "Epoch 00386: val_loss did not improve from 1371.40668\n",
      "Epoch 387/500\n",
      "585/585 [==============================] - 0s 150us/step - loss: 1439.7215 - mean_absolute_error: 1439.7215 - val_loss: 1386.4996 - val_mean_absolute_error: 1386.4996\n",
      "\n",
      "Epoch 00387: val_loss did not improve from 1371.40668\n",
      "Epoch 388/500\n",
      "585/585 [==============================] - 0s 157us/step - loss: 1461.0664 - mean_absolute_error: 1461.0664 - val_loss: 1491.5179 - val_mean_absolute_error: 1491.5179\n",
      "\n",
      "Epoch 00388: val_loss did not improve from 1371.40668\n",
      "Epoch 389/500\n",
      "585/585 [==============================] - 0s 165us/step - loss: 1462.7605 - mean_absolute_error: 1462.7605 - val_loss: 1516.0250 - val_mean_absolute_error: 1516.0250\n",
      "\n",
      "Epoch 00389: val_loss did not improve from 1371.40668\n",
      "Epoch 390/500\n",
      "585/585 [==============================] - 0s 143us/step - loss: 1430.4017 - mean_absolute_error: 1430.4017 - val_loss: 1399.3969 - val_mean_absolute_error: 1399.3969\n",
      "\n",
      "Epoch 00390: val_loss did not improve from 1371.40668\n",
      "Epoch 391/500\n",
      "585/585 [==============================] - 0s 153us/step - loss: 1438.8929 - mean_absolute_error: 1438.8929 - val_loss: 1416.7501 - val_mean_absolute_error: 1416.7501\n",
      "\n",
      "Epoch 00391: val_loss did not improve from 1371.40668\n",
      "Epoch 392/500\n",
      "585/585 [==============================] - 0s 147us/step - loss: 1433.3673 - mean_absolute_error: 1433.3673 - val_loss: 1411.8943 - val_mean_absolute_error: 1411.8943\n",
      "\n",
      "Epoch 00392: val_loss did not improve from 1371.40668\n",
      "Epoch 393/500\n",
      "585/585 [==============================] - 0s 150us/step - loss: 1431.4776 - mean_absolute_error: 1431.4776 - val_loss: 1402.2365 - val_mean_absolute_error: 1402.2365\n",
      "\n",
      "Epoch 00393: val_loss did not improve from 1371.40668\n",
      "Epoch 394/500\n",
      "585/585 [==============================] - 0s 160us/step - loss: 1458.6062 - mean_absolute_error: 1458.6062 - val_loss: 1502.7036 - val_mean_absolute_error: 1502.7036\n",
      "\n",
      "Epoch 00394: val_loss did not improve from 1371.40668\n",
      "Epoch 395/500\n",
      "585/585 [==============================] - 0s 147us/step - loss: 1438.1491 - mean_absolute_error: 1438.1491 - val_loss: 1394.1439 - val_mean_absolute_error: 1394.1439\n",
      "\n",
      "Epoch 00395: val_loss did not improve from 1371.40668\n",
      "Epoch 396/500\n",
      "585/585 [==============================] - 0s 140us/step - loss: 1436.5415 - mean_absolute_error: 1436.5415 - val_loss: 1480.5247 - val_mean_absolute_error: 1480.5247\n",
      "\n",
      "Epoch 00396: val_loss did not improve from 1371.40668\n",
      "Epoch 397/500\n",
      "585/585 [==============================] - 0s 133us/step - loss: 1490.8948 - mean_absolute_error: 1490.8948 - val_loss: 1418.5709 - val_mean_absolute_error: 1418.5709\n",
      "\n",
      "Epoch 00397: val_loss did not improve from 1371.40668\n",
      "Epoch 398/500\n",
      "585/585 [==============================] - 0s 138us/step - loss: 1425.7323 - mean_absolute_error: 1425.7323 - val_loss: 1502.6143 - val_mean_absolute_error: 1502.6143\n",
      "\n",
      "Epoch 00398: val_loss did not improve from 1371.40668\n",
      "Epoch 399/500\n",
      "585/585 [==============================] - 0s 159us/step - loss: 1464.3480 - mean_absolute_error: 1464.3480 - val_loss: 1432.7434 - val_mean_absolute_error: 1432.7434\n",
      "\n",
      "Epoch 00399: val_loss did not improve from 1371.40668\n",
      "Epoch 400/500\n",
      "585/585 [==============================] - 0s 157us/step - loss: 1467.8890 - mean_absolute_error: 1467.8890 - val_loss: 1401.7143 - val_mean_absolute_error: 1401.7143\n",
      "\n",
      "Epoch 00400: val_loss did not improve from 1371.40668\n",
      "Epoch 401/500\n",
      "585/585 [==============================] - ETA: 0s - loss: 1424.0643 - mean_absolute_error: 1424.064 - 0s 143us/step - loss: 1440.2820 - mean_absolute_error: 1440.2820 - val_loss: 1405.6375 - val_mean_absolute_error: 1405.6375\n",
      "\n",
      "Epoch 00401: val_loss did not improve from 1371.40668\n",
      "Epoch 402/500\n",
      "585/585 [==============================] - 0s 150us/step - loss: 1427.6050 - mean_absolute_error: 1427.6050 - val_loss: 1382.2055 - val_mean_absolute_error: 1382.2055\n",
      "\n",
      "Epoch 00402: val_loss did not improve from 1371.40668\n",
      "Epoch 403/500\n",
      "585/585 [==============================] - 0s 159us/step - loss: 1423.6950 - mean_absolute_error: 1423.6950 - val_loss: 1398.3281 - val_mean_absolute_error: 1398.3281\n",
      "\n",
      "Epoch 00403: val_loss did not improve from 1371.40668\n",
      "Epoch 404/500\n",
      "585/585 [==============================] - 0s 160us/step - loss: 1422.8847 - mean_absolute_error: 1422.8847 - val_loss: 1419.9651 - val_mean_absolute_error: 1419.9651\n",
      "\n",
      "Epoch 00404: val_loss did not improve from 1371.40668\n",
      "Epoch 405/500\n",
      "585/585 [==============================] - 0s 138us/step - loss: 1435.1820 - mean_absolute_error: 1435.1820 - val_loss: 1404.4472 - val_mean_absolute_error: 1404.4472\n",
      "\n",
      "Epoch 00405: val_loss did not improve from 1371.40668\n",
      "Epoch 406/500\n",
      "585/585 [==============================] - 0s 155us/step - loss: 1468.6375 - mean_absolute_error: 1468.6375 - val_loss: 1409.5458 - val_mean_absolute_error: 1409.5458\n",
      "\n",
      "Epoch 00406: val_loss did not improve from 1371.40668\n",
      "Epoch 407/500\n",
      "585/585 [==============================] - 0s 583us/step - loss: 1434.6098 - mean_absolute_error: 1434.6098 - val_loss: 1395.9431 - val_mean_absolute_error: 1395.9431\n",
      "\n",
      "Epoch 00407: val_loss did not improve from 1371.40668\n",
      "Epoch 408/500\n",
      "585/585 [==============================] - 0s 169us/step - loss: 1448.8348 - mean_absolute_error: 1448.8348 - val_loss: 1397.3502 - val_mean_absolute_error: 1397.3502\n",
      "\n",
      "Epoch 00408: val_loss did not improve from 1371.40668\n",
      "Epoch 409/500\n",
      "585/585 [==============================] - 0s 159us/step - loss: 1476.4857 - mean_absolute_error: 1476.4857 - val_loss: 1446.2808 - val_mean_absolute_error: 1446.2808\n",
      "\n",
      "Epoch 00409: val_loss did not improve from 1371.40668\n",
      "Epoch 410/500\n",
      "585/585 [==============================] - 0s 131us/step - loss: 1510.5248 - mean_absolute_error: 1510.5248 - val_loss: 1419.3194 - val_mean_absolute_error: 1419.3194\n",
      "\n",
      "Epoch 00410: val_loss did not improve from 1371.40668\n",
      "Epoch 411/500\n",
      "585/585 [==============================] - 0s 143us/step - loss: 1453.9075 - mean_absolute_error: 1453.9075 - val_loss: 1546.0180 - val_mean_absolute_error: 1546.0180\n",
      "\n",
      "Epoch 00411: val_loss did not improve from 1371.40668\n",
      "Epoch 412/500\n",
      "585/585 [==============================] - 0s 159us/step - loss: 1450.8306 - mean_absolute_error: 1450.8306 - val_loss: 1389.0991 - val_mean_absolute_error: 1389.0991\n",
      "\n",
      "Epoch 00412: val_loss did not improve from 1371.40668\n",
      "Epoch 413/500\n",
      "585/585 [==============================] - 0s 128us/step - loss: 1444.6243 - mean_absolute_error: 1444.6243 - val_loss: 1409.3817 - val_mean_absolute_error: 1409.3817\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00413: val_loss did not improve from 1371.40668\n",
      "Epoch 414/500\n",
      "585/585 [==============================] - 0s 124us/step - loss: 1421.9409 - mean_absolute_error: 1421.9409 - val_loss: 1393.9742 - val_mean_absolute_error: 1393.9742\n",
      "\n",
      "Epoch 00414: val_loss did not improve from 1371.40668\n",
      "Epoch 415/500\n",
      "585/585 [==============================] - 0s 159us/step - loss: 1485.0194 - mean_absolute_error: 1485.0194 - val_loss: 1543.4125 - val_mean_absolute_error: 1543.4125\n",
      "\n",
      "Epoch 00415: val_loss did not improve from 1371.40668\n",
      "Epoch 416/500\n",
      "585/585 [==============================] - 0s 162us/step - loss: 1484.6290 - mean_absolute_error: 1484.6290 - val_loss: 1386.7765 - val_mean_absolute_error: 1386.7765\n",
      "\n",
      "Epoch 00416: val_loss did not improve from 1371.40668\n",
      "Epoch 417/500\n",
      "585/585 [==============================] - 0s 153us/step - loss: 1435.0724 - mean_absolute_error: 1435.0724 - val_loss: 1508.5975 - val_mean_absolute_error: 1508.5975\n",
      "\n",
      "Epoch 00417: val_loss did not improve from 1371.40668\n",
      "Epoch 418/500\n",
      "585/585 [==============================] - 0s 147us/step - loss: 1439.8623 - mean_absolute_error: 1439.8623 - val_loss: 1388.2036 - val_mean_absolute_error: 1388.2036\n",
      "\n",
      "Epoch 00418: val_loss did not improve from 1371.40668\n",
      "Epoch 419/500\n",
      "585/585 [==============================] - 0s 155us/step - loss: 1427.8780 - mean_absolute_error: 1427.8780 - val_loss: 1385.0885 - val_mean_absolute_error: 1385.0885\n",
      "\n",
      "Epoch 00419: val_loss did not improve from 1371.40668\n",
      "Epoch 420/500\n",
      "585/585 [==============================] - 0s 165us/step - loss: 1434.0687 - mean_absolute_error: 1434.0687 - val_loss: 1619.1569 - val_mean_absolute_error: 1619.1569\n",
      "\n",
      "Epoch 00420: val_loss did not improve from 1371.40668\n",
      "Epoch 421/500\n",
      "585/585 [==============================] - 0s 145us/step - loss: 1477.8166 - mean_absolute_error: 1477.8166 - val_loss: 1406.4713 - val_mean_absolute_error: 1406.4713\n",
      "\n",
      "Epoch 00421: val_loss did not improve from 1371.40668\n",
      "Epoch 422/500\n",
      "585/585 [==============================] - 0s 136us/step - loss: 1442.7866 - mean_absolute_error: 1442.7866 - val_loss: 1401.7248 - val_mean_absolute_error: 1401.7248\n",
      "\n",
      "Epoch 00422: val_loss did not improve from 1371.40668\n",
      "Epoch 423/500\n",
      "585/585 [==============================] - 0s 140us/step - loss: 1477.5837 - mean_absolute_error: 1477.5837 - val_loss: 1404.8394 - val_mean_absolute_error: 1404.8394\n",
      "\n",
      "Epoch 00423: val_loss did not improve from 1371.40668\n",
      "Epoch 424/500\n",
      "585/585 [==============================] - 0s 148us/step - loss: 1430.5739 - mean_absolute_error: 1430.5739 - val_loss: 1415.6324 - val_mean_absolute_error: 1415.6324\n",
      "\n",
      "Epoch 00424: val_loss did not improve from 1371.40668\n",
      "Epoch 425/500\n",
      "585/585 [==============================] - 0s 155us/step - loss: 1433.6046 - mean_absolute_error: 1433.6046 - val_loss: 1403.4379 - val_mean_absolute_error: 1403.4379\n",
      "\n",
      "Epoch 00425: val_loss did not improve from 1371.40668\n",
      "Epoch 426/500\n",
      "585/585 [==============================] - 0s 147us/step - loss: 1419.4426 - mean_absolute_error: 1419.4426 - val_loss: 1384.8334 - val_mean_absolute_error: 1384.8334\n",
      "\n",
      "Epoch 00426: val_loss did not improve from 1371.40668\n",
      "Epoch 427/500\n",
      "585/585 [==============================] - 0s 147us/step - loss: 1411.1921 - mean_absolute_error: 1411.1921 - val_loss: 1395.8401 - val_mean_absolute_error: 1395.8401\n",
      "\n",
      "Epoch 00427: val_loss did not improve from 1371.40668\n",
      "Epoch 428/500\n",
      "585/585 [==============================] - 0s 157us/step - loss: 1447.6059 - mean_absolute_error: 1447.6059 - val_loss: 1416.3852 - val_mean_absolute_error: 1416.3852\n",
      "\n",
      "Epoch 00428: val_loss did not improve from 1371.40668\n",
      "Epoch 429/500\n",
      "585/585 [==============================] - 0s 162us/step - loss: 1421.9250 - mean_absolute_error: 1421.9250 - val_loss: 1413.5990 - val_mean_absolute_error: 1413.5990\n",
      "\n",
      "Epoch 00429: val_loss did not improve from 1371.40668\n",
      "Epoch 430/500\n",
      "585/585 [==============================] - 0s 152us/step - loss: 1405.5507 - mean_absolute_error: 1405.5507 - val_loss: 1413.2561 - val_mean_absolute_error: 1413.2561\n",
      "\n",
      "Epoch 00430: val_loss did not improve from 1371.40668\n",
      "Epoch 431/500\n",
      "585/585 [==============================] - 0s 147us/step - loss: 1409.9883 - mean_absolute_error: 1409.9883 - val_loss: 1398.1706 - val_mean_absolute_error: 1398.1706\n",
      "\n",
      "Epoch 00431: val_loss did not improve from 1371.40668\n",
      "Epoch 432/500\n",
      "585/585 [==============================] - 0s 162us/step - loss: 1458.4147 - mean_absolute_error: 1458.4147 - val_loss: 1479.1858 - val_mean_absolute_error: 1479.1858\n",
      "\n",
      "Epoch 00432: val_loss did not improve from 1371.40668\n",
      "Epoch 433/500\n",
      "585/585 [==============================] - 0s 165us/step - loss: 1422.8904 - mean_absolute_error: 1422.8904 - val_loss: 1406.5797 - val_mean_absolute_error: 1406.5797\n",
      "\n",
      "Epoch 00433: val_loss did not improve from 1371.40668\n",
      "Epoch 434/500\n",
      "585/585 [==============================] - 0s 157us/step - loss: 1427.7788 - mean_absolute_error: 1427.7788 - val_loss: 1423.6698 - val_mean_absolute_error: 1423.6698\n",
      "\n",
      "Epoch 00434: val_loss did not improve from 1371.40668\n",
      "Epoch 435/500\n",
      "585/585 [==============================] - 0s 145us/step - loss: 1412.0980 - mean_absolute_error: 1412.0980 - val_loss: 1396.8037 - val_mean_absolute_error: 1396.8037\n",
      "\n",
      "Epoch 00435: val_loss did not improve from 1371.40668\n",
      "Epoch 436/500\n",
      "585/585 [==============================] - 0s 138us/step - loss: 1474.4905 - mean_absolute_error: 1474.4905 - val_loss: 1554.8032 - val_mean_absolute_error: 1554.8032\n",
      "\n",
      "Epoch 00436: val_loss did not improve from 1371.40668\n",
      "Epoch 437/500\n",
      "585/585 [==============================] - 0s 164us/step - loss: 1444.0070 - mean_absolute_error: 1444.0070 - val_loss: 1385.6265 - val_mean_absolute_error: 1385.6265\n",
      "\n",
      "Epoch 00437: val_loss did not improve from 1371.40668\n",
      "Epoch 438/500\n",
      "585/585 [==============================] - 0s 142us/step - loss: 1421.5331 - mean_absolute_error: 1421.5331 - val_loss: 1397.4855 - val_mean_absolute_error: 1397.4855\n",
      "\n",
      "Epoch 00438: val_loss did not improve from 1371.40668\n",
      "Epoch 439/500\n",
      "585/585 [==============================] - 0s 145us/step - loss: 1428.6235 - mean_absolute_error: 1428.6235 - val_loss: 1571.0392 - val_mean_absolute_error: 1571.0392\n",
      "\n",
      "Epoch 00439: val_loss did not improve from 1371.40668\n",
      "Epoch 440/500\n",
      "585/585 [==============================] - 0s 133us/step - loss: 1455.8651 - mean_absolute_error: 1455.8651 - val_loss: 1430.8308 - val_mean_absolute_error: 1430.8308\n",
      "\n",
      "Epoch 00440: val_loss did not improve from 1371.40668\n",
      "Epoch 441/500\n",
      "585/585 [==============================] - 0s 145us/step - loss: 1428.9201 - mean_absolute_error: 1428.9201 - val_loss: 1412.0754 - val_mean_absolute_error: 1412.0754\n",
      "\n",
      "Epoch 00441: val_loss did not improve from 1371.40668\n",
      "Epoch 442/500\n",
      "585/585 [==============================] - 0s 150us/step - loss: 1415.8276 - mean_absolute_error: 1415.8276 - val_loss: 1428.8456 - val_mean_absolute_error: 1428.8456\n",
      "\n",
      "Epoch 00442: val_loss did not improve from 1371.40668\n",
      "Epoch 443/500\n",
      "585/585 [==============================] - 0s 128us/step - loss: 1408.8715 - mean_absolute_error: 1408.8715 - val_loss: 1437.8356 - val_mean_absolute_error: 1437.8356\n",
      "\n",
      "Epoch 00443: val_loss did not improve from 1371.40668\n",
      "Epoch 444/500\n",
      "585/585 [==============================] - 0s 124us/step - loss: 1411.3326 - mean_absolute_error: 1411.3326 - val_loss: 1461.1071 - val_mean_absolute_error: 1461.1071\n",
      "\n",
      "Epoch 00444: val_loss did not improve from 1371.40668\n",
      "Epoch 445/500\n",
      "585/585 [==============================] - 0s 133us/step - loss: 1439.1501 - mean_absolute_error: 1439.1501 - val_loss: 1389.4891 - val_mean_absolute_error: 1389.4891\n",
      "\n",
      "Epoch 00445: val_loss did not improve from 1371.40668\n",
      "Epoch 446/500\n",
      "585/585 [==============================] - 0s 148us/step - loss: 1437.3257 - mean_absolute_error: 1437.3257 - val_loss: 1406.9002 - val_mean_absolute_error: 1406.9002\n",
      "\n",
      "Epoch 00446: val_loss did not improve from 1371.40668\n",
      "Epoch 447/500\n",
      "585/585 [==============================] - 0s 155us/step - loss: 1409.8573 - mean_absolute_error: 1409.8573 - val_loss: 1425.1796 - val_mean_absolute_error: 1425.1796\n",
      "\n",
      "Epoch 00447: val_loss did not improve from 1371.40668\n",
      "Epoch 448/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "585/585 [==============================] - 0s 133us/step - loss: 1433.8483 - mean_absolute_error: 1433.8483 - val_loss: 1573.7729 - val_mean_absolute_error: 1573.7729\n",
      "\n",
      "Epoch 00448: val_loss did not improve from 1371.40668\n",
      "Epoch 449/500\n",
      "585/585 [==============================] - 0s 130us/step - loss: 1454.5964 - mean_absolute_error: 1454.5964 - val_loss: 1522.2840 - val_mean_absolute_error: 1522.2840\n",
      "\n",
      "Epoch 00449: val_loss did not improve from 1371.40668\n",
      "Epoch 450/500\n",
      "585/585 [==============================] - 0s 138us/step - loss: 1446.2744 - mean_absolute_error: 1446.2744 - val_loss: 1411.9425 - val_mean_absolute_error: 1411.9425\n",
      "\n",
      "Epoch 00450: val_loss did not improve from 1371.40668\n",
      "Epoch 451/500\n",
      "585/585 [==============================] - 0s 152us/step - loss: 1446.8594 - mean_absolute_error: 1446.8594 - val_loss: 1394.6579 - val_mean_absolute_error: 1394.6579\n",
      "\n",
      "Epoch 00451: val_loss did not improve from 1371.40668\n",
      "Epoch 452/500\n",
      "585/585 [==============================] - 0s 136us/step - loss: 1421.8980 - mean_absolute_error: 1421.8980 - val_loss: 1398.4360 - val_mean_absolute_error: 1398.4360\n",
      "\n",
      "Epoch 00452: val_loss did not improve from 1371.40668\n",
      "Epoch 453/500\n",
      "585/585 [==============================] - 0s 131us/step - loss: 1430.3099 - mean_absolute_error: 1430.3099 - val_loss: 1484.2794 - val_mean_absolute_error: 1484.2794\n",
      "\n",
      "Epoch 00453: val_loss did not improve from 1371.40668\n",
      "Epoch 454/500\n",
      "585/585 [==============================] - 0s 138us/step - loss: 1478.3523 - mean_absolute_error: 1478.3523 - val_loss: 1385.5957 - val_mean_absolute_error: 1385.5957\n",
      "\n",
      "Epoch 00454: val_loss did not improve from 1371.40668\n",
      "Epoch 455/500\n",
      "585/585 [==============================] - 0s 128us/step - loss: 1449.7911 - mean_absolute_error: 1449.7911 - val_loss: 1448.5482 - val_mean_absolute_error: 1448.5482\n",
      "\n",
      "Epoch 00455: val_loss did not improve from 1371.40668\n",
      "Epoch 456/500\n",
      "585/585 [==============================] - 0s 133us/step - loss: 1402.6951 - mean_absolute_error: 1402.6951 - val_loss: 1413.1546 - val_mean_absolute_error: 1413.1546\n",
      "\n",
      "Epoch 00456: val_loss did not improve from 1371.40668\n",
      "Epoch 457/500\n",
      "585/585 [==============================] - 0s 140us/step - loss: 1454.4095 - mean_absolute_error: 1454.4095 - val_loss: 1398.4963 - val_mean_absolute_error: 1398.4963\n",
      "\n",
      "Epoch 00457: val_loss did not improve from 1371.40668\n",
      "Epoch 458/500\n",
      "585/585 [==============================] - 0s 138us/step - loss: 1417.7271 - mean_absolute_error: 1417.7271 - val_loss: 1451.2899 - val_mean_absolute_error: 1451.2899\n",
      "\n",
      "Epoch 00458: val_loss did not improve from 1371.40668\n",
      "Epoch 459/500\n",
      "585/585 [==============================] - 0s 160us/step - loss: 1441.5251 - mean_absolute_error: 1441.5251 - val_loss: 1392.4250 - val_mean_absolute_error: 1392.4250\n",
      "\n",
      "Epoch 00459: val_loss did not improve from 1371.40668\n",
      "Epoch 460/500\n",
      "585/585 [==============================] - 0s 147us/step - loss: 1432.6909 - mean_absolute_error: 1432.6909 - val_loss: 1497.1412 - val_mean_absolute_error: 1497.1412\n",
      "\n",
      "Epoch 00460: val_loss did not improve from 1371.40668\n",
      "Epoch 461/500\n",
      "585/585 [==============================] - 0s 153us/step - loss: 1415.7178 - mean_absolute_error: 1415.7178 - val_loss: 1396.8069 - val_mean_absolute_error: 1396.8069\n",
      "\n",
      "Epoch 00461: val_loss did not improve from 1371.40668\n",
      "Epoch 462/500\n",
      "585/585 [==============================] - 0s 133us/step - loss: 1416.4165 - mean_absolute_error: 1416.4165 - val_loss: 1391.8266 - val_mean_absolute_error: 1391.8266\n",
      "\n",
      "Epoch 00462: val_loss did not improve from 1371.40668\n",
      "Epoch 463/500\n",
      "585/585 [==============================] - 0s 153us/step - loss: 1429.6757 - mean_absolute_error: 1429.6757 - val_loss: 1556.4740 - val_mean_absolute_error: 1556.4740\n",
      "\n",
      "Epoch 00463: val_loss did not improve from 1371.40668\n",
      "Epoch 464/500\n",
      "585/585 [==============================] - 0s 136us/step - loss: 1443.0718 - mean_absolute_error: 1443.0718 - val_loss: 1410.0669 - val_mean_absolute_error: 1410.0669\n",
      "\n",
      "Epoch 00464: val_loss did not improve from 1371.40668\n",
      "Epoch 465/500\n",
      "585/585 [==============================] - 0s 138us/step - loss: 1454.3874 - mean_absolute_error: 1454.3874 - val_loss: 1396.0470 - val_mean_absolute_error: 1396.0470\n",
      "\n",
      "Epoch 00465: val_loss did not improve from 1371.40668\n",
      "Epoch 466/500\n",
      "585/585 [==============================] - 0s 160us/step - loss: 1420.2861 - mean_absolute_error: 1420.2861 - val_loss: 1471.0539 - val_mean_absolute_error: 1471.0539\n",
      "\n",
      "Epoch 00466: val_loss did not improve from 1371.40668\n",
      "Epoch 467/500\n",
      "585/585 [==============================] - 0s 130us/step - loss: 1440.5741 - mean_absolute_error: 1440.5741 - val_loss: 1401.3352 - val_mean_absolute_error: 1401.3352\n",
      "\n",
      "Epoch 00467: val_loss did not improve from 1371.40668\n",
      "Epoch 468/500\n",
      "585/585 [==============================] - 0s 140us/step - loss: 1420.8879 - mean_absolute_error: 1420.8879 - val_loss: 1475.5410 - val_mean_absolute_error: 1475.5410\n",
      "\n",
      "Epoch 00468: val_loss did not improve from 1371.40668\n",
      "Epoch 469/500\n",
      "585/585 [==============================] - 0s 150us/step - loss: 1417.1729 - mean_absolute_error: 1417.1729 - val_loss: 1513.4564 - val_mean_absolute_error: 1513.4564\n",
      "\n",
      "Epoch 00469: val_loss did not improve from 1371.40668\n",
      "Epoch 470/500\n",
      "585/585 [==============================] - 0s 140us/step - loss: 1406.9219 - mean_absolute_error: 1406.9219 - val_loss: 1388.8615 - val_mean_absolute_error: 1388.8615\n",
      "\n",
      "Epoch 00470: val_loss did not improve from 1371.40668\n",
      "Epoch 471/500\n",
      "585/585 [==============================] - 0s 155us/step - loss: 1409.5803 - mean_absolute_error: 1409.5803 - val_loss: 1414.3370 - val_mean_absolute_error: 1414.3370\n",
      "\n",
      "Epoch 00471: val_loss did not improve from 1371.40668\n",
      "Epoch 472/500\n",
      "585/585 [==============================] - 0s 150us/step - loss: 1478.4477 - mean_absolute_error: 1478.4477 - val_loss: 1475.4700 - val_mean_absolute_error: 1475.4700\n",
      "\n",
      "Epoch 00472: val_loss did not improve from 1371.40668\n",
      "Epoch 473/500\n",
      "585/585 [==============================] - 0s 128us/step - loss: 1495.4237 - mean_absolute_error: 1495.4237 - val_loss: 1515.9896 - val_mean_absolute_error: 1515.9896\n",
      "\n",
      "Epoch 00473: val_loss did not improve from 1371.40668\n",
      "Epoch 474/500\n",
      "585/585 [==============================] - 0s 130us/step - loss: 1543.3032 - mean_absolute_error: 1543.3032 - val_loss: 1627.3352 - val_mean_absolute_error: 1627.3352\n",
      "\n",
      "Epoch 00474: val_loss did not improve from 1371.40668\n",
      "Epoch 475/500\n",
      "585/585 [==============================] - 0s 135us/step - loss: 1476.6822 - mean_absolute_error: 1476.6822 - val_loss: 1430.5696 - val_mean_absolute_error: 1430.5696\n",
      "\n",
      "Epoch 00475: val_loss did not improve from 1371.40668\n",
      "Epoch 476/500\n",
      "585/585 [==============================] - 0s 135us/step - loss: 1514.7131 - mean_absolute_error: 1514.7131 - val_loss: 1475.8347 - val_mean_absolute_error: 1475.8347\n",
      "\n",
      "Epoch 00476: val_loss did not improve from 1371.40668\n",
      "Epoch 477/500\n",
      "585/585 [==============================] - 0s 143us/step - loss: 1459.2232 - mean_absolute_error: 1459.2232 - val_loss: 1428.4571 - val_mean_absolute_error: 1428.4571\n",
      "\n",
      "Epoch 00477: val_loss did not improve from 1371.40668\n",
      "Epoch 478/500\n",
      "585/585 [==============================] - 0s 145us/step - loss: 1424.9969 - mean_absolute_error: 1424.9969 - val_loss: 1439.5146 - val_mean_absolute_error: 1439.5146\n",
      "\n",
      "Epoch 00478: val_loss did not improve from 1371.40668\n",
      "Epoch 479/500\n",
      "585/585 [==============================] - 0s 153us/step - loss: 1407.2345 - mean_absolute_error: 1407.2345 - val_loss: 1398.7106 - val_mean_absolute_error: 1398.7106\n",
      "\n",
      "Epoch 00479: val_loss did not improve from 1371.40668\n",
      "Epoch 480/500\n",
      "585/585 [==============================] - 0s 131us/step - loss: 1414.1097 - mean_absolute_error: 1414.1097 - val_loss: 1438.7453 - val_mean_absolute_error: 1438.7453\n",
      "\n",
      "Epoch 00480: val_loss did not improve from 1371.40668\n",
      "Epoch 481/500\n",
      "585/585 [==============================] - 0s 136us/step - loss: 1418.3603 - mean_absolute_error: 1418.3603 - val_loss: 1414.4560 - val_mean_absolute_error: 1414.4560\n",
      "\n",
      "Epoch 00481: val_loss did not improve from 1371.40668\n",
      "Epoch 482/500\n",
      "585/585 [==============================] - 0s 140us/step - loss: 1448.5726 - mean_absolute_error: 1448.5726 - val_loss: 1553.9898 - val_mean_absolute_error: 1553.9898\n",
      "\n",
      "Epoch 00482: val_loss did not improve from 1371.40668\n",
      "Epoch 483/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "585/585 [==============================] - 0s 138us/step - loss: 1446.3181 - mean_absolute_error: 1446.3181 - val_loss: 1412.9274 - val_mean_absolute_error: 1412.9274\n",
      "\n",
      "Epoch 00483: val_loss did not improve from 1371.40668\n",
      "Epoch 484/500\n",
      "585/585 [==============================] - 0s 135us/step - loss: 1443.5794 - mean_absolute_error: 1443.5794 - val_loss: 1462.5709 - val_mean_absolute_error: 1462.5709\n",
      "\n",
      "Epoch 00484: val_loss did not improve from 1371.40668\n",
      "Epoch 485/500\n",
      "585/585 [==============================] - 0s 155us/step - loss: 1417.9890 - mean_absolute_error: 1417.9890 - val_loss: 1436.4760 - val_mean_absolute_error: 1436.4760\n",
      "\n",
      "Epoch 00485: val_loss did not improve from 1371.40668\n",
      "Epoch 486/500\n",
      "585/585 [==============================] - 0s 145us/step - loss: 1403.9669 - mean_absolute_error: 1403.9669 - val_loss: 1419.6216 - val_mean_absolute_error: 1419.6216\n",
      "\n",
      "Epoch 00486: val_loss did not improve from 1371.40668\n",
      "Epoch 487/500\n",
      "585/585 [==============================] - 0s 143us/step - loss: 1425.5755 - mean_absolute_error: 1425.5755 - val_loss: 1406.7763 - val_mean_absolute_error: 1406.7763\n",
      "\n",
      "Epoch 00487: val_loss did not improve from 1371.40668\n",
      "Epoch 488/500\n",
      "585/585 [==============================] - 0s 136us/step - loss: 1413.4742 - mean_absolute_error: 1413.4742 - val_loss: 1402.7817 - val_mean_absolute_error: 1402.7817\n",
      "\n",
      "Epoch 00488: val_loss did not improve from 1371.40668\n",
      "Epoch 489/500\n",
      "585/585 [==============================] - 0s 148us/step - loss: 1401.1919 - mean_absolute_error: 1401.1919 - val_loss: 1414.8361 - val_mean_absolute_error: 1414.8361\n",
      "\n",
      "Epoch 00489: val_loss did not improve from 1371.40668\n",
      "Epoch 490/500\n",
      "585/585 [==============================] - 0s 143us/step - loss: 1397.9690 - mean_absolute_error: 1397.9690 - val_loss: 1422.7129 - val_mean_absolute_error: 1422.7129\n",
      "\n",
      "Epoch 00490: val_loss did not improve from 1371.40668\n",
      "Epoch 491/500\n",
      "585/585 [==============================] - 0s 143us/step - loss: 1421.5586 - mean_absolute_error: 1421.5586 - val_loss: 1390.5736 - val_mean_absolute_error: 1390.5736\n",
      "\n",
      "Epoch 00491: val_loss did not improve from 1371.40668\n",
      "Epoch 492/500\n",
      "585/585 [==============================] - 0s 153us/step - loss: 1432.6372 - mean_absolute_error: 1432.6372 - val_loss: 1452.2827 - val_mean_absolute_error: 1452.2827\n",
      "\n",
      "Epoch 00492: val_loss did not improve from 1371.40668\n",
      "Epoch 493/500\n",
      "585/585 [==============================] - 0s 147us/step - loss: 1443.5687 - mean_absolute_error: 1443.5687 - val_loss: 1466.5260 - val_mean_absolute_error: 1466.5260\n",
      "\n",
      "Epoch 00493: val_loss did not improve from 1371.40668\n",
      "Epoch 494/500\n",
      "585/585 [==============================] - 0s 148us/step - loss: 1395.5435 - mean_absolute_error: 1395.5435 - val_loss: 1391.3964 - val_mean_absolute_error: 1391.3964\n",
      "\n",
      "Epoch 00494: val_loss did not improve from 1371.40668\n",
      "Epoch 495/500\n",
      "585/585 [==============================] - 0s 159us/step - loss: 1406.0688 - mean_absolute_error: 1406.0688 - val_loss: 1461.0512 - val_mean_absolute_error: 1461.0512\n",
      "\n",
      "Epoch 00495: val_loss did not improve from 1371.40668\n",
      "Epoch 496/500\n",
      "585/585 [==============================] - 0s 140us/step - loss: 1398.8908 - mean_absolute_error: 1398.8908 - val_loss: 1410.6755 - val_mean_absolute_error: 1410.6755\n",
      "\n",
      "Epoch 00496: val_loss did not improve from 1371.40668\n",
      "Epoch 497/500\n",
      "585/585 [==============================] - 0s 153us/step - loss: 1456.8591 - mean_absolute_error: 1456.8591 - val_loss: 1413.8967 - val_mean_absolute_error: 1413.8967\n",
      "\n",
      "Epoch 00497: val_loss did not improve from 1371.40668\n",
      "Epoch 498/500\n",
      "585/585 [==============================] - 0s 155us/step - loss: 1414.3213 - mean_absolute_error: 1414.3213 - val_loss: 1418.6915 - val_mean_absolute_error: 1418.6915\n",
      "\n",
      "Epoch 00498: val_loss did not improve from 1371.40668\n",
      "Epoch 499/500\n",
      "585/585 [==============================] - 0s 153us/step - loss: 1402.0841 - mean_absolute_error: 1402.0841 - val_loss: 1507.3630 - val_mean_absolute_error: 1507.3630\n",
      "\n",
      "Epoch 00499: val_loss did not improve from 1371.40668\n",
      "Epoch 500/500\n",
      "585/585 [==============================] - 0s 159us/step - loss: 1408.4513 - mean_absolute_error: 1408.4513 - val_loss: 1418.6442 - val_mean_absolute_error: 1418.6442\n",
      "\n",
      "Epoch 00500: val_loss did not improve from 1371.40668\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1aa03073978>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예제에서는 target을 대회에서 주는 target데이터를 기준으로 미리 train데이터와 맞춰졌있지만\n",
    "# gs/lv데이터는 아니다. 그래서 위에서 나누는 기준으로 삼은cut_line=732을 이용하여 데이터 사이즈를 맞춰준다.\n",
    "# 아니면 애시당초에(맨처음에) 훈련용 데이터와 타겟을 만들어 놓는것도 좋다.\n",
    "NN_model.fit(train, target[:cut_line], epochs=500, batch_size=32, validation_split = 0.2, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 500번을 학습하여 나온 결과들중, 가장 좋은(마지막에 저장된) Weights파일을 가져온다.\n",
    "# Load wights file of the best model :\n",
    "# 파일은 이 코드랑 같은 폴더에 위치해있어야 작동\n",
    "wights_file = '맥주date-Weights-226--1353.83757-cat02-vf05.hdf5' # choose the best checkpoint \n",
    "NN_model.load_weights(wights_file) # load it\n",
    "NN_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "여기서 점수란 R-square값을 의미한다.\n",
      "Random forest을 이용한 맥주의 회귀분석 결과 :\n",
      "훈련세트점수 : 0.899\n",
      "검증세트점수 : -1.389\n",
      "XGBoost을 이용한 맥주의 회귀분석 결과 :\n",
      "훈련세트점수 : 0.661\n",
      "검증세트점수 : -1.226\n",
      "LinearRegression을 이용한 맥주의 회귀분석 결과 :\n",
      "훈련세트점수 : 0.454\n",
      "검증세트점수 : -1.080\n",
      "RidgeRegression을 이용한 맥주의 회귀분석 결과 :\n",
      "훈련세트점수 : 0.445\n",
      "검증세트점수 : -1.067\n",
      "LassoRegression을 이용한 맥주의 회귀분석 결과 :\n",
      "훈련세트점수 : 0.454\n",
      "검증세트점수 : -1.080\n",
      "OLS을 이용한 맥주의 회귀분석 결과 :\n",
      "훈련세트점수 : 0.454\n",
      "검증세트점수 : -1.080\n"
     ]
    }
   ],
   "source": [
    "#2016~2018전체를 난수로 0.67:0.33 = 2:1\n",
    "# train3 = combined.loc[:,'temp':]\n",
    "# target3 = combined.loc[:,'qty']\n",
    "# train_X, val_X, train_y, val_y = train_test_split(train3, target3, test_size = 0.33, random_state = 14)\n",
    "\n",
    "# 2016~2017 : 훈련 / 2018 검증 2:1\n",
    "# 1~732 / 732~1096\n",
    "trainXy = Xy[:cut_line]\n",
    "testXy = Xy[cut_line:]\n",
    "\n",
    "# 독립변수들\n",
    "train_X = trainXy.loc[:,'temp':]\n",
    "# 정답(판매량)\n",
    "train_y = trainXy.loc[:,'qty']\n",
    "\n",
    "val_X = testXy.loc[:,'temp':]\n",
    "val_y = testXy.loc[:,'qty']\n",
    "\n",
    "print('여기서 점수란 R-square값을 의미한다.')\n",
    "# RandomForest 회귀분석\n",
    "RFmodel = RandomForestRegressor()\n",
    "RFmodel.fit(train_X,train_y)\n",
    "# Get the mean absolute error on the validation data\n",
    "RFpredicted = RFmodel.predict(val_X)\n",
    "MAE = mean_absolute_error(val_y , RFpredicted)\n",
    "print('Random forest을 이용한 %s의 회귀분석 결과 :'%item)\n",
    "# print('Random forest validation MAE = ', MAE)\n",
    "print('훈련세트점수 : {:.3f}'.format(RFmodel.score(train_X, train_y)))\n",
    "print('검증세트점수 : {:.3f}'.format(RFmodel.score(val_X, val_y)))\n",
    "\n",
    "# XGBRegressor 회귀분석\n",
    "XGBModel = XGBRegressor(objective='reg:squarederror')\n",
    "XGBModel.fit(train_X,train_y , verbose=False)\n",
    "# Get the mean absolute error on the validation data :\n",
    "XGBpredictions = XGBModel.predict(val_X)\n",
    "MAE = mean_absolute_error(val_y , XGBpredictions)\n",
    "print('XGBoost을 이용한 %s의 회귀분석 결과 :'%item)\n",
    "# print('XGBoost validation MAE = ',MAE)\n",
    "print('훈련세트점수 : {:.3f}'.format(XGBModel.score(train_X, train_y)))\n",
    "print('검증세트점수 : {:.3f}'.format(XGBModel.score(val_X, val_y)))\n",
    "\n",
    "linReg = LinearRegression().fit(train_X, train_y)\n",
    "print('LinearRegression을 이용한 %s의 회귀분석 결과 :'%item)\n",
    "print('훈련세트점수 : {:.3f}'.format(linReg.score(train_X, train_y)))\n",
    "print('검증세트점수 : {:.3f}'.format(linReg.score(val_X, val_y)))\n",
    "\n",
    "ridge = Ridge(alpha=0.1, normalize=True, random_state=0, tol=0.001).fit(train_X, train_y)\n",
    "print('RidgeRegression을 이용한 %s의 회귀분석 결과 :'%item)\n",
    "print('훈련세트점수 : {:.3f}'.format(ridge.score(train_X, train_y)))\n",
    "print('검증세트점수 : {:.3f}'.format(ridge.score(val_X, val_y)))\n",
    "\n",
    "lasso = Lasso(alpha=0.1, max_iter=1000).fit(train_X, train_y)\n",
    "print('LassoRegression을 이용한 %s의 회귀분석 결과 :'%item)\n",
    "print('훈련세트점수 : {:.3f}'.format(lasso.score(train_X, train_y)) )\n",
    "print('검증세트점수 : {:.3f}'.format(lasso.score(val_X, val_y)) )\n",
    "\n",
    "columns_in_data = list(train_X.columns)\n",
    "customF = formulaGen(target='qty',ind_features=columns_in_data)\n",
    "olsModel = sm.OLS.from_formula(customF, data=trainXy).fit()\n",
    "print('OLS을 이용한 %s의 회귀분석 결과 :'%item)\n",
    "print('훈련세트점수 : {:.3f}'.format(olsModel.rsquared) )\n",
    "print('검증세트점수 : {:.3f}'.format( r2_score(val_y, olsModel.predict(val_X))   ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "맥주 ols model\n",
      "사람이 직접 식을 때려 박았을때 : -1.128\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    qty   R-squared:                       0.489\n",
      "Model:                            OLS   Adj. R-squared:                  0.485\n",
      "Method:                 Least Squares   F-statistic:                     115.5\n",
      "Date:                Fri, 19 Jul 2019   Prob (F-statistic):          3.74e-102\n",
      "Time:                        20:56:44   Log-Likelihood:                -6535.5\n",
      "No. Observations:                 732   AIC:                         1.308e+04\n",
      "Df Residuals:                     725   BIC:                         1.312e+04\n",
      "Df Model:                           6                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "================================================================================\n",
      "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------\n",
      "Intercept     1.099e+04    438.125     25.075      0.000    1.01e+04    1.18e+04\n",
      "I(temp ** 2)     6.3674      0.287     22.224      0.000       5.805       6.930\n",
      "cloud          -15.1109     43.686     -0.346      0.730    -100.877      70.655\n",
      "wind          -242.2479    104.721     -2.313      0.021    -447.841     -36.654\n",
      "lgt_time       -79.4371     33.476     -2.373      0.018    -145.158     -13.716\n",
      "rain_or_not   -381.0393    194.535     -1.959      0.051    -762.958       0.880\n",
      "snow_or_not    418.2413    415.673      1.006      0.315    -397.824    1234.307\n",
      "==============================================================================\n",
      "Omnibus:                       16.223   Durbin-Watson:                   0.886\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               15.859\n",
      "Skew:                           0.326   Prob(JB):                     0.000360\n",
      "Kurtosis:                       2.692   Cond. No.                     2.73e+03\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.73e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "print(item, 'ols model')\n",
    "\n",
    "# columns_in_data = ['temp', 'cloud', 'wind', 'lgt_time', 'rain_or_not', 'snow_or_not',\n",
    "#                     '공기상태_0', '공기상태_1', '공기상태_2']\n",
    "\n",
    "# formulaGen은 단순 1차 다항식을 제조해준다.\n",
    "# customF = formulaGen(target='qty',ind_features=columns_in_data)\n",
    "# customF = formulaGen(target='qty',ind_features=['temp', 'wind','lgt_time','rain_or_not'])\n",
    "customF = 'qty ~ I(temp**2) + cloud + wind + lgt_time + rain_or_not + snow_or_not'\n",
    "\n",
    "olsModel = sm.OLS.from_formula(customF, data=trainXy).fit()\n",
    "\n",
    "print('사람이 직접 식을 때려 박았을때 : {:.3f}'.format(r2_score(val_y, olsModel.predict(val_X))) )\n",
    "\n",
    "print(olsModel.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# col_list = ['temp', 'cloud', 'wind', 'lgt_time', 'PM10', 'rain_or_not_o', 'snow_or_not_o',\n",
    "#             '공기상태_0', '공기상태_1', '공기상태_2']\n",
    "col_list = ['temp', 'cloud', 'wind', 'lgt_time', 'PM10', 'rain_or_not_o', 'snow_or_not_o',\n",
    "            '공기상태']\n",
    "combined = Xy.loc[:,'temp':]\n",
    "target = Xy.loc[:,'qty']\n",
    "\n",
    "# 가장 좋다고 판명된 설정을 이용하여, 예측qty생산\n",
    "predictions = NN_model.predict(combined)\n",
    "# RandomForest 회귀분석 예측 qty생산\n",
    "RFpredicted = RFmodel.predict(combined)\n",
    "# XGBRegressor 회귀분석 예측 qty생산\n",
    "XGBpredictions = XGBModel.predict(combined)\n",
    "# linearRegression 회귀분석 예측 qty생산\n",
    "linPred = linReg.predict(combined)\n",
    "# Ridge 회귀분석 예측 qty생산\n",
    "ridPred = ridge.predict(combined)\n",
    "# Lasso 회귀분석 예측 qty생산\n",
    "lassoPred = lasso.predict(combined)\n",
    "# OLS 회귀분석 예측 qty생산\n",
    "olsPred = olsModel.predict(combined)\n",
    "\n",
    "result_df = pd.DataFrame()\n",
    "result_df['date'] = gs_day_w['date']\n",
    "result_df['qty'] = Xy.loc[:,'qty']\n",
    "\n",
    "# print(\"keras 신경망 predictions\",predictions.shape)\n",
    "result_df['keras_qty'] = predictions\n",
    "\n",
    "# print(\"randomforest 예상\",RFpredicted.shape)\n",
    "result_df['rf_qty'] = RFpredicted\n",
    "\n",
    "# print(\"XGBpredictions\",XGBpredictions.shape)\n",
    "result_df['xgb_qty'] = XGBpredictions\n",
    "\n",
    "# print(\"linearRegression 예상\",RFpredicted.shape)\n",
    "result_df['lin_qty'] = linPred\n",
    "\n",
    "# print(\"Ridge 예상\",RFpredicted.shape)\n",
    "result_df['ridge_qty'] = ridPred\n",
    "\n",
    "# print(\"Lasso 예상\",RFpredicted.shape)\n",
    "result_df['lasso_qty'] = lassoPred\n",
    "\n",
    "# print(\"OLS 예상\",RFpredicted.shape)\n",
    "result_df['ols_qty'] = olsPred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras 인공 신경망 모델 MAPE \t: 0.15\n",
      "Linear 모델 MAPE \t\t: 0.17\n",
      "Ridge 모델 MAPE \t\t: 0.17\n",
      "Lasso 모델 MAPE \t\t: 0.17\n",
      "OLS 모델 MAPE \t\t\t: 0.16\n"
     ]
    }
   ],
   "source": [
    "# 예측률 계산\n",
    "# https://yamalab.tistory.com/46\n",
    "\n",
    "# RMSE (Root Mean Squared Error) : \n",
    "# OLS 추정에서 일반적인 표준 오차이다. 예측 대상의 scale(단위 크기)에 주의해야하는 단점이 있다. \n",
    "# MSE는 root를 수식에서 제외, SSE는 root와 분모를 제외한 수식으로, SE가 붙은 척도들은 거기서 거기인 척도들이라고 보면 된다.\n",
    "# 다만 디테일한 사용법에 차이가 있을 뿐.\n",
    "\n",
    "# MAPE (Mean Absolute Percentage Error) :\n",
    "\n",
    "# 위 방법의 단점을 보완한 것이다. \n",
    "# At는 실제값, Ft는 예측값인데, 이를 At로 나누어서 오차를 절대적 크기로 보는것이 아닌\n",
    "# 비율의 크기로 보고자 하는 것이 핵심이다.\n",
    "# 이 방법은 At가 0에 가까울수록 비정상적인 값이 나온다는 단점이 있다.\n",
    "\n",
    "# MAPE가 0에 가까울수록 좋은 모델\n",
    "result_df['mape_keras'] = abs((result_df.qty - result_df.keras_qty) / result_df.qty )\n",
    "result_df['mape_rf'] = abs((result_df.qty - result_df.rf_qty) / result_df.qty )\n",
    "result_df['mape_xgb'] = abs((result_df.qty - result_df.xgb_qty) / result_df.qty )\n",
    "result_df['mape_lin'] = abs((result_df.qty - result_df.lin_qty) / result_df.qty )\n",
    "result_df['mape_ridge'] = abs((result_df.qty - result_df.ridge_qty) / result_df.qty )\n",
    "result_df['mape_lasso'] = abs((result_df.qty - result_df.lasso_qty) / result_df.qty )\n",
    "result_df['mape_ols'] = abs((result_df.qty - result_df.ols_qty) / result_df.qty )\n",
    "\n",
    "print('Keras 인공 신경망 모델 MAPE \\t: {:<.2f}'.format(result_df['mape_keras'].sum() / result_df.shape[0] ))\n",
    "# print('RandomForest 모델 MAPE \\t\\t: {:<.2f}'.format(result_df['mape_rf'].sum() / result_df.shape[0] ))\n",
    "# print('XGBoosting  모델 MAPE \\t\\t: {:<.2f}'.format(result_df['mape_xgb'].sum() / result_df.shape[0] ))\n",
    "print('Linear 모델 MAPE \\t\\t: {:<.2f}'.format(result_df['mape_lin'].sum() / result_df.shape[0] ))\n",
    "print('Ridge 모델 MAPE \\t\\t: {:<.2f}'.format(result_df['mape_ridge'].sum() / result_df.shape[0] ))\n",
    "print('Lasso 모델 MAPE \\t\\t: {:<.2f}'.format(result_df['mape_lasso'].sum() / result_df.shape[0] ))\n",
    "print('OLS 모델 MAPE \\t\\t\\t: {:<.2f}'.format(result_df['mape_ols'].sum() / result_df.shape[0] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1116x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 독립변수 Xy의 col번호: 0=qty\n",
    "# ['qty', 'temp', 'cloud', 'wind', 'lgt_time', 'rain_or_not','snow_or_not', \n",
    "#                                                   '공기상태_0', '공기상태_1', '공기상태_2']\n",
    "\n",
    "# 1~9 : 1 temp ~ 9 공기상태_2\n",
    "n= 1\n",
    "# alpha 값 0~1\n",
    "alp = 1\n",
    "# scatter plot 점 크기\n",
    "dot_size = 20\n",
    "\n",
    "matplotlib.rcParams['font.family'] = 'NanumGothicCoding'\n",
    "plt.figure(figsize=(15.5,7))\n",
    "plt.style.use('ggplot')\n",
    "plt.title('%s - %s vs 판매량' % (item, Xy.columns[n]) )\n",
    "plt.scatter(Xy.iloc[:,n],result_df.qty, label = '실 판매량', s=20, c='k')\n",
    "# plt.scatter(Xy.iloc[:,n],result_df.keras_qty, label = '케라스 신경망 예측', alpha=alp, s=dot_size)\n",
    "# plt.scatter(Xy.iloc[:,n],result_df.rf_qty, label = 'RandomForest 예측', alpha=alp, s=dot_size)\n",
    "# plt.scatter(Xy.iloc[:,n],result_df.xgb_qty, label = 'XGBoosting 예측', alpha=alp, s=dot_size)\n",
    "# plt.scatter(Xy.iloc[:,n],result_df.lin_qty, label = '선형 예측', alpha=alp, s=dot_size)\n",
    "# plt.scatter(Xy.iloc[:,n],result_df.ridge_qty, label = 'Ridge 예측', alpha=alp, s=dot_size)\n",
    "# plt.scatter(Xy.iloc[:,n],result_df.ols_qty, label = 'OLS 예측', alpha=alp, s=dot_size)\n",
    "plt.scatter(Xy.iloc[:,n],result_df.keras_qty, label = '케라스 신경망 예측', alpha=alp, s=dot_size)\n",
    "# X axis\n",
    "plt.xlabel('{}'.format(Xy.columns[n]))\n",
    "\n",
    "# y axis\n",
    "plt.ylabel('판매량')\n",
    "\n",
    "# 범례\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실험 구간"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# # 2016~2017 : 훈련 / 2018 검증 2:1\n",
    "# # 1~106 / 106~156\n",
    "# trainXy = gs_week_w.loc[:cut_line]\n",
    "# testXy = gs_week_w.loc[cut_line:]\n",
    "# train_X =pd.DataFrame(trainXy.loc[:,'temp'])\n",
    "# train_y = trainXy.loc[:,'qty']\n",
    "# val_X = pd.DataFrame(testXy.loc[:,'temp'])\n",
    "# val_y = testXy.loc[:,'qty']\n",
    "\n",
    "\n",
    "\n",
    "# print('여기서 점수란 R-square값을 의미한다.')\n",
    "# # RandomForest 회귀분석\n",
    "# RFmodel = RandomForestRegressor()\n",
    "# RFmodel.fit(train_X,train_y)\n",
    "# # Get the mean absolute error on the validation data\n",
    "# RFpredicted = RFmodel.predict(val_X)\n",
    "# MAE = mean_absolute_error(val_y , RFpredicted)\n",
    "# print('Random forest을 이용한 %s의 회귀분석 결과 :'%item)\n",
    "# # print('Random forest validation MAE = ', MAE)\n",
    "# print('훈련세트점수 : {:.3f}'.format(RFmodel.score(train_X, train_y)))\n",
    "# print('검증세트점수 : {:.3f}'.format(RFmodel.score(val_X, val_y)))\n",
    "\n",
    "# # XGBRegressor 회귀분석\n",
    "# XGBModel = XGBRegressor(objective='reg:squarederror')\n",
    "# XGBModel.fit(train_X,train_y , verbose=False)\n",
    "# # Get the mean absolute error on the validation data :\n",
    "# XGBpredictions = XGBModel.predict(val_X)\n",
    "# MAE = mean_absolute_error(val_y , XGBpredictions)\n",
    "# print('XGBoost을 이용한 %s의 회귀분석 결과 :'%item)\n",
    "# # print('XGBoost validation MAE = ',MAE)\n",
    "# print('훈련세트점수 : {:.3f}'.format(XGBModel.score(train_X, train_y)))\n",
    "# print('검증세트점수 : {:.3f}'.format(XGBModel.score(val_X, val_y)))\n",
    "\n",
    "# linReg = LinearRegression().fit(train_X, train_y)\n",
    "# print('LinearRegression을 이용한 %s의 회귀분석 결과 :'%item)\n",
    "# print('훈련세트점수 : {:.3f}'.format(linReg.score(train_X, train_y)))\n",
    "# print('검증세트점수 : {:.3f}'.format(linReg.score(val_X, val_y)))\n",
    "\n",
    "# ridge = Ridge(alpha=0.1, normalize=True, random_state=0, tol=0.001).fit(train_X, train_y)\n",
    "# print('RidgeRegression을 이용한 %s의 회귀분석 결과 :'%item)\n",
    "# print('훈련세트점수 : {:.3f}'.format(ridge.score(train_X, train_y)))\n",
    "# print('검증세트점수 : {:.3f}'.format(ridge.score(val_X, val_y)))\n",
    "\n",
    "# lasso = Lasso(alpha=0.1, max_iter=1000).fit(train_X, train_y)\n",
    "# print('LassoRegression을 이용한 %s의 회귀분석 결과 :'%item)\n",
    "# print('훈련세트점수 : {:.3f}'.format(lasso.score(train_X, train_y)) )\n",
    "# print('검증세트점수 : {:.3f}'.format(lasso.score(val_X, val_y)) )\n",
    "\n",
    "# customF = formulaGen(target='qty',ind_features=['temp'])\n",
    "# olsModel = sm.OLS.from_formula(customF, data=trainXy).fit()\n",
    "# print('OLS을 이용한 %s의 회귀분석 결과 :'%item)\n",
    "# print('훈련세트점수 : {:.3f}'.format(olsModel.rsquared) )\n",
    "\n",
    "# combined = pd.DataFrame(gs_week_w.loc[:,'temp'])\n",
    "# target = gs_week_w.loc[:,'qty']\n",
    "\n",
    "# # 가장 좋다고 판명된 설정을 이용하여, 예측qty생산\n",
    "# # predictions = NN_model.predict(combined)\n",
    "# # RandomForest 회귀분석 예측 qty생산\n",
    "# RFpredicted = RFmodel.predict(combined)\n",
    "# # XGBRegressor 회귀분석 예측 qty생산\n",
    "# XGBpredictions = XGBModel.predict(combined)\n",
    "# # linearRegression 회귀분석 예측 qty생산\n",
    "# linPred = linReg.predict(combined)\n",
    "# # Ridge 회귀분석 예측 qty생산\n",
    "# ridPred = ridge.predict(combined)\n",
    "# # Lasso 회귀분석 예측 qty생산\n",
    "# lassoPred = lasso.predict(combined)\n",
    "# # OLS 회귀분석 예측 qty생산\n",
    "# olsPred = olsModel.predict(combined)\n",
    "\n",
    "# result_df = pd.DataFrame()\n",
    "# result_df['week'] = gs_week_w['week']\n",
    "# result_df['qty'] = gs_week_w.loc[:,'qty']\n",
    "\n",
    "# # print(\"keras 신경망 predictions\",predictions.shape)\n",
    "# # result_df['keras_qty'] = predictions\n",
    "\n",
    "# # print(\"randomforest 예상\",RFpredicted.shape)\n",
    "# result_df['rf_qty'] = RFpredicted\n",
    "\n",
    "# # print(\"XGBpredictions\",XGBpredictions.shape)\n",
    "# result_df['xgb_qty'] = XGBpredictions\n",
    "\n",
    "# # print(\"linearRegression 예상\",RFpredicted.shape)\n",
    "# result_df['lin_qty'] = linPred\n",
    "\n",
    "# # print(\"Ridge 예상\",RFpredicted.shape)\n",
    "# result_df['ridge_qty'] = ridPred\n",
    "\n",
    "# # print(\"Lasso 예상\",RFpredicted.shape)\n",
    "# result_df['lasso_qty'] = lassoPred\n",
    "\n",
    "# # print(\"OLS 예상\",RFpredicted.shape)\n",
    "# result_df['ols_qty'] = olsPred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ============================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_graph = result_df.loc[:,['week','qty','keras_qty','rf_qty','xgb_qty','lin_qty','ridge_qty','lasso_qty','ols_qty']]\n",
    "# for_visual_col = ['week','temp','cloud','wind','lgt_time','snow','rain','PM10']\n",
    "# df = pd.merge(df_graph, gs_week_w[for_visual_col], on='week', how='left')\n",
    "# # df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2016, 온도\n",
    "# df_graph = df.loc[df.week <= 53]\n",
    "# plt.figure(figsize=(15.5, 10))\n",
    "# plt.scatter(df_graph.temp,df_graph.qty, ls='-', label='실제', color='green', alpha=0.5, lw=8)\n",
    "# plt.scatter(df_graph.temp,df_graph.keras_qty, ls='-', label='keras예측', color='r')\n",
    "# plt.scatter(df_graph.temp,df_graph.rf_qty, ls='-', label='rf예측', color='cyan')\n",
    "# plt.scatter(df_graph.temp,df_graph.xgb_qty, ls='-', label='xgb예측', color='b')\n",
    "# plt.scatter(df_graph.temp,df_graph.lin_qty, ls='-', label='linear예측')\n",
    "# plt.scatter(df_graph.temp,df_graph.ridge_qty, ls='-', label='ridge예측')\n",
    "# plt.scatter(df_graph.temp,df_graph.lasso_qty, ls='-', label='lasso예측',color='yellow')\n",
    "# plt.scatter(df_graph.temp,df_graph.ols_qty, ls='-', label='ols예측', color='violet')\n",
    "# plt.legend()\n",
    "# plt.title('{}년도 {} 판매량 실제/예측'.format( '2016',item ))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qty_columns = list(df_graph.columns)[1:9]\n",
    "# weather_columns = list(df_graph.columns)[9:]\n",
    "# print(qty_columns)\n",
    "# print(weather_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_temp = pd.DataFrame()\n",
    "# # x_temp['temp'] = list(range(-10,35,1))\n",
    "# x_temp['temp'] = np.arange(-9,35,0.5)\n",
    "# combined = x_temp\n",
    "# # RandomForest 회귀분석 예측 qty생산\n",
    "# RFpredicted = RFmodel.predict(combined)\n",
    "# # XGBRegressor 회귀분석 예측 qty생산\n",
    "# XGBpredictions = XGBModel.predict(combined)\n",
    "# # linearRegression 회귀분석 예측 qty생산\n",
    "# linPred = linReg.predict(combined)\n",
    "# # Ridge 회귀분석 예측 qty생산\n",
    "# ridPred = ridge.predict(combined)\n",
    "# # Lasso 회귀분석 예측 qty생산\n",
    "# lassoPred = lasso.predict(combined)\n",
    "# # OLS 회귀분석 예측 qty생산\n",
    "# olsPred = olsModel.predict(combined)\n",
    "\n",
    "# # 2016~2018, 일조시간\n",
    "# df_graph = df.copy()\n",
    "# plt.figure(figsize=(15.5, 10))\n",
    "# plt.scatter(df_graph[weather_columns[0]],df_graph['qty'], ls='-', color='k',label='실 판매량', s=100, alpha=0.7)\n",
    "# plt.plot(x_temp, RFpredicted, label = 'rf')\n",
    "# plt.plot(x_temp, XGBpredictions, label = 'xgb')\n",
    "# plt.plot(x_temp, linPred, label = 'line')\n",
    "# plt.plot(x_temp, ridPred, label = 'ridge')\n",
    "# plt.plot(x_temp, lassoPred, label = 'lasso')\n",
    "# plt.plot(x_temp, olsPred, label = 'ols')\n",
    "# plt.plot()\n",
    "# plt.legend()\n",
    "# plt.title('{}년도 {} 판매량 실제/예측'.format( '2016~2018',item ))\n",
    "# plt.xlabel(weather_columns[0])\n",
    "# plt.ylabel('판매량 (단위 : 1개)')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 실험"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intercept_lin = linReg.intercept_\n",
    "# coef_line = linReg.coef_\n",
    "# # list_col\n",
    "# linePredict = list()\n",
    "# x_temp = list(range(-10,38,1))\n",
    "# for temperature in x_temp:\n",
    "#     linePredict.append(intercept_lin + coef_line[0]*temperature)\n",
    "\n",
    "    \n",
    "# # 2016~2018, 일조시간\n",
    "# df_graph = df.copy()\n",
    "# plt.figure(figsize=(15.5, 10))\n",
    "# plt.scatter(df_graph[weather_columns[0]],df_graph['qty'], ls='-', color='k',label='실 판매량', s=100, alpha=0.3)\n",
    "# # for q_name in qty_columns:\n",
    "# #     plt.plot(df_graph[weather_columns[0]],df_graph[q_name], ls='-', label=q_name)\n",
    "# #     plt.scatter(df_graph.lgt_time,df_graph[q_name], ls='-', label='실제', color='green', alpha=0.5, lw=8)\n",
    "# #     plt.scatter(df_graph.lgt_time,df_graph.keras_qty, ls='-', label='keras예측', color='r')\n",
    "# #     plt.scatter(df_graph.lgt_time,df_graph.rf_qty, ls='-', label='rf예측', color='cyan')\n",
    "# #     plt.scatter(df_graph.lgt_time,df_graph.xgb_qty, ls='-', label='xgb예측', color='b')\n",
    "# #     plt.scatter(df_graph.lgt_time,df_graph.lin_qty, ls='-', label='linear예측')\n",
    "# #     plt.scatter(df_graph.lgt_time,df_graph.ridge_qty, ls='-', label='ridge예측')\n",
    "# #     plt.scatter(df_graph.lgt_time,df_graph.lasso_qty, ls='-', label='lasso예측',color='yellow')\n",
    "# #     plt.scatter(df_graph.lgt_time,df_graph.ols_qty, ls='-', label='ols예측', color='violet')\n",
    "# plt.plot(x_temp, linePredict, 'r--', label='linear회귀, 온도만')\n",
    "\n",
    "# plt.legend()\n",
    "# plt.title('{}년도 {} 판매량 실제/예측'.format( '2016~2018',item ))\n",
    "# plt.xlabel(weather_columns[0])\n",
    "# plt.ylabel('판매량 (단위 : 1개)')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 시간의 경과에 따른 예측량 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 2016\n",
    "# df_graph = result_df.loc[result_df.week <=53]\n",
    "# plt.figure(figsize=(15.5, 10))\n",
    "# plt.plot(df_graph.week,df_graph.qty, ls='-', label='실제', color='green', alpha=0.5, lw=8)\n",
    "# plt.plot(df_graph.week,df_graph.keras_qty, ls='-', label='keras예측', color='r')\n",
    "# plt.plot(df_graph.week,df_graph.rf_qty, ls='-', label='rf예측', color='cyan')\n",
    "# plt.plot(df_graph.week,df_graph.xgb_qty, ls='-', label='xgb예측', color='b')\n",
    "# plt.plot(df_graph.week,df_graph.lin_qty, ls='-', label='linear예측')\n",
    "# plt.plot(df_graph.week,df_graph.ridge_qty, ls='-', label='ridge예측')\n",
    "# plt.plot(df_graph.week,df_graph.lasso_qty, ls='-', label='lasso예측',color='yellow')\n",
    "# plt.plot(df_graph.week,df_graph.ols_qty, ls='-', label='ols예측', color='violet')\n",
    "# plt.legend()\n",
    "# plt.title('{}년도 {} 판매량 실제/예측'.format( '2016',item ))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 2017\n",
    "# df_graph = result_df.loc[(result_df.week >=53)&(result_df.week <=105)]\n",
    "# plt.figure(figsize=(15.5, 10))\n",
    "# plt.plot(df_graph.week,df_graph.qty, ls='-', label='실제', color='green', alpha=0.5, lw=8)\n",
    "# plt.plot(df_graph.week,df_graph.keras_qty, ls='-', label='keras예측', color='r')\n",
    "# plt.plot(df_graph.week,df_graph.rf_qty, ls='-', label='rf예측', color='cyan')\n",
    "# plt.plot(df_graph.week,df_graph.xgb_qty, ls='-', label='xgb예측', color='b')\n",
    "# plt.plot(df_graph.week,df_graph.lin_qty, ls='-', label='linear예측')\n",
    "# plt.plot(df_graph.week,df_graph.ridge_qty, ls='-', label='ridge예측')\n",
    "# plt.plot(df_graph.week,df_graph.lasso_qty, ls='-', label='lasso예측',color='yellow')\n",
    "# plt.plot(df_graph.week,df_graph.ols_qty, ls='-', label='ols예측', color='violet')\n",
    "# plt.title('{}년도 {} 판매량 실제/예측'.format( '2017',item ))\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 2018\n",
    "# df_graph = result_df.loc[(result_df.week >=105)]\n",
    "# plt.figure(figsize=(15.5, 10))\n",
    "# plt.plot(df_graph.week,df_graph.qty, ls='-', label='실제', color='green', alpha=0.5, lw=8)\n",
    "# plt.plot(df_graph.week,df_graph.keras_qty, ls='-', label='keras예측', color='r')\n",
    "# plt.plot(df_graph.week,df_graph.rf_qty, ls='-', label='rf예측', color='cyan')\n",
    "# plt.plot(df_graph.week,df_graph.xgb_qty, ls='-', label='xgb예측', color='b')\n",
    "# plt.plot(df_graph.week,df_graph.lin_qty, ls='-', label='linear예측')\n",
    "# plt.plot(df_graph.week,df_graph.ridge_qty, ls='-', label='ridge예측')\n",
    "# plt.plot(df_graph.week,df_graph.lasso_qty, ls='-', label='lasso예측',color='yellow')\n",
    "# plt.plot(df_graph.week,df_graph.ols_qty, ls='-', label='ols예측', color='violet')\n",
    "# plt.title('{}년도 {} 판매량 실제/예측'.format( '2018',item ))\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 2016~2018\n",
    "# plt.figure(figsize=(15.5, 10))\n",
    "# plt.plot(result_df.week,result_df.qty, ls='-', label='실제', color='green', alpha=0.5, lw=8)\n",
    "# plt.plot(result_df.week,result_df.keras_qty, ls='-', label='keras예측', color='r')\n",
    "# plt.plot(result_df.week,result_df.rf_qty, ls='-', label='rf예측', color='cyan')\n",
    "# plt.plot(result_df.week,result_df.xgb_qty, ls='-', label='xgb예측', color='b')\n",
    "# plt.plot(df_graph.week,df_graph.lin_qty, ls='-', label='linear예측')\n",
    "# plt.plot(df_graph.week,df_graph.ridge_qty, ls='-', label='ridge예측')\n",
    "# plt.plot(df_graph.week,df_graph.lasso_qty, ls='-', label='lasso예측',color='yellow')\n",
    "# plt.plot(df_graph.week,df_graph.ols_qty, ls='-', label='ols예측', color='violet')\n",
    "# plt.title('{}년도 {} 판매량 실제/예측'.format( '2016~2018',item ))\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def r2_score(v_true, v_pred):\n",
    "#     ssr = np.sum(np.square(v_pred - np.mean(v_true)))\n",
    "#     sst = np.sum(np.square(v_true - np.mean(v_true)))\n",
    "#     return ( ssr / sst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checked_for = '2016~2017'\n",
    "# combined = aaaaa.loc[:106,'temp':'PM10']\n",
    "# target = aaaaa.loc[:106,'qty']\n",
    "\n",
    "# # 가장 좋다고 판명된 설정을 이용하여, 예측qty생산\n",
    "# predictions = NN_model.predict(combined)\n",
    "# # RandomForest 회귀분석 예측 qty생산\n",
    "# RFpredicted = RFmodel.predict(combined)\n",
    "# # XGBRegressor 회귀분석 예측 qty생산\n",
    "# XGBpredictions = XGBModel.predict(combined)\n",
    "# # linearRegression 회귀분석 예측 qty생산\n",
    "# linPred = linReg.predict(combined)\n",
    "# # Ridge 회귀분석 예측 qty생산\n",
    "# ridPred = ridge.predict(combined)\n",
    "# # Lasso 회귀분석 예측 qty생산\n",
    "# lassoPred = lasso.predict(combined)\n",
    "# # OLS 회귀분석 예측 qty생산\n",
    "# olsPred = olsModel.predict(combined)\n",
    "# qty = target\n",
    "\n",
    "# print(checked_for)\n",
    "# print('RF R2값  \\t: ','{:<.5f}'.format(r2_score(qty, RFpredicted)) )\n",
    "# print('XGB R2값  \\t: ','{:<.5f}'.format(r2_score(qty, XGBpredictions)) )\n",
    "# print('KerasNN R2값\\t: ','{:<.5f}'.format(r2_score(qty,predictions )) )\n",
    "# print('LinReg R2값\\t: ','{:<.5f}'.format(r2_score(qty, linPred)) )\n",
    "# print('Ridge R2값  \\t: ','{:<.5f}'.format(r2_score(qty, ridPred)) )\n",
    "# print('Lasso R2값\\t: ','{:<.5f}'.format(r2_score(qty, lassoPred )) )\n",
    "# print('OLS R2값\\t: ','{:<.5f}'.format(r2_score(qty, olsPred )) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checked_for = '2018'\n",
    "# combined = aaaaa.loc[106:,'temp':'PM10']\n",
    "# target = aaaaa.loc[106:,'qty']\n",
    "\n",
    "# # 가장 좋다고 판명된 설정을 이용하여, 예측qty생산\n",
    "# predictions = NN_model.predict(combined)\n",
    "# # RandomForest 회귀분석 예측 qty생산\n",
    "# RFpredicted = RFmodel.predict(combined)\n",
    "# # XGBRegressor 회귀분석 예측 qty생산\n",
    "# XGBpredictions = XGBModel.predict(combined)\n",
    "# # linearRegression 회귀분석 예측 qty생산\n",
    "# linPred = linReg.predict(combined)\n",
    "# # Ridge 회귀분석 예측 qty생산\n",
    "# ridPred = ridge.predict(combined)\n",
    "# # Lasso 회귀분석 예측 qty생산\n",
    "# lassoPred = lasso.predict(combined)\n",
    "# # OLS 회귀분석 예측 qty생산\n",
    "# olsPred = olsModel.predict(combined)\n",
    "\n",
    "# qty = target\n",
    "\n",
    "# print(checked_for)\n",
    "# print('RF R2값  \\t: ','{:<.5f}'.format(r2_score(qty, RFpredicted)) )\n",
    "# print('XGB R2값  \\t: ','{:<.5f}'.format(r2_score(qty, XGBpredictions)) )\n",
    "# print('KerasNN R2값\\t: ','{:<.5f}'.format(r2_score(qty,predictions )) )\n",
    "# print('LinReg R2값\\t: ','{:<.5f}'.format(r2_score(qty, linPred)) )\n",
    "# print('Ridge R2값  \\t: ','{:<.5f}'.format(r2_score(qty, ridPred)) )\n",
    "# print('Lasso R2값\\t: ','{:<.5f}'.format(r2_score(qty, lassoPred )) )\n",
    "# print('OLS R2값\\t: ','{:<.5f}'.format(r2_score(qty, olsPred )) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checked_for = '2016~2018'\n",
    "# combined = aaaaa.loc[:,'temp':'PM10']\n",
    "# target = aaaaa.loc[:,'qty']\n",
    "\n",
    "# # 가장 좋다고 판명된 설정을 이용하여, 예측qty생산\n",
    "# predictions = NN_model.predict(combined)\n",
    "# # RandomForest 회귀분석 예측 qty생산\n",
    "# RFpredicted = RFmodel.predict(combined)\n",
    "# # XGBRegressor 회귀분석 예측 qty생산\n",
    "# XGBpredictions = XGBModel.predict(combined)\n",
    "# # linearRegression 회귀분석 예측 qty생산\n",
    "# linPred = linReg.predict(combined)\n",
    "# # Ridge 회귀분석 예측 qty생산\n",
    "# ridPred = ridge.predict(combined)\n",
    "# # Lasso 회귀분석 예측 qty생산\n",
    "# lassoPred = lasso.predict(combined)\n",
    "# # OLS 회귀분석 예측 qty생산\n",
    "# olsPred = olsModel.predict(combined)\n",
    "\n",
    "# qty = target\n",
    "\n",
    "# print(checked_for)\n",
    "# print('RF R2값  \\t: ','{:<.5f}'.format(r2_score(qty, RFpredicted)) )\n",
    "# print('XGB R2값  \\t: ','{:<.5f}'.format(r2_score(qty, XGBpredictions)) )\n",
    "# print('KerasNN R2값\\t: ','{:<.5f}'.format(r2_score(qty,predictions )) )\n",
    "# print('LinReg R2값\\t: ','{:<.5f}'.format(r2_score(qty, linPred)) )\n",
    "# print('Ridge R2값  \\t: ','{:<.5f}'.format(r2_score(qty, ridPred)) )\n",
    "# print('Lasso R2값\\t: ','{:<.5f}'.format(r2_score(qty, lassoPred )) )\n",
    "# print('OLS R2값\\t: ','{:<.5f}'.format(r2_score(qty, olsPred )) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = 'D:/project/contest/data/result/'\n",
    "# result_df.to_csv(path+item+'_'+grouped_by+'_predict(lowVIF07).csv', encoding='utf-8', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
