{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "# 인공신경망관련 패키지\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "\n",
    "# 회귀분석 관련 패키지\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error \n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from scipy import stats\n",
    "\n",
    "# R2 값, 결정계수 계산\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# OLS회귀분석\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# 시각화 패키지\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sb\n",
    "\n",
    "# 데이터 처리를 위한 패키지\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# 다중공선성(multicollinearity) 처리를 위한VIF 확인 패키지\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# 한글 처리\n",
    "from matplotlib import rc, font_manager\n",
    "font_name = font_manager.FontProperties(fname='C:/Windows/Fonts/NanumGothicCoding.ttf').get_name()\n",
    "rc('font',family=font_name)\n",
    "\n",
    "# from matplotlib import rcParams\n",
    "# rcParams['font.family'] = 'NanumGothicCoding'\n",
    "\n",
    "# - 마이너스 사인 처리\n",
    "matplotlib.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# DeprecationWarning경고 무시\n",
    "# 향후 안쓰일 함수들을 이용해서 만들어져 있기 때문에 필요하다 없으면, 사방이 붉어진다.\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "# MAD 기반 예제코드\n",
    "def mad_based_outlier(points, thresh=3.5):\n",
    "    if len(points.shape) == 1:\n",
    "        points = points[:,None]\n",
    "    median = np.median(points, axis=0)\n",
    "    diff = np.sum((points - median)**2, axis=-1)\n",
    "    diff = np.sqrt(diff)\n",
    "    med_abs_deviation = np.median(diff)\n",
    "    modified_z_score = 0.6745 * diff / med_abs_deviation\n",
    "    return modified_z_score > thresh \n",
    "\n",
    "# 출처: https://pythonanalysis.tistory.com/7 [Python 데이터 분석]\n",
    "#########################################################################\n",
    "\n",
    "# 소셜 데이터 처리를 위한 함수\n",
    "# 1. 모든 소셜 데이터 column들의 첫번째는 : 날짜다.\n",
    "# 2. 각 소셜데이터는 social_키워드.블로그/트위터/뉴스/총합 으로 되어 있다.\n",
    "def changeColNames(d,before, after) : \n",
    "    # 컬럼이름 시리즈로 만들어 반환\n",
    "    # 통합하기 쉽게, 모든 데이터들의 날짜컬럼 이름을 date로 통일\n",
    "    new_col_names = ['date']\n",
    "    new_col_names.extend(list(d.columns)[1:])\n",
    "    d.columns = new_col_names\n",
    "    return pd.Series(d.columns).apply(lambda x : x.replace(before,after))\n",
    "\n",
    "#########################################################################\n",
    "# modeling 함수로 만들어 처리하기\n",
    "def linReg(df, item, cols_using):\n",
    "    cols = cols_using\n",
    "    X = df.loc[df['category']==item, cols]\n",
    "    y = df.loc[df['category']==item,'qty']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=0)\n",
    "\n",
    "    model = LinearRegression().fit(X_train, y_train)\n",
    "  \n",
    "    print('LinearRegression을 이용한 %s의 회귀분석 결과 :'%item)\n",
    "    print('훈련세트점수 : {:.2f}'.format(model.score(X_train, y_train)))\n",
    "    print('검증세트점수 : {:.2f}'.format(model.score(X_test, y_test)))\n",
    "\n",
    "    \n",
    "def ridgeReg(df, item, cols_using):\n",
    "    cols = cols_using\n",
    "    X = df.loc[df['category']==item,cols]\n",
    "    y = df.loc[df['category']==item,'qty']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=0)\n",
    "\n",
    "    ridge = Ridge(alpha=0.1, normalize=True, random_state=0, tol=0.001).fit(X_train, y_train)\n",
    "    \n",
    "    print('RidgeRegression을 이용한 %s의 회귀분석 결과 :'%item)\n",
    "    print('훈련세트점수 : {:.2f}'.format(ridge.score(X_train, y_train)))\n",
    "    print('검증세트점수 : {:.2f}'.format(ridge.score(X_test, y_test)))\n",
    "\n",
    "\n",
    "def lassoReg(df, item, cols_using):\n",
    "    cols = cols_using\n",
    "    X = df.loc[df['category']==item,cols]\n",
    "    y = df.loc[df['category']==item,'qty']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=0)\n",
    "\n",
    "    lasso = Lasso(alpha=0.1, max_iter=1000).fit(X=X_train, y=y_train)\n",
    "  \n",
    "    print('LassoRegression을 이용한 %s의 회귀분석 결과 :'%item)\n",
    "    print('훈련세트점수 : {:.2f}'.format(lasso.score(X_train, y_train)) )\n",
    "    print('검증세트점수 : {:.2f}'.format(lasso.score(X_test, y_test)) )\n",
    "\n",
    "    #사용한 특성수\n",
    "    print('사용한 특성수 : {}'.format(np.sum(lasso.coef_ != 0)) )\n",
    "#########################################################################\n",
    "\n",
    "# 자료가 1일 1행이라는 전제하에\n",
    "# df길이를 이용하여 날짜수를 계산, 이후 2016년 1월1일을 1번째주 1일이라 기준하에\n",
    "# 몇번째 주인지 알려주는 컬럼 추가. 향후 주단위로 종합할때 스인다.\n",
    "def addDayWeek(df):\n",
    "    df_work = df.copy()\n",
    "    df_work['day'] = pd.Series(range(1,df_work.shape[0]+1)).astype('int64')\n",
    "    df_work['week'] = df_work['day'].apply(lambda x : math.ceil(x/7))\n",
    "    return df_work\n",
    "#########################################################################\n",
    "# 자료를 병합해주는 함수, 어떤 item인지 어느 컬럼을 기준으로 할지 받아서 병합\n",
    "def mergeForAnalysis(df1, df2, df3, item, on_what='date'):\n",
    "    merged_df = pd.merge(df1.loc[df1.category==item], df2, on=on_what, how='left')\n",
    "    merged_df = pd.merge(merged_df, df3, on=on_what, how='left')\n",
    "    return merged_df\n",
    "\n",
    "\n",
    "#########################################################################\n",
    "def lowVIF(df, n=7, cols_using =['temp', 'cloud', 'wind','humid', 'hpa', 'sun_time', 'lgt_time', \n",
    "       'SO2', 'CO', 'O3', 'NO2', 'PM10', 'PM25'] ):\n",
    "    col_to_use = cols_using\n",
    "    vif = pd.DataFrame()\n",
    "    vif[\"VIF_Factor\"] = [variance_inflation_factor(\n",
    "        df[col_to_use].values, i) for i in range(df[col_to_use].shape[1])]\n",
    "    vif[\"features\"] = col_to_use\n",
    "    vif.sort_values(\"VIF_Factor\")\n",
    "    lowest_vif = vif.sort_values(\"VIF_Factor\")[:n].reset_index()\n",
    "    lowest_vif.drop(columns='index', inplace=True)\n",
    "    return lowest_vif\n",
    "\n",
    "#########################################################################\n",
    "# ols모델용 formula 생성\n",
    "def formulaGen(target, ind_features):\n",
    "    '''\n",
    "    formulaGen(목표컬럼명,[변수컬럼명1, 변수컬럼명2,...])\n",
    "    '''\n",
    "    custom_formula = target + \" ~ \"\n",
    "    for f in range(len(ind_features)):\n",
    "        custom_formula += ind_features[f]\n",
    "        if f!=(len(ind_features)-1):\n",
    "            custom_formula += \" + \"\n",
    "    return custom_formula\n",
    "#########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기 (전처리 된 GS, 랄라블라, 날씨)\n",
    "gs = pd.read_csv('d:/project/contest/data/processed/p_gs.csv', parse_dates=['date'])\n",
    "lv = pd.read_csv('d:/project/contest/data/processed/p_lavla.csv', parse_dates=['date'])\n",
    "# w = pd.read_csv('d:/project/contest/data/processed/p_wUVair_seoul_category.csv', parse_dates=['date'], index_col=0)\n",
    "w = pd.read_csv('d:/project/contest/data/processed/날씨_ver071915.csv', parse_dates=['date'], index_col=0)\n",
    "sns_all = pd.read_csv('d:/project/contest/data/processed/social_all.csv', parse_dates=['date'])\n",
    "\n",
    "# GS/lv 서울시만\n",
    "gs_seoul = gs.loc[gs.pvn_nm =='서울특별시']\n",
    "lv_seoul = lv.loc[lv.pvn_nm =='서울특별시']\n",
    "w_seoul = w.loc[w['loc']==108]\n",
    "\n",
    "cols_to_keep = ['date','bor_nm','gender','age_cd','category','qty']\n",
    "\n",
    "# 일일, 구단위, 상품별 판매량 종합\n",
    "lv_grouped = lv_seoul[cols_to_keep].groupby(by=['date','bor_nm','category']).sum().reset_index()\n",
    "\n",
    "# 일단위로 자료 종합(qty는 일일 합계)\n",
    "day_lv_grouped = lv_grouped.groupby(by=['date','category']).sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '선케어'만 빼서 df생성\n",
    "item = '선케어'\n",
    "grouped_by = 'date'\n",
    "day_lv_grouped_w_item = pd.merge(day_lv_grouped.loc[day_lv_grouped.category==item],w_seoul,on='date',how='left')\n",
    "# day_gs_grouped_w_item.head(3)\n",
    "day_lv_grouped_w_sns_item = pd.merge(day_lv_grouped_w_item, sns_all,on='date',how='left')\n",
    "\n",
    "# 일단 uv = 자외선 지수는 결측치가 많아서 제외\n",
    "selected_cols = ['date', 'category', 'qty', 'temp', 'rain', 'cloud', 'wind','humid', 'hpa',\n",
    "                 'sun_time', 'lgt_time', 'snow','rain_or_not','snow_or_not','미세', '초미세', '공기상태',\n",
    "                 'SO2', 'CO', 'O3', 'NO2', 'PM10', 'PM25',\n",
    "                 'pm_blog', 'pm_twitter', 'pm_news', 'pm_total',\n",
    "                 'health_blog', 'health_twitter', 'health_news', 'health_total',\n",
    "                 'date_blog', 'date_twitter', 'date_news', 'date_total',\n",
    "                 'br_blog', 'br_twitter', 'br_news', 'br_total',\n",
    "                 'hobby_blog', 'hobby_twitter', 'hobby_news', 'hobby_total']\n",
    "lv_day_w = day_lv_grouped_w_sns_item[selected_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAD적용\n",
    "lv_day_w['outlier'] = pd.DataFrame(mad_based_outlier(lv_day_w['qty']))\n",
    "lv_day_w = lv_day_w.loc[lv_day_w.outlier==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VIF_Factor</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.239620</td>\n",
       "      <td>snow_or_not</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.479988</td>\n",
       "      <td>rain_or_not</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.114369</td>\n",
       "      <td>공기상태</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.013218</td>\n",
       "      <td>temp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.725926</td>\n",
       "      <td>cloud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8.084050</td>\n",
       "      <td>lgt_time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9.334878</td>\n",
       "      <td>wind</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VIF_Factor     features\n",
       "0    1.239620  snow_or_not\n",
       "1    2.479988  rain_or_not\n",
       "2    3.114369         공기상태\n",
       "3    4.013218         temp\n",
       "4    6.725926        cloud\n",
       "5    8.084050     lgt_time\n",
       "6    9.334878         wind"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list_col = ['temp', 'cloud', 'wind', 'lgt_time', 'PM10'] # +,'rain_or_not','snow_or_not'\n",
    "list_col = ['temp', 'cloud', 'wind','lgt_time',\n",
    "            'rain_or_not', 'snow_or_not', '공기상태'] #+'rain_or_not', 'snow_or_not'\n",
    "lowVIF(w,20,list_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data = lv_day_w.loc[lv_day_w.date.between('2016-01-01','2017-12-31')]\n",
    "test_data = lv_day_w.loc[lv_day_w.date.between('2018-01-01','2018-12-31')]\n",
    "\n",
    "# 3년치 데이터 분리 : 종속변수('qty': 판매량)와 독립변수(판매량 제외 나머지 전부)\n",
    "# 날씨 데이터만\n",
    "combined = lv_day_w.loc[:,list_col]\n",
    "target = lv_day_w.loc[:,'qty']\n",
    "Xy = pd.concat([target,combined], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cols_with_no_nans(df,col_type):\n",
    "    '''\n",
    "    Arguments :\n",
    "    df : The dataframe to process\n",
    "    col_type : \n",
    "          num : to only get numerical columns with no nans\n",
    "          no_num : to only get nun-numerical columns with no nans\n",
    "          all : to get any columns with no nans    \n",
    "    '''\n",
    "    if (col_type == 'num'):\n",
    "        predictors = df.select_dtypes(exclude=['object'])\n",
    "    elif (col_type == 'no_num'):\n",
    "        predictors = df.select_dtypes(include=['object'])\n",
    "    elif (col_type == 'all'):\n",
    "        predictors = df\n",
    "    else :\n",
    "        print('Error : choose a type (num, no_num, all)')\n",
    "        return 0\n",
    "    cols_with_no_nans = []\n",
    "    for col in predictors.columns:\n",
    "        if not df[col].isnull().any():\n",
    "            cols_with_no_nans.append(col)\n",
    "    return cols_with_no_nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "수치형 자료 컬럼 갯수 : 7\n",
      "오브젝트형 자료 컬럼 갯수 : 0\n"
     ]
    }
   ],
   "source": [
    "num_cols = get_cols_with_no_nans(combined , 'num')\n",
    "cat_cols = get_cols_with_no_nans(combined , 'no_num')\n",
    "\n",
    "print ('수치형 자료 컬럼 갯수 :',len(num_cols))\n",
    "print ('오브젝트형 자료 컬럼 갯수 :',len(cat_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x720 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "combined = combined[num_cols + cat_cols]\n",
    "combined.hist(figsize = (12,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data = train_data[num_cols + cat_cols]\n",
    "train_data['Target'] = target\n",
    "\n",
    "C_mat = train_data.corr()\n",
    "fig = plt.figure(figsize = (15,15))\n",
    "\n",
    "sb.heatmap(C_mat, vmax = .8, square = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분류형(category형) 컬럼 수정 전, 총 7 개의 columns이 있었습니다.\n",
      "분류형(category형) 컬럼 수정 후, 총 10 개의 columns이 있었습니다.\n"
     ]
    }
   ],
   "source": [
    "def oneHotEncode(df,colNames):\n",
    "    for col in colNames:\n",
    "        # 해당 컬럼의 데이터 타입이 object란 소리는 숫자가 아니다 = 분류형 데이터\n",
    "        if( df[col].dtype == np.dtype('object')):\n",
    "            # 더미 컬럼 생성\n",
    "            dummies = pd.get_dummies(df[col],prefix=col)\n",
    "            # 원본 데이터에 이어 붙이기 axis=1 컬럼방향으로 \n",
    "            df = pd.concat([df,dummies],axis=1)\n",
    "\n",
    "            # 기존의 str형 컬럼 삭제\n",
    "            df.drop([col],axis = 1 , inplace=True)\n",
    "    return df\n",
    "    \n",
    "\n",
    "print('분류형(category형) 컬럼 수정 전, 총 {} 개의 columns이 있었습니다.'.format(combined.shape[1]))\n",
    "combined = oneHotEncode(combined, cat_cols)\n",
    "#### 내가 '공기상태'라는 컬럼이 사실은 category형이라는것을 알기에 직접 dummy컬럼 생성\n",
    "airCondition_dummies = pd.get_dummies(combined['공기상태'],prefix='공기상태')\n",
    "combined = pd.concat([combined, airCondition_dummies], axis=1)\n",
    "combined.drop(['공기상태'],axis = 1 , inplace=True)\n",
    "######################################################################################\n",
    "print('분류형(category형) 컬럼 수정 후, 총 {} 개의 columns이 있었습니다.'.format(combined.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temp</th>\n",
       "      <th>cloud</th>\n",
       "      <th>wind</th>\n",
       "      <th>lgt_time</th>\n",
       "      <th>rain_or_not</th>\n",
       "      <th>snow_or_not</th>\n",
       "      <th>공기상태_0</th>\n",
       "      <th>공기상태_1</th>\n",
       "      <th>공기상태_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   temp  cloud  wind  lgt_time  rain_or_not  snow_or_not  공기상태_0  공기상태_1  \\\n",
       "0   1.2    7.0   1.6       2.1            0            0       0       0   \n",
       "\n",
       "   공기상태_2  \n",
       "0       1  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 공기상태_0,공기상태_1,공기상태_2가 전부 0이면,   공기상태_3이 1이란 소리고\n",
    "#                                                               공기상태가 '매우나쁨' 임을 추정할수 있다.\n",
    "# 그런이유로 공기상태_3삭제\n",
    "combined.drop(['공기상태_3'],axis = 1 , inplace=True)\n",
    "combined.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xy = pd.concat([target,combined], axis=1)\n",
    "# Xy.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(732, 9)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 첫 2년 : 732 일\n",
    "cut_line = 732\n",
    "def split_combined():\n",
    "    global combined\n",
    "    train = combined[:cut_line]\n",
    "    test = combined[cut_line:]\n",
    "\n",
    "    return train , test \n",
    "  \n",
    "train, test = split_combined()\n",
    "\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0719 21:03:46.199893  1468 deprecation_wrapper.py:119] From C:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0719 21:03:46.215827  1468 deprecation_wrapper.py:119] From C:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0719 21:03:46.217822  1468 deprecation_wrapper.py:119] From C:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4115: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "W0719 21:03:46.271678  1468 deprecation_wrapper.py:119] From C:\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 128)               1280      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 166,145\n",
      "Trainable params: 166,145\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 신경망 모델 생성\n",
    "NN_model = Sequential()\n",
    "\n",
    "# The Input Layer :\n",
    "NN_model.add(Dense(128, kernel_initializer='normal',input_dim = train.shape[1], activation='relu'))\n",
    "\n",
    "# The Hidden Layers :\n",
    "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "\n",
    "# The Output Layer :\n",
    "NN_model.add(Dense(1, kernel_initializer='normal',activation='linear'))\n",
    "\n",
    "# Compile the network :\n",
    "# optimizer에 여러 방식이 있다.\n",
    "NN_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
    "NN_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인공 신경망에 의해 생성된 weight 자료를 저장하기 위해서\n",
    "checkpoint_name = item+grouped_by+'-Weights-{epoch:03d}--{val_loss:.5f}-cat04-vf05.hdf5' \n",
    "\n",
    "# save_best_only값이 저장되어, 모든 weight값을 저장하지 않고, val_loss값이 줄어들때마다(적을수록 좋다.) 저장\n",
    "checkpoint = ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose = 1, save_best_only = True, mode ='auto')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0719 21:03:53.419629  1468 deprecation_wrapper.py:119] From C:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "W0719 21:03:53.512155  1468 deprecation_wrapper.py:119] From C:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 585 samples, validate on 147 samples\n",
      "Epoch 1/500\n",
      "585/585 [==============================] - 0s 524us/step - loss: 3191.1874 - mean_absolute_error: 3191.1874 - val_loss: 1271.9631 - val_mean_absolute_error: 1271.9631\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1271.96314, saving model to 선케어date-Weights-001--1271.96314-cat04-vf05.hdf5\n",
      "Epoch 2/500\n",
      "585/585 [==============================] - 0s 79us/step - loss: 2621.8924 - mean_absolute_error: 2621.8924 - val_loss: 547.2553 - val_mean_absolute_error: 547.2553\n",
      "\n",
      "Epoch 00002: val_loss improved from 1271.96314 to 547.25534, saving model to 선케어date-Weights-002--547.25534-cat04-vf05.hdf5\n",
      "Epoch 3/500\n",
      "585/585 [==============================] - 0s 80us/step - loss: 1429.3428 - mean_absolute_error: 1429.3428 - val_loss: 651.8771 - val_mean_absolute_error: 651.8771\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 547.25534\n",
      "Epoch 4/500\n",
      "585/585 [==============================] - 0s 68us/step - loss: 1338.5443 - mean_absolute_error: 1338.5443 - val_loss: 683.5171 - val_mean_absolute_error: 683.5171\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 547.25534\n",
      "Epoch 5/500\n",
      "585/585 [==============================] - 0s 75us/step - loss: 1297.6260 - mean_absolute_error: 1297.6260 - val_loss: 778.1190 - val_mean_absolute_error: 778.1190\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 547.25534\n",
      "Epoch 6/500\n",
      "585/585 [==============================] - 0s 65us/step - loss: 1281.6166 - mean_absolute_error: 1281.6166 - val_loss: 723.1272 - val_mean_absolute_error: 723.1272\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 547.25534\n",
      "Epoch 7/500\n",
      "585/585 [==============================] - 0s 72us/step - loss: 1272.3117 - mean_absolute_error: 1272.3117 - val_loss: 667.0220 - val_mean_absolute_error: 667.0220\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 547.25534\n",
      "Epoch 8/500\n",
      "585/585 [==============================] - 0s 85us/step - loss: 1253.5829 - mean_absolute_error: 1253.5829 - val_loss: 676.5420 - val_mean_absolute_error: 676.5420\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 547.25534\n",
      "Epoch 9/500\n",
      "585/585 [==============================] - 0s 84us/step - loss: 1252.3255 - mean_absolute_error: 1252.3255 - val_loss: 743.8358 - val_mean_absolute_error: 743.8358\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 547.25534\n",
      "Epoch 10/500\n",
      "585/585 [==============================] - 0s 73us/step - loss: 1243.3356 - mean_absolute_error: 1243.3356 - val_loss: 725.7650 - val_mean_absolute_error: 725.7650\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 547.25534\n",
      "Epoch 11/500\n",
      "585/585 [==============================] - 0s 80us/step - loss: 1243.2750 - mean_absolute_error: 1243.2750 - val_loss: 634.9504 - val_mean_absolute_error: 634.9504\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 547.25534\n",
      "Epoch 12/500\n",
      "585/585 [==============================] - 0s 85us/step - loss: 1216.8250 - mean_absolute_error: 1216.8250 - val_loss: 695.6286 - val_mean_absolute_error: 695.6286\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 547.25534\n",
      "Epoch 13/500\n",
      "585/585 [==============================] - 0s 85us/step - loss: 1220.2037 - mean_absolute_error: 1220.2037 - val_loss: 690.2397 - val_mean_absolute_error: 690.2397\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 547.25534\n",
      "Epoch 14/500\n",
      "585/585 [==============================] - 0s 75us/step - loss: 1209.3791 - mean_absolute_error: 1209.3791 - val_loss: 691.9632 - val_mean_absolute_error: 691.9632\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 547.25534\n",
      "Epoch 15/500\n",
      "585/585 [==============================] - 0s 84us/step - loss: 1198.2941 - mean_absolute_error: 1198.2941 - val_loss: 780.5562 - val_mean_absolute_error: 780.5562\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 547.25534\n",
      "Epoch 16/500\n",
      "585/585 [==============================] - 0s 84us/step - loss: 1241.4244 - mean_absolute_error: 1241.4244 - val_loss: 654.2327 - val_mean_absolute_error: 654.2327\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 547.25534\n",
      "Epoch 17/500\n",
      "585/585 [==============================] - 0s 90us/step - loss: 1202.2398 - mean_absolute_error: 1202.2398 - val_loss: 646.4167 - val_mean_absolute_error: 646.4167\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 547.25534\n",
      "Epoch 18/500\n",
      "585/585 [==============================] - 0s 82us/step - loss: 1195.4261 - mean_absolute_error: 1195.4261 - val_loss: 701.1917 - val_mean_absolute_error: 701.1917\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 547.25534\n",
      "Epoch 19/500\n",
      "585/585 [==============================] - 0s 82us/step - loss: 1180.9273 - mean_absolute_error: 1180.9273 - val_loss: 679.4098 - val_mean_absolute_error: 679.4098\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 547.25534\n",
      "Epoch 20/500\n",
      "585/585 [==============================] - 0s 90us/step - loss: 1174.8574 - mean_absolute_error: 1174.8574 - val_loss: 697.0409 - val_mean_absolute_error: 697.0409\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 547.25534\n",
      "Epoch 21/500\n",
      "585/585 [==============================] - 0s 85us/step - loss: 1171.7932 - mean_absolute_error: 1171.7932 - val_loss: 635.9007 - val_mean_absolute_error: 635.9007\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 547.25534\n",
      "Epoch 22/500\n",
      "585/585 [==============================] - 0s 80us/step - loss: 1173.3754 - mean_absolute_error: 1173.3754 - val_loss: 679.2136 - val_mean_absolute_error: 679.2136\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 547.25534\n",
      "Epoch 23/500\n",
      "585/585 [==============================] - 0s 89us/step - loss: 1165.1603 - mean_absolute_error: 1165.1603 - val_loss: 749.4972 - val_mean_absolute_error: 749.4972\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 547.25534\n",
      "Epoch 24/500\n",
      "585/585 [==============================] - 0s 87us/step - loss: 1174.5016 - mean_absolute_error: 1174.5016 - val_loss: 638.5535 - val_mean_absolute_error: 638.5535\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 547.25534\n",
      "Epoch 25/500\n",
      "585/585 [==============================] - 0s 89us/step - loss: 1181.2334 - mean_absolute_error: 1181.2334 - val_loss: 712.9431 - val_mean_absolute_error: 712.9431\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 547.25534\n",
      "Epoch 26/500\n",
      "585/585 [==============================] - 0s 101us/step - loss: 1149.1057 - mean_absolute_error: 1149.1057 - val_loss: 603.5182 - val_mean_absolute_error: 603.5182\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 547.25534\n",
      "Epoch 27/500\n",
      "585/585 [==============================] - 0s 77us/step - loss: 1224.2440 - mean_absolute_error: 1224.2440 - val_loss: 613.6706 - val_mean_absolute_error: 613.6706\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 547.25534\n",
      "Epoch 28/500\n",
      "585/585 [==============================] - 0s 77us/step - loss: 1198.2825 - mean_absolute_error: 1198.2825 - val_loss: 636.0302 - val_mean_absolute_error: 636.0302\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 547.25534\n",
      "Epoch 29/500\n",
      "585/585 [==============================] - 0s 80us/step - loss: 1153.7089 - mean_absolute_error: 1153.7089 - val_loss: 644.5111 - val_mean_absolute_error: 644.5111\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 547.25534\n",
      "Epoch 30/500\n",
      "585/585 [==============================] - 0s 84us/step - loss: 1151.6364 - mean_absolute_error: 1151.6364 - val_loss: 664.9698 - val_mean_absolute_error: 664.9698\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 547.25534\n",
      "Epoch 31/500\n",
      "585/585 [==============================] - 0s 80us/step - loss: 1147.7609 - mean_absolute_error: 1147.7609 - val_loss: 632.0940 - val_mean_absolute_error: 632.0940\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 547.25534\n",
      "Epoch 32/500\n",
      "585/585 [==============================] - 0s 80us/step - loss: 1171.1986 - mean_absolute_error: 1171.1986 - val_loss: 621.2672 - val_mean_absolute_error: 621.2672\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 547.25534\n",
      "Epoch 33/500\n",
      "585/585 [==============================] - 0s 92us/step - loss: 1147.6814 - mean_absolute_error: 1147.6814 - val_loss: 712.2603 - val_mean_absolute_error: 712.2603\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 547.25534\n",
      "Epoch 34/500\n",
      "585/585 [==============================] - 0s 84us/step - loss: 1159.3180 - mean_absolute_error: 1159.3180 - val_loss: 691.5029 - val_mean_absolute_error: 691.5029\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 547.25534\n",
      "Epoch 35/500\n",
      "585/585 [==============================] - 0s 82us/step - loss: 1180.2800 - mean_absolute_error: 1180.2800 - val_loss: 682.2968 - val_mean_absolute_error: 682.2968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00035: val_loss did not improve from 547.25534\n",
      "Epoch 36/500\n",
      "585/585 [==============================] - 0s 89us/step - loss: 1171.9348 - mean_absolute_error: 1171.9348 - val_loss: 679.3997 - val_mean_absolute_error: 679.3997\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 547.25534\n",
      "Epoch 37/500\n",
      "585/585 [==============================] - 0s 85us/step - loss: 1133.8343 - mean_absolute_error: 1133.8343 - val_loss: 621.8844 - val_mean_absolute_error: 621.8844\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 547.25534\n",
      "Epoch 38/500\n",
      "585/585 [==============================] - 0s 84us/step - loss: 1144.1353 - mean_absolute_error: 1144.1353 - val_loss: 693.1258 - val_mean_absolute_error: 693.1258\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 547.25534\n",
      "Epoch 39/500\n",
      "585/585 [==============================] - 0s 82us/step - loss: 1135.6290 - mean_absolute_error: 1135.6290 - val_loss: 689.4933 - val_mean_absolute_error: 689.4933\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 547.25534\n",
      "Epoch 40/500\n",
      "585/585 [==============================] - 0s 82us/step - loss: 1139.3869 - mean_absolute_error: 1139.3869 - val_loss: 731.4928 - val_mean_absolute_error: 731.4928\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 547.25534\n",
      "Epoch 41/500\n",
      "585/585 [==============================] - 0s 80us/step - loss: 1149.3180 - mean_absolute_error: 1149.3180 - val_loss: 699.2451 - val_mean_absolute_error: 699.2451\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 547.25534\n",
      "Epoch 42/500\n",
      "585/585 [==============================] - 0s 78us/step - loss: 1137.2466 - mean_absolute_error: 1137.2466 - val_loss: 666.4674 - val_mean_absolute_error: 666.4674\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 547.25534\n",
      "Epoch 43/500\n",
      "585/585 [==============================] - 0s 85us/step - loss: 1143.9513 - mean_absolute_error: 1143.9513 - val_loss: 631.8161 - val_mean_absolute_error: 631.8161\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 547.25534\n",
      "Epoch 44/500\n",
      "585/585 [==============================] - 0s 80us/step - loss: 1139.1961 - mean_absolute_error: 1139.1961 - val_loss: 641.7122 - val_mean_absolute_error: 641.7122\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 547.25534\n",
      "Epoch 45/500\n",
      "585/585 [==============================] - 0s 80us/step - loss: 1157.4611 - mean_absolute_error: 1157.4611 - val_loss: 677.5391 - val_mean_absolute_error: 677.5391\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 547.25534\n",
      "Epoch 46/500\n",
      "585/585 [==============================] - 0s 85us/step - loss: 1190.4643 - mean_absolute_error: 1190.4643 - val_loss: 692.3917 - val_mean_absolute_error: 692.3917\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 547.25534\n",
      "Epoch 47/500\n",
      "585/585 [==============================] - 0s 84us/step - loss: 1134.4466 - mean_absolute_error: 1134.4466 - val_loss: 652.1682 - val_mean_absolute_error: 652.1682\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 547.25534\n",
      "Epoch 48/500\n",
      "585/585 [==============================] - 0s 85us/step - loss: 1150.9659 - mean_absolute_error: 1150.9659 - val_loss: 663.5872 - val_mean_absolute_error: 663.5872\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 547.25534\n",
      "Epoch 49/500\n",
      "585/585 [==============================] - 0s 78us/step - loss: 1133.4710 - mean_absolute_error: 1133.4710 - val_loss: 677.2711 - val_mean_absolute_error: 677.2711\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 547.25534\n",
      "Epoch 50/500\n",
      "585/585 [==============================] - 0s 85us/step - loss: 1123.0399 - mean_absolute_error: 1123.0399 - val_loss: 671.6191 - val_mean_absolute_error: 671.6191\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 547.25534\n",
      "Epoch 51/500\n",
      "585/585 [==============================] - 0s 87us/step - loss: 1137.9230 - mean_absolute_error: 1137.9230 - val_loss: 630.1496 - val_mean_absolute_error: 630.1496\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 547.25534\n",
      "Epoch 52/500\n",
      "585/585 [==============================] - 0s 87us/step - loss: 1116.5472 - mean_absolute_error: 1116.5472 - val_loss: 684.4328 - val_mean_absolute_error: 684.4328\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 547.25534\n",
      "Epoch 53/500\n",
      "585/585 [==============================] - 0s 78us/step - loss: 1124.9028 - mean_absolute_error: 1124.9028 - val_loss: 851.2247 - val_mean_absolute_error: 851.2247\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 547.25534\n",
      "Epoch 54/500\n",
      "585/585 [==============================] - 0s 90us/step - loss: 1168.5185 - mean_absolute_error: 1168.5185 - val_loss: 682.9588 - val_mean_absolute_error: 682.9588\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 547.25534\n",
      "Epoch 55/500\n",
      "585/585 [==============================] - 0s 92us/step - loss: 1154.3452 - mean_absolute_error: 1154.3452 - val_loss: 742.6655 - val_mean_absolute_error: 742.6655\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 547.25534\n",
      "Epoch 56/500\n",
      "585/585 [==============================] - 0s 90us/step - loss: 1148.7414 - mean_absolute_error: 1148.7414 - val_loss: 744.9952 - val_mean_absolute_error: 744.9952\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 547.25534\n",
      "Epoch 57/500\n",
      "585/585 [==============================] - 0s 92us/step - loss: 1121.9604 - mean_absolute_error: 1121.9604 - val_loss: 658.2360 - val_mean_absolute_error: 658.2360\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 547.25534\n",
      "Epoch 58/500\n",
      "585/585 [==============================] - 0s 84us/step - loss: 1111.6514 - mean_absolute_error: 1111.6514 - val_loss: 662.4292 - val_mean_absolute_error: 662.4292\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 547.25534\n",
      "Epoch 59/500\n",
      "585/585 [==============================] - 0s 89us/step - loss: 1124.5630 - mean_absolute_error: 1124.5630 - val_loss: 645.4336 - val_mean_absolute_error: 645.4336\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 547.25534\n",
      "Epoch 60/500\n",
      "585/585 [==============================] - 0s 90us/step - loss: 1152.4331 - mean_absolute_error: 1152.4331 - val_loss: 654.5845 - val_mean_absolute_error: 654.5845\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 547.25534\n",
      "Epoch 61/500\n",
      "585/585 [==============================] - 0s 85us/step - loss: 1126.8636 - mean_absolute_error: 1126.8636 - val_loss: 652.6232 - val_mean_absolute_error: 652.6232\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 547.25534\n",
      "Epoch 62/500\n",
      "585/585 [==============================] - 0s 87us/step - loss: 1112.0312 - mean_absolute_error: 1112.0312 - val_loss: 691.9908 - val_mean_absolute_error: 691.9908\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 547.25534\n",
      "Epoch 63/500\n",
      "585/585 [==============================] - 0s 87us/step - loss: 1111.7042 - mean_absolute_error: 1111.7042 - val_loss: 678.3865 - val_mean_absolute_error: 678.3865\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 547.25534\n",
      "Epoch 64/500\n",
      "585/585 [==============================] - 0s 77us/step - loss: 1102.4940 - mean_absolute_error: 1102.4940 - val_loss: 647.9964 - val_mean_absolute_error: 647.9964\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 547.25534\n",
      "Epoch 65/500\n",
      "585/585 [==============================] - 0s 89us/step - loss: 1102.6355 - mean_absolute_error: 1102.6355 - val_loss: 710.7949 - val_mean_absolute_error: 710.7949\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 547.25534\n",
      "Epoch 66/500\n",
      "585/585 [==============================] - 0s 95us/step - loss: 1118.0737 - mean_absolute_error: 1118.0737 - val_loss: 654.0208 - val_mean_absolute_error: 654.0208\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 547.25534\n",
      "Epoch 67/500\n",
      "585/585 [==============================] - 0s 90us/step - loss: 1099.3856 - mean_absolute_error: 1099.3856 - val_loss: 659.8625 - val_mean_absolute_error: 659.8625\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 547.25534\n",
      "Epoch 68/500\n",
      "585/585 [==============================] - 0s 99us/step - loss: 1100.1388 - mean_absolute_error: 1100.1388 - val_loss: 668.1857 - val_mean_absolute_error: 668.1857\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 547.25534\n",
      "Epoch 69/500\n",
      "585/585 [==============================] - 0s 94us/step - loss: 1092.4034 - mean_absolute_error: 1092.4034 - val_loss: 687.1937 - val_mean_absolute_error: 687.1937\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 547.25534\n",
      "Epoch 70/500\n",
      "585/585 [==============================] - 0s 111us/step - loss: 1105.9490 - mean_absolute_error: 1105.9490 - val_loss: 675.0476 - val_mean_absolute_error: 675.0476\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 547.25534\n",
      "Epoch 71/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "585/585 [==============================] - 0s 107us/step - loss: 1093.6084 - mean_absolute_error: 1093.6084 - val_loss: 658.8795 - val_mean_absolute_error: 658.8795\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 547.25534\n",
      "Epoch 72/500\n",
      "585/585 [==============================] - 0s 95us/step - loss: 1104.4494 - mean_absolute_error: 1104.4494 - val_loss: 656.0883 - val_mean_absolute_error: 656.0883\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 547.25534\n",
      "Epoch 73/500\n",
      "585/585 [==============================] - 0s 90us/step - loss: 1089.1860 - mean_absolute_error: 1089.1860 - val_loss: 730.8752 - val_mean_absolute_error: 730.8752\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 547.25534\n",
      "Epoch 74/500\n",
      "585/585 [==============================] - 0s 101us/step - loss: 1095.1773 - mean_absolute_error: 1095.1773 - val_loss: 654.3100 - val_mean_absolute_error: 654.3100\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 547.25534\n",
      "Epoch 75/500\n",
      "585/585 [==============================] - 0s 97us/step - loss: 1100.6784 - mean_absolute_error: 1100.6784 - val_loss: 641.0950 - val_mean_absolute_error: 641.0950\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 547.25534\n",
      "Epoch 76/500\n",
      "585/585 [==============================] - 0s 95us/step - loss: 1095.3516 - mean_absolute_error: 1095.3516 - val_loss: 688.9095 - val_mean_absolute_error: 688.9095\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 547.25534\n",
      "Epoch 77/500\n",
      "585/585 [==============================] - 0s 89us/step - loss: 1088.1618 - mean_absolute_error: 1088.1618 - val_loss: 643.3985 - val_mean_absolute_error: 643.3985\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 547.25534\n",
      "Epoch 78/500\n",
      "585/585 [==============================] - 0s 94us/step - loss: 1084.8600 - mean_absolute_error: 1084.8600 - val_loss: 655.1034 - val_mean_absolute_error: 655.1034\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 547.25534\n",
      "Epoch 79/500\n",
      "585/585 [==============================] - 0s 95us/step - loss: 1082.6437 - mean_absolute_error: 1082.6437 - val_loss: 634.0269 - val_mean_absolute_error: 634.0269\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 547.25534\n",
      "Epoch 80/500\n",
      "585/585 [==============================] - 0s 92us/step - loss: 1102.8864 - mean_absolute_error: 1102.8864 - val_loss: 633.2236 - val_mean_absolute_error: 633.2236\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 547.25534\n",
      "Epoch 81/500\n",
      "585/585 [==============================] - 0s 106us/step - loss: 1084.7585 - mean_absolute_error: 1084.7585 - val_loss: 626.5566 - val_mean_absolute_error: 626.5566\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 547.25534\n",
      "Epoch 82/500\n",
      "585/585 [==============================] - 0s 101us/step - loss: 1120.8927 - mean_absolute_error: 1120.8927 - val_loss: 636.6953 - val_mean_absolute_error: 636.6953\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 547.25534\n",
      "Epoch 83/500\n",
      "585/585 [==============================] - 0s 99us/step - loss: 1097.0286 - mean_absolute_error: 1097.0286 - val_loss: 626.6525 - val_mean_absolute_error: 626.6525\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 547.25534\n",
      "Epoch 84/500\n",
      "585/585 [==============================] - 0s 90us/step - loss: 1108.6718 - mean_absolute_error: 1108.6718 - val_loss: 630.4819 - val_mean_absolute_error: 630.4819\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 547.25534\n",
      "Epoch 85/500\n",
      "585/585 [==============================] - 0s 92us/step - loss: 1089.9946 - mean_absolute_error: 1089.9946 - val_loss: 657.2791 - val_mean_absolute_error: 657.2791\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 547.25534\n",
      "Epoch 86/500\n",
      "585/585 [==============================] - 0s 99us/step - loss: 1076.3115 - mean_absolute_error: 1076.3115 - val_loss: 636.4179 - val_mean_absolute_error: 636.4179\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 547.25534\n",
      "Epoch 87/500\n",
      "585/585 [==============================] - 0s 99us/step - loss: 1081.7810 - mean_absolute_error: 1081.7810 - val_loss: 692.6065 - val_mean_absolute_error: 692.6065\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 547.25534\n",
      "Epoch 88/500\n",
      "585/585 [==============================] - 0s 92us/step - loss: 1077.8260 - mean_absolute_error: 1077.8260 - val_loss: 714.8499 - val_mean_absolute_error: 714.8499\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 547.25534\n",
      "Epoch 89/500\n",
      "585/585 [==============================] - 0s 99us/step - loss: 1074.3446 - mean_absolute_error: 1074.3446 - val_loss: 652.8324 - val_mean_absolute_error: 652.8324\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 547.25534\n",
      "Epoch 90/500\n",
      "585/585 [==============================] - 0s 95us/step - loss: 1067.9104 - mean_absolute_error: 1067.9104 - val_loss: 667.7940 - val_mean_absolute_error: 667.7940\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 547.25534\n",
      "Epoch 91/500\n",
      "585/585 [==============================] - 0s 92us/step - loss: 1080.5436 - mean_absolute_error: 1080.5436 - val_loss: 645.2620 - val_mean_absolute_error: 645.2620\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 547.25534\n",
      "Epoch 92/500\n",
      "585/585 [==============================] - 0s 104us/step - loss: 1069.3959 - mean_absolute_error: 1069.3959 - val_loss: 642.1587 - val_mean_absolute_error: 642.1587\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 547.25534\n",
      "Epoch 93/500\n",
      "585/585 [==============================] - 0s 99us/step - loss: 1073.5891 - mean_absolute_error: 1073.5891 - val_loss: 598.6247 - val_mean_absolute_error: 598.6247\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 547.25534\n",
      "Epoch 94/500\n",
      "585/585 [==============================] - 0s 109us/step - loss: 1099.1206 - mean_absolute_error: 1099.1206 - val_loss: 644.6192 - val_mean_absolute_error: 644.6192\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 547.25534\n",
      "Epoch 95/500\n",
      "585/585 [==============================] - 0s 121us/step - loss: 1067.7943 - mean_absolute_error: 1067.7943 - val_loss: 694.8607 - val_mean_absolute_error: 694.8607\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 547.25534\n",
      "Epoch 96/500\n",
      "585/585 [==============================] - 0s 113us/step - loss: 1078.4829 - mean_absolute_error: 1078.4829 - val_loss: 633.2447 - val_mean_absolute_error: 633.2447\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 547.25534\n",
      "Epoch 97/500\n",
      "585/585 [==============================] - 0s 114us/step - loss: 1101.3193 - mean_absolute_error: 1101.3193 - val_loss: 613.2121 - val_mean_absolute_error: 613.2121\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 547.25534\n",
      "Epoch 98/500\n",
      "585/585 [==============================] - 0s 116us/step - loss: 1103.1319 - mean_absolute_error: 1103.1319 - val_loss: 580.1482 - val_mean_absolute_error: 580.1482\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 547.25534\n",
      "Epoch 99/500\n",
      "585/585 [==============================] - 0s 116us/step - loss: 1115.0548 - mean_absolute_error: 1115.0548 - val_loss: 624.1834 - val_mean_absolute_error: 624.1834\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 547.25534\n",
      "Epoch 100/500\n",
      "585/585 [==============================] - 0s 119us/step - loss: 1063.0773 - mean_absolute_error: 1063.0773 - val_loss: 667.2091 - val_mean_absolute_error: 667.2091\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 547.25534\n",
      "Epoch 101/500\n",
      "585/585 [==============================] - 0s 111us/step - loss: 1075.0708 - mean_absolute_error: 1075.0708 - val_loss: 749.3525 - val_mean_absolute_error: 749.3525\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 547.25534\n",
      "Epoch 102/500\n",
      "585/585 [==============================] - 0s 118us/step - loss: 1080.5210 - mean_absolute_error: 1080.5210 - val_loss: 673.8068 - val_mean_absolute_error: 673.8068\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 547.25534\n",
      "Epoch 103/500\n",
      "585/585 [==============================] - 0s 107us/step - loss: 1062.7798 - mean_absolute_error: 1062.7798 - val_loss: 708.1188 - val_mean_absolute_error: 708.1188\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 547.25534\n",
      "Epoch 104/500\n",
      "585/585 [==============================] - 0s 97us/step - loss: 1058.8888 - mean_absolute_error: 1058.8888 - val_loss: 688.9352 - val_mean_absolute_error: 688.9352\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 547.25534\n",
      "Epoch 105/500\n",
      "585/585 [==============================] - 0s 107us/step - loss: 1066.2659 - mean_absolute_error: 1066.2659 - val_loss: 683.8185 - val_mean_absolute_error: 683.8185\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 547.25534\n",
      "Epoch 106/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "585/585 [==============================] - 0s 114us/step - loss: 1083.5224 - mean_absolute_error: 1083.5224 - val_loss: 687.5822 - val_mean_absolute_error: 687.5822\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 547.25534\n",
      "Epoch 107/500\n",
      "585/585 [==============================] - 0s 114us/step - loss: 1062.3231 - mean_absolute_error: 1062.3231 - val_loss: 663.0789 - val_mean_absolute_error: 663.0789\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 547.25534\n",
      "Epoch 108/500\n",
      "585/585 [==============================] - 0s 109us/step - loss: 1064.1027 - mean_absolute_error: 1064.1027 - val_loss: 734.1858 - val_mean_absolute_error: 734.1858\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 547.25534\n",
      "Epoch 109/500\n",
      "585/585 [==============================] - 0s 113us/step - loss: 1052.3143 - mean_absolute_error: 1052.3143 - val_loss: 653.1100 - val_mean_absolute_error: 653.1100\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 547.25534\n",
      "Epoch 110/500\n",
      "585/585 [==============================] - 0s 111us/step - loss: 1051.2647 - mean_absolute_error: 1051.2647 - val_loss: 673.7370 - val_mean_absolute_error: 673.7370\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 547.25534\n",
      "Epoch 111/500\n",
      "585/585 [==============================] - 0s 121us/step - loss: 1041.8598 - mean_absolute_error: 1041.8598 - val_loss: 626.0062 - val_mean_absolute_error: 626.0062\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 547.25534\n",
      "Epoch 112/500\n",
      "585/585 [==============================] - 0s 121us/step - loss: 1055.0190 - mean_absolute_error: 1055.0190 - val_loss: 633.6316 - val_mean_absolute_error: 633.6316\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 547.25534\n",
      "Epoch 113/500\n",
      "585/585 [==============================] - 0s 121us/step - loss: 1037.0535 - mean_absolute_error: 1037.0535 - val_loss: 657.8288 - val_mean_absolute_error: 657.8288\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 547.25534\n",
      "Epoch 114/500\n",
      "585/585 [==============================] - 0s 111us/step - loss: 1038.3039 - mean_absolute_error: 1038.3039 - val_loss: 653.7395 - val_mean_absolute_error: 653.7395\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 547.25534\n",
      "Epoch 115/500\n",
      "585/585 [==============================] - 0s 114us/step - loss: 1048.7547 - mean_absolute_error: 1048.7547 - val_loss: 670.0259 - val_mean_absolute_error: 670.0259\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 547.25534\n",
      "Epoch 116/500\n",
      "585/585 [==============================] - 0s 116us/step - loss: 1065.5917 - mean_absolute_error: 1065.5917 - val_loss: 680.4248 - val_mean_absolute_error: 680.4248\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 547.25534\n",
      "Epoch 117/500\n",
      "585/585 [==============================] - 0s 114us/step - loss: 1043.7361 - mean_absolute_error: 1043.7361 - val_loss: 686.6219 - val_mean_absolute_error: 686.6219\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 547.25534\n",
      "Epoch 118/500\n",
      "585/585 [==============================] - 0s 118us/step - loss: 1039.2710 - mean_absolute_error: 1039.2710 - val_loss: 712.2329 - val_mean_absolute_error: 712.2329\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 547.25534\n",
      "Epoch 119/500\n",
      "585/585 [==============================] - 0s 119us/step - loss: 1069.3203 - mean_absolute_error: 1069.3203 - val_loss: 645.4334 - val_mean_absolute_error: 645.4334\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 547.25534\n",
      "Epoch 120/500\n",
      "585/585 [==============================] - 0s 124us/step - loss: 1074.8666 - mean_absolute_error: 1074.8666 - val_loss: 599.6605 - val_mean_absolute_error: 599.6605\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 547.25534\n",
      "Epoch 121/500\n",
      "585/585 [==============================] - 0s 119us/step - loss: 1054.9096 - mean_absolute_error: 1054.9096 - val_loss: 630.2537 - val_mean_absolute_error: 630.2537\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 547.25534\n",
      "Epoch 122/500\n",
      "585/585 [==============================] - 0s 116us/step - loss: 1051.0639 - mean_absolute_error: 1051.0639 - val_loss: 619.2135 - val_mean_absolute_error: 619.2135\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 547.25534\n",
      "Epoch 123/500\n",
      "585/585 [==============================] - 0s 133us/step - loss: 1040.3992 - mean_absolute_error: 1040.3992 - val_loss: 662.5157 - val_mean_absolute_error: 662.5157\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 547.25534\n",
      "Epoch 124/500\n",
      "585/585 [==============================] - 0s 138us/step - loss: 1045.4928 - mean_absolute_error: 1045.4928 - val_loss: 760.9730 - val_mean_absolute_error: 760.9730\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 547.25534\n",
      "Epoch 125/500\n",
      "585/585 [==============================] - 0s 131us/step - loss: 1047.6610 - mean_absolute_error: 1047.6610 - val_loss: 689.8164 - val_mean_absolute_error: 689.8164\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 547.25534\n",
      "Epoch 126/500\n",
      "585/585 [==============================] - 0s 140us/step - loss: 1033.9698 - mean_absolute_error: 1033.9698 - val_loss: 725.0252 - val_mean_absolute_error: 725.0252\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 547.25534\n",
      "Epoch 127/500\n",
      "585/585 [==============================] - 0s 119us/step - loss: 1026.8000 - mean_absolute_error: 1026.8000 - val_loss: 728.8265 - val_mean_absolute_error: 728.8265\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 547.25534\n",
      "Epoch 128/500\n",
      "585/585 [==============================] - 0s 119us/step - loss: 1062.9389 - mean_absolute_error: 1062.9389 - val_loss: 684.8493 - val_mean_absolute_error: 684.8493\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 547.25534\n",
      "Epoch 129/500\n",
      "585/585 [==============================] - 0s 136us/step - loss: 1031.2520 - mean_absolute_error: 1031.2520 - val_loss: 615.1990 - val_mean_absolute_error: 615.1990\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 547.25534\n",
      "Epoch 130/500\n",
      "585/585 [==============================] - 0s 123us/step - loss: 1019.7204 - mean_absolute_error: 1019.7204 - val_loss: 630.8255 - val_mean_absolute_error: 630.8255\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 547.25534\n",
      "Epoch 131/500\n",
      "585/585 [==============================] - 0s 119us/step - loss: 1030.2052 - mean_absolute_error: 1030.2052 - val_loss: 632.4237 - val_mean_absolute_error: 632.4237\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 547.25534\n",
      "Epoch 132/500\n",
      "585/585 [==============================] - 0s 133us/step - loss: 1031.9929 - mean_absolute_error: 1031.9929 - val_loss: 632.9022 - val_mean_absolute_error: 632.9022\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 547.25534\n",
      "Epoch 133/500\n",
      "585/585 [==============================] - 0s 131us/step - loss: 1032.1609 - mean_absolute_error: 1032.1609 - val_loss: 650.9953 - val_mean_absolute_error: 650.9953\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 547.25534\n",
      "Epoch 134/500\n",
      "585/585 [==============================] - 0s 116us/step - loss: 1025.6840 - mean_absolute_error: 1025.6840 - val_loss: 703.4894 - val_mean_absolute_error: 703.4894\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 547.25534\n",
      "Epoch 135/500\n",
      "585/585 [==============================] - 0s 121us/step - loss: 1026.8164 - mean_absolute_error: 1026.8164 - val_loss: 627.5649 - val_mean_absolute_error: 627.5649\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 547.25534\n",
      "Epoch 136/500\n",
      "585/585 [==============================] - 0s 138us/step - loss: 1014.9906 - mean_absolute_error: 1014.9906 - val_loss: 610.1877 - val_mean_absolute_error: 610.1877\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 547.25534\n",
      "Epoch 137/500\n",
      "585/585 [==============================] - 0s 131us/step - loss: 1021.5255 - mean_absolute_error: 1021.5255 - val_loss: 678.6899 - val_mean_absolute_error: 678.6899\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 547.25534\n",
      "Epoch 138/500\n",
      "585/585 [==============================] - 0s 138us/step - loss: 1008.5612 - mean_absolute_error: 1008.5612 - val_loss: 653.3572 - val_mean_absolute_error: 653.3572\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 547.25534\n",
      "Epoch 139/500\n",
      "585/585 [==============================] - 0s 118us/step - loss: 1013.4105 - mean_absolute_error: 1013.4105 - val_loss: 645.0971 - val_mean_absolute_error: 645.0971\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 547.25534\n",
      "Epoch 140/500\n",
      "585/585 [==============================] - 0s 113us/step - loss: 1006.6978 - mean_absolute_error: 1006.6978 - val_loss: 664.4480 - val_mean_absolute_error: 664.4480\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 547.25534\n",
      "Epoch 141/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "585/585 [==============================] - 0s 116us/step - loss: 1036.4655 - mean_absolute_error: 1036.4655 - val_loss: 728.1688 - val_mean_absolute_error: 728.1688\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 547.25534\n",
      "Epoch 142/500\n",
      "585/585 [==============================] - 0s 99us/step - loss: 1046.5318 - mean_absolute_error: 1046.5318 - val_loss: 688.1003 - val_mean_absolute_error: 688.1003\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 547.25534\n",
      "Epoch 143/500\n",
      "585/585 [==============================] - 0s 109us/step - loss: 1008.4635 - mean_absolute_error: 1008.4635 - val_loss: 718.9421 - val_mean_absolute_error: 718.9421\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 547.25534\n",
      "Epoch 144/500\n",
      "585/585 [==============================] - 0s 113us/step - loss: 1013.9228 - mean_absolute_error: 1013.9228 - val_loss: 636.4983 - val_mean_absolute_error: 636.4983\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 547.25534\n",
      "Epoch 145/500\n",
      "585/585 [==============================] - 0s 121us/step - loss: 1002.0534 - mean_absolute_error: 1002.0534 - val_loss: 697.0198 - val_mean_absolute_error: 697.0198\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 547.25534\n",
      "Epoch 146/500\n",
      "585/585 [==============================] - 0s 131us/step - loss: 1005.0578 - mean_absolute_error: 1005.0578 - val_loss: 698.2490 - val_mean_absolute_error: 698.2490\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 547.25534\n",
      "Epoch 147/500\n",
      "585/585 [==============================] - 0s 118us/step - loss: 1012.8736 - mean_absolute_error: 1012.8736 - val_loss: 669.7720 - val_mean_absolute_error: 669.7720\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 547.25534\n",
      "Epoch 148/500\n",
      "585/585 [==============================] - 0s 118us/step - loss: 1006.5490 - mean_absolute_error: 1006.5490 - val_loss: 637.7317 - val_mean_absolute_error: 637.7317\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 547.25534\n",
      "Epoch 149/500\n",
      "585/585 [==============================] - 0s 130us/step - loss: 1029.8959 - mean_absolute_error: 1029.8959 - val_loss: 626.0281 - val_mean_absolute_error: 626.0281\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 547.25534\n",
      "Epoch 150/500\n",
      "585/585 [==============================] - 0s 119us/step - loss: 996.6945 - mean_absolute_error: 996.6945 - val_loss: 602.6774 - val_mean_absolute_error: 602.6774\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 547.25534\n",
      "Epoch 151/500\n",
      "585/585 [==============================] - 0s 124us/step - loss: 999.6590 - mean_absolute_error: 999.6590 - val_loss: 646.8924 - val_mean_absolute_error: 646.8924\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 547.25534\n",
      "Epoch 152/500\n",
      "585/585 [==============================] - 0s 128us/step - loss: 989.5748 - mean_absolute_error: 989.5748 - val_loss: 639.9924 - val_mean_absolute_error: 639.9924\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 547.25534\n",
      "Epoch 153/500\n",
      "585/585 [==============================] - 0s 123us/step - loss: 993.3540 - mean_absolute_error: 993.3540 - val_loss: 624.1403 - val_mean_absolute_error: 624.1403\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 547.25534\n",
      "Epoch 154/500\n",
      "585/585 [==============================] - 0s 121us/step - loss: 1017.8201 - mean_absolute_error: 1017.8201 - val_loss: 601.8931 - val_mean_absolute_error: 601.8931\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 547.25534\n",
      "Epoch 155/500\n",
      "585/585 [==============================] - 0s 133us/step - loss: 1011.6217 - mean_absolute_error: 1011.6217 - val_loss: 670.8011 - val_mean_absolute_error: 670.8011\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 547.25534\n",
      "Epoch 156/500\n",
      "585/585 [==============================] - 0s 128us/step - loss: 1028.3781 - mean_absolute_error: 1028.3781 - val_loss: 681.3889 - val_mean_absolute_error: 681.3889\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 547.25534\n",
      "Epoch 157/500\n",
      "585/585 [==============================] - 0s 116us/step - loss: 983.1874 - mean_absolute_error: 983.1874 - val_loss: 580.8731 - val_mean_absolute_error: 580.8731\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 547.25534\n",
      "Epoch 158/500\n",
      "585/585 [==============================] - 0s 138us/step - loss: 1028.2037 - mean_absolute_error: 1028.2037 - val_loss: 616.9974 - val_mean_absolute_error: 616.9974\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 547.25534\n",
      "Epoch 159/500\n",
      "585/585 [==============================] - 0s 131us/step - loss: 984.6430 - mean_absolute_error: 984.6430 - val_loss: 690.1446 - val_mean_absolute_error: 690.1446\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 547.25534\n",
      "Epoch 160/500\n",
      "585/585 [==============================] - 0s 140us/step - loss: 1011.3723 - mean_absolute_error: 1011.3723 - val_loss: 634.5883 - val_mean_absolute_error: 634.5883\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 547.25534\n",
      "Epoch 161/500\n",
      "585/585 [==============================] - 0s 131us/step - loss: 1030.3717 - mean_absolute_error: 1030.3717 - val_loss: 587.8641 - val_mean_absolute_error: 587.8641\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 547.25534\n",
      "Epoch 162/500\n",
      "585/585 [==============================] - 0s 126us/step - loss: 999.8402 - mean_absolute_error: 999.8402 - val_loss: 621.1569 - val_mean_absolute_error: 621.1569\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 547.25534\n",
      "Epoch 163/500\n",
      "585/585 [==============================] - 0s 128us/step - loss: 990.3824 - mean_absolute_error: 990.3824 - val_loss: 625.8123 - val_mean_absolute_error: 625.8123\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 547.25534\n",
      "Epoch 164/500\n",
      "585/585 [==============================] - 0s 130us/step - loss: 985.2780 - mean_absolute_error: 985.2780 - val_loss: 645.6419 - val_mean_absolute_error: 645.6419\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 547.25534\n",
      "Epoch 165/500\n",
      "585/585 [==============================] - 0s 140us/step - loss: 990.9904 - mean_absolute_error: 990.9904 - val_loss: 554.7649 - val_mean_absolute_error: 554.7649\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 547.25534\n",
      "Epoch 166/500\n",
      "585/585 [==============================] - 0s 124us/step - loss: 1061.6886 - mean_absolute_error: 1061.6886 - val_loss: 551.8242 - val_mean_absolute_error: 551.8242\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 547.25534\n",
      "Epoch 167/500\n",
      "585/585 [==============================] - 0s 133us/step - loss: 1057.3485 - mean_absolute_error: 1057.3485 - val_loss: 561.2605 - val_mean_absolute_error: 561.2605\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 547.25534\n",
      "Epoch 168/500\n",
      "585/585 [==============================] - 0s 130us/step - loss: 1062.0988 - mean_absolute_error: 1062.0988 - val_loss: 548.1177 - val_mean_absolute_error: 548.1177\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 547.25534\n",
      "Epoch 169/500\n",
      "585/585 [==============================] - 0s 142us/step - loss: 1012.7190 - mean_absolute_error: 1012.7190 - val_loss: 550.9550 - val_mean_absolute_error: 550.9550\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 547.25534\n",
      "Epoch 170/500\n",
      "585/585 [==============================] - 0s 126us/step - loss: 1002.2644 - mean_absolute_error: 1002.2644 - val_loss: 691.8241 - val_mean_absolute_error: 691.8241\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 547.25534\n",
      "Epoch 171/500\n",
      "585/585 [==============================] - 0s 131us/step - loss: 985.4678 - mean_absolute_error: 985.4678 - val_loss: 633.3928 - val_mean_absolute_error: 633.3928\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 547.25534\n",
      "Epoch 172/500\n",
      "585/585 [==============================] - 0s 135us/step - loss: 976.4067 - mean_absolute_error: 976.4067 - val_loss: 619.0097 - val_mean_absolute_error: 619.0097\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 547.25534\n",
      "Epoch 173/500\n",
      "585/585 [==============================] - 0s 126us/step - loss: 971.9043 - mean_absolute_error: 971.9043 - val_loss: 593.9787 - val_mean_absolute_error: 593.9787\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 547.25534\n",
      "Epoch 174/500\n",
      "585/585 [==============================] - 0s 130us/step - loss: 966.9725 - mean_absolute_error: 966.9725 - val_loss: 651.7346 - val_mean_absolute_error: 651.7346\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 547.25534\n",
      "Epoch 175/500\n",
      "585/585 [==============================] - 0s 128us/step - loss: 974.4340 - mean_absolute_error: 974.4340 - val_loss: 578.8187 - val_mean_absolute_error: 578.8187\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 547.25534\n",
      "Epoch 176/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "585/585 [==============================] - 0s 123us/step - loss: 969.0983 - mean_absolute_error: 969.0983 - val_loss: 626.5026 - val_mean_absolute_error: 626.5026\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 547.25534\n",
      "Epoch 177/500\n",
      "585/585 [==============================] - 0s 119us/step - loss: 982.6313 - mean_absolute_error: 982.6313 - val_loss: 606.8321 - val_mean_absolute_error: 606.8321\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 547.25534\n",
      "Epoch 178/500\n",
      "585/585 [==============================] - 0s 138us/step - loss: 965.6937 - mean_absolute_error: 965.6937 - val_loss: 619.0128 - val_mean_absolute_error: 619.0128\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 547.25534\n",
      "Epoch 179/500\n",
      "585/585 [==============================] - 0s 131us/step - loss: 988.1865 - mean_absolute_error: 988.1865 - val_loss: 628.7174 - val_mean_absolute_error: 628.7174\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 547.25534\n",
      "Epoch 180/500\n",
      "585/585 [==============================] - 0s 135us/step - loss: 959.2261 - mean_absolute_error: 959.2261 - val_loss: 599.5068 - val_mean_absolute_error: 599.5068\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 547.25534\n",
      "Epoch 181/500\n",
      "585/585 [==============================] - 0s 131us/step - loss: 962.0499 - mean_absolute_error: 962.0499 - val_loss: 559.5773 - val_mean_absolute_error: 559.5773\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 547.25534\n",
      "Epoch 182/500\n",
      "585/585 [==============================] - 0s 126us/step - loss: 995.8400 - mean_absolute_error: 995.8400 - val_loss: 622.8753 - val_mean_absolute_error: 622.8753\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 547.25534\n",
      "Epoch 183/500\n",
      "585/585 [==============================] - 0s 131us/step - loss: 1000.0251 - mean_absolute_error: 1000.0251 - val_loss: 641.5565 - val_mean_absolute_error: 641.5565\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 547.25534\n",
      "Epoch 184/500\n",
      "585/585 [==============================] - 0s 140us/step - loss: 958.6977 - mean_absolute_error: 958.6977 - val_loss: 616.1977 - val_mean_absolute_error: 616.1977\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 547.25534\n",
      "Epoch 185/500\n",
      "585/585 [==============================] - 0s 138us/step - loss: 966.5089 - mean_absolute_error: 966.5089 - val_loss: 573.7301 - val_mean_absolute_error: 573.7301\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 547.25534\n",
      "Epoch 186/500\n",
      "585/585 [==============================] - 0s 128us/step - loss: 995.8419 - mean_absolute_error: 995.8419 - val_loss: 579.0877 - val_mean_absolute_error: 579.0877\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 547.25534\n",
      "Epoch 187/500\n",
      "585/585 [==============================] - 0s 128us/step - loss: 980.0078 - mean_absolute_error: 980.0078 - val_loss: 647.3010 - val_mean_absolute_error: 647.3010\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 547.25534\n",
      "Epoch 188/500\n",
      "585/585 [==============================] - 0s 143us/step - loss: 958.4519 - mean_absolute_error: 958.4519 - val_loss: 667.4334 - val_mean_absolute_error: 667.4334\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 547.25534\n",
      "Epoch 189/500\n",
      "585/585 [==============================] - 0s 142us/step - loss: 954.8325 - mean_absolute_error: 954.8325 - val_loss: 590.7390 - val_mean_absolute_error: 590.7390\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 547.25534\n",
      "Epoch 190/500\n",
      "585/585 [==============================] - 0s 136us/step - loss: 985.4362 - mean_absolute_error: 985.4362 - val_loss: 570.1316 - val_mean_absolute_error: 570.1316\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 547.25534\n",
      "Epoch 191/500\n",
      "585/585 [==============================] - ETA: 0s - loss: 924.5099 - mean_absolute_error: 924.5099  - 0s 140us/step - loss: 955.5244 - mean_absolute_error: 955.5244 - val_loss: 623.6180 - val_mean_absolute_error: 623.6180\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 547.25534\n",
      "Epoch 192/500\n",
      "585/585 [==============================] - 0s 138us/step - loss: 954.2610 - mean_absolute_error: 954.2610 - val_loss: 594.8234 - val_mean_absolute_error: 594.8234\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 547.25534\n",
      "Epoch 193/500\n",
      "585/585 [==============================] - 0s 128us/step - loss: 979.0293 - mean_absolute_error: 979.0293 - val_loss: 597.4089 - val_mean_absolute_error: 597.4089\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 547.25534\n",
      "Epoch 194/500\n",
      "585/585 [==============================] - 0s 119us/step - loss: 941.8488 - mean_absolute_error: 941.8488 - val_loss: 632.6371 - val_mean_absolute_error: 632.6371\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 547.25534\n",
      "Epoch 195/500\n",
      "585/585 [==============================] - 0s 126us/step - loss: 951.9110 - mean_absolute_error: 951.9110 - val_loss: 652.5550 - val_mean_absolute_error: 652.5550\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 547.25534\n",
      "Epoch 196/500\n",
      "585/585 [==============================] - 0s 138us/step - loss: 963.8473 - mean_absolute_error: 963.8473 - val_loss: 644.9612 - val_mean_absolute_error: 644.9612\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 547.25534\n",
      "Epoch 197/500\n",
      "585/585 [==============================] - 0s 138us/step - loss: 980.8821 - mean_absolute_error: 980.8821 - val_loss: 597.0423 - val_mean_absolute_error: 597.0423\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 547.25534\n",
      "Epoch 198/500\n",
      "585/585 [==============================] - 0s 131us/step - loss: 951.2858 - mean_absolute_error: 951.2858 - val_loss: 572.1718 - val_mean_absolute_error: 572.1718\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 547.25534\n",
      "Epoch 199/500\n",
      "585/585 [==============================] - 0s 118us/step - loss: 943.4385 - mean_absolute_error: 943.4385 - val_loss: 595.2098 - val_mean_absolute_error: 595.2098\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 547.25534\n",
      "Epoch 200/500\n",
      "585/585 [==============================] - 0s 128us/step - loss: 946.7109 - mean_absolute_error: 946.7109 - val_loss: 604.7911 - val_mean_absolute_error: 604.7911\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 547.25534\n",
      "Epoch 201/500\n",
      "585/585 [==============================] - 0s 119us/step - loss: 942.9362 - mean_absolute_error: 942.9362 - val_loss: 563.0988 - val_mean_absolute_error: 563.0988\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 547.25534\n",
      "Epoch 202/500\n",
      "585/585 [==============================] - 0s 135us/step - loss: 937.1807 - mean_absolute_error: 937.1807 - val_loss: 729.5199 - val_mean_absolute_error: 729.5199\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 547.25534\n",
      "Epoch 203/500\n",
      "585/585 [==============================] - 0s 128us/step - loss: 986.6226 - mean_absolute_error: 986.6226 - val_loss: 644.0317 - val_mean_absolute_error: 644.0317\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 547.25534\n",
      "Epoch 204/500\n",
      "585/585 [==============================] - 0s 124us/step - loss: 966.6573 - mean_absolute_error: 966.6573 - val_loss: 553.8730 - val_mean_absolute_error: 553.8730\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 547.25534\n",
      "Epoch 205/500\n",
      "585/585 [==============================] - 0s 124us/step - loss: 939.9980 - mean_absolute_error: 939.9980 - val_loss: 613.3334 - val_mean_absolute_error: 613.3334\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 547.25534\n",
      "Epoch 206/500\n",
      "585/585 [==============================] - 0s 131us/step - loss: 937.5777 - mean_absolute_error: 937.5777 - val_loss: 579.2104 - val_mean_absolute_error: 579.2104\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 547.25534\n",
      "Epoch 207/500\n",
      "585/585 [==============================] - 0s 143us/step - loss: 968.3797 - mean_absolute_error: 968.3797 - val_loss: 603.7944 - val_mean_absolute_error: 603.7944\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 547.25534\n",
      "Epoch 208/500\n",
      "585/585 [==============================] - 0s 130us/step - loss: 934.9083 - mean_absolute_error: 934.9083 - val_loss: 611.5529 - val_mean_absolute_error: 611.5529\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 547.25534\n",
      "Epoch 209/500\n",
      "585/585 [==============================] - 0s 136us/step - loss: 935.9804 - mean_absolute_error: 935.9804 - val_loss: 671.2911 - val_mean_absolute_error: 671.2911\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 547.25534\n",
      "Epoch 210/500\n",
      "585/585 [==============================] - 0s 143us/step - loss: 933.8186 - mean_absolute_error: 933.8186 - val_loss: 544.6157 - val_mean_absolute_error: 544.6157\n",
      "\n",
      "Epoch 00210: val_loss improved from 547.25534 to 544.61573, saving model to 선케어date-Weights-210--544.61573-cat04-vf05.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 211/500\n",
      "585/585 [==============================] - 0s 118us/step - loss: 936.1910 - mean_absolute_error: 936.1910 - val_loss: 578.7354 - val_mean_absolute_error: 578.7354\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 544.61573\n",
      "Epoch 212/500\n",
      "585/585 [==============================] - 0s 118us/step - loss: 935.8694 - mean_absolute_error: 935.8694 - val_loss: 603.1607 - val_mean_absolute_error: 603.1607\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 544.61573\n",
      "Epoch 213/500\n",
      "585/585 [==============================] - 0s 138us/step - loss: 948.6730 - mean_absolute_error: 948.6730 - val_loss: 564.9634 - val_mean_absolute_error: 564.9634\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 544.61573\n",
      "Epoch 214/500\n",
      "585/585 [==============================] - 0s 119us/step - loss: 934.1552 - mean_absolute_error: 934.1552 - val_loss: 551.9810 - val_mean_absolute_error: 551.9810\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 544.61573\n",
      "Epoch 215/500\n",
      "585/585 [==============================] - 0s 130us/step - loss: 930.2609 - mean_absolute_error: 930.2609 - val_loss: 542.6469 - val_mean_absolute_error: 542.6469\n",
      "\n",
      "Epoch 00215: val_loss improved from 544.61573 to 542.64689, saving model to 선케어date-Weights-215--542.64689-cat04-vf05.hdf5\n",
      "Epoch 216/500\n",
      "585/585 [==============================] - 0s 114us/step - loss: 965.0031 - mean_absolute_error: 965.0031 - val_loss: 577.4593 - val_mean_absolute_error: 577.4593\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 542.64689\n",
      "Epoch 217/500\n",
      "585/585 [==============================] - 0s 121us/step - loss: 949.7270 - mean_absolute_error: 949.7270 - val_loss: 636.6966 - val_mean_absolute_error: 636.6966\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 542.64689\n",
      "Epoch 218/500\n",
      "585/585 [==============================] - 0s 133us/step - loss: 955.3852 - mean_absolute_error: 955.3852 - val_loss: 609.5602 - val_mean_absolute_error: 609.5602\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 542.64689\n",
      "Epoch 219/500\n",
      "585/585 [==============================] - 0s 126us/step - loss: 929.0612 - mean_absolute_error: 929.0612 - val_loss: 613.7289 - val_mean_absolute_error: 613.7289\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 542.64689\n",
      "Epoch 220/500\n",
      "585/585 [==============================] - 0s 128us/step - loss: 923.9073 - mean_absolute_error: 923.9073 - val_loss: 627.6133 - val_mean_absolute_error: 627.6133\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 542.64689\n",
      "Epoch 221/500\n",
      "585/585 [==============================] - 0s 131us/step - loss: 939.8769 - mean_absolute_error: 939.8769 - val_loss: 596.1779 - val_mean_absolute_error: 596.1779\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 542.64689\n",
      "Epoch 222/500\n",
      "585/585 [==============================] - 0s 145us/step - loss: 954.9256 - mean_absolute_error: 954.9256 - val_loss: 586.0470 - val_mean_absolute_error: 586.0470\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 542.64689\n",
      "Epoch 223/500\n",
      "585/585 [==============================] - 0s 124us/step - loss: 916.3190 - mean_absolute_error: 916.3190 - val_loss: 607.5438 - val_mean_absolute_error: 607.5438\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 542.64689\n",
      "Epoch 224/500\n",
      "585/585 [==============================] - 0s 138us/step - loss: 931.9010 - mean_absolute_error: 931.9010 - val_loss: 665.7635 - val_mean_absolute_error: 665.7635\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 542.64689\n",
      "Epoch 225/500\n",
      "585/585 [==============================] - 0s 263us/step - loss: 935.3975 - mean_absolute_error: 935.3975 - val_loss: 557.2312 - val_mean_absolute_error: 557.2312\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 542.64689\n",
      "Epoch 226/500\n",
      "585/585 [==============================] - 0s 370us/step - loss: 934.2095 - mean_absolute_error: 934.2095 - val_loss: 587.7217 - val_mean_absolute_error: 587.7217\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 542.64689\n",
      "Epoch 227/500\n",
      "585/585 [==============================] - 0s 135us/step - loss: 924.8867 - mean_absolute_error: 924.8867 - val_loss: 679.2174 - val_mean_absolute_error: 679.2174\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 542.64689\n",
      "Epoch 228/500\n",
      "585/585 [==============================] - 0s 116us/step - loss: 957.4786 - mean_absolute_error: 957.4786 - val_loss: 568.9200 - val_mean_absolute_error: 568.9200\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 542.64689\n",
      "Epoch 229/500\n",
      "585/585 [==============================] - 0s 135us/step - loss: 928.1740 - mean_absolute_error: 928.1740 - val_loss: 535.5870 - val_mean_absolute_error: 535.5870\n",
      "\n",
      "Epoch 00229: val_loss improved from 542.64689 to 535.58702, saving model to 선케어date-Weights-229--535.58702-cat04-vf05.hdf5\n",
      "Epoch 230/500\n",
      "585/585 [==============================] - 0s 123us/step - loss: 929.6847 - mean_absolute_error: 929.6847 - val_loss: 559.5216 - val_mean_absolute_error: 559.5216\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 535.58702\n",
      "Epoch 231/500\n",
      "585/585 [==============================] - 0s 126us/step - loss: 919.8958 - mean_absolute_error: 919.8958 - val_loss: 596.0390 - val_mean_absolute_error: 596.0390\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 535.58702\n",
      "Epoch 232/500\n",
      "585/585 [==============================] - 0s 136us/step - loss: 927.8454 - mean_absolute_error: 927.8454 - val_loss: 631.0338 - val_mean_absolute_error: 631.0338\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 535.58702\n",
      "Epoch 233/500\n",
      "585/585 [==============================] - 0s 114us/step - loss: 912.3042 - mean_absolute_error: 912.3042 - val_loss: 620.8023 - val_mean_absolute_error: 620.8023\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 535.58702\n",
      "Epoch 234/500\n",
      "585/585 [==============================] - 0s 119us/step - loss: 925.7365 - mean_absolute_error: 925.7365 - val_loss: 588.7969 - val_mean_absolute_error: 588.7969\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 535.58702\n",
      "Epoch 235/500\n",
      "585/585 [==============================] - 0s 133us/step - loss: 929.2725 - mean_absolute_error: 929.2725 - val_loss: 668.1082 - val_mean_absolute_error: 668.1082\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 535.58702\n",
      "Epoch 236/500\n",
      "585/585 [==============================] - 0s 114us/step - loss: 927.4620 - mean_absolute_error: 927.4620 - val_loss: 683.5949 - val_mean_absolute_error: 683.5949\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 535.58702\n",
      "Epoch 237/500\n",
      "585/585 [==============================] - 0s 114us/step - loss: 927.4706 - mean_absolute_error: 927.4706 - val_loss: 597.2930 - val_mean_absolute_error: 597.2930\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 535.58702\n",
      "Epoch 238/500\n",
      "585/585 [==============================] - 0s 114us/step - loss: 909.7360 - mean_absolute_error: 909.7360 - val_loss: 524.9580 - val_mean_absolute_error: 524.9580\n",
      "\n",
      "Epoch 00238: val_loss improved from 535.58702 to 524.95797, saving model to 선케어date-Weights-238--524.95797-cat04-vf05.hdf5\n",
      "Epoch 239/500\n",
      "585/585 [==============================] - 0s 124us/step - loss: 958.7845 - mean_absolute_error: 958.7845 - val_loss: 526.8229 - val_mean_absolute_error: 526.8229\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 524.95797\n",
      "Epoch 240/500\n",
      "585/585 [==============================] - 0s 131us/step - loss: 924.6200 - mean_absolute_error: 924.6200 - val_loss: 599.0039 - val_mean_absolute_error: 599.0039\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 524.95797\n",
      "Epoch 241/500\n",
      "585/585 [==============================] - 0s 124us/step - loss: 919.1435 - mean_absolute_error: 919.1435 - val_loss: 597.0877 - val_mean_absolute_error: 597.0877\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 524.95797\n",
      "Epoch 242/500\n",
      "585/585 [==============================] - 0s 121us/step - loss: 953.3946 - mean_absolute_error: 953.3946 - val_loss: 569.2168 - val_mean_absolute_error: 569.2168\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 524.95797\n",
      "Epoch 243/500\n",
      "585/585 [==============================] - 0s 121us/step - loss: 917.4796 - mean_absolute_error: 917.4796 - val_loss: 575.0401 - val_mean_absolute_error: 575.0401\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 524.95797\n",
      "Epoch 244/500\n",
      "585/585 [==============================] - 0s 119us/step - loss: 917.4629 - mean_absolute_error: 917.4629 - val_loss: 565.1485 - val_mean_absolute_error: 565.1485\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 524.95797\n",
      "Epoch 245/500\n",
      "585/585 [==============================] - 0s 142us/step - loss: 921.5548 - mean_absolute_error: 921.5548 - val_loss: 593.8681 - val_mean_absolute_error: 593.8681\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00245: val_loss did not improve from 524.95797\n",
      "Epoch 246/500\n",
      "585/585 [==============================] - 0s 130us/step - loss: 925.2535 - mean_absolute_error: 925.2535 - val_loss: 575.4700 - val_mean_absolute_error: 575.4700\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 524.95797\n",
      "Epoch 247/500\n",
      "585/585 [==============================] - 0s 121us/step - loss: 917.5661 - mean_absolute_error: 917.5661 - val_loss: 607.5830 - val_mean_absolute_error: 607.5830\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 524.95797\n",
      "Epoch 248/500\n",
      "585/585 [==============================] - 0s 124us/step - loss: 937.5934 - mean_absolute_error: 937.5934 - val_loss: 545.6942 - val_mean_absolute_error: 545.6942\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 524.95797\n",
      "Epoch 249/500\n",
      "585/585 [==============================] - 0s 147us/step - loss: 904.0371 - mean_absolute_error: 904.0371 - val_loss: 599.7125 - val_mean_absolute_error: 599.7125\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 524.95797\n",
      "Epoch 250/500\n",
      "585/585 [==============================] - 0s 143us/step - loss: 914.7296 - mean_absolute_error: 914.7296 - val_loss: 585.0013 - val_mean_absolute_error: 585.0013\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 524.95797\n",
      "Epoch 251/500\n",
      "585/585 [==============================] - 0s 135us/step - loss: 912.0602 - mean_absolute_error: 912.0602 - val_loss: 526.7636 - val_mean_absolute_error: 526.7636\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 524.95797\n",
      "Epoch 252/500\n",
      "585/585 [==============================] - 0s 140us/step - loss: 971.7327 - mean_absolute_error: 971.7327 - val_loss: 550.6364 - val_mean_absolute_error: 550.6364\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 524.95797\n",
      "Epoch 253/500\n",
      "585/585 [==============================] - 0s 150us/step - loss: 938.4014 - mean_absolute_error: 938.4014 - val_loss: 619.0894 - val_mean_absolute_error: 619.0894\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 524.95797\n",
      "Epoch 254/500\n",
      "585/585 [==============================] - 0s 157us/step - loss: 924.3918 - mean_absolute_error: 924.3918 - val_loss: 605.4408 - val_mean_absolute_error: 605.4408\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 524.95797\n",
      "Epoch 255/500\n",
      "585/585 [==============================] - 0s 179us/step - loss: 912.3372 - mean_absolute_error: 912.3372 - val_loss: 574.2979 - val_mean_absolute_error: 574.2979\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 524.95797\n",
      "Epoch 256/500\n",
      "585/585 [==============================] - 0s 169us/step - loss: 906.1530 - mean_absolute_error: 906.1530 - val_loss: 561.7003 - val_mean_absolute_error: 561.7003\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 524.95797\n",
      "Epoch 257/500\n",
      "585/585 [==============================] - 0s 169us/step - loss: 904.8021 - mean_absolute_error: 904.8021 - val_loss: 550.0509 - val_mean_absolute_error: 550.0509\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 524.95797\n",
      "Epoch 258/500\n",
      "585/585 [==============================] - 0s 170us/step - loss: 920.3912 - mean_absolute_error: 920.3912 - val_loss: 606.3003 - val_mean_absolute_error: 606.3003\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 524.95797\n",
      "Epoch 259/500\n",
      "585/585 [==============================] - 0s 164us/step - loss: 946.6982 - mean_absolute_error: 946.6982 - val_loss: 565.2655 - val_mean_absolute_error: 565.2655\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 524.95797\n",
      "Epoch 260/500\n",
      "585/585 [==============================] - 0s 162us/step - loss: 922.3279 - mean_absolute_error: 922.3279 - val_loss: 606.9645 - val_mean_absolute_error: 606.9645\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 524.95797\n",
      "Epoch 261/500\n",
      "585/585 [==============================] - 0s 160us/step - loss: 919.4258 - mean_absolute_error: 919.4258 - val_loss: 563.3636 - val_mean_absolute_error: 563.3636\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 524.95797\n",
      "Epoch 262/500\n",
      "585/585 [==============================] - 0s 165us/step - loss: 895.2685 - mean_absolute_error: 895.2685 - val_loss: 588.9543 - val_mean_absolute_error: 588.9543\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 524.95797\n",
      "Epoch 263/500\n",
      "585/585 [==============================] - 0s 152us/step - loss: 906.1462 - mean_absolute_error: 906.1462 - val_loss: 585.3125 - val_mean_absolute_error: 585.3125\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 524.95797\n",
      "Epoch 264/500\n",
      "585/585 [==============================] - 0s 164us/step - loss: 905.6336 - mean_absolute_error: 905.6336 - val_loss: 537.1185 - val_mean_absolute_error: 537.1185\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 524.95797\n",
      "Epoch 265/500\n",
      "585/585 [==============================] - 0s 153us/step - loss: 911.2212 - mean_absolute_error: 911.2212 - val_loss: 555.7006 - val_mean_absolute_error: 555.7006\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 524.95797\n",
      "Epoch 266/500\n",
      "585/585 [==============================] - 0s 147us/step - loss: 904.2426 - mean_absolute_error: 904.2426 - val_loss: 616.3171 - val_mean_absolute_error: 616.3171\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 524.95797\n",
      "Epoch 267/500\n",
      "585/585 [==============================] - 0s 160us/step - loss: 903.3094 - mean_absolute_error: 903.3094 - val_loss: 622.7048 - val_mean_absolute_error: 622.7048\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 524.95797\n",
      "Epoch 268/500\n",
      "585/585 [==============================] - 0s 157us/step - loss: 898.4821 - mean_absolute_error: 898.4821 - val_loss: 552.9932 - val_mean_absolute_error: 552.9932\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 524.95797\n",
      "Epoch 269/500\n",
      "585/585 [==============================] - 0s 143us/step - loss: 955.3348 - mean_absolute_error: 955.3348 - val_loss: 583.5131 - val_mean_absolute_error: 583.5131\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 524.95797\n",
      "Epoch 270/500\n",
      "585/585 [==============================] - 0s 136us/step - loss: 892.4128 - mean_absolute_error: 892.4128 - val_loss: 548.4431 - val_mean_absolute_error: 548.4431\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 524.95797\n",
      "Epoch 271/500\n",
      "585/585 [==============================] - 0s 145us/step - loss: 903.9853 - mean_absolute_error: 903.9853 - val_loss: 580.3943 - val_mean_absolute_error: 580.3943\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 524.95797\n",
      "Epoch 272/500\n",
      "585/585 [==============================] - 0s 150us/step - loss: 889.6918 - mean_absolute_error: 889.6918 - val_loss: 625.9167 - val_mean_absolute_error: 625.9167\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 524.95797\n",
      "Epoch 273/500\n",
      "585/585 [==============================] - 0s 135us/step - loss: 951.3337 - mean_absolute_error: 951.3337 - val_loss: 623.5278 - val_mean_absolute_error: 623.5278\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 524.95797\n",
      "Epoch 274/500\n",
      "585/585 [==============================] - 0s 138us/step - loss: 895.7528 - mean_absolute_error: 895.7528 - val_loss: 615.2194 - val_mean_absolute_error: 615.2194\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 524.95797\n",
      "Epoch 275/500\n",
      "585/585 [==============================] - 0s 138us/step - loss: 902.4849 - mean_absolute_error: 902.4849 - val_loss: 593.0053 - val_mean_absolute_error: 593.0053\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 524.95797\n",
      "Epoch 276/500\n",
      "585/585 [==============================] - 0s 128us/step - loss: 909.4911 - mean_absolute_error: 909.4911 - val_loss: 560.3859 - val_mean_absolute_error: 560.3859\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 524.95797\n",
      "Epoch 277/500\n",
      "585/585 [==============================] - 0s 140us/step - loss: 904.5647 - mean_absolute_error: 904.5647 - val_loss: 597.4007 - val_mean_absolute_error: 597.4007\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 524.95797\n",
      "Epoch 278/500\n",
      "585/585 [==============================] - 0s 140us/step - loss: 881.2953 - mean_absolute_error: 881.2953 - val_loss: 585.8589 - val_mean_absolute_error: 585.8589\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 524.95797\n",
      "Epoch 279/500\n",
      "585/585 [==============================] - 0s 142us/step - loss: 899.0641 - mean_absolute_error: 899.0641 - val_loss: 599.1210 - val_mean_absolute_error: 599.1210\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 524.95797\n",
      "Epoch 280/500\n",
      "585/585 [==============================] - 0s 145us/step - loss: 880.5706 - mean_absolute_error: 880.5706 - val_loss: 580.2117 - val_mean_absolute_error: 580.2117\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 524.95797\n",
      "Epoch 281/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "585/585 [==============================] - 0s 135us/step - loss: 900.6516 - mean_absolute_error: 900.6516 - val_loss: 578.8222 - val_mean_absolute_error: 578.8222\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 524.95797\n",
      "Epoch 282/500\n",
      "585/585 [==============================] - 0s 135us/step - loss: 901.1924 - mean_absolute_error: 901.1924 - val_loss: 643.4745 - val_mean_absolute_error: 643.4745\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 524.95797\n",
      "Epoch 283/500\n",
      "585/585 [==============================] - 0s 159us/step - loss: 898.3414 - mean_absolute_error: 898.3414 - val_loss: 573.4756 - val_mean_absolute_error: 573.4756\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 524.95797\n",
      "Epoch 284/500\n",
      "585/585 [==============================] - 0s 138us/step - loss: 894.7324 - mean_absolute_error: 894.7324 - val_loss: 675.6309 - val_mean_absolute_error: 675.6309\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 524.95797\n",
      "Epoch 285/500\n",
      "585/585 [==============================] - 0s 150us/step - loss: 909.2079 - mean_absolute_error: 909.2079 - val_loss: 618.4408 - val_mean_absolute_error: 618.4408\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 524.95797\n",
      "Epoch 286/500\n",
      "585/585 [==============================] - 0s 145us/step - loss: 884.0193 - mean_absolute_error: 884.0193 - val_loss: 572.3797 - val_mean_absolute_error: 572.3797\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 524.95797\n",
      "Epoch 287/500\n",
      "585/585 [==============================] - 0s 147us/step - loss: 888.7714 - mean_absolute_error: 888.7714 - val_loss: 598.9746 - val_mean_absolute_error: 598.9746\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 524.95797\n",
      "Epoch 288/500\n",
      "585/585 [==============================] - 0s 147us/step - loss: 880.6673 - mean_absolute_error: 880.6673 - val_loss: 627.2010 - val_mean_absolute_error: 627.2010\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 524.95797\n",
      "Epoch 289/500\n",
      "585/585 [==============================] - 0s 148us/step - loss: 889.2867 - mean_absolute_error: 889.2867 - val_loss: 555.1738 - val_mean_absolute_error: 555.1738\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 524.95797\n",
      "Epoch 290/500\n",
      "585/585 [==============================] - 0s 138us/step - loss: 940.3048 - mean_absolute_error: 940.3048 - val_loss: 544.7466 - val_mean_absolute_error: 544.7466\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 524.95797\n",
      "Epoch 291/500\n",
      "585/585 [==============================] - 0s 145us/step - loss: 946.8581 - mean_absolute_error: 946.8581 - val_loss: 629.4766 - val_mean_absolute_error: 629.4766\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 524.95797\n",
      "Epoch 292/500\n",
      "585/585 [==============================] - 0s 147us/step - loss: 950.0383 - mean_absolute_error: 950.0383 - val_loss: 686.5709 - val_mean_absolute_error: 686.5709\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 524.95797\n",
      "Epoch 293/500\n",
      "585/585 [==============================] - 0s 136us/step - loss: 884.3609 - mean_absolute_error: 884.3609 - val_loss: 577.5915 - val_mean_absolute_error: 577.5915\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 524.95797\n",
      "Epoch 294/500\n",
      "585/585 [==============================] - 0s 153us/step - loss: 886.2931 - mean_absolute_error: 886.2931 - val_loss: 609.0282 - val_mean_absolute_error: 609.0282\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 524.95797\n",
      "Epoch 295/500\n",
      "585/585 [==============================] - 0s 145us/step - loss: 882.2154 - mean_absolute_error: 882.2154 - val_loss: 595.5062 - val_mean_absolute_error: 595.5062\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 524.95797\n",
      "Epoch 296/500\n",
      "585/585 [==============================] - 0s 136us/step - loss: 880.3255 - mean_absolute_error: 880.3255 - val_loss: 631.4477 - val_mean_absolute_error: 631.4477\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 524.95797\n",
      "Epoch 297/500\n",
      "585/585 [==============================] - 0s 145us/step - loss: 883.5336 - mean_absolute_error: 883.5336 - val_loss: 573.1647 - val_mean_absolute_error: 573.1647\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 524.95797\n",
      "Epoch 298/500\n",
      "585/585 [==============================] - 0s 147us/step - loss: 874.0125 - mean_absolute_error: 874.0125 - val_loss: 644.2351 - val_mean_absolute_error: 644.2351\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 524.95797\n",
      "Epoch 299/500\n",
      "585/585 [==============================] - 0s 141us/step - loss: 919.5443 - mean_absolute_error: 919.5443 - val_loss: 631.2825 - val_mean_absolute_error: 631.2825\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 524.95797\n",
      "Epoch 300/500\n",
      "585/585 [==============================] - 0s 124us/step - loss: 870.7431 - mean_absolute_error: 870.7431 - val_loss: 641.1058 - val_mean_absolute_error: 641.1058\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 524.95797\n",
      "Epoch 301/500\n",
      "585/585 [==============================] - 0s 123us/step - loss: 881.1013 - mean_absolute_error: 881.1013 - val_loss: 595.3084 - val_mean_absolute_error: 595.3084\n",
      "\n",
      "Epoch 00301: val_loss did not improve from 524.95797\n",
      "Epoch 302/500\n",
      "585/585 [==============================] - 0s 124us/step - loss: 881.8920 - mean_absolute_error: 881.8920 - val_loss: 624.3107 - val_mean_absolute_error: 624.3107\n",
      "\n",
      "Epoch 00302: val_loss did not improve from 524.95797\n",
      "Epoch 303/500\n",
      "585/585 [==============================] - 0s 130us/step - loss: 880.8501 - mean_absolute_error: 880.8501 - val_loss: 619.3751 - val_mean_absolute_error: 619.3751\n",
      "\n",
      "Epoch 00303: val_loss did not improve from 524.95797\n",
      "Epoch 304/500\n",
      "585/585 [==============================] - 0s 138us/step - loss: 894.3442 - mean_absolute_error: 894.3442 - val_loss: 589.0584 - val_mean_absolute_error: 589.0584\n",
      "\n",
      "Epoch 00304: val_loss did not improve from 524.95797\n",
      "Epoch 305/500\n",
      "585/585 [==============================] - 0s 128us/step - loss: 890.4673 - mean_absolute_error: 890.4673 - val_loss: 578.5516 - val_mean_absolute_error: 578.5516\n",
      "\n",
      "Epoch 00305: val_loss did not improve from 524.95797\n",
      "Epoch 306/500\n",
      "585/585 [==============================] - 0s 145us/step - loss: 904.3715 - mean_absolute_error: 904.3715 - val_loss: 565.2261 - val_mean_absolute_error: 565.2261\n",
      "\n",
      "Epoch 00306: val_loss did not improve from 524.95797\n",
      "Epoch 307/500\n",
      "585/585 [==============================] - 0s 145us/step - loss: 906.6808 - mean_absolute_error: 906.6808 - val_loss: 604.9738 - val_mean_absolute_error: 604.9738\n",
      "\n",
      "Epoch 00307: val_loss did not improve from 524.95797\n",
      "Epoch 308/500\n",
      "585/585 [==============================] - 0s 128us/step - loss: 869.6121 - mean_absolute_error: 869.6121 - val_loss: 648.5600 - val_mean_absolute_error: 648.5600\n",
      "\n",
      "Epoch 00308: val_loss did not improve from 524.95797\n",
      "Epoch 309/500\n",
      "585/585 [==============================] - ETA: 0s - loss: 900.3192 - mean_absolute_error: 900.319 - 0s 124us/step - loss: 885.0197 - mean_absolute_error: 885.0197 - val_loss: 604.9885 - val_mean_absolute_error: 604.9885\n",
      "\n",
      "Epoch 00309: val_loss did not improve from 524.95797\n",
      "Epoch 310/500\n",
      "585/585 [==============================] - 0s 131us/step - loss: 907.0968 - mean_absolute_error: 907.0968 - val_loss: 616.8379 - val_mean_absolute_error: 616.8379\n",
      "\n",
      "Epoch 00310: val_loss did not improve from 524.95797\n",
      "Epoch 311/500\n",
      "585/585 [==============================] - 0s 135us/step - loss: 901.3985 - mean_absolute_error: 901.3985 - val_loss: 684.6684 - val_mean_absolute_error: 684.6684\n",
      "\n",
      "Epoch 00311: val_loss did not improve from 524.95797\n",
      "Epoch 312/500\n",
      "585/585 [==============================] - 0s 136us/step - loss: 878.1596 - mean_absolute_error: 878.1596 - val_loss: 625.3103 - val_mean_absolute_error: 625.3103\n",
      "\n",
      "Epoch 00312: val_loss did not improve from 524.95797\n",
      "Epoch 313/500\n",
      "585/585 [==============================] - 0s 135us/step - loss: 870.1982 - mean_absolute_error: 870.1982 - val_loss: 608.2342 - val_mean_absolute_error: 608.2342\n",
      "\n",
      "Epoch 00313: val_loss did not improve from 524.95797\n",
      "Epoch 314/500\n",
      "585/585 [==============================] - 0s 136us/step - loss: 898.8516 - mean_absolute_error: 898.8516 - val_loss: 622.7180 - val_mean_absolute_error: 622.7180\n",
      "\n",
      "Epoch 00314: val_loss did not improve from 524.95797\n",
      "Epoch 315/500\n",
      "585/585 [==============================] - 0s 130us/step - loss: 866.8086 - mean_absolute_error: 866.8086 - val_loss: 625.6466 - val_mean_absolute_error: 625.6466\n",
      "\n",
      "Epoch 00315: val_loss did not improve from 524.95797\n",
      "Epoch 316/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "585/585 [==============================] - 0s 153us/step - loss: 872.4262 - mean_absolute_error: 872.4262 - val_loss: 615.1952 - val_mean_absolute_error: 615.1952\n",
      "\n",
      "Epoch 00316: val_loss did not improve from 524.95797\n",
      "Epoch 317/500\n",
      "585/585 [==============================] - 0s 143us/step - loss: 925.5428 - mean_absolute_error: 925.5428 - val_loss: 611.5600 - val_mean_absolute_error: 611.5600\n",
      "\n",
      "Epoch 00317: val_loss did not improve from 524.95797\n",
      "Epoch 318/500\n",
      "585/585 [==============================] - 0s 147us/step - loss: 877.8437 - mean_absolute_error: 877.8437 - val_loss: 600.4823 - val_mean_absolute_error: 600.4823\n",
      "\n",
      "Epoch 00318: val_loss did not improve from 524.95797\n",
      "Epoch 319/500\n",
      "585/585 [==============================] - 0s 147us/step - loss: 885.2373 - mean_absolute_error: 885.2373 - val_loss: 599.1329 - val_mean_absolute_error: 599.1329\n",
      "\n",
      "Epoch 00319: val_loss did not improve from 524.95797\n",
      "Epoch 320/500\n",
      "585/585 [==============================] - 0s 145us/step - loss: 894.4746 - mean_absolute_error: 894.4746 - val_loss: 658.6400 - val_mean_absolute_error: 658.6400\n",
      "\n",
      "Epoch 00320: val_loss did not improve from 524.95797\n",
      "Epoch 321/500\n",
      "585/585 [==============================] - 0s 148us/step - loss: 863.1473 - mean_absolute_error: 863.1473 - val_loss: 593.2007 - val_mean_absolute_error: 593.2007\n",
      "\n",
      "Epoch 00321: val_loss did not improve from 524.95797\n",
      "Epoch 322/500\n",
      "585/585 [==============================] - 0s 155us/step - loss: 851.7145 - mean_absolute_error: 851.7145 - val_loss: 612.6633 - val_mean_absolute_error: 612.6633\n",
      "\n",
      "Epoch 00322: val_loss did not improve from 524.95797\n",
      "Epoch 323/500\n",
      "585/585 [==============================] - 0s 148us/step - loss: 867.3287 - mean_absolute_error: 867.3287 - val_loss: 600.7094 - val_mean_absolute_error: 600.7094\n",
      "\n",
      "Epoch 00323: val_loss did not improve from 524.95797\n",
      "Epoch 324/500\n",
      "585/585 [==============================] - 0s 133us/step - loss: 886.9454 - mean_absolute_error: 886.9454 - val_loss: 703.7808 - val_mean_absolute_error: 703.7808\n",
      "\n",
      "Epoch 00324: val_loss did not improve from 524.95797\n",
      "Epoch 325/500\n",
      "585/585 [==============================] - 0s 138us/step - loss: 945.8830 - mean_absolute_error: 945.8830 - val_loss: 561.0494 - val_mean_absolute_error: 561.0494\n",
      "\n",
      "Epoch 00325: val_loss did not improve from 524.95797\n",
      "Epoch 326/500\n",
      "585/585 [==============================] - 0s 150us/step - loss: 937.9265 - mean_absolute_error: 937.9265 - val_loss: 669.1264 - val_mean_absolute_error: 669.1264\n",
      "\n",
      "Epoch 00326: val_loss did not improve from 524.95797\n",
      "Epoch 327/500\n",
      "585/585 [==============================] - 0s 133us/step - loss: 895.0821 - mean_absolute_error: 895.0821 - val_loss: 613.3034 - val_mean_absolute_error: 613.3034\n",
      "\n",
      "Epoch 00327: val_loss did not improve from 524.95797\n",
      "Epoch 328/500\n",
      "585/585 [==============================] - 0s 148us/step - loss: 882.7170 - mean_absolute_error: 882.7170 - val_loss: 618.1570 - val_mean_absolute_error: 618.1570\n",
      "\n",
      "Epoch 00328: val_loss did not improve from 524.95797\n",
      "Epoch 329/500\n",
      "585/585 [==============================] - 0s 140us/step - loss: 909.8205 - mean_absolute_error: 909.8205 - val_loss: 664.0072 - val_mean_absolute_error: 664.0072\n",
      "\n",
      "Epoch 00329: val_loss did not improve from 524.95797\n",
      "Epoch 330/500\n",
      "585/585 [==============================] - 0s 147us/step - loss: 879.8895 - mean_absolute_error: 879.8895 - val_loss: 579.6376 - val_mean_absolute_error: 579.6376\n",
      "\n",
      "Epoch 00330: val_loss did not improve from 524.95797\n",
      "Epoch 331/500\n",
      "585/585 [==============================] - 0s 145us/step - loss: 857.7518 - mean_absolute_error: 857.7518 - val_loss: 631.6348 - val_mean_absolute_error: 631.6348\n",
      "\n",
      "Epoch 00331: val_loss did not improve from 524.95797\n",
      "Epoch 332/500\n",
      "585/585 [==============================] - 0s 130us/step - loss: 859.3128 - mean_absolute_error: 859.3128 - val_loss: 600.1157 - val_mean_absolute_error: 600.1157\n",
      "\n",
      "Epoch 00332: val_loss did not improve from 524.95797\n",
      "Epoch 333/500\n",
      "585/585 [==============================] - 0s 133us/step - loss: 865.4204 - mean_absolute_error: 865.4204 - val_loss: 646.4917 - val_mean_absolute_error: 646.4917\n",
      "\n",
      "Epoch 00333: val_loss did not improve from 524.95797\n",
      "Epoch 334/500\n",
      "585/585 [==============================] - 0s 136us/step - loss: 866.4827 - mean_absolute_error: 866.4827 - val_loss: 615.3606 - val_mean_absolute_error: 615.3606\n",
      "\n",
      "Epoch 00334: val_loss did not improve from 524.95797\n",
      "Epoch 335/500\n",
      "585/585 [==============================] - 0s 148us/step - loss: 867.6275 - mean_absolute_error: 867.6275 - val_loss: 659.5820 - val_mean_absolute_error: 659.5820\n",
      "\n",
      "Epoch 00335: val_loss did not improve from 524.95797\n",
      "Epoch 336/500\n",
      "585/585 [==============================] - 0s 145us/step - loss: 869.9351 - mean_absolute_error: 869.9351 - val_loss: 640.5830 - val_mean_absolute_error: 640.5830\n",
      "\n",
      "Epoch 00336: val_loss did not improve from 524.95797\n",
      "Epoch 337/500\n",
      "585/585 [==============================] - 0s 136us/step - loss: 882.2161 - mean_absolute_error: 882.2161 - val_loss: 662.3183 - val_mean_absolute_error: 662.3183\n",
      "\n",
      "Epoch 00337: val_loss did not improve from 524.95797\n",
      "Epoch 338/500\n",
      "585/585 [==============================] - 0s 152us/step - loss: 849.2308 - mean_absolute_error: 849.2308 - val_loss: 738.2204 - val_mean_absolute_error: 738.2204\n",
      "\n",
      "Epoch 00338: val_loss did not improve from 524.95797\n",
      "Epoch 339/500\n",
      "585/585 [==============================] - 0s 152us/step - loss: 859.8625 - mean_absolute_error: 859.8625 - val_loss: 641.1048 - val_mean_absolute_error: 641.1048\n",
      "\n",
      "Epoch 00339: val_loss did not improve from 524.95797\n",
      "Epoch 340/500\n",
      "585/585 [==============================] - 0s 138us/step - loss: 841.7172 - mean_absolute_error: 841.7172 - val_loss: 676.5725 - val_mean_absolute_error: 676.5725\n",
      "\n",
      "Epoch 00340: val_loss did not improve from 524.95797\n",
      "Epoch 341/500\n",
      "585/585 [==============================] - 0s 142us/step - loss: 886.3460 - mean_absolute_error: 886.3460 - val_loss: 595.1943 - val_mean_absolute_error: 595.1943\n",
      "\n",
      "Epoch 00341: val_loss did not improve from 524.95797\n",
      "Epoch 342/500\n",
      "585/585 [==============================] - 0s 145us/step - loss: 870.3719 - mean_absolute_error: 870.3719 - val_loss: 625.9795 - val_mean_absolute_error: 625.9795\n",
      "\n",
      "Epoch 00342: val_loss did not improve from 524.95797\n",
      "Epoch 343/500\n",
      "585/585 [==============================] - 0s 130us/step - loss: 875.1090 - mean_absolute_error: 875.1090 - val_loss: 638.2095 - val_mean_absolute_error: 638.2095\n",
      "\n",
      "Epoch 00343: val_loss did not improve from 524.95797\n",
      "Epoch 344/500\n",
      "585/585 [==============================] - 0s 147us/step - loss: 868.1150 - mean_absolute_error: 868.1150 - val_loss: 628.5890 - val_mean_absolute_error: 628.5890\n",
      "\n",
      "Epoch 00344: val_loss did not improve from 524.95797\n",
      "Epoch 345/500\n",
      "585/585 [==============================] - 0s 138us/step - loss: 839.2204 - mean_absolute_error: 839.2204 - val_loss: 630.0081 - val_mean_absolute_error: 630.0081\n",
      "\n",
      "Epoch 00345: val_loss did not improve from 524.95797\n",
      "Epoch 346/500\n",
      "585/585 [==============================] - 0s 140us/step - loss: 861.4099 - mean_absolute_error: 861.4099 - val_loss: 620.3273 - val_mean_absolute_error: 620.3273\n",
      "\n",
      "Epoch 00346: val_loss did not improve from 524.95797\n",
      "Epoch 347/500\n",
      "585/585 [==============================] - 0s 143us/step - loss: 857.2666 - mean_absolute_error: 857.2666 - val_loss: 637.7231 - val_mean_absolute_error: 637.7231\n",
      "\n",
      "Epoch 00347: val_loss did not improve from 524.95797\n",
      "Epoch 348/500\n",
      "585/585 [==============================] - 0s 131us/step - loss: 873.9059 - mean_absolute_error: 873.9059 - val_loss: 673.1635 - val_mean_absolute_error: 673.1635\n",
      "\n",
      "Epoch 00348: val_loss did not improve from 524.95797\n",
      "Epoch 349/500\n",
      "585/585 [==============================] - 0s 121us/step - loss: 863.1688 - mean_absolute_error: 863.1688 - val_loss: 649.5892 - val_mean_absolute_error: 649.5892\n",
      "\n",
      "Epoch 00349: val_loss did not improve from 524.95797\n",
      "Epoch 350/500\n",
      "585/585 [==============================] - 0s 126us/step - loss: 850.9880 - mean_absolute_error: 850.9880 - val_loss: 630.7103 - val_mean_absolute_error: 630.7103\n",
      "\n",
      "Epoch 00350: val_loss did not improve from 524.95797\n",
      "Epoch 351/500\n",
      "585/585 [==============================] - 0s 124us/step - loss: 844.3011 - mean_absolute_error: 844.3011 - val_loss: 606.6649 - val_mean_absolute_error: 606.6649\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00351: val_loss did not improve from 524.95797\n",
      "Epoch 352/500\n",
      "585/585 [==============================] - 0s 138us/step - loss: 882.3951 - mean_absolute_error: 882.3951 - val_loss: 624.9607 - val_mean_absolute_error: 624.9607\n",
      "\n",
      "Epoch 00352: val_loss did not improve from 524.95797\n",
      "Epoch 353/500\n",
      "585/585 [==============================] - 0s 133us/step - loss: 876.3669 - mean_absolute_error: 876.3669 - val_loss: 636.3378 - val_mean_absolute_error: 636.3378\n",
      "\n",
      "Epoch 00353: val_loss did not improve from 524.95797\n",
      "Epoch 354/500\n",
      "585/585 [==============================] - 0s 147us/step - loss: 840.5184 - mean_absolute_error: 840.5184 - val_loss: 629.4042 - val_mean_absolute_error: 629.4042\n",
      "\n",
      "Epoch 00354: val_loss did not improve from 524.95797\n",
      "Epoch 355/500\n",
      "585/585 [==============================] - 0s 140us/step - loss: 843.9552 - mean_absolute_error: 843.9552 - val_loss: 656.4499 - val_mean_absolute_error: 656.4499\n",
      "\n",
      "Epoch 00355: val_loss did not improve from 524.95797\n",
      "Epoch 356/500\n",
      "585/585 [==============================] - 0s 143us/step - loss: 837.4738 - mean_absolute_error: 837.4738 - val_loss: 660.1100 - val_mean_absolute_error: 660.1100\n",
      "\n",
      "Epoch 00356: val_loss did not improve from 524.95797\n",
      "Epoch 357/500\n",
      "585/585 [==============================] - 0s 142us/step - loss: 864.7613 - mean_absolute_error: 864.7613 - val_loss: 643.7919 - val_mean_absolute_error: 643.7919\n",
      "\n",
      "Epoch 00357: val_loss did not improve from 524.95797\n",
      "Epoch 358/500\n",
      "585/585 [==============================] - 0s 128us/step - loss: 839.3699 - mean_absolute_error: 839.3699 - val_loss: 645.6100 - val_mean_absolute_error: 645.6100\n",
      "\n",
      "Epoch 00358: val_loss did not improve from 524.95797\n",
      "Epoch 359/500\n",
      "585/585 [==============================] - 0s 143us/step - loss: 840.0352 - mean_absolute_error: 840.0352 - val_loss: 657.6997 - val_mean_absolute_error: 657.6997\n",
      "\n",
      "Epoch 00359: val_loss did not improve from 524.95797\n",
      "Epoch 360/500\n",
      "585/585 [==============================] - 0s 131us/step - loss: 834.9686 - mean_absolute_error: 834.9686 - val_loss: 657.6664 - val_mean_absolute_error: 657.6664\n",
      "\n",
      "Epoch 00360: val_loss did not improve from 524.95797\n",
      "Epoch 361/500\n",
      "585/585 [==============================] - 0s 157us/step - loss: 843.5050 - mean_absolute_error: 843.5050 - val_loss: 607.2500 - val_mean_absolute_error: 607.2500\n",
      "\n",
      "Epoch 00361: val_loss did not improve from 524.95797\n",
      "Epoch 362/500\n",
      "585/585 [==============================] - 0s 160us/step - loss: 859.6261 - mean_absolute_error: 859.6261 - val_loss: 761.1543 - val_mean_absolute_error: 761.1543\n",
      "\n",
      "Epoch 00362: val_loss did not improve from 524.95797\n",
      "Epoch 363/500\n",
      "585/585 [==============================] - 0s 145us/step - loss: 855.8679 - mean_absolute_error: 855.8679 - val_loss: 609.9647 - val_mean_absolute_error: 609.9647\n",
      "\n",
      "Epoch 00363: val_loss did not improve from 524.95797\n",
      "Epoch 364/500\n",
      "585/585 [==============================] - 0s 153us/step - loss: 830.4942 - mean_absolute_error: 830.4942 - val_loss: 701.6136 - val_mean_absolute_error: 701.6136\n",
      "\n",
      "Epoch 00364: val_loss did not improve from 524.95797\n",
      "Epoch 365/500\n",
      "585/585 [==============================] - 0s 155us/step - loss: 848.8594 - mean_absolute_error: 848.8594 - val_loss: 615.3136 - val_mean_absolute_error: 615.3136\n",
      "\n",
      "Epoch 00365: val_loss did not improve from 524.95797\n",
      "Epoch 366/500\n",
      "585/585 [==============================] - 0s 162us/step - loss: 843.1105 - mean_absolute_error: 843.1105 - val_loss: 597.9612 - val_mean_absolute_error: 597.9612\n",
      "\n",
      "Epoch 00366: val_loss did not improve from 524.95797\n",
      "Epoch 367/500\n",
      "585/585 [==============================] - 0s 150us/step - loss: 907.9255 - mean_absolute_error: 907.9255 - val_loss: 673.1124 - val_mean_absolute_error: 673.1124\n",
      "\n",
      "Epoch 00367: val_loss did not improve from 524.95797\n",
      "Epoch 368/500\n",
      "585/585 [==============================] - 0s 165us/step - loss: 838.3674 - mean_absolute_error: 838.3674 - val_loss: 657.5451 - val_mean_absolute_error: 657.5451\n",
      "\n",
      "Epoch 00368: val_loss did not improve from 524.95797\n",
      "Epoch 369/500\n",
      "585/585 [==============================] - 0s 155us/step - loss: 841.3975 - mean_absolute_error: 841.3975 - val_loss: 666.2497 - val_mean_absolute_error: 666.2497\n",
      "\n",
      "Epoch 00369: val_loss did not improve from 524.95797\n",
      "Epoch 370/500\n",
      "585/585 [==============================] - 0s 155us/step - loss: 867.2586 - mean_absolute_error: 867.2586 - val_loss: 648.2744 - val_mean_absolute_error: 648.2744\n",
      "\n",
      "Epoch 00370: val_loss did not improve from 524.95797\n",
      "Epoch 371/500\n",
      "585/585 [==============================] - 0s 143us/step - loss: 831.3586 - mean_absolute_error: 831.3586 - val_loss: 621.1811 - val_mean_absolute_error: 621.1811\n",
      "\n",
      "Epoch 00371: val_loss did not improve from 524.95797\n",
      "Epoch 372/500\n",
      "585/585 [==============================] - 0s 160us/step - loss: 848.2671 - mean_absolute_error: 848.2671 - val_loss: 688.3541 - val_mean_absolute_error: 688.3541\n",
      "\n",
      "Epoch 00372: val_loss did not improve from 524.95797\n",
      "Epoch 373/500\n",
      "585/585 [==============================] - 0s 157us/step - loss: 832.4235 - mean_absolute_error: 832.4235 - val_loss: 687.6589 - val_mean_absolute_error: 687.6589\n",
      "\n",
      "Epoch 00373: val_loss did not improve from 524.95797\n",
      "Epoch 374/500\n",
      "585/585 [==============================] - 0s 152us/step - loss: 835.0407 - mean_absolute_error: 835.0407 - val_loss: 616.7350 - val_mean_absolute_error: 616.7350\n",
      "\n",
      "Epoch 00374: val_loss did not improve from 524.95797\n",
      "Epoch 375/500\n",
      "585/585 [==============================] - 0s 160us/step - loss: 849.4432 - mean_absolute_error: 849.4432 - val_loss: 638.8367 - val_mean_absolute_error: 638.8367\n",
      "\n",
      "Epoch 00375: val_loss did not improve from 524.95797\n",
      "Epoch 376/500\n",
      "585/585 [==============================] - 0s 164us/step - loss: 834.9100 - mean_absolute_error: 834.9100 - val_loss: 654.5263 - val_mean_absolute_error: 654.5263\n",
      "\n",
      "Epoch 00376: val_loss did not improve from 524.95797\n",
      "Epoch 377/500\n",
      "585/585 [==============================] - 0s 148us/step - loss: 854.2711 - mean_absolute_error: 854.2711 - val_loss: 705.6625 - val_mean_absolute_error: 705.6625\n",
      "\n",
      "Epoch 00377: val_loss did not improve from 524.95797\n",
      "Epoch 378/500\n",
      "585/585 [==============================] - 0s 169us/step - loss: 839.5508 - mean_absolute_error: 839.5508 - val_loss: 686.6565 - val_mean_absolute_error: 686.6565\n",
      "\n",
      "Epoch 00378: val_loss did not improve from 524.95797\n",
      "Epoch 379/500\n",
      "585/585 [==============================] - 0s 142us/step - loss: 844.3370 - mean_absolute_error: 844.3370 - val_loss: 647.7274 - val_mean_absolute_error: 647.7274\n",
      "\n",
      "Epoch 00379: val_loss did not improve from 524.95797\n",
      "Epoch 380/500\n",
      "585/585 [==============================] - 0s 143us/step - loss: 830.2008 - mean_absolute_error: 830.2008 - val_loss: 649.4682 - val_mean_absolute_error: 649.4682\n",
      "\n",
      "Epoch 00380: val_loss did not improve from 524.95797\n",
      "Epoch 381/500\n",
      "585/585 [==============================] - 0s 143us/step - loss: 824.4738 - mean_absolute_error: 824.4738 - val_loss: 651.1026 - val_mean_absolute_error: 651.1026\n",
      "\n",
      "Epoch 00381: val_loss did not improve from 524.95797\n",
      "Epoch 382/500\n",
      "585/585 [==============================] - 0s 150us/step - loss: 818.2811 - mean_absolute_error: 818.2811 - val_loss: 655.6811 - val_mean_absolute_error: 655.6811\n",
      "\n",
      "Epoch 00382: val_loss did not improve from 524.95797\n",
      "Epoch 383/500\n",
      "585/585 [==============================] - 0s 155us/step - loss: 823.3138 - mean_absolute_error: 823.3138 - val_loss: 656.8221 - val_mean_absolute_error: 656.8221\n",
      "\n",
      "Epoch 00383: val_loss did not improve from 524.95797\n",
      "Epoch 384/500\n",
      "585/585 [==============================] - 0s 148us/step - loss: 844.5962 - mean_absolute_error: 844.5962 - val_loss: 648.2564 - val_mean_absolute_error: 648.2564\n",
      "\n",
      "Epoch 00384: val_loss did not improve from 524.95797\n",
      "Epoch 385/500\n",
      "585/585 [==============================] - 0s 159us/step - loss: 832.5490 - mean_absolute_error: 832.5490 - val_loss: 634.7528 - val_mean_absolute_error: 634.7528\n",
      "\n",
      "Epoch 00385: val_loss did not improve from 524.95797\n",
      "Epoch 386/500\n",
      "585/585 [==============================] - 0s 142us/step - loss: 825.1107 - mean_absolute_error: 825.1107 - val_loss: 645.4812 - val_mean_absolute_error: 645.4812\n",
      "\n",
      "Epoch 00386: val_loss did not improve from 524.95797\n",
      "Epoch 387/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "585/585 [==============================] - 0s 142us/step - loss: 847.8219 - mean_absolute_error: 847.8219 - val_loss: 634.4021 - val_mean_absolute_error: 634.4021\n",
      "\n",
      "Epoch 00387: val_loss did not improve from 524.95797\n",
      "Epoch 388/500\n",
      "585/585 [==============================] - 0s 160us/step - loss: 835.3602 - mean_absolute_error: 835.3602 - val_loss: 673.6248 - val_mean_absolute_error: 673.6248\n",
      "\n",
      "Epoch 00388: val_loss did not improve from 524.95797\n",
      "Epoch 389/500\n",
      "585/585 [==============================] - 0s 164us/step - loss: 827.9216 - mean_absolute_error: 827.9216 - val_loss: 660.0740 - val_mean_absolute_error: 660.0740\n",
      "\n",
      "Epoch 00389: val_loss did not improve from 524.95797\n",
      "Epoch 390/500\n",
      "585/585 [==============================] - 0s 160us/step - loss: 835.0942 - mean_absolute_error: 835.0942 - val_loss: 700.1442 - val_mean_absolute_error: 700.1442\n",
      "\n",
      "Epoch 00390: val_loss did not improve from 524.95797\n",
      "Epoch 391/500\n",
      "585/585 [==============================] - 0s 152us/step - loss: 859.5610 - mean_absolute_error: 859.5610 - val_loss: 613.3660 - val_mean_absolute_error: 613.3660\n",
      "\n",
      "Epoch 00391: val_loss did not improve from 524.95797\n",
      "Epoch 392/500\n",
      "585/585 [==============================] - 0s 177us/step - loss: 851.6853 - mean_absolute_error: 851.6853 - val_loss: 645.5436 - val_mean_absolute_error: 645.5436\n",
      "\n",
      "Epoch 00392: val_loss did not improve from 524.95797\n",
      "Epoch 393/500\n",
      "585/585 [==============================] - 0s 176us/step - loss: 821.1216 - mean_absolute_error: 821.1216 - val_loss: 669.8885 - val_mean_absolute_error: 669.8885\n",
      "\n",
      "Epoch 00393: val_loss did not improve from 524.95797\n",
      "Epoch 394/500\n",
      "585/585 [==============================] - 0s 169us/step - loss: 814.1240 - mean_absolute_error: 814.1240 - val_loss: 681.7436 - val_mean_absolute_error: 681.7436\n",
      "\n",
      "Epoch 00394: val_loss did not improve from 524.95797\n",
      "Epoch 395/500\n",
      "585/585 [==============================] - 0s 159us/step - loss: 810.1860 - mean_absolute_error: 810.1860 - val_loss: 647.7654 - val_mean_absolute_error: 647.7654\n",
      "\n",
      "Epoch 00395: val_loss did not improve from 524.95797\n",
      "Epoch 396/500\n",
      "585/585 [==============================] - 0s 162us/step - loss: 826.4814 - mean_absolute_error: 826.4814 - val_loss: 671.4927 - val_mean_absolute_error: 671.4927\n",
      "\n",
      "Epoch 00396: val_loss did not improve from 524.95797\n",
      "Epoch 397/500\n",
      "585/585 [==============================] - 0s 159us/step - loss: 873.5517 - mean_absolute_error: 873.5517 - val_loss: 633.9814 - val_mean_absolute_error: 633.9814\n",
      "\n",
      "Epoch 00397: val_loss did not improve from 524.95797\n",
      "Epoch 398/500\n",
      "585/585 [==============================] - 0s 155us/step - loss: 832.2935 - mean_absolute_error: 832.2935 - val_loss: 635.3987 - val_mean_absolute_error: 635.3987\n",
      "\n",
      "Epoch 00398: val_loss did not improve from 524.95797\n",
      "Epoch 399/500\n",
      "585/585 [==============================] - 0s 135us/step - loss: 880.7422 - mean_absolute_error: 880.7422 - val_loss: 705.9324 - val_mean_absolute_error: 705.9324\n",
      "\n",
      "Epoch 00399: val_loss did not improve from 524.95797\n",
      "Epoch 400/500\n",
      "585/585 [==============================] - 0s 150us/step - loss: 941.9472 - mean_absolute_error: 941.9472 - val_loss: 612.8133 - val_mean_absolute_error: 612.8133\n",
      "\n",
      "Epoch 00400: val_loss did not improve from 524.95797\n",
      "Epoch 401/500\n",
      "585/585 [==============================] - 0s 153us/step - loss: 859.3279 - mean_absolute_error: 859.3279 - val_loss: 630.0615 - val_mean_absolute_error: 630.0615\n",
      "\n",
      "Epoch 00401: val_loss did not improve from 524.95797\n",
      "Epoch 402/500\n",
      "585/585 [==============================] - 0s 147us/step - loss: 809.3897 - mean_absolute_error: 809.3897 - val_loss: 644.9586 - val_mean_absolute_error: 644.9586\n",
      "\n",
      "Epoch 00402: val_loss did not improve from 524.95797\n",
      "Epoch 403/500\n",
      "585/585 [==============================] - 0s 148us/step - loss: 824.9022 - mean_absolute_error: 824.9022 - val_loss: 661.7359 - val_mean_absolute_error: 661.7359\n",
      "\n",
      "Epoch 00403: val_loss did not improve from 524.95797\n",
      "Epoch 404/500\n",
      "585/585 [==============================] - 0s 157us/step - loss: 815.1947 - mean_absolute_error: 815.1947 - val_loss: 716.5738 - val_mean_absolute_error: 716.5738\n",
      "\n",
      "Epoch 00404: val_loss did not improve from 524.95797\n",
      "Epoch 405/500\n",
      "585/585 [==============================] - 0s 150us/step - loss: 824.3714 - mean_absolute_error: 824.3714 - val_loss: 631.8644 - val_mean_absolute_error: 631.8644\n",
      "\n",
      "Epoch 00405: val_loss did not improve from 524.95797\n",
      "Epoch 406/500\n",
      "585/585 [==============================] - 0s 138us/step - loss: 823.9496 - mean_absolute_error: 823.9496 - val_loss: 673.3221 - val_mean_absolute_error: 673.3221\n",
      "\n",
      "Epoch 00406: val_loss did not improve from 524.95797\n",
      "Epoch 407/500\n",
      "585/585 [==============================] - 0s 152us/step - loss: 859.6632 - mean_absolute_error: 859.6632 - val_loss: 600.8009 - val_mean_absolute_error: 600.8009\n",
      "\n",
      "Epoch 00407: val_loss did not improve from 524.95797\n",
      "Epoch 408/500\n",
      "585/585 [==============================] - 0s 152us/step - loss: 874.9798 - mean_absolute_error: 874.9798 - val_loss: 757.8687 - val_mean_absolute_error: 757.8687\n",
      "\n",
      "Epoch 00408: val_loss did not improve from 524.95797\n",
      "Epoch 409/500\n",
      "585/585 [==============================] - 0s 138us/step - loss: 840.3848 - mean_absolute_error: 840.3848 - val_loss: 627.7674 - val_mean_absolute_error: 627.7674\n",
      "\n",
      "Epoch 00409: val_loss did not improve from 524.95797\n",
      "Epoch 410/500\n",
      "585/585 [==============================] - 0s 141us/step - loss: 856.9751 - mean_absolute_error: 856.9751 - val_loss: 617.8404 - val_mean_absolute_error: 617.8404\n",
      "\n",
      "Epoch 00410: val_loss did not improve from 524.95797\n",
      "Epoch 411/500\n",
      "585/585 [==============================] - 0s 123us/step - loss: 834.0833 - mean_absolute_error: 834.0833 - val_loss: 655.9422 - val_mean_absolute_error: 655.9422\n",
      "\n",
      "Epoch 00411: val_loss did not improve from 524.95797\n",
      "Epoch 412/500\n",
      "585/585 [==============================] - 0s 140us/step - loss: 819.2167 - mean_absolute_error: 819.2167 - val_loss: 640.9981 - val_mean_absolute_error: 640.9981\n",
      "\n",
      "Epoch 00412: val_loss did not improve from 524.95797\n",
      "Epoch 413/500\n",
      "585/585 [==============================] - 0s 138us/step - loss: 804.3854 - mean_absolute_error: 804.3854 - val_loss: 672.2157 - val_mean_absolute_error: 672.2157\n",
      "\n",
      "Epoch 00413: val_loss did not improve from 524.95797\n",
      "Epoch 414/500\n",
      "585/585 [==============================] - 0s 130us/step - loss: 824.6767 - mean_absolute_error: 824.6767 - val_loss: 632.7445 - val_mean_absolute_error: 632.7445\n",
      "\n",
      "Epoch 00414: val_loss did not improve from 524.95797\n",
      "Epoch 415/500\n",
      "585/585 [==============================] - 0s 152us/step - loss: 822.6203 - mean_absolute_error: 822.6203 - val_loss: 692.0386 - val_mean_absolute_error: 692.0386\n",
      "\n",
      "Epoch 00415: val_loss did not improve from 524.95797\n",
      "Epoch 416/500\n",
      "585/585 [==============================] - 0s 135us/step - loss: 832.7025 - mean_absolute_error: 832.7025 - val_loss: 648.7938 - val_mean_absolute_error: 648.7938\n",
      "\n",
      "Epoch 00416: val_loss did not improve from 524.95797\n",
      "Epoch 417/500\n",
      "585/585 [==============================] - 0s 130us/step - loss: 828.6336 - mean_absolute_error: 828.6336 - val_loss: 776.1528 - val_mean_absolute_error: 776.1528\n",
      "\n",
      "Epoch 00417: val_loss did not improve from 524.95797\n",
      "Epoch 418/500\n",
      "585/585 [==============================] - 0s 136us/step - loss: 823.6574 - mean_absolute_error: 823.6574 - val_loss: 697.2295 - val_mean_absolute_error: 697.2295\n",
      "\n",
      "Epoch 00418: val_loss did not improve from 524.95797\n",
      "Epoch 419/500\n",
      "585/585 [==============================] - 0s 131us/step - loss: 849.7883 - mean_absolute_error: 849.7883 - val_loss: 713.5936 - val_mean_absolute_error: 713.5936\n",
      "\n",
      "Epoch 00419: val_loss did not improve from 524.95797\n",
      "Epoch 420/500\n",
      "585/585 [==============================] - 0s 131us/step - loss: 835.8002 - mean_absolute_error: 835.8002 - val_loss: 662.8940 - val_mean_absolute_error: 662.8940\n",
      "\n",
      "Epoch 00420: val_loss did not improve from 524.95797\n",
      "Epoch 421/500\n",
      "585/585 [==============================] - 0s 133us/step - loss: 852.7016 - mean_absolute_error: 852.7016 - val_loss: 613.1499 - val_mean_absolute_error: 613.1499\n",
      "\n",
      "Epoch 00421: val_loss did not improve from 524.95797\n",
      "Epoch 422/500\n",
      "585/585 [==============================] - 0s 135us/step - loss: 827.0121 - mean_absolute_error: 827.0121 - val_loss: 738.1571 - val_mean_absolute_error: 738.1571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00422: val_loss did not improve from 524.95797\n",
      "Epoch 423/500\n",
      "585/585 [==============================] - 0s 136us/step - loss: 800.6961 - mean_absolute_error: 800.6961 - val_loss: 713.6927 - val_mean_absolute_error: 713.6927\n",
      "\n",
      "Epoch 00423: val_loss did not improve from 524.95797\n",
      "Epoch 424/500\n",
      "585/585 [==============================] - 0s 147us/step - loss: 807.2719 - mean_absolute_error: 807.2719 - val_loss: 649.8955 - val_mean_absolute_error: 649.8955\n",
      "\n",
      "Epoch 00424: val_loss did not improve from 524.95797\n",
      "Epoch 425/500\n",
      "585/585 [==============================] - 0s 142us/step - loss: 815.5864 - mean_absolute_error: 815.5864 - val_loss: 662.7483 - val_mean_absolute_error: 662.7483\n",
      "\n",
      "Epoch 00425: val_loss did not improve from 524.95797\n",
      "Epoch 426/500\n",
      "585/585 [==============================] - 0s 138us/step - loss: 818.2453 - mean_absolute_error: 818.2453 - val_loss: 641.8186 - val_mean_absolute_error: 641.8186\n",
      "\n",
      "Epoch 00426: val_loss did not improve from 524.95797\n",
      "Epoch 427/500\n",
      "585/585 [==============================] - 0s 138us/step - loss: 804.2747 - mean_absolute_error: 804.2747 - val_loss: 663.7202 - val_mean_absolute_error: 663.7202\n",
      "\n",
      "Epoch 00427: val_loss did not improve from 524.95797\n",
      "Epoch 428/500\n",
      "585/585 [==============================] - 0s 143us/step - loss: 807.0190 - mean_absolute_error: 807.0190 - val_loss: 625.5917 - val_mean_absolute_error: 625.5917\n",
      "\n",
      "Epoch 00428: val_loss did not improve from 524.95797\n",
      "Epoch 429/500\n",
      "585/585 [==============================] - 0s 145us/step - loss: 839.0944 - mean_absolute_error: 839.0944 - val_loss: 697.6979 - val_mean_absolute_error: 697.6979\n",
      "\n",
      "Epoch 00429: val_loss did not improve from 524.95797\n",
      "Epoch 430/500\n",
      "585/585 [==============================] - 0s 143us/step - loss: 813.2140 - mean_absolute_error: 813.2140 - val_loss: 674.9993 - val_mean_absolute_error: 674.9993\n",
      "\n",
      "Epoch 00430: val_loss did not improve from 524.95797\n",
      "Epoch 431/500\n",
      "585/585 [==============================] - 0s 143us/step - loss: 810.6592 - mean_absolute_error: 810.6592 - val_loss: 662.1368 - val_mean_absolute_error: 662.1368\n",
      "\n",
      "Epoch 00431: val_loss did not improve from 524.95797\n",
      "Epoch 432/500\n",
      "585/585 [==============================] - 0s 138us/step - loss: 808.8818 - mean_absolute_error: 808.8818 - val_loss: 620.5506 - val_mean_absolute_error: 620.5506\n",
      "\n",
      "Epoch 00432: val_loss did not improve from 524.95797\n",
      "Epoch 433/500\n",
      "585/585 [==============================] - 0s 138us/step - loss: 841.5228 - mean_absolute_error: 841.5228 - val_loss: 760.6446 - val_mean_absolute_error: 760.6446\n",
      "\n",
      "Epoch 00433: val_loss did not improve from 524.95797\n",
      "Epoch 434/500\n",
      "585/585 [==============================] - 0s 148us/step - loss: 841.3895 - mean_absolute_error: 841.3895 - val_loss: 652.4135 - val_mean_absolute_error: 652.4135\n",
      "\n",
      "Epoch 00434: val_loss did not improve from 524.95797\n",
      "Epoch 435/500\n",
      "585/585 [==============================] - 0s 131us/step - loss: 815.9516 - mean_absolute_error: 815.9516 - val_loss: 619.2181 - val_mean_absolute_error: 619.2181\n",
      "\n",
      "Epoch 00435: val_loss did not improve from 524.95797\n",
      "Epoch 436/500\n",
      "585/585 [==============================] - 0s 140us/step - loss: 803.0626 - mean_absolute_error: 803.0626 - val_loss: 644.4291 - val_mean_absolute_error: 644.4291\n",
      "\n",
      "Epoch 00436: val_loss did not improve from 524.95797\n",
      "Epoch 437/500\n",
      "585/585 [==============================] - 0s 133us/step - loss: 834.8414 - mean_absolute_error: 834.8414 - val_loss: 702.4836 - val_mean_absolute_error: 702.4836\n",
      "\n",
      "Epoch 00437: val_loss did not improve from 524.95797\n",
      "Epoch 438/500\n",
      "585/585 [==============================] - 0s 140us/step - loss: 834.0437 - mean_absolute_error: 834.0437 - val_loss: 651.8381 - val_mean_absolute_error: 651.8381\n",
      "\n",
      "Epoch 00438: val_loss did not improve from 524.95797\n",
      "Epoch 439/500\n",
      "585/585 [==============================] - 0s 150us/step - loss: 818.9687 - mean_absolute_error: 818.9687 - val_loss: 662.4107 - val_mean_absolute_error: 662.4107\n",
      "\n",
      "Epoch 00439: val_loss did not improve from 524.95797\n",
      "Epoch 440/500\n",
      "585/585 [==============================] - 0s 131us/step - loss: 799.6163 - mean_absolute_error: 799.6163 - val_loss: 658.7652 - val_mean_absolute_error: 658.7652\n",
      "\n",
      "Epoch 00440: val_loss did not improve from 524.95797\n",
      "Epoch 441/500\n",
      "585/585 [==============================] - 0s 138us/step - loss: 847.2245 - mean_absolute_error: 847.2245 - val_loss: 667.7839 - val_mean_absolute_error: 667.7839\n",
      "\n",
      "Epoch 00441: val_loss did not improve from 524.95797\n",
      "Epoch 442/500\n",
      "585/585 [==============================] - 0s 126us/step - loss: 789.9729 - mean_absolute_error: 789.9729 - val_loss: 663.4371 - val_mean_absolute_error: 663.4371\n",
      "\n",
      "Epoch 00442: val_loss did not improve from 524.95797\n",
      "Epoch 443/500\n",
      "585/585 [==============================] - 0s 131us/step - loss: 798.6558 - mean_absolute_error: 798.6558 - val_loss: 674.4158 - val_mean_absolute_error: 674.4158\n",
      "\n",
      "Epoch 00443: val_loss did not improve from 524.95797\n",
      "Epoch 444/500\n",
      "585/585 [==============================] - 0s 128us/step - loss: 787.6914 - mean_absolute_error: 787.6914 - val_loss: 685.0544 - val_mean_absolute_error: 685.0544\n",
      "\n",
      "Epoch 00444: val_loss did not improve from 524.95797\n",
      "Epoch 445/500\n",
      "585/585 [==============================] - 0s 136us/step - loss: 817.0655 - mean_absolute_error: 817.0655 - val_loss: 655.9975 - val_mean_absolute_error: 655.9975\n",
      "\n",
      "Epoch 00445: val_loss did not improve from 524.95797\n",
      "Epoch 446/500\n",
      "585/585 [==============================] - 0s 128us/step - loss: 798.8565 - mean_absolute_error: 798.8565 - val_loss: 664.1374 - val_mean_absolute_error: 664.1374\n",
      "\n",
      "Epoch 00446: val_loss did not improve from 524.95797\n",
      "Epoch 447/500\n",
      "585/585 [==============================] - 0s 138us/step - loss: 786.2933 - mean_absolute_error: 786.2933 - val_loss: 660.2708 - val_mean_absolute_error: 660.2708\n",
      "\n",
      "Epoch 00447: val_loss did not improve from 524.95797\n",
      "Epoch 448/500\n",
      "585/585 [==============================] - 0s 150us/step - loss: 802.4831 - mean_absolute_error: 802.4831 - val_loss: 692.1077 - val_mean_absolute_error: 692.1077\n",
      "\n",
      "Epoch 00448: val_loss did not improve from 524.95797\n",
      "Epoch 449/500\n",
      "585/585 [==============================] - 0s 131us/step - loss: 805.8947 - mean_absolute_error: 805.8947 - val_loss: 647.8595 - val_mean_absolute_error: 647.8595\n",
      "\n",
      "Epoch 00449: val_loss did not improve from 524.95797\n",
      "Epoch 450/500\n",
      "585/585 [==============================] - 0s 128us/step - loss: 818.7755 - mean_absolute_error: 818.7755 - val_loss: 647.8360 - val_mean_absolute_error: 647.8360\n",
      "\n",
      "Epoch 00450: val_loss did not improve from 524.95797\n",
      "Epoch 451/500\n",
      "585/585 [==============================] - 0s 148us/step - loss: 806.9386 - mean_absolute_error: 806.9386 - val_loss: 660.9929 - val_mean_absolute_error: 660.9929\n",
      "\n",
      "Epoch 00451: val_loss did not improve from 524.95797\n",
      "Epoch 452/500\n",
      "585/585 [==============================] - 0s 142us/step - loss: 800.9016 - mean_absolute_error: 800.9016 - val_loss: 638.5703 - val_mean_absolute_error: 638.5703\n",
      "\n",
      "Epoch 00452: val_loss did not improve from 524.95797\n",
      "Epoch 453/500\n",
      "585/585 [==============================] - 0s 138us/step - loss: 789.1147 - mean_absolute_error: 789.1147 - val_loss: 686.4600 - val_mean_absolute_error: 686.4600\n",
      "\n",
      "Epoch 00453: val_loss did not improve from 524.95797\n",
      "Epoch 454/500\n",
      "585/585 [==============================] - 0s 126us/step - loss: 780.2737 - mean_absolute_error: 780.2737 - val_loss: 662.3002 - val_mean_absolute_error: 662.3002\n",
      "\n",
      "Epoch 00454: val_loss did not improve from 524.95797\n",
      "Epoch 455/500\n",
      "585/585 [==============================] - 0s 130us/step - loss: 804.8723 - mean_absolute_error: 804.8723 - val_loss: 648.0282 - val_mean_absolute_error: 648.0282\n",
      "\n",
      "Epoch 00455: val_loss did not improve from 524.95797\n",
      "Epoch 456/500\n",
      "585/585 [==============================] - 0s 128us/step - loss: 803.1285 - mean_absolute_error: 803.1285 - val_loss: 681.7411 - val_mean_absolute_error: 681.7411\n",
      "\n",
      "Epoch 00456: val_loss did not improve from 524.95797\n",
      "Epoch 457/500\n",
      "585/585 [==============================] - 0s 128us/step - loss: 868.7372 - mean_absolute_error: 868.7372 - val_loss: 626.7697 - val_mean_absolute_error: 626.7697\n",
      "\n",
      "Epoch 00457: val_loss did not improve from 524.95797\n",
      "Epoch 458/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "585/585 [==============================] - 0s 121us/step - loss: 862.5099 - mean_absolute_error: 862.5099 - val_loss: 692.3347 - val_mean_absolute_error: 692.3347\n",
      "\n",
      "Epoch 00458: val_loss did not improve from 524.95797\n",
      "Epoch 459/500\n",
      "585/585 [==============================] - 0s 124us/step - loss: 815.8295 - mean_absolute_error: 815.8295 - val_loss: 679.7314 - val_mean_absolute_error: 679.7314\n",
      "\n",
      "Epoch 00459: val_loss did not improve from 524.95797\n",
      "Epoch 460/500\n",
      "585/585 [==============================] - 0s 128us/step - loss: 790.9023 - mean_absolute_error: 790.9023 - val_loss: 683.9003 - val_mean_absolute_error: 683.9003\n",
      "\n",
      "Epoch 00460: val_loss did not improve from 524.95797\n",
      "Epoch 461/500\n",
      "585/585 [==============================] - 0s 147us/step - loss: 806.2559 - mean_absolute_error: 806.2559 - val_loss: 673.8144 - val_mean_absolute_error: 673.8144\n",
      "\n",
      "Epoch 00461: val_loss did not improve from 524.95797\n",
      "Epoch 462/500\n",
      "585/585 [==============================] - 0s 140us/step - loss: 784.5931 - mean_absolute_error: 784.5931 - val_loss: 677.3648 - val_mean_absolute_error: 677.3648\n",
      "\n",
      "Epoch 00462: val_loss did not improve from 524.95797\n",
      "Epoch 463/500\n",
      "585/585 [==============================] - 0s 135us/step - loss: 779.1417 - mean_absolute_error: 779.1417 - val_loss: 675.9577 - val_mean_absolute_error: 675.9577\n",
      "\n",
      "Epoch 00463: val_loss did not improve from 524.95797\n",
      "Epoch 464/500\n",
      "585/585 [==============================] - 0s 145us/step - loss: 789.3528 - mean_absolute_error: 789.3528 - val_loss: 754.6586 - val_mean_absolute_error: 754.6586\n",
      "\n",
      "Epoch 00464: val_loss did not improve from 524.95797\n",
      "Epoch 465/500\n",
      "585/585 [==============================] - 0s 116us/step - loss: 796.5889 - mean_absolute_error: 796.5889 - val_loss: 712.9972 - val_mean_absolute_error: 712.9972\n",
      "\n",
      "Epoch 00465: val_loss did not improve from 524.95797\n",
      "Epoch 466/500\n",
      "585/585 [==============================] - 0s 124us/step - loss: 809.6663 - mean_absolute_error: 809.6663 - val_loss: 618.1982 - val_mean_absolute_error: 618.1982\n",
      "\n",
      "Epoch 00466: val_loss did not improve from 524.95797\n",
      "Epoch 467/500\n",
      "585/585 [==============================] - 0s 152us/step - loss: 819.8145 - mean_absolute_error: 819.8145 - val_loss: 713.6870 - val_mean_absolute_error: 713.6870\n",
      "\n",
      "Epoch 00467: val_loss did not improve from 524.95797\n",
      "Epoch 468/500\n",
      "585/585 [==============================] - 0s 136us/step - loss: 788.8364 - mean_absolute_error: 788.8364 - val_loss: 686.9418 - val_mean_absolute_error: 686.9418\n",
      "\n",
      "Epoch 00468: val_loss did not improve from 524.95797\n",
      "Epoch 469/500\n",
      "585/585 [==============================] - 0s 150us/step - loss: 765.6567 - mean_absolute_error: 765.6567 - val_loss: 671.8220 - val_mean_absolute_error: 671.8220\n",
      "\n",
      "Epoch 00469: val_loss did not improve from 524.95797\n",
      "Epoch 470/500\n",
      "585/585 [==============================] - 0s 123us/step - loss: 775.0052 - mean_absolute_error: 775.0052 - val_loss: 700.5256 - val_mean_absolute_error: 700.5256\n",
      "\n",
      "Epoch 00470: val_loss did not improve from 524.95797\n",
      "Epoch 471/500\n",
      "585/585 [==============================] - 0s 138us/step - loss: 761.1615 - mean_absolute_error: 761.1615 - val_loss: 658.3246 - val_mean_absolute_error: 658.3246\n",
      "\n",
      "Epoch 00471: val_loss did not improve from 524.95797\n",
      "Epoch 472/500\n",
      "585/585 [==============================] - 0s 138us/step - loss: 808.4762 - mean_absolute_error: 808.4762 - val_loss: 707.2421 - val_mean_absolute_error: 707.2421\n",
      "\n",
      "Epoch 00472: val_loss did not improve from 524.95797\n",
      "Epoch 473/500\n",
      "585/585 [==============================] - 0s 147us/step - loss: 821.4517 - mean_absolute_error: 821.4517 - val_loss: 643.1544 - val_mean_absolute_error: 643.1544\n",
      "\n",
      "Epoch 00473: val_loss did not improve from 524.95797\n",
      "Epoch 474/500\n",
      "585/585 [==============================] - 0s 133us/step - loss: 882.5216 - mean_absolute_error: 882.5216 - val_loss: 629.9974 - val_mean_absolute_error: 629.9974\n",
      "\n",
      "Epoch 00474: val_loss did not improve from 524.95797\n",
      "Epoch 475/500\n",
      "585/585 [==============================] - 0s 131us/step - loss: 854.3595 - mean_absolute_error: 854.3595 - val_loss: 712.1217 - val_mean_absolute_error: 712.1217\n",
      "\n",
      "Epoch 00475: val_loss did not improve from 524.95797\n",
      "Epoch 476/500\n",
      "585/585 [==============================] - 0s 131us/step - loss: 854.3709 - mean_absolute_error: 854.3709 - val_loss: 762.0859 - val_mean_absolute_error: 762.0859\n",
      "\n",
      "Epoch 00476: val_loss did not improve from 524.95797\n",
      "Epoch 477/500\n",
      "585/585 [==============================] - 0s 126us/step - loss: 789.1811 - mean_absolute_error: 789.1811 - val_loss: 673.7232 - val_mean_absolute_error: 673.7232\n",
      "\n",
      "Epoch 00477: val_loss did not improve from 524.95797\n",
      "Epoch 478/500\n",
      "585/585 [==============================] - 0s 136us/step - loss: 808.8165 - mean_absolute_error: 808.8165 - val_loss: 645.3753 - val_mean_absolute_error: 645.3753\n",
      "\n",
      "Epoch 00478: val_loss did not improve from 524.95797\n",
      "Epoch 479/500\n",
      "585/585 [==============================] - 0s 145us/step - loss: 802.5883 - mean_absolute_error: 802.5883 - val_loss: 724.9020 - val_mean_absolute_error: 724.9020\n",
      "\n",
      "Epoch 00479: val_loss did not improve from 524.95797\n",
      "Epoch 480/500\n",
      "585/585 [==============================] - 0s 138us/step - loss: 778.5944 - mean_absolute_error: 778.5944 - val_loss: 675.6945 - val_mean_absolute_error: 675.6945\n",
      "\n",
      "Epoch 00480: val_loss did not improve from 524.95797\n",
      "Epoch 481/500\n",
      "585/585 [==============================] - 0s 135us/step - loss: 765.1512 - mean_absolute_error: 765.1512 - val_loss: 702.8958 - val_mean_absolute_error: 702.8958\n",
      "\n",
      "Epoch 00481: val_loss did not improve from 524.95797\n",
      "Epoch 482/500\n",
      "585/585 [==============================] - 0s 116us/step - loss: 779.9889 - mean_absolute_error: 779.9889 - val_loss: 693.7118 - val_mean_absolute_error: 693.7118\n",
      "\n",
      "Epoch 00482: val_loss did not improve from 524.95797\n",
      "Epoch 483/500\n",
      "585/585 [==============================] - 0s 119us/step - loss: 772.6282 - mean_absolute_error: 772.6282 - val_loss: 768.0047 - val_mean_absolute_error: 768.0047\n",
      "\n",
      "Epoch 00483: val_loss did not improve from 524.95797\n",
      "Epoch 484/500\n",
      "585/585 [==============================] - 0s 135us/step - loss: 788.3517 - mean_absolute_error: 788.3517 - val_loss: 692.0376 - val_mean_absolute_error: 692.0376\n",
      "\n",
      "Epoch 00484: val_loss did not improve from 524.95797\n",
      "Epoch 485/500\n",
      "585/585 [==============================] - 0s 131us/step - loss: 770.8005 - mean_absolute_error: 770.8005 - val_loss: 642.1802 - val_mean_absolute_error: 642.1802\n",
      "\n",
      "Epoch 00485: val_loss did not improve from 524.95797\n",
      "Epoch 486/500\n",
      "585/585 [==============================] - 0s 145us/step - loss: 753.5210 - mean_absolute_error: 753.5210 - val_loss: 672.1432 - val_mean_absolute_error: 672.1432\n",
      "\n",
      "Epoch 00486: val_loss did not improve from 524.95797\n",
      "Epoch 487/500\n",
      "585/585 [==============================] - 0s 126us/step - loss: 761.5037 - mean_absolute_error: 761.5037 - val_loss: 653.9379 - val_mean_absolute_error: 653.9379\n",
      "\n",
      "Epoch 00487: val_loss did not improve from 524.95797\n",
      "Epoch 488/500\n",
      "585/585 [==============================] - 0s 147us/step - loss: 772.3094 - mean_absolute_error: 772.3094 - val_loss: 660.0200 - val_mean_absolute_error: 660.0200\n",
      "\n",
      "Epoch 00488: val_loss did not improve from 524.95797\n",
      "Epoch 489/500\n",
      "585/585 [==============================] - 0s 131us/step - loss: 755.1910 - mean_absolute_error: 755.1910 - val_loss: 666.7260 - val_mean_absolute_error: 666.7260\n",
      "\n",
      "Epoch 00489: val_loss did not improve from 524.95797\n",
      "Epoch 490/500\n",
      "585/585 [==============================] - 0s 130us/step - loss: 760.7153 - mean_absolute_error: 760.7153 - val_loss: 731.2381 - val_mean_absolute_error: 731.2381\n",
      "\n",
      "Epoch 00490: val_loss did not improve from 524.95797\n",
      "Epoch 491/500\n",
      "585/585 [==============================] - 0s 162us/step - loss: 782.5442 - mean_absolute_error: 782.5442 - val_loss: 639.9955 - val_mean_absolute_error: 639.9955\n",
      "\n",
      "Epoch 00491: val_loss did not improve from 524.95797\n",
      "Epoch 492/500\n",
      "585/585 [==============================] - 0s 135us/step - loss: 777.3061 - mean_absolute_error: 777.3061 - val_loss: 682.8541 - val_mean_absolute_error: 682.8541\n",
      "\n",
      "Epoch 00492: val_loss did not improve from 524.95797\n",
      "Epoch 493/500\n",
      "585/585 [==============================] - 0s 135us/step - loss: 796.1852 - mean_absolute_error: 796.1852 - val_loss: 652.5066 - val_mean_absolute_error: 652.5066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00493: val_loss did not improve from 524.95797\n",
      "Epoch 494/500\n",
      "585/585 [==============================] - 0s 131us/step - loss: 802.2509 - mean_absolute_error: 802.2509 - val_loss: 816.5206 - val_mean_absolute_error: 816.5206\n",
      "\n",
      "Epoch 00494: val_loss did not improve from 524.95797\n",
      "Epoch 495/500\n",
      "585/585 [==============================] - 0s 135us/step - loss: 786.0715 - mean_absolute_error: 786.0715 - val_loss: 715.9642 - val_mean_absolute_error: 715.9642\n",
      "\n",
      "Epoch 00495: val_loss did not improve from 524.95797\n",
      "Epoch 496/500\n",
      "585/585 [==============================] - 0s 145us/step - loss: 769.0119 - mean_absolute_error: 769.0119 - val_loss: 701.2104 - val_mean_absolute_error: 701.2104\n",
      "\n",
      "Epoch 00496: val_loss did not improve from 524.95797\n",
      "Epoch 497/500\n",
      "585/585 [==============================] - 0s 148us/step - loss: 764.0921 - mean_absolute_error: 764.0921 - val_loss: 674.6322 - val_mean_absolute_error: 674.6322\n",
      "\n",
      "Epoch 00497: val_loss did not improve from 524.95797\n",
      "Epoch 498/500\n",
      "585/585 [==============================] - 0s 143us/step - loss: 761.4359 - mean_absolute_error: 761.4359 - val_loss: 669.2136 - val_mean_absolute_error: 669.2136\n",
      "\n",
      "Epoch 00498: val_loss did not improve from 524.95797\n",
      "Epoch 499/500\n",
      "585/585 [==============================] - 0s 142us/step - loss: 787.9219 - mean_absolute_error: 787.9219 - val_loss: 702.8174 - val_mean_absolute_error: 702.8174\n",
      "\n",
      "Epoch 00499: val_loss did not improve from 524.95797\n",
      "Epoch 500/500\n",
      "585/585 [==============================] - 0s 147us/step - loss: 786.6917 - mean_absolute_error: 786.6917 - val_loss: 789.6859 - val_mean_absolute_error: 789.6859\n",
      "\n",
      "Epoch 00500: val_loss did not improve from 524.95797\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25829d00470>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예제에서는 target을 대회에서 주는 target데이터를 기준으로 미리 train데이터와 맞춰졌있지만\n",
    "# gs/lv데이터는 아니다. 그래서 위에서 나누는 기준으로 삼은cut_line=732을 이용하여 데이터 사이즈를 맞춰준다.\n",
    "# 아니면 애시당초에(맨처음에) 훈련용 데이터와 타겟을 만들어 놓는것도 좋다.\n",
    "NN_model.fit(train, target[:cut_line], epochs=500, batch_size=32, validation_split = 0.2, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 500번을 학습하여 나온 결과들중, 가장 좋은(마지막에 저장된) Weights파일을 가져온다.\n",
    "# Load wights file of the best model :\n",
    "# 파일은 이 코드랑 같은 폴더에 위치해있어야 작동\n",
    "wights_file = '선케어date-Weights-245--529.65846-cat04-vf05.hdf5'\n",
    "NN_model.load_weights(wights_file) # load it\n",
    "NN_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "여기서 점수란 R-square값을 의미한다.\n",
      "Random forest을 이용한 선케어의 회귀분석 결과 :\n",
      "훈련세트점수 : 0.922\n",
      "검증세트점수 : 0.529\n",
      "XGBoost을 이용한 선케어의 회귀분석 결과 :\n",
      "훈련세트점수 : 0.796\n",
      "검증세트점수 : 0.522\n",
      "LinearRegression을 이용한 선케어의 회귀분석 결과 :\n",
      "훈련세트점수 : 0.527\n",
      "검증세트점수 : 0.466\n",
      "RidgeRegression을 이용한 선케어의 회귀분석 결과 :\n",
      "훈련세트점수 : 0.518\n",
      "검증세트점수 : 0.469\n",
      "LassoRegression을 이용한 선케어의 회귀분석 결과 :\n",
      "훈련세트점수 : 0.527\n",
      "검증세트점수 : 0.466\n",
      "OLS을 이용한 선케어의 회귀분석 결과 :\n",
      "훈련세트점수 : 0.527\n",
      "검증세트점수 : 0.466\n"
     ]
    }
   ],
   "source": [
    "#2016~2018전체를 난수로 0.67:0.33 = 2:1\n",
    "# train3 = combined.loc[:,'temp':]\n",
    "# target3 = combined.loc[:,'qty']\n",
    "# train_X, val_X, train_y, val_y = train_test_split(train3, target3, test_size = 0.33, random_state = 14)\n",
    "\n",
    "# 2016~2017 : 훈련 / 2018 검증 2:1\n",
    "# 1~732 / 732~1096\n",
    "trainXy = Xy[:cut_line]\n",
    "testXy = Xy[cut_line:]\n",
    "\n",
    "# 독립변수들\n",
    "train_X = trainXy.loc[:,'temp':]\n",
    "# 정답(판매량)\n",
    "train_y = trainXy.loc[:,'qty']\n",
    "\n",
    "val_X = testXy.loc[:,'temp':]\n",
    "val_y = testXy.loc[:,'qty']\n",
    "\n",
    "print('여기서 점수란 R-square값을 의미한다.')\n",
    "# RandomForest 회귀분석\n",
    "RFmodel = RandomForestRegressor()\n",
    "RFmodel.fit(train_X,train_y)\n",
    "# Get the mean absolute error on the validation data\n",
    "RFpredicted = RFmodel.predict(val_X)\n",
    "MAE = mean_absolute_error(val_y , RFpredicted)\n",
    "print('Random forest을 이용한 %s의 회귀분석 결과 :'%item)\n",
    "# print('Random forest validation MAE = ', MAE)\n",
    "print('훈련세트점수 : {:.3f}'.format(RFmodel.score(train_X, train_y)))\n",
    "print('검증세트점수 : {:.3f}'.format(RFmodel.score(val_X, val_y)))\n",
    "\n",
    "# XGBRegressor 회귀분석\n",
    "XGBModel = XGBRegressor(objective='reg:squarederror')\n",
    "XGBModel.fit(train_X,train_y , verbose=False)\n",
    "# Get the mean absolute error on the validation data :\n",
    "XGBpredictions = XGBModel.predict(val_X)\n",
    "MAE = mean_absolute_error(val_y , XGBpredictions)\n",
    "print('XGBoost을 이용한 %s의 회귀분석 결과 :'%item)\n",
    "# print('XGBoost validation MAE = ',MAE)\n",
    "print('훈련세트점수 : {:.3f}'.format(XGBModel.score(train_X, train_y)))\n",
    "print('검증세트점수 : {:.3f}'.format(XGBModel.score(val_X, val_y)))\n",
    "\n",
    "linReg = LinearRegression().fit(train_X, train_y)\n",
    "print('LinearRegression을 이용한 %s의 회귀분석 결과 :'%item)\n",
    "print('훈련세트점수 : {:.3f}'.format(linReg.score(train_X, train_y)))\n",
    "print('검증세트점수 : {:.3f}'.format(linReg.score(val_X, val_y)))\n",
    "\n",
    "ridge = Ridge(alpha=0.1, normalize=True, random_state=0, tol=0.001).fit(train_X, train_y)\n",
    "print('RidgeRegression을 이용한 %s의 회귀분석 결과 :'%item)\n",
    "print('훈련세트점수 : {:.3f}'.format(ridge.score(train_X, train_y)))\n",
    "print('검증세트점수 : {:.3f}'.format(ridge.score(val_X, val_y)))\n",
    "\n",
    "lasso = Lasso(alpha=0.1, max_iter=1000).fit(train_X, train_y)\n",
    "print('LassoRegression을 이용한 %s의 회귀분석 결과 :'%item)\n",
    "print('훈련세트점수 : {:.3f}'.format(lasso.score(train_X, train_y)) )\n",
    "print('검증세트점수 : {:.3f}'.format(lasso.score(val_X, val_y)) )\n",
    "\n",
    "columns_in_data = list(train_X.columns)\n",
    "customF = formulaGen(target='qty',ind_features=columns_in_data)\n",
    "olsModel = sm.OLS.from_formula(customF, data=trainXy).fit()\n",
    "print('OLS을 이용한 %s의 회귀분석 결과 :'%item)\n",
    "print('훈련세트점수 : {:.3f}'.format(olsModel.rsquared) )\n",
    "print('검증세트점수 : {:.3f}'.format( r2_score(val_y, olsModel.predict(val_X))   ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사람이 직접 식을 때려 박았을때 : 0.526\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    qty   R-squared:                       0.544\n",
      "Model:                            OLS   Adj. R-squared:                  0.540\n",
      "Method:                 Least Squares   F-statistic:                     143.9\n",
      "Date:                Fri, 19 Jul 2019   Prob (F-statistic):          6.21e-120\n",
      "Time:                        21:04:47   Log-Likelihood:                -6387.0\n",
      "No. Observations:                 732   AIC:                         1.279e+04\n",
      "Df Residuals:                     725   BIC:                         1.282e+04\n",
      "Df Model:                           6                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "================================================================================\n",
      "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------\n",
      "Intercept     -751.5701    359.723     -2.089      0.037   -1457.794     -45.346\n",
      "I(temp ** 2)     5.2232      0.230     22.667      0.000       4.771       5.676\n",
      "cloud          156.6730     34.853      4.495      0.000      88.248     225.098\n",
      "wind           106.8038     82.385      1.296      0.195     -54.938     268.546\n",
      "lgt_time       178.6105     27.932      6.394      0.000     123.773     233.448\n",
      "rain_or_not    290.5965    161.701      1.797      0.073     -26.861     608.054\n",
      "snow_or_not   -324.6933    297.002     -1.093      0.275    -907.780     258.394\n",
      "==============================================================================\n",
      "Omnibus:                       52.370   Durbin-Watson:                   0.469\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               70.786\n",
      "Skew:                           0.587   Prob(JB):                     4.26e-16\n",
      "Kurtosis:                       3.972   Cond. No.                     2.48e+03\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.48e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "# columns_in_data = ['temp', 'cloud', 'wind', 'lgt_time', 'rain_or_not', 'snow_or_not',\n",
    "#                     '공기상태_0', '공기상태_1', '공기상태_2']\n",
    "\n",
    "# formulaGen은 단순 1차 다항식을 제조해준다.\n",
    "# customF = formulaGen(target='qty',ind_features=columns_in_data)\n",
    "# customF = formulaGen(target='qty',ind_features=['temp', 'wind','lgt_time','rain_or_not'])\n",
    "customF = 'qty ~ I(temp**2) + cloud + wind + lgt_time + rain_or_not + snow_or_not'\n",
    "\n",
    "olsModel = sm.OLS.from_formula(customF, data=trainXy).fit()\n",
    "print('사람이 직접 식을 때려 박았을때 : {:.3f}'.format(r2_score(val_y, olsModel.predict(val_X))) )\n",
    "print(olsModel.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# col_list = ['temp', 'cloud', 'wind', 'lgt_time', 'PM10', 'rain_or_not_o', 'snow_or_not_o',\n",
    "#             '공기상태_0', '공기상태_1', '공기상태_2']\n",
    "col_list = ['temp', 'cloud', 'wind', 'lgt_time', 'PM10', 'rain_or_not_o', 'snow_or_not_o',\n",
    "            '공기상태']\n",
    "combined = Xy.loc[:,'temp':]\n",
    "target = Xy.loc[:,'qty']\n",
    "\n",
    "# 가장 좋다고 판명된 설정을 이용하여, 예측qty생산\n",
    "predictions = NN_model.predict(combined)\n",
    "# RandomForest 회귀분석 예측 qty생산\n",
    "RFpredicted = RFmodel.predict(combined)\n",
    "# XGBRegressor 회귀분석 예측 qty생산\n",
    "XGBpredictions = XGBModel.predict(combined)\n",
    "# linearRegression 회귀분석 예측 qty생산\n",
    "linPred = linReg.predict(combined)\n",
    "# Ridge 회귀분석 예측 qty생산\n",
    "ridPred = ridge.predict(combined)\n",
    "# Lasso 회귀분석 예측 qty생산\n",
    "lassoPred = lasso.predict(combined)\n",
    "# OLS 회귀분석 예측 qty생산\n",
    "olsPred = olsModel.predict(combined)\n",
    "\n",
    "result_df = pd.DataFrame()\n",
    "result_df['date'] = lv_day_w['date']\n",
    "result_df['qty'] = Xy.loc[:,'qty']\n",
    "\n",
    "# print(\"keras 신경망 predictions\",predictions.shape)\n",
    "result_df['keras_qty'] = predictions\n",
    "\n",
    "# print(\"randomforest 예상\",RFpredicted.shape)\n",
    "result_df['rf_qty'] = RFpredicted\n",
    "\n",
    "# print(\"XGBpredictions\",XGBpredictions.shape)\n",
    "result_df['xgb_qty'] = XGBpredictions\n",
    "\n",
    "# print(\"linearRegression 예상\",RFpredicted.shape)\n",
    "result_df['lin_qty'] = linPred\n",
    "\n",
    "# print(\"Ridge 예상\",RFpredicted.shape)\n",
    "result_df['ridge_qty'] = ridPred\n",
    "\n",
    "# print(\"Lasso 예상\",RFpredicted.shape)\n",
    "result_df['lasso_qty'] = lassoPred\n",
    "\n",
    "# print(\"OLS 예상\",RFpredicted.shape)\n",
    "result_df['ols_qty'] = olsPred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras 인공 신경망 모델 MAPE \t: 0.36\n",
      "Linear 모델 MAPE \t\t: 0.59\n",
      "Ridge 모델 MAPE \t\t: 0.59\n",
      "Lasso 모델 MAPE \t\t: 0.59\n",
      "OLS 모델 MAPE \t\t\t: 0.52\n"
     ]
    }
   ],
   "source": [
    "# 예측률 계산\n",
    "# https://yamalab.tistory.com/46\n",
    "\n",
    "# RMSE (Root Mean Squared Error) : \n",
    "# OLS 추정에서 일반적인 표준 오차이다. 예측 대상의 scale(단위 크기)에 주의해야하는 단점이 있다. \n",
    "# MSE는 root를 수식에서 제외, SSE는 root와 분모를 제외한 수식으로, SE가 붙은 척도들은 거기서 거기인 척도들이라고 보면 된다.\n",
    "# 다만 디테일한 사용법에 차이가 있을 뿐.\n",
    "\n",
    "# MAPE (Mean Absolute Percentage Error) :\n",
    "\n",
    "# 위 방법의 단점을 보완한 것이다. \n",
    "# At는 실제값, Ft는 예측값인데, 이를 At로 나누어서 오차를 절대적 크기로 보는것이 아닌\n",
    "# 비율의 크기로 보고자 하는 것이 핵심이다.\n",
    "# 이 방법은 At가 0에 가까울수록 비정상적인 값이 나온다는 단점이 있다.\n",
    "\n",
    "# MAPE가 0에 가까울수록 좋은 모델\n",
    "result_df['mape_keras'] = abs((result_df.qty - result_df.keras_qty) / result_df.qty )\n",
    "result_df['mape_rf'] = abs((result_df.qty - result_df.rf_qty) / result_df.qty )\n",
    "result_df['mape_xgb'] = abs((result_df.qty - result_df.xgb_qty) / result_df.qty )\n",
    "result_df['mape_lin'] = abs((result_df.qty - result_df.lin_qty) / result_df.qty )\n",
    "result_df['mape_ridge'] = abs((result_df.qty - result_df.ridge_qty) / result_df.qty )\n",
    "result_df['mape_lasso'] = abs((result_df.qty - result_df.lasso_qty) / result_df.qty )\n",
    "result_df['mape_ols'] = abs((result_df.qty - result_df.ols_qty) / result_df.qty )\n",
    "\n",
    "print('Keras 인공 신경망 모델 MAPE \\t: {:<.2f}'.format(result_df['mape_keras'].sum() / result_df.shape[0] ))\n",
    "# print('RandomForest 모델 MAPE \\t\\t: {:<.2f}'.format(result_df['mape_rf'].sum() / result_df.shape[0] ))\n",
    "# print('XGBoosting  모델 MAPE \\t\\t: {:<.2f}'.format(result_df['mape_xgb'].sum() / result_df.shape[0] ))\n",
    "print('Linear 모델 MAPE \\t\\t: {:<.2f}'.format(result_df['mape_lin'].sum() / result_df.shape[0] ))\n",
    "print('Ridge 모델 MAPE \\t\\t: {:<.2f}'.format(result_df['mape_ridge'].sum() / result_df.shape[0] ))\n",
    "print('Lasso 모델 MAPE \\t\\t: {:<.2f}'.format(result_df['mape_lasso'].sum() / result_df.shape[0] ))\n",
    "print('OLS 모델 MAPE \\t\\t\\t: {:<.2f}'.format(result_df['mape_ols'].sum() / result_df.shape[0] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1116x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 독립변수 Xy의 col번호: 0=qty\n",
    "# ['qty', 'temp', 'cloud', 'wind', 'lgt_time', 'rain_or_not','snow_or_not', \n",
    "#                                                   '공기상태_0', '공기상태_1', '공기상태_2']\n",
    "\n",
    "# 1~9 : 1 temp ~ 9 공기상태_2\n",
    "n= 1\n",
    "# alpha 값 0~1\n",
    "alp = 1\n",
    "# scatter plot 점 크기\n",
    "dot_size = 20\n",
    "\n",
    "matplotlib.rcParams['font.family'] = 'NanumGothicCoding'\n",
    "plt.figure(figsize=(15.5,7))\n",
    "plt.style.use('ggplot')\n",
    "plt.title('%s - %s vs 판매량' % (item, Xy.columns[n]) )\n",
    "plt.scatter(Xy.iloc[:,n],result_df.qty, label = '실 판매량', s=20, c='k')\n",
    "plt.scatter(Xy.iloc[:,n],result_df.keras_qty, label = '케라스 신경망 예측', alpha=alp, s=dot_size)\n",
    "# plt.scatter(Xy.iloc[:,n],result_df.rf_qty, label = 'RandomForest 예측', alpha=alp, s=dot_size)\n",
    "# plt.scatter(Xy.iloc[:,n],result_df.xgb_qty, label = 'XGBoosting 예측', alpha=alp, s=dot_size)\n",
    "# plt.scatter(Xy.iloc[:,n],result_df.lin_qty, label = '선형 예측', alpha=alp, s=dot_size)\n",
    "# plt.scatter(Xy.iloc[:,n],result_df.ridge_qty, label = 'Ridge 예측', alpha=alp, s=dot_size)\n",
    "# plt.scatter(Xy.iloc[:,n],result_df.ols_qty, label = 'OLS 예측', alpha=alp, s=dot_size)\n",
    "\n",
    "# X axis\n",
    "plt.xlabel('{}'.format(Xy.columns[n]))\n",
    "\n",
    "# y axis\n",
    "plt.ylabel('판매량')\n",
    "\n",
    "# 범례\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실험 구간"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# # 2016~2017 : 훈련 / 2018 검증 2:1\n",
    "# # 1~106 / 106~156\n",
    "# trainXy = gs_week_w.loc[:cut_line]\n",
    "# testXy = gs_week_w.loc[cut_line:]\n",
    "# train_X =pd.DataFrame(trainXy.loc[:,'temp'])\n",
    "# train_y = trainXy.loc[:,'qty']\n",
    "# val_X = pd.DataFrame(testXy.loc[:,'temp'])\n",
    "# val_y = testXy.loc[:,'qty']\n",
    "\n",
    "\n",
    "\n",
    "# print('여기서 점수란 R-square값을 의미한다.')\n",
    "# # RandomForest 회귀분석\n",
    "# RFmodel = RandomForestRegressor()\n",
    "# RFmodel.fit(train_X,train_y)\n",
    "# # Get the mean absolute error on the validation data\n",
    "# RFpredicted = RFmodel.predict(val_X)\n",
    "# MAE = mean_absolute_error(val_y , RFpredicted)\n",
    "# print('Random forest을 이용한 %s의 회귀분석 결과 :'%item)\n",
    "# # print('Random forest validation MAE = ', MAE)\n",
    "# print('훈련세트점수 : {:.3f}'.format(RFmodel.score(train_X, train_y)))\n",
    "# print('검증세트점수 : {:.3f}'.format(RFmodel.score(val_X, val_y)))\n",
    "\n",
    "# # XGBRegressor 회귀분석\n",
    "# XGBModel = XGBRegressor(objective='reg:squarederror')\n",
    "# XGBModel.fit(train_X,train_y , verbose=False)\n",
    "# # Get the mean absolute error on the validation data :\n",
    "# XGBpredictions = XGBModel.predict(val_X)\n",
    "# MAE = mean_absolute_error(val_y , XGBpredictions)\n",
    "# print('XGBoost을 이용한 %s의 회귀분석 결과 :'%item)\n",
    "# # print('XGBoost validation MAE = ',MAE)\n",
    "# print('훈련세트점수 : {:.3f}'.format(XGBModel.score(train_X, train_y)))\n",
    "# print('검증세트점수 : {:.3f}'.format(XGBModel.score(val_X, val_y)))\n",
    "\n",
    "# linReg = LinearRegression().fit(train_X, train_y)\n",
    "# print('LinearRegression을 이용한 %s의 회귀분석 결과 :'%item)\n",
    "# print('훈련세트점수 : {:.3f}'.format(linReg.score(train_X, train_y)))\n",
    "# print('검증세트점수 : {:.3f}'.format(linReg.score(val_X, val_y)))\n",
    "\n",
    "# ridge = Ridge(alpha=0.1, normalize=True, random_state=0, tol=0.001).fit(train_X, train_y)\n",
    "# print('RidgeRegression을 이용한 %s의 회귀분석 결과 :'%item)\n",
    "# print('훈련세트점수 : {:.3f}'.format(ridge.score(train_X, train_y)))\n",
    "# print('검증세트점수 : {:.3f}'.format(ridge.score(val_X, val_y)))\n",
    "\n",
    "# lasso = Lasso(alpha=0.1, max_iter=1000).fit(train_X, train_y)\n",
    "# print('LassoRegression을 이용한 %s의 회귀분석 결과 :'%item)\n",
    "# print('훈련세트점수 : {:.3f}'.format(lasso.score(train_X, train_y)) )\n",
    "# print('검증세트점수 : {:.3f}'.format(lasso.score(val_X, val_y)) )\n",
    "\n",
    "# customF = formulaGen(target='qty',ind_features=['temp'])\n",
    "# olsModel = sm.OLS.from_formula(customF, data=trainXy).fit()\n",
    "# print('OLS을 이용한 %s의 회귀분석 결과 :'%item)\n",
    "# print('훈련세트점수 : {:.3f}'.format(olsModel.rsquared) )\n",
    "\n",
    "# combined = pd.DataFrame(gs_week_w.loc[:,'temp'])\n",
    "# target = gs_week_w.loc[:,'qty']\n",
    "\n",
    "# # 가장 좋다고 판명된 설정을 이용하여, 예측qty생산\n",
    "# # predictions = NN_model.predict(combined)\n",
    "# # RandomForest 회귀분석 예측 qty생산\n",
    "# RFpredicted = RFmodel.predict(combined)\n",
    "# # XGBRegressor 회귀분석 예측 qty생산\n",
    "# XGBpredictions = XGBModel.predict(combined)\n",
    "# # linearRegression 회귀분석 예측 qty생산\n",
    "# linPred = linReg.predict(combined)\n",
    "# # Ridge 회귀분석 예측 qty생산\n",
    "# ridPred = ridge.predict(combined)\n",
    "# # Lasso 회귀분석 예측 qty생산\n",
    "# lassoPred = lasso.predict(combined)\n",
    "# # OLS 회귀분석 예측 qty생산\n",
    "# olsPred = olsModel.predict(combined)\n",
    "\n",
    "# result_df = pd.DataFrame()\n",
    "# result_df['week'] = gs_week_w['week']\n",
    "# result_df['qty'] = gs_week_w.loc[:,'qty']\n",
    "\n",
    "# # print(\"keras 신경망 predictions\",predictions.shape)\n",
    "# # result_df['keras_qty'] = predictions\n",
    "\n",
    "# # print(\"randomforest 예상\",RFpredicted.shape)\n",
    "# result_df['rf_qty'] = RFpredicted\n",
    "\n",
    "# # print(\"XGBpredictions\",XGBpredictions.shape)\n",
    "# result_df['xgb_qty'] = XGBpredictions\n",
    "\n",
    "# # print(\"linearRegression 예상\",RFpredicted.shape)\n",
    "# result_df['lin_qty'] = linPred\n",
    "\n",
    "# # print(\"Ridge 예상\",RFpredicted.shape)\n",
    "# result_df['ridge_qty'] = ridPred\n",
    "\n",
    "# # print(\"Lasso 예상\",RFpredicted.shape)\n",
    "# result_df['lasso_qty'] = lassoPred\n",
    "\n",
    "# # print(\"OLS 예상\",RFpredicted.shape)\n",
    "# result_df['ols_qty'] = olsPred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ============================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_graph = result_df.loc[:,['week','qty','keras_qty','rf_qty','xgb_qty','lin_qty','ridge_qty','lasso_qty','ols_qty']]\n",
    "# for_visual_col = ['week','temp','cloud','wind','lgt_time','snow','rain','PM10']\n",
    "# df = pd.merge(df_graph, gs_week_w[for_visual_col], on='week', how='left')\n",
    "# # df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2016, 온도\n",
    "# df_graph = df.loc[df.week <= 53]\n",
    "# plt.figure(figsize=(15.5, 10))\n",
    "# plt.scatter(df_graph.temp,df_graph.qty, ls='-', label='실제', color='green', alpha=0.5, lw=8)\n",
    "# plt.scatter(df_graph.temp,df_graph.keras_qty, ls='-', label='keras예측', color='r')\n",
    "# plt.scatter(df_graph.temp,df_graph.rf_qty, ls='-', label='rf예측', color='cyan')\n",
    "# plt.scatter(df_graph.temp,df_graph.xgb_qty, ls='-', label='xgb예측', color='b')\n",
    "# plt.scatter(df_graph.temp,df_graph.lin_qty, ls='-', label='linear예측')\n",
    "# plt.scatter(df_graph.temp,df_graph.ridge_qty, ls='-', label='ridge예측')\n",
    "# plt.scatter(df_graph.temp,df_graph.lasso_qty, ls='-', label='lasso예측',color='yellow')\n",
    "# plt.scatter(df_graph.temp,df_graph.ols_qty, ls='-', label='ols예측', color='violet')\n",
    "# plt.legend()\n",
    "# plt.title('{}년도 {} 판매량 실제/예측'.format( '2016',item ))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qty_columns = list(df_graph.columns)[1:9]\n",
    "# weather_columns = list(df_graph.columns)[9:]\n",
    "# print(qty_columns)\n",
    "# print(weather_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_temp = pd.DataFrame()\n",
    "# # x_temp['temp'] = list(range(-10,35,1))\n",
    "# x_temp['temp'] = np.arange(-9,35,0.5)\n",
    "# combined = x_temp\n",
    "# # RandomForest 회귀분석 예측 qty생산\n",
    "# RFpredicted = RFmodel.predict(combined)\n",
    "# # XGBRegressor 회귀분석 예측 qty생산\n",
    "# XGBpredictions = XGBModel.predict(combined)\n",
    "# # linearRegression 회귀분석 예측 qty생산\n",
    "# linPred = linReg.predict(combined)\n",
    "# # Ridge 회귀분석 예측 qty생산\n",
    "# ridPred = ridge.predict(combined)\n",
    "# # Lasso 회귀분석 예측 qty생산\n",
    "# lassoPred = lasso.predict(combined)\n",
    "# # OLS 회귀분석 예측 qty생산\n",
    "# olsPred = olsModel.predict(combined)\n",
    "\n",
    "# # 2016~2018, 일조시간\n",
    "# df_graph = df.copy()\n",
    "# plt.figure(figsize=(15.5, 10))\n",
    "# plt.scatter(df_graph[weather_columns[0]],df_graph['qty'], ls='-', color='k',label='실 판매량', s=100, alpha=0.7)\n",
    "# plt.plot(x_temp, RFpredicted, label = 'rf')\n",
    "# plt.plot(x_temp, XGBpredictions, label = 'xgb')\n",
    "# plt.plot(x_temp, linPred, label = 'line')\n",
    "# plt.plot(x_temp, ridPred, label = 'ridge')\n",
    "# plt.plot(x_temp, lassoPred, label = 'lasso')\n",
    "# plt.plot(x_temp, olsPred, label = 'ols')\n",
    "# plt.plot()\n",
    "# plt.legend()\n",
    "# plt.title('{}년도 {} 판매량 실제/예측'.format( '2016~2018',item ))\n",
    "# plt.xlabel(weather_columns[0])\n",
    "# plt.ylabel('판매량 (단위 : 1개)')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 실험"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intercept_lin = linReg.intercept_\n",
    "# coef_line = linReg.coef_\n",
    "# # list_col\n",
    "# linePredict = list()\n",
    "# x_temp = list(range(-10,38,1))\n",
    "# for temperature in x_temp:\n",
    "#     linePredict.append(intercept_lin + coef_line[0]*temperature)\n",
    "\n",
    "    \n",
    "# # 2016~2018, 일조시간\n",
    "# df_graph = df.copy()\n",
    "# plt.figure(figsize=(15.5, 10))\n",
    "# plt.scatter(df_graph[weather_columns[0]],df_graph['qty'], ls='-', color='k',label='실 판매량', s=100, alpha=0.3)\n",
    "# # for q_name in qty_columns:\n",
    "# #     plt.plot(df_graph[weather_columns[0]],df_graph[q_name], ls='-', label=q_name)\n",
    "# #     plt.scatter(df_graph.lgt_time,df_graph[q_name], ls='-', label='실제', color='green', alpha=0.5, lw=8)\n",
    "# #     plt.scatter(df_graph.lgt_time,df_graph.keras_qty, ls='-', label='keras예측', color='r')\n",
    "# #     plt.scatter(df_graph.lgt_time,df_graph.rf_qty, ls='-', label='rf예측', color='cyan')\n",
    "# #     plt.scatter(df_graph.lgt_time,df_graph.xgb_qty, ls='-', label='xgb예측', color='b')\n",
    "# #     plt.scatter(df_graph.lgt_time,df_graph.lin_qty, ls='-', label='linear예측')\n",
    "# #     plt.scatter(df_graph.lgt_time,df_graph.ridge_qty, ls='-', label='ridge예측')\n",
    "# #     plt.scatter(df_graph.lgt_time,df_graph.lasso_qty, ls='-', label='lasso예측',color='yellow')\n",
    "# #     plt.scatter(df_graph.lgt_time,df_graph.ols_qty, ls='-', label='ols예측', color='violet')\n",
    "# plt.plot(x_temp, linePredict, 'r--', label='linear회귀, 온도만')\n",
    "\n",
    "# plt.legend()\n",
    "# plt.title('{}년도 {} 판매량 실제/예측'.format( '2016~2018',item ))\n",
    "# plt.xlabel(weather_columns[0])\n",
    "# plt.ylabel('판매량 (단위 : 1개)')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 시간의 경과에 따른 예측량 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 2016\n",
    "# df_graph = result_df.loc[result_df.week <=53]\n",
    "# plt.figure(figsize=(15.5, 10))\n",
    "# plt.plot(df_graph.week,df_graph.qty, ls='-', label='실제', color='green', alpha=0.5, lw=8)\n",
    "# plt.plot(df_graph.week,df_graph.keras_qty, ls='-', label='keras예측', color='r')\n",
    "# plt.plot(df_graph.week,df_graph.rf_qty, ls='-', label='rf예측', color='cyan')\n",
    "# plt.plot(df_graph.week,df_graph.xgb_qty, ls='-', label='xgb예측', color='b')\n",
    "# plt.plot(df_graph.week,df_graph.lin_qty, ls='-', label='linear예측')\n",
    "# plt.plot(df_graph.week,df_graph.ridge_qty, ls='-', label='ridge예측')\n",
    "# plt.plot(df_graph.week,df_graph.lasso_qty, ls='-', label='lasso예측',color='yellow')\n",
    "# plt.plot(df_graph.week,df_graph.ols_qty, ls='-', label='ols예측', color='violet')\n",
    "# plt.legend()\n",
    "# plt.title('{}년도 {} 판매량 실제/예측'.format( '2016',item ))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 2017\n",
    "# df_graph = result_df.loc[(result_df.week >=53)&(result_df.week <=105)]\n",
    "# plt.figure(figsize=(15.5, 10))\n",
    "# plt.plot(df_graph.week,df_graph.qty, ls='-', label='실제', color='green', alpha=0.5, lw=8)\n",
    "# plt.plot(df_graph.week,df_graph.keras_qty, ls='-', label='keras예측', color='r')\n",
    "# plt.plot(df_graph.week,df_graph.rf_qty, ls='-', label='rf예측', color='cyan')\n",
    "# plt.plot(df_graph.week,df_graph.xgb_qty, ls='-', label='xgb예측', color='b')\n",
    "# plt.plot(df_graph.week,df_graph.lin_qty, ls='-', label='linear예측')\n",
    "# plt.plot(df_graph.week,df_graph.ridge_qty, ls='-', label='ridge예측')\n",
    "# plt.plot(df_graph.week,df_graph.lasso_qty, ls='-', label='lasso예측',color='yellow')\n",
    "# plt.plot(df_graph.week,df_graph.ols_qty, ls='-', label='ols예측', color='violet')\n",
    "# plt.title('{}년도 {} 판매량 실제/예측'.format( '2017',item ))\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 2018\n",
    "# df_graph = result_df.loc[(result_df.week >=105)]\n",
    "# plt.figure(figsize=(15.5, 10))\n",
    "# plt.plot(df_graph.week,df_graph.qty, ls='-', label='실제', color='green', alpha=0.5, lw=8)\n",
    "# plt.plot(df_graph.week,df_graph.keras_qty, ls='-', label='keras예측', color='r')\n",
    "# plt.plot(df_graph.week,df_graph.rf_qty, ls='-', label='rf예측', color='cyan')\n",
    "# plt.plot(df_graph.week,df_graph.xgb_qty, ls='-', label='xgb예측', color='b')\n",
    "# plt.plot(df_graph.week,df_graph.lin_qty, ls='-', label='linear예측')\n",
    "# plt.plot(df_graph.week,df_graph.ridge_qty, ls='-', label='ridge예측')\n",
    "# plt.plot(df_graph.week,df_graph.lasso_qty, ls='-', label='lasso예측',color='yellow')\n",
    "# plt.plot(df_graph.week,df_graph.ols_qty, ls='-', label='ols예측', color='violet')\n",
    "# plt.title('{}년도 {} 판매량 실제/예측'.format( '2018',item ))\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 2016~2018\n",
    "# plt.figure(figsize=(15.5, 10))\n",
    "# plt.plot(result_df.week,result_df.qty, ls='-', label='실제', color='green', alpha=0.5, lw=8)\n",
    "# plt.plot(result_df.week,result_df.keras_qty, ls='-', label='keras예측', color='r')\n",
    "# plt.plot(result_df.week,result_df.rf_qty, ls='-', label='rf예측', color='cyan')\n",
    "# plt.plot(result_df.week,result_df.xgb_qty, ls='-', label='xgb예측', color='b')\n",
    "# plt.plot(df_graph.week,df_graph.lin_qty, ls='-', label='linear예측')\n",
    "# plt.plot(df_graph.week,df_graph.ridge_qty, ls='-', label='ridge예측')\n",
    "# plt.plot(df_graph.week,df_graph.lasso_qty, ls='-', label='lasso예측',color='yellow')\n",
    "# plt.plot(df_graph.week,df_graph.ols_qty, ls='-', label='ols예측', color='violet')\n",
    "# plt.title('{}년도 {} 판매량 실제/예측'.format( '2016~2018',item ))\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def r2_score(v_true, v_pred):\n",
    "#     ssr = np.sum(np.square(v_pred - np.mean(v_true)))\n",
    "#     sst = np.sum(np.square(v_true - np.mean(v_true)))\n",
    "#     return ( ssr / sst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checked_for = '2016~2017'\n",
    "# combined = aaaaa.loc[:106,'temp':'PM10']\n",
    "# target = aaaaa.loc[:106,'qty']\n",
    "\n",
    "# # 가장 좋다고 판명된 설정을 이용하여, 예측qty생산\n",
    "# predictions = NN_model.predict(combined)\n",
    "# # RandomForest 회귀분석 예측 qty생산\n",
    "# RFpredicted = RFmodel.predict(combined)\n",
    "# # XGBRegressor 회귀분석 예측 qty생산\n",
    "# XGBpredictions = XGBModel.predict(combined)\n",
    "# # linearRegression 회귀분석 예측 qty생산\n",
    "# linPred = linReg.predict(combined)\n",
    "# # Ridge 회귀분석 예측 qty생산\n",
    "# ridPred = ridge.predict(combined)\n",
    "# # Lasso 회귀분석 예측 qty생산\n",
    "# lassoPred = lasso.predict(combined)\n",
    "# # OLS 회귀분석 예측 qty생산\n",
    "# olsPred = olsModel.predict(combined)\n",
    "# qty = target\n",
    "\n",
    "# print(checked_for)\n",
    "# print('RF R2값  \\t: ','{:<.5f}'.format(r2_score(qty, RFpredicted)) )\n",
    "# print('XGB R2값  \\t: ','{:<.5f}'.format(r2_score(qty, XGBpredictions)) )\n",
    "# print('KerasNN R2값\\t: ','{:<.5f}'.format(r2_score(qty,predictions )) )\n",
    "# print('LinReg R2값\\t: ','{:<.5f}'.format(r2_score(qty, linPred)) )\n",
    "# print('Ridge R2값  \\t: ','{:<.5f}'.format(r2_score(qty, ridPred)) )\n",
    "# print('Lasso R2값\\t: ','{:<.5f}'.format(r2_score(qty, lassoPred )) )\n",
    "# print('OLS R2값\\t: ','{:<.5f}'.format(r2_score(qty, olsPred )) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checked_for = '2018'\n",
    "# combined = aaaaa.loc[106:,'temp':'PM10']\n",
    "# target = aaaaa.loc[106:,'qty']\n",
    "\n",
    "# # 가장 좋다고 판명된 설정을 이용하여, 예측qty생산\n",
    "# predictions = NN_model.predict(combined)\n",
    "# # RandomForest 회귀분석 예측 qty생산\n",
    "# RFpredicted = RFmodel.predict(combined)\n",
    "# # XGBRegressor 회귀분석 예측 qty생산\n",
    "# XGBpredictions = XGBModel.predict(combined)\n",
    "# # linearRegression 회귀분석 예측 qty생산\n",
    "# linPred = linReg.predict(combined)\n",
    "# # Ridge 회귀분석 예측 qty생산\n",
    "# ridPred = ridge.predict(combined)\n",
    "# # Lasso 회귀분석 예측 qty생산\n",
    "# lassoPred = lasso.predict(combined)\n",
    "# # OLS 회귀분석 예측 qty생산\n",
    "# olsPred = olsModel.predict(combined)\n",
    "\n",
    "# qty = target\n",
    "\n",
    "# print(checked_for)\n",
    "# print('RF R2값  \\t: ','{:<.5f}'.format(r2_score(qty, RFpredicted)) )\n",
    "# print('XGB R2값  \\t: ','{:<.5f}'.format(r2_score(qty, XGBpredictions)) )\n",
    "# print('KerasNN R2값\\t: ','{:<.5f}'.format(r2_score(qty,predictions )) )\n",
    "# print('LinReg R2값\\t: ','{:<.5f}'.format(r2_score(qty, linPred)) )\n",
    "# print('Ridge R2값  \\t: ','{:<.5f}'.format(r2_score(qty, ridPred)) )\n",
    "# print('Lasso R2값\\t: ','{:<.5f}'.format(r2_score(qty, lassoPred )) )\n",
    "# print('OLS R2값\\t: ','{:<.5f}'.format(r2_score(qty, olsPred )) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checked_for = '2016~2018'\n",
    "# combined = aaaaa.loc[:,'temp':'PM10']\n",
    "# target = aaaaa.loc[:,'qty']\n",
    "\n",
    "# # 가장 좋다고 판명된 설정을 이용하여, 예측qty생산\n",
    "# predictions = NN_model.predict(combined)\n",
    "# # RandomForest 회귀분석 예측 qty생산\n",
    "# RFpredicted = RFmodel.predict(combined)\n",
    "# # XGBRegressor 회귀분석 예측 qty생산\n",
    "# XGBpredictions = XGBModel.predict(combined)\n",
    "# # linearRegression 회귀분석 예측 qty생산\n",
    "# linPred = linReg.predict(combined)\n",
    "# # Ridge 회귀분석 예측 qty생산\n",
    "# ridPred = ridge.predict(combined)\n",
    "# # Lasso 회귀분석 예측 qty생산\n",
    "# lassoPred = lasso.predict(combined)\n",
    "# # OLS 회귀분석 예측 qty생산\n",
    "# olsPred = olsModel.predict(combined)\n",
    "\n",
    "# qty = target\n",
    "\n",
    "# print(checked_for)\n",
    "# print('RF R2값  \\t: ','{:<.5f}'.format(r2_score(qty, RFpredicted)) )\n",
    "# print('XGB R2값  \\t: ','{:<.5f}'.format(r2_score(qty, XGBpredictions)) )\n",
    "# print('KerasNN R2값\\t: ','{:<.5f}'.format(r2_score(qty,predictions )) )\n",
    "# print('LinReg R2값\\t: ','{:<.5f}'.format(r2_score(qty, linPred)) )\n",
    "# print('Ridge R2값  \\t: ','{:<.5f}'.format(r2_score(qty, ridPred)) )\n",
    "# print('Lasso R2값\\t: ','{:<.5f}'.format(r2_score(qty, lassoPred )) )\n",
    "# print('OLS R2값\\t: ','{:<.5f}'.format(r2_score(qty, olsPred )) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = 'D:/project/contest/data/result/'\n",
    "# result_df.to_csv(path+item+'_'+grouped_by+'_predict(lowVIF07).csv', encoding='utf-8', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
