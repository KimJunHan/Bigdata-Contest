{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "# 인공신경망관련 패키지\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "\n",
    "# 회귀분석 관련 패키지\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error \n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from scipy import stats\n",
    "\n",
    "# R2 값, 결정계수 계산\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# OLS회귀분석\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# 시각화 패키지\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sb\n",
    "\n",
    "# 데이터 처리를 위한 패키지\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# 다중공선성(multicollinearity) 처리를 위한VIF 확인 패키지\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# 한글 처리\n",
    "from matplotlib import rc, font_manager\n",
    "font_name = font_manager.FontProperties(fname='C:/Windows/Fonts/NanumGothicCoding.ttf').get_name()\n",
    "rc('font',family=font_name)\n",
    "\n",
    "# from matplotlib import rcParams\n",
    "# rcParams['font.family'] = 'NanumGothicCoding'\n",
    "\n",
    "# - 마이너스 사인 처리\n",
    "matplotlib.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# DeprecationWarning경고 무시\n",
    "# 향후 안쓰일 함수들을 이용해서 만들어져 있기 때문에 필요하다 없으면, 사방이 붉어진다.\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "# MAD 기반 예제코드\n",
    "def mad_based_outlier(points, thresh=3.5):\n",
    "    if len(points.shape) == 1:\n",
    "        points = points[:,None]\n",
    "    median = np.median(points, axis=0)\n",
    "    diff = np.sum((points - median)**2, axis=-1)\n",
    "    diff = np.sqrt(diff)\n",
    "    med_abs_deviation = np.median(diff)\n",
    "    modified_z_score = 0.6745 * diff / med_abs_deviation\n",
    "    return modified_z_score > thresh \n",
    "\n",
    "# 출처: https://pythonanalysis.tistory.com/7 [Python 데이터 분석]\n",
    "#########################################################################\n",
    "\n",
    "# 소셜 데이터 처리를 위한 함수\n",
    "# 1. 모든 소셜 데이터 column들의 첫번째는 : 날짜다.\n",
    "# 2. 각 소셜데이터는 social_키워드.블로그/트위터/뉴스/총합 으로 되어 있다.\n",
    "def changeColNames(d,before, after) : \n",
    "    # 컬럼이름 시리즈로 만들어 반환\n",
    "    # 통합하기 쉽게, 모든 데이터들의 날짜컬럼 이름을 date로 통일\n",
    "    new_col_names = ['date']\n",
    "    new_col_names.extend(list(d.columns)[1:])\n",
    "    d.columns = new_col_names\n",
    "    return pd.Series(d.columns).apply(lambda x : x.replace(before,after))\n",
    "\n",
    "#########################################################################\n",
    "# modeling 함수로 만들어 처리하기\n",
    "def linReg(df, item, cols_using):\n",
    "    cols = cols_using\n",
    "    X = df.loc[df['category']==item, cols]\n",
    "    y = df.loc[df['category']==item,'qty']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=0)\n",
    "\n",
    "    model = LinearRegression().fit(X_train, y_train)\n",
    "  \n",
    "    print('LinearRegression을 이용한 %s의 회귀분석 결과 :'%item)\n",
    "    print('훈련세트점수 : {:.2f}'.format(model.score(X_train, y_train)))\n",
    "    print('검증세트점수 : {:.2f}'.format(model.score(X_test, y_test)))\n",
    "\n",
    "    \n",
    "def ridgeReg(df, item, cols_using):\n",
    "    cols = cols_using\n",
    "    X = df.loc[df['category']==item,cols]\n",
    "    y = df.loc[df['category']==item,'qty']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=0)\n",
    "\n",
    "    ridge = Ridge(alpha=0.1, normalize=True, random_state=0, tol=0.001).fit(X_train, y_train)\n",
    "    \n",
    "    print('RidgeRegression을 이용한 %s의 회귀분석 결과 :'%item)\n",
    "    print('훈련세트점수 : {:.2f}'.format(ridge.score(X_train, y_train)))\n",
    "    print('검증세트점수 : {:.2f}'.format(ridge.score(X_test, y_test)))\n",
    "\n",
    "\n",
    "def lassoReg(df, item, cols_using):\n",
    "    cols = cols_using\n",
    "    X = df.loc[df['category']==item,cols]\n",
    "    y = df.loc[df['category']==item,'qty']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=0)\n",
    "\n",
    "    lasso = Lasso(alpha=0.1, max_iter=1000).fit(X=X_train, y=y_train)\n",
    "  \n",
    "    print('LassoRegression을 이용한 %s의 회귀분석 결과 :'%item)\n",
    "    print('훈련세트점수 : {:.2f}'.format(lasso.score(X_train, y_train)) )\n",
    "    print('검증세트점수 : {:.2f}'.format(lasso.score(X_test, y_test)) )\n",
    "\n",
    "    #사용한 특성수\n",
    "    print('사용한 특성수 : {}'.format(np.sum(lasso.coef_ != 0)) )\n",
    "#########################################################################\n",
    "\n",
    "# 자료가 1일 1행이라는 전제하에\n",
    "# df길이를 이용하여 날짜수를 계산, 이후 2016년 1월1일을 1번째주 1일이라 기준하에\n",
    "# 몇번째 주인지 알려주는 컬럼 추가. 향후 주단위로 종합할때 스인다.\n",
    "def addDayWeek(df):\n",
    "    df_work = df.copy()\n",
    "    df_work['day'] = pd.Series(range(1,df_work.shape[0]+1)).astype('int64')\n",
    "    df_work['week'] = df_work['day'].apply(lambda x : math.ceil(x/7))\n",
    "    return df_work\n",
    "#########################################################################\n",
    "# 자료를 병합해주는 함수, 어떤 item인지 어느 컬럼을 기준으로 할지 받아서 병합\n",
    "def mergeForAnalysis(df1, df2, df3, item, on_what='date'):\n",
    "    merged_df = pd.merge(df1.loc[df1.category==item], df2, on=on_what, how='left')\n",
    "    merged_df = pd.merge(merged_df, df3, on=on_what, how='left')\n",
    "    return merged_df\n",
    "\n",
    "\n",
    "#########################################################################\n",
    "def lowVIF(df, n=7, cols_using =['temp', 'cloud', 'wind','humid', 'hpa', 'sun_time', 'lgt_time', \n",
    "       'SO2', 'CO', 'O3', 'NO2', 'PM10', 'PM25'] ):\n",
    "    col_to_use = cols_using\n",
    "    vif = pd.DataFrame()\n",
    "    vif[\"VIF_Factor\"] = [variance_inflation_factor(\n",
    "        df[col_to_use].values, i) for i in range(df[col_to_use].shape[1])]\n",
    "    vif[\"features\"] = col_to_use\n",
    "    vif.sort_values(\"VIF_Factor\")\n",
    "    lowest_vif = vif.sort_values(\"VIF_Factor\")[:n].reset_index()\n",
    "    lowest_vif.drop(columns='index', inplace=True)\n",
    "    return lowest_vif\n",
    "\n",
    "#########################################################################\n",
    "# ols모델용 formula 생성\n",
    "def formulaGen(target, ind_features):\n",
    "    '''\n",
    "    formulaGen(목표컬럼명,[변수컬럼명1, 변수컬럼명2,...])\n",
    "    '''\n",
    "    custom_formula = target + \" ~ \"\n",
    "    for f in range(len(ind_features)):\n",
    "        custom_formula += ind_features[f]\n",
    "        if f!=(len(ind_features)-1):\n",
    "            custom_formula += \" + \"\n",
    "    return custom_formula\n",
    "#########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기 (전처리 된 GS, 랄라블라, 날씨)\n",
    "gs = pd.read_csv('d:/project/contest/data/processed/p_gs.csv', parse_dates=['date'])\n",
    "lv = pd.read_csv('d:/project/contest/data/processed/p_lavla.csv', parse_dates=['date'])\n",
    "# w = pd.read_csv('d:/project/contest/data/processed/p_wUVair_seoul_category.csv', parse_dates=['date'], index_col=0)\n",
    "w = pd.read_csv('d:/project/contest/data/processed/날씨_ver071915.csv', parse_dates=['date'], index_col=0)\n",
    "sns_all = pd.read_csv('d:/project/contest/data/processed/social_all.csv', parse_dates=['date'])\n",
    "\n",
    "# GS/lv 서울시만\n",
    "gs_seoul = gs.loc[gs.pvn_nm =='서울특별시']\n",
    "lv_seoul = lv.loc[lv.pvn_nm =='서울특별시']\n",
    "w_seoul = w.loc[w['loc']==108]\n",
    "\n",
    "cols_to_keep = ['date','bor_nm','gender','age_cd','category','qty']\n",
    "\n",
    "# 일일, 구단위, 상품별 판매량 종합\n",
    "gs_grouped = gs_seoul[cols_to_keep].groupby(by=['date','bor_nm','category']).sum().reset_index()\n",
    "\n",
    "# 일단위로 자료 종합(qty는 일일 합계)\n",
    "day_gs_grouped = gs_grouped.groupby(by=['date','category']).sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '맥주'만 빼서 df생성\n",
    "item = '맥주'\n",
    "grouped_by = 'date'\n",
    "day_gs_grouped_w_item = pd.merge(day_gs_grouped.loc[day_gs_grouped.category==item],w_seoul,on='date',how='left')\n",
    "# day_gs_grouped_w_item.head(3)\n",
    "day_gs_grouped_w_sns_item = pd.merge(day_gs_grouped_w_item, sns_all,on='date',how='left')\n",
    "\n",
    "# 일단 uv = 자외선 지수는 결측치가 많아서 제외\n",
    "selected_cols = ['date', 'category', 'qty', 'temp', 'rain', 'cloud', 'wind','humid', 'hpa',\n",
    "                 'sun_time', 'lgt_time', 'snow','rain_or_not','snow_or_not','미세', '초미세', '공기상태',\n",
    "                 'SO2', 'CO', 'O3', 'NO2', 'PM10', 'PM25',\n",
    "                 'pm_blog', 'pm_twitter', 'pm_news', 'pm_total',\n",
    "                 'health_blog', 'health_twitter', 'health_news', 'health_total',\n",
    "                 'date_blog', 'date_twitter', 'date_news', 'date_total',\n",
    "                 'br_blog', 'br_twitter', 'br_news', 'br_total',\n",
    "                 'hobby_blog', 'hobby_twitter', 'hobby_news', 'hobby_total']\n",
    "gs_day_w = day_gs_grouped_w_sns_item[selected_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAD적용\n",
    "gs_day_w['outlier'] = pd.DataFrame(mad_based_outlier(gs_day_w['qty']))\n",
    "gs_day_w = gs_day_w.loc[gs_day_w.outlier==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VIF_Factor</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.239620</td>\n",
       "      <td>snow_or_not</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.479988</td>\n",
       "      <td>rain_or_not</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.114369</td>\n",
       "      <td>공기상태</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.013218</td>\n",
       "      <td>temp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.725926</td>\n",
       "      <td>cloud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8.084050</td>\n",
       "      <td>lgt_time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9.334878</td>\n",
       "      <td>wind</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VIF_Factor     features\n",
       "0    1.239620  snow_or_not\n",
       "1    2.479988  rain_or_not\n",
       "2    3.114369         공기상태\n",
       "3    4.013218         temp\n",
       "4    6.725926        cloud\n",
       "5    8.084050     lgt_time\n",
       "6    9.334878         wind"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list_col = ['temp', 'cloud', 'wind', 'lgt_time', 'PM10'] # +,'rain_or_not','snow_or_not'\n",
    "list_col = ['temp', 'cloud', 'wind','lgt_time',\n",
    "            'rain_or_not', 'snow_or_not', '공기상태'] #+'rain_or_not', 'snow_or_not'\n",
    "lowVIF(w,20,list_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data = gs_day_w.loc[gs_day_w.date.between('2016-01-01','2017-12-31')]\n",
    "test_data = gs_day_w.loc[gs_day_w.date.between('2018-01-01','2018-12-31')]\n",
    "\n",
    "# 3년치 데이터 분리 : 종속변수('qty': 판매량)와 독립변수(판매량 제외 나머지 전부)\n",
    "# 날씨 데이터만\n",
    "combined = gs_day_w.loc[:,list_col]\n",
    "target = gs_day_w.loc[:,'qty']\n",
    "Xy = pd.concat([target,combined], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cols_with_no_nans(df,col_type):\n",
    "    '''\n",
    "    Arguments :\n",
    "    df : The dataframe to process\n",
    "    col_type : \n",
    "          num : to only get numerical columns with no nans\n",
    "          no_num : to only get nun-numerical columns with no nans\n",
    "          all : to get any columns with no nans    \n",
    "    '''\n",
    "    if (col_type == 'num'):\n",
    "        predictors = df.select_dtypes(exclude=['object'])\n",
    "    elif (col_type == 'no_num'):\n",
    "        predictors = df.select_dtypes(include=['object'])\n",
    "    elif (col_type == 'all'):\n",
    "        predictors = df\n",
    "    else :\n",
    "        print('Error : choose a type (num, no_num, all)')\n",
    "        return 0\n",
    "    cols_with_no_nans = []\n",
    "    for col in predictors.columns:\n",
    "        if not df[col].isnull().any():\n",
    "            cols_with_no_nans.append(col)\n",
    "    return cols_with_no_nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "수치형 자료 컬럼 갯수 : 7\n",
      "오브젝트형 자료 컬럼 갯수 : 0\n"
     ]
    }
   ],
   "source": [
    "num_cols = get_cols_with_no_nans(combined , 'num')\n",
    "cat_cols = get_cols_with_no_nans(combined , 'no_num')\n",
    "\n",
    "print ('수치형 자료 컬럼 갯수 :',len(num_cols))\n",
    "print ('오브젝트형 자료 컬럼 갯수 :',len(cat_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x720 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "combined = combined[num_cols + cat_cols]\n",
    "combined.hist(figsize = (12,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data = train_data[num_cols + cat_cols]\n",
    "train_data['Target'] = target\n",
    "\n",
    "C_mat = train_data.corr()\n",
    "fig = plt.figure(figsize = (15,15))\n",
    "\n",
    "sb.heatmap(C_mat, vmax = .8, square = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분류형(category형) 컬럼 수정 전, 총 7 개의 columns이 있었습니다.\n",
      "분류형(category형) 컬럼 수정 후, 총 10 개의 columns이 있었습니다.\n"
     ]
    }
   ],
   "source": [
    "def oneHotEncode(df,colNames):\n",
    "    for col in colNames:\n",
    "        # 해당 컬럼의 데이터 타입이 object란 소리는 숫자가 아니다 = 분류형 데이터\n",
    "        if( df[col].dtype == np.dtype('object')):\n",
    "            # 더미 컬럼 생성\n",
    "            dummies = pd.get_dummies(df[col],prefix=col)\n",
    "            # 원본 데이터에 이어 붙이기 axis=1 컬럼방향으로 \n",
    "            df = pd.concat([df,dummies],axis=1)\n",
    "\n",
    "            # 기존의 str형 컬럼 삭제\n",
    "            df.drop([col],axis = 1 , inplace=True)\n",
    "    return df\n",
    "    \n",
    "\n",
    "print('분류형(category형) 컬럼 수정 전, 총 {} 개의 columns이 있었습니다.'.format(combined.shape[1]))\n",
    "combined = oneHotEncode(combined, cat_cols)\n",
    "#### 내가 '공기상태'라는 컬럼이 사실은 category형이라는것을 알기에 직접 dummy컬럼 생성\n",
    "airCondition_dummies = pd.get_dummies(combined['공기상태'],prefix='공기상태')\n",
    "combined = pd.concat([combined, airCondition_dummies], axis=1)\n",
    "combined.drop(['공기상태'],axis = 1 , inplace=True)\n",
    "######################################################################################\n",
    "print('분류형(category형) 컬럼 수정 후, 총 {} 개의 columns이 있었습니다.'.format(combined.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temp</th>\n",
       "      <th>cloud</th>\n",
       "      <th>wind</th>\n",
       "      <th>lgt_time</th>\n",
       "      <th>rain_or_not</th>\n",
       "      <th>snow_or_not</th>\n",
       "      <th>공기상태_0</th>\n",
       "      <th>공기상태_1</th>\n",
       "      <th>공기상태_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   temp  cloud  wind  lgt_time  rain_or_not  snow_or_not  공기상태_0  공기상태_1  \\\n",
       "0   1.2    7.0   1.6       2.1            0            0       0       0   \n",
       "\n",
       "   공기상태_2  \n",
       "0       1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 공기상태_0,공기상태_1,공기상태_2가 전부 0이면,   공기상태_3이 1이란 소리고\n",
    "#                                                               공기상태가 '매우나쁨' 임을 추정할수 있다.\n",
    "# 그런이유로 공기상태_3삭제\n",
    "combined.drop(['공기상태_3'],axis = 1 , inplace=True)\n",
    "combined.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xy = pd.concat([target,combined], axis=1)\n",
    "# Xy.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(732, 9)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 첫 2년 : 732 일\n",
    "cut_line = 732\n",
    "def split_combined():\n",
    "    global combined\n",
    "    train = combined[:cut_line]\n",
    "    test = combined[cut_line:]\n",
    "\n",
    "    return train , test \n",
    "  \n",
    "train, test = split_combined()\n",
    "\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0719 18:53:00.910785  4492 deprecation_wrapper.py:119] From C:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0719 18:53:00.937714  4492 deprecation_wrapper.py:119] From C:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0719 18:53:00.942701  4492 deprecation_wrapper.py:119] From C:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4115: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "W0719 18:53:00.995582  4492 deprecation_wrapper.py:119] From C:\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 128)               1280      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 166,145\n",
      "Trainable params: 166,145\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 신경망 모델 생성\n",
    "NN_model = Sequential()\n",
    "\n",
    "# The Input Layer :\n",
    "NN_model.add(Dense(128, kernel_initializer='normal',input_dim = train.shape[1], activation='relu'))\n",
    "\n",
    "# The Hidden Layers :\n",
    "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "\n",
    "# The Output Layer :\n",
    "NN_model.add(Dense(1, kernel_initializer='normal',activation='linear'))\n",
    "\n",
    "# Compile the network :\n",
    "# optimizer에 여러 방식이 있다.\n",
    "NN_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
    "NN_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인공 신경망에 의해 생성된 weight 자료를 저장하기 위해서\n",
    "checkpoint_name = item+grouped_by+'-Weights-{epoch:03d}--{val_loss:.5f}-cat02-vf05.hdf5' \n",
    "\n",
    "# save_best_only값이 저장되어, 모든 weight값을 저장하지 않고, val_loss값이 줄어들때마다(적을수록 좋다.) 저장\n",
    "checkpoint = ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose = 1, save_best_only = True, mode ='auto')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0719 17:03:57.696182  6196 deprecation_wrapper.py:119] From C:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "W0719 17:03:57.813839  6196 deprecation_wrapper.py:119] From C:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 585 samples, validate on 147 samples\n",
      "Epoch 1/500\n",
      "585/585 [==============================] - 0s 556us/step - loss: 11596.8018 - mean_absolute_error: 11596.8018 - val_loss: 11558.8349 - val_mean_absolute_error: 11558.8349\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 11558.83493, saving model to 맥주date-Weights-001--11558.83493-cat02-vf05.hdf5\n",
      "Epoch 2/500\n",
      "585/585 [==============================] - 0s 94us/step - loss: 10963.6176 - mean_absolute_error: 10963.6176 - val_loss: 9350.7162 - val_mean_absolute_error: 9350.7162\n",
      "\n",
      "Epoch 00002: val_loss improved from 11558.83493 to 9350.71619, saving model to 맥주date-Weights-002--9350.71619-cat02-vf05.hdf5\n",
      "Epoch 3/500\n",
      "585/585 [==============================] - 0s 75us/step - loss: 5044.2864 - mean_absolute_error: 5044.2864 - val_loss: 2753.2377 - val_mean_absolute_error: 2753.2377\n",
      "\n",
      "Epoch 00003: val_loss improved from 9350.71619 to 2753.23767, saving model to 맥주date-Weights-003--2753.23767-cat02-vf05.hdf5\n",
      "Epoch 4/500\n",
      "585/585 [==============================] - 0s 92us/step - loss: 2458.5926 - mean_absolute_error: 2458.5926 - val_loss: 1781.5000 - val_mean_absolute_error: 1781.5000\n",
      "\n",
      "Epoch 00004: val_loss improved from 2753.23767 to 1781.50001, saving model to 맥주date-Weights-004--1781.50001-cat02-vf05.hdf5\n",
      "Epoch 5/500\n",
      "585/585 [==============================] - 0s 82us/step - loss: 1934.1011 - mean_absolute_error: 1934.1011 - val_loss: 1694.5299 - val_mean_absolute_error: 1694.5299\n",
      "\n",
      "Epoch 00005: val_loss improved from 1781.50001 to 1694.52986, saving model to 맥주date-Weights-005--1694.52986-cat02-vf05.hdf5\n",
      "Epoch 6/500\n",
      "585/585 [==============================] - 0s 84us/step - loss: 1867.5920 - mean_absolute_error: 1867.5920 - val_loss: 1629.7140 - val_mean_absolute_error: 1629.7140\n",
      "\n",
      "Epoch 00006: val_loss improved from 1694.52986 to 1629.71404, saving model to 맥주date-Weights-006--1629.71404-cat02-vf05.hdf5\n",
      "Epoch 7/500\n",
      "585/585 [==============================] - 0s 84us/step - loss: 1846.7374 - mean_absolute_error: 1846.7374 - val_loss: 2039.4541 - val_mean_absolute_error: 2039.4541\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1629.71404\n",
      "Epoch 8/500\n",
      "585/585 [==============================] - 0s 85us/step - loss: 1890.3494 - mean_absolute_error: 1890.3494 - val_loss: 1774.9838 - val_mean_absolute_error: 1774.9838\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1629.71404\n",
      "Epoch 9/500\n",
      "585/585 [==============================] - 0s 79us/step - loss: 1812.4997 - mean_absolute_error: 1812.4997 - val_loss: 1618.0543 - val_mean_absolute_error: 1618.0543\n",
      "\n",
      "Epoch 00009: val_loss improved from 1629.71404 to 1618.05429, saving model to 맥주date-Weights-009--1618.05429-cat02-vf05.hdf5\n",
      "Epoch 10/500\n",
      "585/585 [==============================] - 0s 102us/step - loss: 1857.9394 - mean_absolute_error: 1857.9394 - val_loss: 1787.1113 - val_mean_absolute_error: 1787.1113\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1618.05429\n",
      "Epoch 11/500\n",
      "585/585 [==============================] - 0s 87us/step - loss: 1821.3976 - mean_absolute_error: 1821.3976 - val_loss: 1604.7437 - val_mean_absolute_error: 1604.7437\n",
      "\n",
      "Epoch 00011: val_loss improved from 1618.05429 to 1604.74370, saving model to 맥주date-Weights-011--1604.74370-cat02-vf05.hdf5\n",
      "Epoch 12/500\n",
      "585/585 [==============================] - 0s 80us/step - loss: 1837.5025 - mean_absolute_error: 1837.5025 - val_loss: 1644.2778 - val_mean_absolute_error: 1644.2778\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1604.74370\n",
      "Epoch 13/500\n",
      "585/585 [==============================] - 0s 75us/step - loss: 1820.5678 - mean_absolute_error: 1820.5678 - val_loss: 1576.5053 - val_mean_absolute_error: 1576.5053\n",
      "\n",
      "Epoch 00013: val_loss improved from 1604.74370 to 1576.50531, saving model to 맥주date-Weights-013--1576.50531-cat02-vf05.hdf5\n",
      "Epoch 14/500\n",
      "585/585 [==============================] - 0s 80us/step - loss: 1812.7393 - mean_absolute_error: 1812.7393 - val_loss: 1607.8388 - val_mean_absolute_error: 1607.8388\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1576.50531\n",
      "Epoch 15/500\n",
      "585/585 [==============================] - 0s 84us/step - loss: 1806.7725 - mean_absolute_error: 1806.7725 - val_loss: 1739.3543 - val_mean_absolute_error: 1739.3543\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1576.50531\n",
      "Epoch 16/500\n",
      "585/585 [==============================] - 0s 80us/step - loss: 1779.4108 - mean_absolute_error: 1779.4108 - val_loss: 1586.2672 - val_mean_absolute_error: 1586.2672\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1576.50531\n",
      "Epoch 17/500\n",
      "585/585 [==============================] - 0s 84us/step - loss: 1783.1428 - mean_absolute_error: 1783.1428 - val_loss: 1609.2830 - val_mean_absolute_error: 1609.2830\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1576.50531\n",
      "Epoch 18/500\n",
      "585/585 [==============================] - 0s 80us/step - loss: 1773.4096 - mean_absolute_error: 1773.4096 - val_loss: 1722.1963 - val_mean_absolute_error: 1722.1963\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1576.50531\n",
      "Epoch 19/500\n",
      "585/585 [==============================] - 0s 87us/step - loss: 1758.0863 - mean_absolute_error: 1758.0863 - val_loss: 1544.7813 - val_mean_absolute_error: 1544.7813\n",
      "\n",
      "Epoch 00019: val_loss improved from 1576.50531 to 1544.78134, saving model to 맥주date-Weights-019--1544.78134-cat02-vf05.hdf5\n",
      "Epoch 20/500\n",
      "585/585 [==============================] - 0s 92us/step - loss: 1773.3098 - mean_absolute_error: 1773.3098 - val_loss: 1605.1809 - val_mean_absolute_error: 1605.1809\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1544.78134\n",
      "Epoch 21/500\n",
      "585/585 [==============================] - 0s 92us/step - loss: 1816.8143 - mean_absolute_error: 1816.8143 - val_loss: 1685.9772 - val_mean_absolute_error: 1685.9772\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1544.78134\n",
      "Epoch 22/500\n",
      "585/585 [==============================] - 0s 82us/step - loss: 1797.4933 - mean_absolute_error: 1797.4933 - val_loss: 1689.5757 - val_mean_absolute_error: 1689.5757\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1544.78134\n",
      "Epoch 23/500\n",
      "585/585 [==============================] - 0s 84us/step - loss: 1758.4883 - mean_absolute_error: 1758.4883 - val_loss: 1662.6609 - val_mean_absolute_error: 1662.6609\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1544.78134\n",
      "Epoch 24/500\n",
      "585/585 [==============================] - 0s 80us/step - loss: 1775.6796 - mean_absolute_error: 1775.6796 - val_loss: 1822.5531 - val_mean_absolute_error: 1822.5531\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1544.78134\n",
      "Epoch 25/500\n",
      "585/585 [==============================] - 0s 72us/step - loss: 1832.0730 - mean_absolute_error: 1832.0730 - val_loss: 1653.8150 - val_mean_absolute_error: 1653.8150\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1544.78134\n",
      "Epoch 26/500\n",
      "585/585 [==============================] - 0s 73us/step - loss: 1729.5324 - mean_absolute_error: 1729.5324 - val_loss: 1531.5829 - val_mean_absolute_error: 1531.5829\n",
      "\n",
      "Epoch 00026: val_loss improved from 1544.78134 to 1531.58291, saving model to 맥주date-Weights-026--1531.58291-cat02-vf05.hdf5\n",
      "Epoch 27/500\n",
      "585/585 [==============================] - 0s 90us/step - loss: 1715.8736 - mean_absolute_error: 1715.8736 - val_loss: 1541.3487 - val_mean_absolute_error: 1541.3487\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1531.58291\n",
      "Epoch 28/500\n",
      "585/585 [==============================] - 0s 95us/step - loss: 1712.8706 - mean_absolute_error: 1712.8706 - val_loss: 1530.6625 - val_mean_absolute_error: 1530.6625\n",
      "\n",
      "Epoch 00028: val_loss improved from 1531.58291 to 1530.66246, saving model to 맥주date-Weights-028--1530.66246-cat02-vf05.hdf5\n",
      "Epoch 29/500\n",
      "585/585 [==============================] - 0s 70us/step - loss: 1723.4739 - mean_absolute_error: 1723.4739 - val_loss: 1521.6069 - val_mean_absolute_error: 1521.6069\n",
      "\n",
      "Epoch 00029: val_loss improved from 1530.66246 to 1521.60686, saving model to 맥주date-Weights-029--1521.60686-cat02-vf05.hdf5\n",
      "Epoch 30/500\n",
      "585/585 [==============================] - 0s 77us/step - loss: 1709.0116 - mean_absolute_error: 1709.0116 - val_loss: 1540.1350 - val_mean_absolute_error: 1540.1350\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1521.60686\n",
      "Epoch 31/500\n",
      "585/585 [==============================] - 0s 73us/step - loss: 1728.6764 - mean_absolute_error: 1728.6764 - val_loss: 1533.0345 - val_mean_absolute_error: 1533.0345\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1521.60686\n",
      "Epoch 32/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "585/585 [==============================] - 0s 85us/step - loss: 1697.0026 - mean_absolute_error: 1697.0026 - val_loss: 1502.9036 - val_mean_absolute_error: 1502.9036\n",
      "\n",
      "Epoch 00032: val_loss improved from 1521.60686 to 1502.90364, saving model to 맥주date-Weights-032--1502.90364-cat02-vf05.hdf5\n",
      "Epoch 33/500\n",
      "585/585 [==============================] - 0s 82us/step - loss: 1709.4192 - mean_absolute_error: 1709.4192 - val_loss: 1487.9341 - val_mean_absolute_error: 1487.9341\n",
      "\n",
      "Epoch 00033: val_loss improved from 1502.90364 to 1487.93406, saving model to 맥주date-Weights-033--1487.93406-cat02-vf05.hdf5\n",
      "Epoch 34/500\n",
      "585/585 [==============================] - 0s 74us/step - loss: 1727.1749 - mean_absolute_error: 1727.1749 - val_loss: 1502.0464 - val_mean_absolute_error: 1502.0464\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1487.93406\n",
      "Epoch 35/500\n",
      "585/585 [==============================] - 0s 82us/step - loss: 1719.2800 - mean_absolute_error: 1719.2800 - val_loss: 1473.1204 - val_mean_absolute_error: 1473.1204\n",
      "\n",
      "Epoch 00035: val_loss improved from 1487.93406 to 1473.12040, saving model to 맥주date-Weights-035--1473.12040-cat02-vf05.hdf5\n",
      "Epoch 36/500\n",
      "585/585 [==============================] - 0s 77us/step - loss: 1678.2770 - mean_absolute_error: 1678.2770 - val_loss: 1522.0833 - val_mean_absolute_error: 1522.0833\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1473.12040\n",
      "Epoch 37/500\n",
      "585/585 [==============================] - 0s 74us/step - loss: 1674.0102 - mean_absolute_error: 1674.0102 - val_loss: 1611.8601 - val_mean_absolute_error: 1611.8601\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1473.12040\n",
      "Epoch 38/500\n",
      "585/585 [==============================] - 0s 78us/step - loss: 1691.5052 - mean_absolute_error: 1691.5052 - val_loss: 1602.0391 - val_mean_absolute_error: 1602.0391\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1473.12040\n",
      "Epoch 39/500\n",
      "585/585 [==============================] - 0s 84us/step - loss: 1761.9171 - mean_absolute_error: 1761.9171 - val_loss: 1528.8975 - val_mean_absolute_error: 1528.8975\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1473.12040\n",
      "Epoch 40/500\n",
      "585/585 [==============================] - 0s 82us/step - loss: 1758.8794 - mean_absolute_error: 1758.8794 - val_loss: 1459.9421 - val_mean_absolute_error: 1459.9421\n",
      "\n",
      "Epoch 00040: val_loss improved from 1473.12040 to 1459.94212, saving model to 맥주date-Weights-040--1459.94212-cat02-vf05.hdf5\n",
      "Epoch 41/500\n",
      "585/585 [==============================] - 0s 78us/step - loss: 1688.8190 - mean_absolute_error: 1688.8190 - val_loss: 1483.5639 - val_mean_absolute_error: 1483.5639\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1459.94212\n",
      "Epoch 42/500\n",
      "585/585 [==============================] - 0s 80us/step - loss: 1670.2042 - mean_absolute_error: 1670.2042 - val_loss: 1570.9728 - val_mean_absolute_error: 1570.9728\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1459.94212\n",
      "Epoch 43/500\n",
      "585/585 [==============================] - 0s 78us/step - loss: 1684.9237 - mean_absolute_error: 1684.9237 - val_loss: 1492.0665 - val_mean_absolute_error: 1492.0665\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1459.94212\n",
      "Epoch 44/500\n",
      "585/585 [==============================] - 0s 75us/step - loss: 1649.0750 - mean_absolute_error: 1649.0750 - val_loss: 1496.2385 - val_mean_absolute_error: 1496.2385\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1459.94212\n",
      "Epoch 45/500\n",
      "585/585 [==============================] - 0s 90us/step - loss: 1665.0677 - mean_absolute_error: 1665.0677 - val_loss: 1485.5316 - val_mean_absolute_error: 1485.5316\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1459.94212\n",
      "Epoch 46/500\n",
      "585/585 [==============================] - 0s 85us/step - loss: 1672.0502 - mean_absolute_error: 1672.0502 - val_loss: 1813.4807 - val_mean_absolute_error: 1813.4807\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1459.94212\n",
      "Epoch 47/500\n",
      "585/585 [==============================] - 0s 90us/step - loss: 1685.9538 - mean_absolute_error: 1685.9538 - val_loss: 1635.8139 - val_mean_absolute_error: 1635.8139\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 1459.94212\n",
      "Epoch 48/500\n",
      "585/585 [==============================] - 0s 85us/step - loss: 1685.9898 - mean_absolute_error: 1685.9898 - val_loss: 1531.0706 - val_mean_absolute_error: 1531.0706\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 1459.94212\n",
      "Epoch 49/500\n",
      "585/585 [==============================] - 0s 72us/step - loss: 1670.7709 - mean_absolute_error: 1670.7709 - val_loss: 1522.2311 - val_mean_absolute_error: 1522.2311\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1459.94212\n",
      "Epoch 50/500\n",
      "585/585 [==============================] - 0s 101us/step - loss: 1633.5389 - mean_absolute_error: 1633.5389 - val_loss: 1454.9828 - val_mean_absolute_error: 1454.9828\n",
      "\n",
      "Epoch 00050: val_loss improved from 1459.94212 to 1454.98277, saving model to 맥주date-Weights-050--1454.98277-cat02-vf05.hdf5\n",
      "Epoch 51/500\n",
      "585/585 [==============================] - 0s 113us/step - loss: 1650.5402 - mean_absolute_error: 1650.5402 - val_loss: 1468.9725 - val_mean_absolute_error: 1468.9725\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 1454.98277\n",
      "Epoch 52/500\n",
      "585/585 [==============================] - 0s 89us/step - loss: 1633.1730 - mean_absolute_error: 1633.1730 - val_loss: 1452.7977 - val_mean_absolute_error: 1452.7977\n",
      "\n",
      "Epoch 00052: val_loss improved from 1454.98277 to 1452.79765, saving model to 맥주date-Weights-052--1452.79765-cat02-vf05.hdf5\n",
      "Epoch 53/500\n",
      "585/585 [==============================] - 0s 81us/step - loss: 1624.9045 - mean_absolute_error: 1624.9045 - val_loss: 1465.0449 - val_mean_absolute_error: 1465.0449\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 1452.79765\n",
      "Epoch 54/500\n",
      "585/585 [==============================] - 0s 85us/step - loss: 1630.4869 - mean_absolute_error: 1630.4869 - val_loss: 1470.0656 - val_mean_absolute_error: 1470.0656\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 1452.79765\n",
      "Epoch 55/500\n",
      "585/585 [==============================] - 0s 80us/step - loss: 1657.4414 - mean_absolute_error: 1657.4414 - val_loss: 1675.0041 - val_mean_absolute_error: 1675.0041\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 1452.79765\n",
      "Epoch 56/500\n",
      "585/585 [==============================] - 0s 89us/step - loss: 1639.7563 - mean_absolute_error: 1639.7563 - val_loss: 1466.5613 - val_mean_absolute_error: 1466.5613\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 1452.79765\n",
      "Epoch 57/500\n",
      "585/585 [==============================] - 0s 84us/step - loss: 1625.2317 - mean_absolute_error: 1625.2317 - val_loss: 1453.1682 - val_mean_absolute_error: 1453.1682\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 1452.79765\n",
      "Epoch 58/500\n",
      "585/585 [==============================] - 0s 92us/step - loss: 1645.0539 - mean_absolute_error: 1645.0539 - val_loss: 1470.1999 - val_mean_absolute_error: 1470.1999\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 1452.79765\n",
      "Epoch 59/500\n",
      "585/585 [==============================] - 0s 87us/step - loss: 1626.5335 - mean_absolute_error: 1626.5335 - val_loss: 1531.0425 - val_mean_absolute_error: 1531.0425\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 1452.79765\n",
      "Epoch 60/500\n",
      "585/585 [==============================] - 0s 90us/step - loss: 1666.6829 - mean_absolute_error: 1666.6829 - val_loss: 1456.7377 - val_mean_absolute_error: 1456.7377\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 1452.79765\n",
      "Epoch 61/500\n",
      "585/585 [==============================] - 0s 82us/step - loss: 1616.2200 - mean_absolute_error: 1616.2200 - val_loss: 1449.4580 - val_mean_absolute_error: 1449.4580\n",
      "\n",
      "Epoch 00061: val_loss improved from 1452.79765 to 1449.45799, saving model to 맥주date-Weights-061--1449.45799-cat02-vf05.hdf5\n",
      "Epoch 62/500\n",
      "585/585 [==============================] - 0s 82us/step - loss: 1639.2267 - mean_absolute_error: 1639.2267 - val_loss: 1640.5331 - val_mean_absolute_error: 1640.5331\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 1449.45799\n",
      "Epoch 63/500\n",
      "585/585 [==============================] - 0s 84us/step - loss: 1692.8654 - mean_absolute_error: 1692.8654 - val_loss: 1508.0891 - val_mean_absolute_error: 1508.0891\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 1449.45799\n",
      "Epoch 64/500\n",
      "585/585 [==============================] - 0s 91us/step - loss: 1627.7347 - mean_absolute_error: 1627.7347 - val_loss: 1451.1154 - val_mean_absolute_error: 1451.1154\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 1449.45799\n",
      "Epoch 65/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "585/585 [==============================] - 0s 85us/step - loss: 1614.7299 - mean_absolute_error: 1614.7299 - val_loss: 1405.7060 - val_mean_absolute_error: 1405.7060\n",
      "\n",
      "Epoch 00065: val_loss improved from 1449.45799 to 1405.70598, saving model to 맥주date-Weights-065--1405.70598-cat02-vf05.hdf5\n",
      "Epoch 66/500\n",
      "585/585 [==============================] - 0s 106us/step - loss: 1589.7490 - mean_absolute_error: 1589.7490 - val_loss: 1442.3559 - val_mean_absolute_error: 1442.3559\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 1405.70598\n",
      "Epoch 67/500\n",
      "585/585 [==============================] - 0s 92us/step - loss: 1587.9191 - mean_absolute_error: 1587.9191 - val_loss: 1432.9124 - val_mean_absolute_error: 1432.9124\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 1405.70598\n",
      "Epoch 68/500\n",
      "585/585 [==============================] - 0s 94us/step - loss: 1598.1714 - mean_absolute_error: 1598.1714 - val_loss: 1434.0053 - val_mean_absolute_error: 1434.0053\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 1405.70598\n",
      "Epoch 69/500\n",
      "585/585 [==============================] - 0s 92us/step - loss: 1630.2703 - mean_absolute_error: 1630.2703 - val_loss: 1437.8736 - val_mean_absolute_error: 1437.8736\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 1405.70598\n",
      "Epoch 70/500\n",
      "585/585 [==============================] - 0s 95us/step - loss: 1581.1598 - mean_absolute_error: 1581.1598 - val_loss: 1425.8040 - val_mean_absolute_error: 1425.8040\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 1405.70598\n",
      "Epoch 71/500\n",
      "585/585 [==============================] - 0s 85us/step - loss: 1602.7897 - mean_absolute_error: 1602.7897 - val_loss: 1457.0635 - val_mean_absolute_error: 1457.0635\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 1405.70598\n",
      "Epoch 72/500\n",
      "585/585 [==============================] - 0s 87us/step - loss: 1620.0061 - mean_absolute_error: 1620.0061 - val_loss: 1435.6157 - val_mean_absolute_error: 1435.6157\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 1405.70598\n",
      "Epoch 73/500\n",
      "585/585 [==============================] - 0s 90us/step - loss: 1599.0761 - mean_absolute_error: 1599.0761 - val_loss: 1406.1453 - val_mean_absolute_error: 1406.1453\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 1405.70598\n",
      "Epoch 74/500\n",
      "585/585 [==============================] - 0s 84us/step - loss: 1571.9179 - mean_absolute_error: 1571.9179 - val_loss: 1401.2832 - val_mean_absolute_error: 1401.2832\n",
      "\n",
      "Epoch 00074: val_loss improved from 1405.70598 to 1401.28322, saving model to 맥주date-Weights-074--1401.28322-cat02-vf05.hdf5\n",
      "Epoch 75/500\n",
      "585/585 [==============================] - 0s 87us/step - loss: 1582.8875 - mean_absolute_error: 1582.8875 - val_loss: 1398.2205 - val_mean_absolute_error: 1398.2205\n",
      "\n",
      "Epoch 00075: val_loss improved from 1401.28322 to 1398.22045, saving model to 맥주date-Weights-075--1398.22045-cat02-vf05.hdf5\n",
      "Epoch 76/500\n",
      "585/585 [==============================] - 0s 85us/step - loss: 1600.9476 - mean_absolute_error: 1600.9476 - val_loss: 1442.5435 - val_mean_absolute_error: 1442.5435\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 1398.22045\n",
      "Epoch 77/500\n",
      "585/585 [==============================] - 0s 80us/step - loss: 1596.9638 - mean_absolute_error: 1596.9638 - val_loss: 1441.2628 - val_mean_absolute_error: 1441.2628\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 1398.22045\n",
      "Epoch 78/500\n",
      "585/585 [==============================] - 0s 87us/step - loss: 1560.3048 - mean_absolute_error: 1560.3048 - val_loss: 1404.0061 - val_mean_absolute_error: 1404.0061\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 1398.22045\n",
      "Epoch 79/500\n",
      "585/585 [==============================] - 0s 87us/step - loss: 1560.4239 - mean_absolute_error: 1560.4239 - val_loss: 1438.9064 - val_mean_absolute_error: 1438.9064\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 1398.22045\n",
      "Epoch 80/500\n",
      "585/585 [==============================] - 0s 87us/step - loss: 1591.0903 - mean_absolute_error: 1591.0903 - val_loss: 1505.5358 - val_mean_absolute_error: 1505.5358\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 1398.22045\n",
      "Epoch 81/500\n",
      "585/585 [==============================] - 0s 92us/step - loss: 1616.5052 - mean_absolute_error: 1616.5052 - val_loss: 1469.2640 - val_mean_absolute_error: 1469.2640\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 1398.22045\n",
      "Epoch 82/500\n",
      "585/585 [==============================] - 0s 94us/step - loss: 1587.7233 - mean_absolute_error: 1587.7233 - val_loss: 1431.1385 - val_mean_absolute_error: 1431.1385\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 1398.22045\n",
      "Epoch 83/500\n",
      "585/585 [==============================] - 0s 95us/step - loss: 1629.2619 - mean_absolute_error: 1629.2619 - val_loss: 1543.9095 - val_mean_absolute_error: 1543.9095\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 1398.22045\n",
      "Epoch 84/500\n",
      "585/585 [==============================] - 0s 109us/step - loss: 1595.8801 - mean_absolute_error: 1595.8801 - val_loss: 1415.5290 - val_mean_absolute_error: 1415.5290\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 1398.22045\n",
      "Epoch 85/500\n",
      "585/585 [==============================] - 0s 126us/step - loss: 1566.0284 - mean_absolute_error: 1566.0284 - val_loss: 1372.5830 - val_mean_absolute_error: 1372.5830\n",
      "\n",
      "Epoch 00085: val_loss improved from 1398.22045 to 1372.58297, saving model to 맥주date-Weights-085--1372.58297-cat02-vf05.hdf5\n",
      "Epoch 86/500\n",
      "585/585 [==============================] - 0s 94us/step - loss: 1637.3069 - mean_absolute_error: 1637.3069 - val_loss: 1400.9167 - val_mean_absolute_error: 1400.9167\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 1372.58297\n",
      "Epoch 87/500\n",
      "585/585 [==============================] - 0s 98us/step - loss: 1550.3929 - mean_absolute_error: 1550.3929 - val_loss: 1411.8054 - val_mean_absolute_error: 1411.8054\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 1372.58297\n",
      "Epoch 88/500\n",
      "585/585 [==============================] - 0s 109us/step - loss: 1570.5461 - mean_absolute_error: 1570.5461 - val_loss: 1538.1417 - val_mean_absolute_error: 1538.1417\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 1372.58297\n",
      "Epoch 89/500\n",
      "585/585 [==============================] - 0s 89us/step - loss: 1582.3334 - mean_absolute_error: 1582.3334 - val_loss: 1402.4139 - val_mean_absolute_error: 1402.4139\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 1372.58297\n",
      "Epoch 90/500\n",
      "585/585 [==============================] - 0s 107us/step - loss: 1567.3012 - mean_absolute_error: 1567.3012 - val_loss: 1509.6460 - val_mean_absolute_error: 1509.6460\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 1372.58297\n",
      "Epoch 91/500\n",
      "585/585 [==============================] - 0s 104us/step - loss: 1566.7352 - mean_absolute_error: 1566.7352 - val_loss: 1407.7262 - val_mean_absolute_error: 1407.7262\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 1372.58297\n",
      "Epoch 92/500\n",
      "585/585 [==============================] - 0s 97us/step - loss: 1547.9435 - mean_absolute_error: 1547.9435 - val_loss: 1427.7837 - val_mean_absolute_error: 1427.7837\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 1372.58297\n",
      "Epoch 93/500\n",
      "585/585 [==============================] - 0s 94us/step - loss: 1547.3066 - mean_absolute_error: 1547.3066 - val_loss: 1414.6944 - val_mean_absolute_error: 1414.6944\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 1372.58297\n",
      "Epoch 94/500\n",
      "585/585 [==============================] - 0s 117us/step - loss: 1550.6832 - mean_absolute_error: 1550.6832 - val_loss: 1628.7912 - val_mean_absolute_error: 1628.7912\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 1372.58297\n",
      "Epoch 95/500\n",
      "585/585 [==============================] - 0s 89us/step - loss: 1646.6992 - mean_absolute_error: 1646.6992 - val_loss: 1471.9641 - val_mean_absolute_error: 1471.9641\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 1372.58297\n",
      "Epoch 96/500\n",
      "585/585 [==============================] - 0s 99us/step - loss: 1569.5592 - mean_absolute_error: 1569.5592 - val_loss: 1396.8325 - val_mean_absolute_error: 1396.8325\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 1372.58297\n",
      "Epoch 97/500\n",
      "585/585 [==============================] - 0s 109us/step - loss: 1567.7192 - mean_absolute_error: 1567.7192 - val_loss: 1371.7325 - val_mean_absolute_error: 1371.7325\n",
      "\n",
      "Epoch 00097: val_loss improved from 1372.58297 to 1371.73250, saving model to 맥주date-Weights-097--1371.73250-cat02-vf05.hdf5\n",
      "Epoch 98/500\n",
      "585/585 [==============================] - 0s 109us/step - loss: 1524.2343 - mean_absolute_error: 1524.2343 - val_loss: 1399.2249 - val_mean_absolute_error: 1399.2249\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00098: val_loss did not improve from 1371.73250\n",
      "Epoch 99/500\n",
      "585/585 [==============================] - 0s 92us/step - loss: 1529.1182 - mean_absolute_error: 1529.1182 - val_loss: 1396.2788 - val_mean_absolute_error: 1396.2788\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 1371.73250\n",
      "Epoch 100/500\n",
      "585/585 [==============================] - 0s 92us/step - loss: 1545.0668 - mean_absolute_error: 1545.0668 - val_loss: 1393.8480 - val_mean_absolute_error: 1393.8480\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 1371.73250\n",
      "Epoch 101/500\n",
      "585/585 [==============================] - 0s 89us/step - loss: 1529.6353 - mean_absolute_error: 1529.6353 - val_loss: 1422.9715 - val_mean_absolute_error: 1422.9715\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 1371.73250\n",
      "Epoch 102/500\n",
      "585/585 [==============================] - 0s 97us/step - loss: 1536.4391 - mean_absolute_error: 1536.4391 - val_loss: 1419.9412 - val_mean_absolute_error: 1419.9412\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 1371.73250\n",
      "Epoch 103/500\n",
      "585/585 [==============================] - 0s 97us/step - loss: 1535.3317 - mean_absolute_error: 1535.3317 - val_loss: 1392.6216 - val_mean_absolute_error: 1392.6216\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 1371.73250\n",
      "Epoch 104/500\n",
      "585/585 [==============================] - 0s 98us/step - loss: 1530.1224 - mean_absolute_error: 1530.1224 - val_loss: 1431.5499 - val_mean_absolute_error: 1431.5499\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 1371.73250\n",
      "Epoch 105/500\n",
      "585/585 [==============================] - 0s 104us/step - loss: 1524.1927 - mean_absolute_error: 1524.1927 - val_loss: 1408.7068 - val_mean_absolute_error: 1408.7068\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 1371.73250\n",
      "Epoch 106/500\n",
      "585/585 [==============================] - 0s 94us/step - loss: 1568.4250 - mean_absolute_error: 1568.4250 - val_loss: 1622.8537 - val_mean_absolute_error: 1622.8537\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 1371.73250\n",
      "Epoch 107/500\n",
      "585/585 [==============================] - 0s 100us/step - loss: 1542.0464 - mean_absolute_error: 1542.0464 - val_loss: 1409.0496 - val_mean_absolute_error: 1409.0496\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 1371.73250\n",
      "Epoch 108/500\n",
      "585/585 [==============================] - 0s 94us/step - loss: 1528.3426 - mean_absolute_error: 1528.3426 - val_loss: 1409.8334 - val_mean_absolute_error: 1409.8334\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 1371.73250\n",
      "Epoch 109/500\n",
      "585/585 [==============================] - 0s 114us/step - loss: 1545.2930 - mean_absolute_error: 1545.2930 - val_loss: 1362.9579 - val_mean_absolute_error: 1362.9579\n",
      "\n",
      "Epoch 00109: val_loss improved from 1371.73250 to 1362.95789, saving model to 맥주date-Weights-109--1362.95789-cat02-vf05.hdf5\n",
      "Epoch 110/500\n",
      "585/585 [==============================] - 0s 97us/step - loss: 1521.1102 - mean_absolute_error: 1521.1102 - val_loss: 1419.8004 - val_mean_absolute_error: 1419.8004\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 1362.95789\n",
      "Epoch 111/500\n",
      "585/585 [==============================] - 0s 115us/step - loss: 1513.2019 - mean_absolute_error: 1513.2019 - val_loss: 1429.9119 - val_mean_absolute_error: 1429.9119\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 1362.95789\n",
      "Epoch 112/500\n",
      "585/585 [==============================] - 0s 128us/step - loss: 1508.7885 - mean_absolute_error: 1508.7885 - val_loss: 1384.8273 - val_mean_absolute_error: 1384.8273\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 1362.95789\n",
      "Epoch 113/500\n",
      "585/585 [==============================] - 0s 105us/step - loss: 1561.9627 - mean_absolute_error: 1561.9627 - val_loss: 1386.1305 - val_mean_absolute_error: 1386.1305\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 1362.95789\n",
      "Epoch 114/500\n",
      "585/585 [==============================] - 0s 115us/step - loss: 1521.2929 - mean_absolute_error: 1521.2929 - val_loss: 1413.3491 - val_mean_absolute_error: 1413.3491\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 1362.95789\n",
      "Epoch 115/500\n",
      "585/585 [==============================] - 0s 109us/step - loss: 1512.7146 - mean_absolute_error: 1512.7146 - val_loss: 1408.0372 - val_mean_absolute_error: 1408.0372\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 1362.95789\n",
      "Epoch 116/500\n",
      "585/585 [==============================] - 0s 101us/step - loss: 1553.1070 - mean_absolute_error: 1553.1070 - val_loss: 1420.3978 - val_mean_absolute_error: 1420.3978\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 1362.95789\n",
      "Epoch 117/500\n",
      "585/585 [==============================] - 0s 120us/step - loss: 1618.3151 - mean_absolute_error: 1618.3151 - val_loss: 1410.0561 - val_mean_absolute_error: 1410.0561\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 1362.95789\n",
      "Epoch 118/500\n",
      "585/585 [==============================] - 0s 102us/step - loss: 1569.4232 - mean_absolute_error: 1569.4232 - val_loss: 1403.0401 - val_mean_absolute_error: 1403.0401\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 1362.95789\n",
      "Epoch 119/500\n",
      "585/585 [==============================] - 0s 114us/step - loss: 1508.0000 - mean_absolute_error: 1508.0000 - val_loss: 1414.3085 - val_mean_absolute_error: 1414.3085\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 1362.95789\n",
      "Epoch 120/500\n",
      "585/585 [==============================] - 0s 123us/step - loss: 1529.7778 - mean_absolute_error: 1529.7778 - val_loss: 1391.2431 - val_mean_absolute_error: 1391.2431\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 1362.95789\n",
      "Epoch 121/500\n",
      "585/585 [==============================] - 0s 150us/step - loss: 1599.4006 - mean_absolute_error: 1599.4006 - val_loss: 1415.5835 - val_mean_absolute_error: 1415.5835\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 1362.95789\n",
      "Epoch 122/500\n",
      "585/585 [==============================] - 0s 116us/step - loss: 1546.0593 - mean_absolute_error: 1546.0593 - val_loss: 1412.9033 - val_mean_absolute_error: 1412.9033\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 1362.95789\n",
      "Epoch 123/500\n",
      "585/585 [==============================] - 0s 114us/step - loss: 1505.1114 - mean_absolute_error: 1505.1114 - val_loss: 1368.7820 - val_mean_absolute_error: 1368.7820\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 1362.95789\n",
      "Epoch 124/500\n",
      "585/585 [==============================] - 0s 118us/step - loss: 1489.5569 - mean_absolute_error: 1489.5569 - val_loss: 1414.5518 - val_mean_absolute_error: 1414.5518\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 1362.95789\n",
      "Epoch 125/500\n",
      "585/585 [==============================] - 0s 121us/step - loss: 1503.5642 - mean_absolute_error: 1503.5642 - val_loss: 1413.6233 - val_mean_absolute_error: 1413.6233\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 1362.95789\n",
      "Epoch 126/500\n",
      "585/585 [==============================] - 0s 118us/step - loss: 1519.3563 - mean_absolute_error: 1519.3563 - val_loss: 1432.1632 - val_mean_absolute_error: 1432.1632\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 1362.95789\n",
      "Epoch 127/500\n",
      "585/585 [==============================] - 0s 130us/step - loss: 1565.6335 - mean_absolute_error: 1565.6335 - val_loss: 1388.1204 - val_mean_absolute_error: 1388.1204\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 1362.95789\n",
      "Epoch 128/500\n",
      "585/585 [==============================] - 0s 126us/step - loss: 1516.6429 - mean_absolute_error: 1516.6429 - val_loss: 1391.5636 - val_mean_absolute_error: 1391.5636\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 1362.95789\n",
      "Epoch 129/500\n",
      "585/585 [==============================] - 0s 135us/step - loss: 1521.9192 - mean_absolute_error: 1521.9192 - val_loss: 1409.2766 - val_mean_absolute_error: 1409.2766\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 1362.95789\n",
      "Epoch 130/500\n",
      "585/585 [==============================] - 0s 118us/step - loss: 1523.2801 - mean_absolute_error: 1523.2801 - val_loss: 1401.9815 - val_mean_absolute_error: 1401.9815\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 1362.95789\n",
      "Epoch 131/500\n",
      "585/585 [==============================] - 0s 113us/step - loss: 1492.0241 - mean_absolute_error: 1492.0241 - val_loss: 1394.2824 - val_mean_absolute_error: 1394.2824\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 1362.95789\n",
      "Epoch 132/500\n",
      "585/585 [==============================] - 0s 131us/step - loss: 1525.7309 - mean_absolute_error: 1525.7309 - val_loss: 1441.8923 - val_mean_absolute_error: 1441.8923\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 1362.95789\n",
      "Epoch 133/500\n",
      "585/585 [==============================] - 0s 119us/step - loss: 1533.9518 - mean_absolute_error: 1533.9518 - val_loss: 1431.9180 - val_mean_absolute_error: 1431.9180\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 1362.95789\n",
      "Epoch 134/500\n",
      "585/585 [==============================] - 0s 110us/step - loss: 1512.3202 - mean_absolute_error: 1512.3202 - val_loss: 1481.8127 - val_mean_absolute_error: 1481.8127\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 1362.95789\n",
      "Epoch 135/500\n",
      "585/585 [==============================] - 0s 141us/step - loss: 1545.2980 - mean_absolute_error: 1545.2980 - val_loss: 1373.5515 - val_mean_absolute_error: 1373.5515\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 1362.95789\n",
      "Epoch 136/500\n",
      "585/585 [==============================] - 0s 118us/step - loss: 1508.5336 - mean_absolute_error: 1508.5336 - val_loss: 1435.6977 - val_mean_absolute_error: 1435.6977\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 1362.95789\n",
      "Epoch 137/500\n",
      "585/585 [==============================] - 0s 119us/step - loss: 1518.5211 - mean_absolute_error: 1518.5211 - val_loss: 1390.9720 - val_mean_absolute_error: 1390.9720\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 1362.95789\n",
      "Epoch 138/500\n",
      "585/585 [==============================] - 0s 121us/step - loss: 1531.0932 - mean_absolute_error: 1531.0932 - val_loss: 1384.0479 - val_mean_absolute_error: 1384.0479\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 1362.95789\n",
      "Epoch 139/500\n",
      "585/585 [==============================] - 0s 119us/step - loss: 1493.1597 - mean_absolute_error: 1493.1597 - val_loss: 1504.5304 - val_mean_absolute_error: 1504.5304\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 1362.95789\n",
      "Epoch 140/500\n",
      "585/585 [==============================] - 0s 116us/step - loss: 1513.8785 - mean_absolute_error: 1513.8785 - val_loss: 1423.9973 - val_mean_absolute_error: 1423.9973\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 1362.95789\n",
      "Epoch 141/500\n",
      "585/585 [==============================] - 0s 114us/step - loss: 1500.1931 - mean_absolute_error: 1500.1931 - val_loss: 1428.4595 - val_mean_absolute_error: 1428.4595\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 1362.95789\n",
      "Epoch 142/500\n",
      "585/585 [==============================] - 0s 126us/step - loss: 1516.7583 - mean_absolute_error: 1516.7583 - val_loss: 1419.9280 - val_mean_absolute_error: 1419.9280\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 1362.95789\n",
      "Epoch 143/500\n",
      "585/585 [==============================] - 0s 114us/step - loss: 1493.2834 - mean_absolute_error: 1493.2834 - val_loss: 1395.0342 - val_mean_absolute_error: 1395.0342\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 1362.95789\n",
      "Epoch 144/500\n",
      "585/585 [==============================] - 0s 116us/step - loss: 1519.6575 - mean_absolute_error: 1519.6575 - val_loss: 1473.9308 - val_mean_absolute_error: 1473.9308\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 1362.95789\n",
      "Epoch 145/500\n",
      "585/585 [==============================] - 0s 113us/step - loss: 1487.1890 - mean_absolute_error: 1487.1890 - val_loss: 1385.9541 - val_mean_absolute_error: 1385.9541\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 1362.95789\n",
      "Epoch 146/500\n",
      "585/585 [==============================] - 0s 119us/step - loss: 1496.2484 - mean_absolute_error: 1496.2484 - val_loss: 1441.4875 - val_mean_absolute_error: 1441.4875\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 1362.95789\n",
      "Epoch 147/500\n",
      "585/585 [==============================] - 0s 110us/step - loss: 1508.4406 - mean_absolute_error: 1508.4406 - val_loss: 1421.3490 - val_mean_absolute_error: 1421.3490\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 1362.95789\n",
      "Epoch 148/500\n",
      "585/585 [==============================] - 0s 140us/step - loss: 1497.4049 - mean_absolute_error: 1497.4049 - val_loss: 1435.5819 - val_mean_absolute_error: 1435.5819\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 1362.95789\n",
      "Epoch 149/500\n",
      "585/585 [==============================] - 0s 167us/step - loss: 1489.7462 - mean_absolute_error: 1489.7462 - val_loss: 1390.2618 - val_mean_absolute_error: 1390.2618\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 1362.95789\n",
      "Epoch 150/500\n",
      "585/585 [==============================] - 0s 182us/step - loss: 1520.3222 - mean_absolute_error: 1520.3222 - val_loss: 1441.4178 - val_mean_absolute_error: 1441.4178\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 1362.95789\n",
      "Epoch 151/500\n",
      "585/585 [==============================] - 0s 140us/step - loss: 1543.6721 - mean_absolute_error: 1543.6721 - val_loss: 1432.4937 - val_mean_absolute_error: 1432.4937\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 1362.95789\n",
      "Epoch 152/500\n",
      "585/585 [==============================] - 0s 145us/step - loss: 1535.4717 - mean_absolute_error: 1535.4717 - val_loss: 1479.7601 - val_mean_absolute_error: 1479.7601\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 1362.95789\n",
      "Epoch 153/500\n",
      "585/585 [==============================] - 0s 130us/step - loss: 1503.9848 - mean_absolute_error: 1503.9848 - val_loss: 1355.2878 - val_mean_absolute_error: 1355.2878\n",
      "\n",
      "Epoch 00153: val_loss improved from 1362.95789 to 1355.28782, saving model to 맥주date-Weights-153--1355.28782-cat02-vf05.hdf5\n",
      "Epoch 154/500\n",
      "585/585 [==============================] - 0s 123us/step - loss: 1493.5139 - mean_absolute_error: 1493.5139 - val_loss: 1504.9908 - val_mean_absolute_error: 1504.9908\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 1355.28782\n",
      "Epoch 155/500\n",
      "585/585 [==============================] - 0s 138us/step - loss: 1473.5093 - mean_absolute_error: 1473.5093 - val_loss: 1391.0797 - val_mean_absolute_error: 1391.0797\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 1355.28782\n",
      "Epoch 156/500\n",
      "585/585 [==============================] - 0s 164us/step - loss: 1495.6699 - mean_absolute_error: 1495.6699 - val_loss: 1600.2818 - val_mean_absolute_error: 1600.2818\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 1355.28782\n",
      "Epoch 157/500\n",
      "585/585 [==============================] - 0s 138us/step - loss: 1504.2692 - mean_absolute_error: 1504.2692 - val_loss: 1410.8673 - val_mean_absolute_error: 1410.8673\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 1355.28782\n",
      "Epoch 158/500\n",
      "585/585 [==============================] - 0s 135us/step - loss: 1487.5091 - mean_absolute_error: 1487.5091 - val_loss: 1415.2072 - val_mean_absolute_error: 1415.2072\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 1355.28782\n",
      "Epoch 159/500\n",
      "585/585 [==============================] - 0s 164us/step - loss: 1504.3356 - mean_absolute_error: 1504.3356 - val_loss: 1389.5523 - val_mean_absolute_error: 1389.5523\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 1355.28782\n",
      "Epoch 160/500\n",
      "585/585 [==============================] - 0s 194us/step - loss: 1504.1150 - mean_absolute_error: 1504.1150 - val_loss: 1382.1680 - val_mean_absolute_error: 1382.1680\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 1355.28782\n",
      "Epoch 161/500\n",
      "585/585 [==============================] - 0s 240us/step - loss: 1500.0759 - mean_absolute_error: 1500.0759 - val_loss: 1394.6775 - val_mean_absolute_error: 1394.6775\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 1355.28782\n",
      "Epoch 162/500\n",
      "585/585 [==============================] - 0s 331us/step - loss: 1499.2213 - mean_absolute_error: 1499.2213 - val_loss: 1379.4088 - val_mean_absolute_error: 1379.4088\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 1355.28782\n",
      "Epoch 163/500\n",
      "585/585 [==============================] - 0s 256us/step - loss: 1533.5582 - mean_absolute_error: 1533.5582 - val_loss: 1458.3301 - val_mean_absolute_error: 1458.3301\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 1355.28782\n",
      "Epoch 164/500\n",
      "585/585 [==============================] - 0s 170us/step - loss: 1520.9766 - mean_absolute_error: 1520.9766 - val_loss: 1504.4231 - val_mean_absolute_error: 1504.4231\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 1355.28782\n",
      "Epoch 165/500\n",
      "585/585 [==============================] - 0s 264us/step - loss: 1477.2979 - mean_absolute_error: 1477.2979 - val_loss: 1403.5075 - val_mean_absolute_error: 1403.5075\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 1355.28782\n",
      "Epoch 166/500\n",
      "585/585 [==============================] - 0s 143us/step - loss: 1502.7948 - mean_absolute_error: 1502.7948 - val_loss: 1408.4592 - val_mean_absolute_error: 1408.4592\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 1355.28782\n",
      "Epoch 167/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "585/585 [==============================] - 0s 147us/step - loss: 1494.8657 - mean_absolute_error: 1494.8657 - val_loss: 1385.7995 - val_mean_absolute_error: 1385.7995\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 1355.28782\n",
      "Epoch 168/500\n",
      "585/585 [==============================] - 0s 189us/step - loss: 1496.8490 - mean_absolute_error: 1496.8490 - val_loss: 1389.2441 - val_mean_absolute_error: 1389.2441\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 1355.28782\n",
      "Epoch 169/500\n",
      "585/585 [==============================] - 0s 167us/step - loss: 1529.1231 - mean_absolute_error: 1529.1231 - val_loss: 1419.0136 - val_mean_absolute_error: 1419.0136\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 1355.28782\n",
      "Epoch 170/500\n",
      "585/585 [==============================] - 0s 234us/step - loss: 1522.3890 - mean_absolute_error: 1522.3890 - val_loss: 1416.7481 - val_mean_absolute_error: 1416.7481\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 1355.28782\n",
      "Epoch 171/500\n",
      "585/585 [==============================] - 0s 223us/step - loss: 1517.9529 - mean_absolute_error: 1517.9529 - val_loss: 1391.8490 - val_mean_absolute_error: 1391.8490\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 1355.28782\n",
      "Epoch 172/500\n",
      "585/585 [==============================] - 0s 189us/step - loss: 1500.4045 - mean_absolute_error: 1500.4045 - val_loss: 1494.7016 - val_mean_absolute_error: 1494.7016\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 1355.28782\n",
      "Epoch 173/500\n",
      "585/585 [==============================] - 0s 164us/step - loss: 1520.3029 - mean_absolute_error: 1520.3029 - val_loss: 1668.2752 - val_mean_absolute_error: 1668.2752\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 1355.28782\n",
      "Epoch 174/500\n",
      "585/585 [==============================] - 0s 153us/step - loss: 1568.5978 - mean_absolute_error: 1568.5978 - val_loss: 1466.5945 - val_mean_absolute_error: 1466.5945\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 1355.28782\n",
      "Epoch 175/500\n",
      "585/585 [==============================] - 0s 142us/step - loss: 1489.5362 - mean_absolute_error: 1489.5362 - val_loss: 1445.9808 - val_mean_absolute_error: 1445.9808\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 1355.28782\n",
      "Epoch 176/500\n",
      "585/585 [==============================] - 0s 140us/step - loss: 1516.2442 - mean_absolute_error: 1516.2442 - val_loss: 1397.4518 - val_mean_absolute_error: 1397.4518\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 1355.28782\n",
      "Epoch 177/500\n",
      "585/585 [==============================] - 0s 147us/step - loss: 1566.0154 - mean_absolute_error: 1566.0154 - val_loss: 1404.1581 - val_mean_absolute_error: 1404.1581\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 1355.28782\n",
      "Epoch 178/500\n",
      "585/585 [==============================] - 0s 133us/step - loss: 1498.3918 - mean_absolute_error: 1498.3918 - val_loss: 1391.4767 - val_mean_absolute_error: 1391.4767\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 1355.28782\n",
      "Epoch 179/500\n",
      "585/585 [==============================] - 0s 128us/step - loss: 1491.4158 - mean_absolute_error: 1491.4158 - val_loss: 1399.7230 - val_mean_absolute_error: 1399.7230\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 1355.28782\n",
      "Epoch 180/500\n",
      "585/585 [==============================] - 0s 143us/step - loss: 1497.8155 - mean_absolute_error: 1497.8155 - val_loss: 1383.2782 - val_mean_absolute_error: 1383.2782\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 1355.28782\n",
      "Epoch 181/500\n",
      "585/585 [==============================] - 0s 129us/step - loss: 1553.3523 - mean_absolute_error: 1553.3523 - val_loss: 1530.9836 - val_mean_absolute_error: 1530.9836\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 1355.28782\n",
      "Epoch 182/500\n",
      "585/585 [==============================] - 0s 140us/step - loss: 1490.7771 - mean_absolute_error: 1490.7771 - val_loss: 1408.2986 - val_mean_absolute_error: 1408.2986\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 1355.28782\n",
      "Epoch 183/500\n",
      "585/585 [==============================] - 0s 147us/step - loss: 1476.4195 - mean_absolute_error: 1476.4195 - val_loss: 1431.1904 - val_mean_absolute_error: 1431.1904\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 1355.28782\n",
      "Epoch 184/500\n",
      "585/585 [==============================] - 0s 135us/step - loss: 1501.7164 - mean_absolute_error: 1501.7164 - val_loss: 1448.8052 - val_mean_absolute_error: 1448.8052\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 1355.28782\n",
      "Epoch 185/500\n",
      "585/585 [==============================] - 0s 152us/step - loss: 1481.5285 - mean_absolute_error: 1481.5285 - val_loss: 1394.1052 - val_mean_absolute_error: 1394.1052\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 1355.28782\n",
      "Epoch 186/500\n",
      "585/585 [==============================] - 0s 143us/step - loss: 1481.6284 - mean_absolute_error: 1481.6284 - val_loss: 1382.6257 - val_mean_absolute_error: 1382.6257\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 1355.28782\n",
      "Epoch 187/500\n",
      "585/585 [==============================] - 0s 136us/step - loss: 1473.5794 - mean_absolute_error: 1473.5794 - val_loss: 1391.1665 - val_mean_absolute_error: 1391.1665\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 1355.28782\n",
      "Epoch 188/500\n",
      "585/585 [==============================] - 0s 130us/step - loss: 1525.0079 - mean_absolute_error: 1525.0079 - val_loss: 1408.3579 - val_mean_absolute_error: 1408.3579\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 1355.28782\n",
      "Epoch 189/500\n",
      "585/585 [==============================] - 0s 136us/step - loss: 1527.8023 - mean_absolute_error: 1527.8023 - val_loss: 1447.8799 - val_mean_absolute_error: 1447.8799\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 1355.28782\n",
      "Epoch 190/500\n",
      "585/585 [==============================] - 0s 143us/step - loss: 1472.2845 - mean_absolute_error: 1472.2845 - val_loss: 1429.7889 - val_mean_absolute_error: 1429.7889\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 1355.28782\n",
      "Epoch 191/500\n",
      "585/585 [==============================] - 0s 181us/step - loss: 1476.1002 - mean_absolute_error: 1476.1002 - val_loss: 1466.7904 - val_mean_absolute_error: 1466.7904\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 1355.28782\n",
      "Epoch 192/500\n",
      "585/585 [==============================] - 0s 133us/step - loss: 1494.1504 - mean_absolute_error: 1494.1504 - val_loss: 1367.8065 - val_mean_absolute_error: 1367.8065\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 1355.28782\n",
      "Epoch 193/500\n",
      "585/585 [==============================] - 0s 142us/step - loss: 1479.1277 - mean_absolute_error: 1479.1277 - val_loss: 1390.1186 - val_mean_absolute_error: 1390.1186\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 1355.28782\n",
      "Epoch 194/500\n",
      "585/585 [==============================] - 0s 150us/step - loss: 1490.5843 - mean_absolute_error: 1490.5843 - val_loss: 1453.4497 - val_mean_absolute_error: 1453.4497\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 1355.28782\n",
      "Epoch 195/500\n",
      "585/585 [==============================] - 0s 138us/step - loss: 1469.5314 - mean_absolute_error: 1469.5314 - val_loss: 1391.0740 - val_mean_absolute_error: 1391.0740\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 1355.28782\n",
      "Epoch 196/500\n",
      "585/585 [==============================] - 0s 154us/step - loss: 1465.9589 - mean_absolute_error: 1465.9589 - val_loss: 1396.7529 - val_mean_absolute_error: 1396.7529\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 1355.28782\n",
      "Epoch 197/500\n",
      "585/585 [==============================] - 0s 144us/step - loss: 1473.1364 - mean_absolute_error: 1473.1364 - val_loss: 1370.5980 - val_mean_absolute_error: 1370.5980\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 1355.28782\n",
      "Epoch 198/500\n",
      "585/585 [==============================] - 0s 131us/step - loss: 1470.3363 - mean_absolute_error: 1470.3363 - val_loss: 1409.1998 - val_mean_absolute_error: 1409.1998\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 1355.28782\n",
      "Epoch 199/500\n",
      "585/585 [==============================] - 0s 133us/step - loss: 1462.7051 - mean_absolute_error: 1462.7051 - val_loss: 1383.6788 - val_mean_absolute_error: 1383.6788\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 1355.28782\n",
      "Epoch 200/500\n",
      "585/585 [==============================] - 0s 136us/step - loss: 1477.2291 - mean_absolute_error: 1477.2291 - val_loss: 1395.0821 - val_mean_absolute_error: 1395.0821\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 1355.28782\n",
      "Epoch 201/500\n",
      "585/585 [==============================] - 0s 135us/step - loss: 1479.9686 - mean_absolute_error: 1479.9686 - val_loss: 1414.6711 - val_mean_absolute_error: 1414.6711\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 1355.28782\n",
      "Epoch 202/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "585/585 [==============================] - 0s 134us/step - loss: 1464.3196 - mean_absolute_error: 1464.3196 - val_loss: 1516.7045 - val_mean_absolute_error: 1516.7045\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 1355.28782\n",
      "Epoch 203/500\n",
      "585/585 [==============================] - 0s 171us/step - loss: 1486.2670 - mean_absolute_error: 1486.2670 - val_loss: 1434.5563 - val_mean_absolute_error: 1434.5563\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 1355.28782\n",
      "Epoch 204/500\n",
      "585/585 [==============================] - 0s 153us/step - loss: 1504.2377 - mean_absolute_error: 1504.2377 - val_loss: 1358.6337 - val_mean_absolute_error: 1358.6337\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 1355.28782\n",
      "Epoch 205/500\n",
      "585/585 [==============================] - 0s 152us/step - loss: 1488.2133 - mean_absolute_error: 1488.2133 - val_loss: 1510.6562 - val_mean_absolute_error: 1510.6562\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 1355.28782\n",
      "Epoch 206/500\n",
      "585/585 [==============================] - 0s 152us/step - loss: 1482.7375 - mean_absolute_error: 1482.7375 - val_loss: 1395.3899 - val_mean_absolute_error: 1395.3899\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 1355.28782\n",
      "Epoch 207/500\n",
      "585/585 [==============================] - 0s 167us/step - loss: 1509.4852 - mean_absolute_error: 1509.4852 - val_loss: 1374.3876 - val_mean_absolute_error: 1374.3876\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 1355.28782\n",
      "Epoch 208/500\n",
      "585/585 [==============================] - 0s 135us/step - loss: 1466.2896 - mean_absolute_error: 1466.2896 - val_loss: 1396.6591 - val_mean_absolute_error: 1396.6591\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 1355.28782\n",
      "Epoch 209/500\n",
      "585/585 [==============================] - 0s 145us/step - loss: 1476.3842 - mean_absolute_error: 1476.3842 - val_loss: 1391.2896 - val_mean_absolute_error: 1391.2896\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 1355.28782\n",
      "Epoch 210/500\n",
      "585/585 [==============================] - 0s 160us/step - loss: 1484.9156 - mean_absolute_error: 1484.9156 - val_loss: 1387.0147 - val_mean_absolute_error: 1387.0147\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 1355.28782\n",
      "Epoch 211/500\n",
      "585/585 [==============================] - 0s 153us/step - loss: 1481.2839 - mean_absolute_error: 1481.2839 - val_loss: 1414.2159 - val_mean_absolute_error: 1414.2159\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 1355.28782\n",
      "Epoch 212/500\n",
      "585/585 [==============================] - 0s 147us/step - loss: 1499.5391 - mean_absolute_error: 1499.5391 - val_loss: 1575.1635 - val_mean_absolute_error: 1575.1635\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 1355.28782\n",
      "Epoch 213/500\n",
      "585/585 [==============================] - 0s 135us/step - loss: 1601.5945 - mean_absolute_error: 1601.5945 - val_loss: 1436.8801 - val_mean_absolute_error: 1436.8801\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 1355.28782\n",
      "Epoch 214/500\n",
      "585/585 [==============================] - 0s 134us/step - loss: 1527.9881 - mean_absolute_error: 1527.9881 - val_loss: 1549.9808 - val_mean_absolute_error: 1549.9808\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 1355.28782\n",
      "Epoch 215/500\n",
      "585/585 [==============================] - 0s 137us/step - loss: 1463.1925 - mean_absolute_error: 1463.1925 - val_loss: 1395.3701 - val_mean_absolute_error: 1395.3701\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 1355.28782\n",
      "Epoch 216/500\n",
      "585/585 [==============================] - 0s 138us/step - loss: 1463.8414 - mean_absolute_error: 1463.8414 - val_loss: 1435.4110 - val_mean_absolute_error: 1435.4110\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 1355.28782\n",
      "Epoch 217/500\n",
      "585/585 [==============================] - 0s 141us/step - loss: 1460.5332 - mean_absolute_error: 1460.5332 - val_loss: 1400.5716 - val_mean_absolute_error: 1400.5716\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 1355.28782\n",
      "Epoch 218/500\n",
      "585/585 [==============================] - 0s 135us/step - loss: 1457.3469 - mean_absolute_error: 1457.3469 - val_loss: 1393.9288 - val_mean_absolute_error: 1393.9288\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 1355.28782\n",
      "Epoch 219/500\n",
      "585/585 [==============================] - 0s 130us/step - loss: 1461.8038 - mean_absolute_error: 1461.8038 - val_loss: 1421.6178 - val_mean_absolute_error: 1421.6178\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 1355.28782\n",
      "Epoch 220/500\n",
      "585/585 [==============================] - 0s 127us/step - loss: 1459.4254 - mean_absolute_error: 1459.4254 - val_loss: 1445.9734 - val_mean_absolute_error: 1445.9734\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 1355.28782\n",
      "Epoch 221/500\n",
      "585/585 [==============================] - 0s 122us/step - loss: 1503.8185 - mean_absolute_error: 1503.8185 - val_loss: 1415.1776 - val_mean_absolute_error: 1415.1776\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 1355.28782\n",
      "Epoch 222/500\n",
      "585/585 [==============================] - 0s 129us/step - loss: 1466.2334 - mean_absolute_error: 1466.2334 - val_loss: 1373.1100 - val_mean_absolute_error: 1373.1100\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 1355.28782\n",
      "Epoch 223/500\n",
      "585/585 [==============================] - 0s 143us/step - loss: 1470.9659 - mean_absolute_error: 1470.9659 - val_loss: 1430.3699 - val_mean_absolute_error: 1430.3699\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 1355.28782\n",
      "Epoch 224/500\n",
      "585/585 [==============================] - 0s 154us/step - loss: 1509.4780 - mean_absolute_error: 1509.4780 - val_loss: 1408.9958 - val_mean_absolute_error: 1408.9958\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 1355.28782\n",
      "Epoch 225/500\n",
      "585/585 [==============================] - ETA: 0s - loss: 1504.0875 - mean_absolute_error: 1504.087 - 0s 138us/step - loss: 1470.6419 - mean_absolute_error: 1470.6419 - val_loss: 1407.0655 - val_mean_absolute_error: 1407.0655\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 1355.28782\n",
      "Epoch 226/500\n",
      "585/585 [==============================] - 0s 142us/step - loss: 1512.5618 - mean_absolute_error: 1512.5618 - val_loss: 1353.8376 - val_mean_absolute_error: 1353.8376\n",
      "\n",
      "Epoch 00226: val_loss improved from 1355.28782 to 1353.83757, saving model to 맥주date-Weights-226--1353.83757-cat02-vf05.hdf5\n",
      "Epoch 227/500\n",
      "585/585 [==============================] - 0s 142us/step - loss: 1484.5131 - mean_absolute_error: 1484.5131 - val_loss: 1519.8779 - val_mean_absolute_error: 1519.8779\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 1353.83757\n",
      "Epoch 228/500\n",
      "585/585 [==============================] - 0s 135us/step - loss: 1469.0960 - mean_absolute_error: 1469.0960 - val_loss: 1413.7525 - val_mean_absolute_error: 1413.7525\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 1353.83757\n",
      "Epoch 229/500\n",
      "585/585 [==============================] - 0s 128us/step - loss: 1465.2967 - mean_absolute_error: 1465.2967 - val_loss: 1382.4696 - val_mean_absolute_error: 1382.4696\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 1353.83757\n",
      "Epoch 230/500\n",
      "585/585 [==============================] - 0s 130us/step - loss: 1467.0528 - mean_absolute_error: 1467.0528 - val_loss: 1420.1005 - val_mean_absolute_error: 1420.1005\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 1353.83757\n",
      "Epoch 231/500\n",
      "585/585 [==============================] - 0s 136us/step - loss: 1453.0061 - mean_absolute_error: 1453.0061 - val_loss: 1418.7288 - val_mean_absolute_error: 1418.7288\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 1353.83757\n",
      "Epoch 232/500\n",
      "585/585 [==============================] - 0s 126us/step - loss: 1444.3872 - mean_absolute_error: 1444.3872 - val_loss: 1374.3308 - val_mean_absolute_error: 1374.3308\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 1353.83757\n",
      "Epoch 233/500\n",
      "585/585 [==============================] - 0s 147us/step - loss: 1475.1955 - mean_absolute_error: 1475.1955 - val_loss: 1396.6876 - val_mean_absolute_error: 1396.6876\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 1353.83757\n",
      "Epoch 234/500\n",
      "585/585 [==============================] - 0s 135us/step - loss: 1468.7669 - mean_absolute_error: 1468.7669 - val_loss: 1403.1841 - val_mean_absolute_error: 1403.1841\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 1353.83757\n",
      "Epoch 235/500\n",
      "585/585 [==============================] - 0s 136us/step - loss: 1460.1387 - mean_absolute_error: 1460.1387 - val_loss: 1372.8638 - val_mean_absolute_error: 1372.8638\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 1353.83757\n",
      "Epoch 236/500\n",
      "585/585 [==============================] - 0s 136us/step - loss: 1482.9768 - mean_absolute_error: 1482.9768 - val_loss: 1449.4583 - val_mean_absolute_error: 1449.4583\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 1353.83757\n",
      "Epoch 237/500\n",
      "585/585 [==============================] - 0s 135us/step - loss: 1492.5494 - mean_absolute_error: 1492.5494 - val_loss: 1398.3648 - val_mean_absolute_error: 1398.3648\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 1353.83757\n",
      "Epoch 238/500\n",
      "585/585 [==============================] - 0s 146us/step - loss: 1448.0490 - mean_absolute_error: 1448.0490 - val_loss: 1450.3439 - val_mean_absolute_error: 1450.3439\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 1353.83757\n",
      "Epoch 239/500\n",
      "585/585 [==============================] - 0s 226us/step - loss: 1472.6823 - mean_absolute_error: 1472.6823 - val_loss: 1408.1216 - val_mean_absolute_error: 1408.1216\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 1353.83757\n",
      "Epoch 240/500\n",
      "585/585 [==============================] - 0s 170us/step - loss: 1470.5039 - mean_absolute_error: 1470.5039 - val_loss: 1479.8625 - val_mean_absolute_error: 1479.8625\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 1353.83757\n",
      "Epoch 241/500\n",
      "585/585 [==============================] - 0s 168us/step - loss: 1498.0247 - mean_absolute_error: 1498.0247 - val_loss: 1443.8534 - val_mean_absolute_error: 1443.8534\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 1353.83757\n",
      "Epoch 242/500\n",
      "585/585 [==============================] - 0s 165us/step - loss: 1453.8137 - mean_absolute_error: 1453.8137 - val_loss: 1376.7051 - val_mean_absolute_error: 1376.7051\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 1353.83757\n",
      "Epoch 243/500\n",
      "585/585 [==============================] - 0s 159us/step - loss: 1483.9733 - mean_absolute_error: 1483.9733 - val_loss: 1383.3836 - val_mean_absolute_error: 1383.3836\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 1353.83757\n",
      "Epoch 244/500\n",
      "585/585 [==============================] - 0s 148us/step - loss: 1470.7493 - mean_absolute_error: 1470.7493 - val_loss: 1416.0330 - val_mean_absolute_error: 1416.0330\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 1353.83757\n",
      "Epoch 245/500\n",
      "585/585 [==============================] - 0s 135us/step - loss: 1457.7551 - mean_absolute_error: 1457.7551 - val_loss: 1394.6465 - val_mean_absolute_error: 1394.6465\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 1353.83757\n",
      "Epoch 246/500\n",
      "585/585 [==============================] - 0s 165us/step - loss: 1540.5268 - mean_absolute_error: 1540.5268 - val_loss: 1409.6542 - val_mean_absolute_error: 1409.6542\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 1353.83757\n",
      "Epoch 247/500\n",
      "585/585 [==============================] - 0s 184us/step - loss: 1456.9899 - mean_absolute_error: 1456.9899 - val_loss: 1395.1848 - val_mean_absolute_error: 1395.1848\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 1353.83757\n",
      "Epoch 248/500\n",
      "585/585 [==============================] - 0s 157us/step - loss: 1456.6768 - mean_absolute_error: 1456.6768 - val_loss: 1388.3604 - val_mean_absolute_error: 1388.3604\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 1353.83757\n",
      "Epoch 249/500\n",
      "585/585 [==============================] - 0s 160us/step - loss: 1465.0260 - mean_absolute_error: 1465.0260 - val_loss: 1399.5603 - val_mean_absolute_error: 1399.5603\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 1353.83757\n",
      "Epoch 250/500\n",
      "585/585 [==============================] - 0s 182us/step - loss: 1476.3208 - mean_absolute_error: 1476.3208 - val_loss: 1540.6485 - val_mean_absolute_error: 1540.6485\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 1353.83757\n",
      "Epoch 251/500\n",
      "585/585 [==============================] - 0s 235us/step - loss: 1464.2014 - mean_absolute_error: 1464.2014 - val_loss: 1482.7247 - val_mean_absolute_error: 1482.7247\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 1353.83757\n",
      "Epoch 252/500\n",
      "585/585 [==============================] - 0s 196us/step - loss: 1479.7738 - mean_absolute_error: 1479.7738 - val_loss: 1411.0451 - val_mean_absolute_error: 1411.0451\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 1353.83757\n",
      "Epoch 253/500\n",
      "585/585 [==============================] - 0s 126us/step - loss: 1556.5985 - mean_absolute_error: 1556.5985 - val_loss: 1381.1638 - val_mean_absolute_error: 1381.1638\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 1353.83757\n",
      "Epoch 254/500\n",
      "585/585 [==============================] - 0s 150us/step - loss: 1458.5663 - mean_absolute_error: 1458.5663 - val_loss: 1389.7120 - val_mean_absolute_error: 1389.7120\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 1353.83757\n",
      "Epoch 255/500\n",
      "585/585 [==============================] - 0s 147us/step - loss: 1465.3980 - mean_absolute_error: 1465.3980 - val_loss: 1409.5368 - val_mean_absolute_error: 1409.5368\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 1353.83757\n",
      "Epoch 256/500\n",
      "585/585 [==============================] - 0s 153us/step - loss: 1449.7099 - mean_absolute_error: 1449.7099 - val_loss: 1423.0877 - val_mean_absolute_error: 1423.0877\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 1353.83757\n",
      "Epoch 257/500\n",
      "585/585 [==============================] - 0s 136us/step - loss: 1464.3224 - mean_absolute_error: 1464.3224 - val_loss: 1377.9390 - val_mean_absolute_error: 1377.9390\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 1353.83757\n",
      "Epoch 258/500\n",
      "585/585 [==============================] - 0s 148us/step - loss: 1489.8806 - mean_absolute_error: 1489.8806 - val_loss: 1444.5115 - val_mean_absolute_error: 1444.5115\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 1353.83757\n",
      "Epoch 259/500\n",
      "585/585 [==============================] - 0s 181us/step - loss: 1470.2139 - mean_absolute_error: 1470.2139 - val_loss: 1368.1855 - val_mean_absolute_error: 1368.1855\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 1353.83757\n",
      "Epoch 260/500\n",
      "585/585 [==============================] - 0s 466us/step - loss: 1462.9860 - mean_absolute_error: 1462.9860 - val_loss: 1401.6932 - val_mean_absolute_error: 1401.6932\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 1353.83757\n",
      "Epoch 261/500\n",
      "585/585 [==============================] - 0s 268us/step - loss: 1444.8801 - mean_absolute_error: 1444.8801 - val_loss: 1382.8618 - val_mean_absolute_error: 1382.8618\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 1353.83757\n",
      "Epoch 262/500\n",
      "585/585 [==============================] - 0s 218us/step - loss: 1441.2187 - mean_absolute_error: 1441.2187 - val_loss: 1382.9141 - val_mean_absolute_error: 1382.9141\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 1353.83757\n",
      "Epoch 263/500\n",
      "585/585 [==============================] - 0s 191us/step - loss: 1472.1308 - mean_absolute_error: 1472.1308 - val_loss: 1383.5682 - val_mean_absolute_error: 1383.5682\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 1353.83757\n",
      "Epoch 264/500\n",
      "585/585 [==============================] - 0s 283us/step - loss: 1456.6443 - mean_absolute_error: 1456.6443 - val_loss: 1404.4013 - val_mean_absolute_error: 1404.4013\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 1353.83757\n",
      "Epoch 265/500\n",
      "585/585 [==============================] - 0s 265us/step - loss: 1465.1284 - mean_absolute_error: 1465.1284 - val_loss: 1451.5886 - val_mean_absolute_error: 1451.5886\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 1353.83757\n",
      "Epoch 266/500\n",
      "585/585 [==============================] - 0s 177us/step - loss: 1463.5534 - mean_absolute_error: 1463.5534 - val_loss: 1375.9997 - val_mean_absolute_error: 1375.9997\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 1353.83757\n",
      "Epoch 267/500\n",
      "585/585 [==============================] - 0s 185us/step - loss: 1453.5142 - mean_absolute_error: 1453.5142 - val_loss: 1410.2629 - val_mean_absolute_error: 1410.2629\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 1353.83757\n",
      "Epoch 268/500\n",
      "585/585 [==============================] - 0s 169us/step - loss: 1463.3511 - mean_absolute_error: 1463.3511 - val_loss: 1389.4128 - val_mean_absolute_error: 1389.4128\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 1353.83757\n",
      "Epoch 269/500\n",
      "585/585 [==============================] - 0s 170us/step - loss: 1495.3681 - mean_absolute_error: 1495.3681 - val_loss: 1597.3079 - val_mean_absolute_error: 1597.3079\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 1353.83757\n",
      "Epoch 270/500\n",
      "585/585 [==============================] - 0s 170us/step - loss: 1502.4845 - mean_absolute_error: 1502.4845 - val_loss: 1364.5134 - val_mean_absolute_error: 1364.5134\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 1353.83757\n",
      "Epoch 271/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "585/585 [==============================] - 0s 159us/step - loss: 1499.1999 - mean_absolute_error: 1499.1999 - val_loss: 1546.4504 - val_mean_absolute_error: 1546.4504\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 1353.83757\n",
      "Epoch 272/500\n",
      "585/585 [==============================] - 0s 170us/step - loss: 1542.0195 - mean_absolute_error: 1542.0195 - val_loss: 1394.1328 - val_mean_absolute_error: 1394.1328\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 1353.83757\n",
      "Epoch 273/500\n",
      "585/585 [==============================] - 0s 181us/step - loss: 1448.4080 - mean_absolute_error: 1448.4080 - val_loss: 1435.2701 - val_mean_absolute_error: 1435.2701\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 1353.83757\n",
      "Epoch 274/500\n",
      "585/585 [==============================] - 0s 155us/step - loss: 1468.4344 - mean_absolute_error: 1468.4344 - val_loss: 1524.7827 - val_mean_absolute_error: 1524.7827\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 1353.83757\n",
      "Epoch 275/500\n",
      "585/585 [==============================] - 0s 159us/step - loss: 1448.9988 - mean_absolute_error: 1448.9988 - val_loss: 1404.8980 - val_mean_absolute_error: 1404.8980\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 1353.83757\n",
      "Epoch 276/500\n",
      "585/585 [==============================] - 0s 164us/step - loss: 1470.7431 - mean_absolute_error: 1470.7431 - val_loss: 1391.4956 - val_mean_absolute_error: 1391.4956\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 1353.83757\n",
      "Epoch 277/500\n",
      "585/585 [==============================] - 0s 172us/step - loss: 1490.8652 - mean_absolute_error: 1490.8652 - val_loss: 1400.0239 - val_mean_absolute_error: 1400.0239\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 1353.83757\n",
      "Epoch 278/500\n",
      "585/585 [==============================] - 0s 182us/step - loss: 1475.5421 - mean_absolute_error: 1475.5421 - val_loss: 1446.4190 - val_mean_absolute_error: 1446.4190\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 1353.83757\n",
      "Epoch 279/500\n",
      "585/585 [==============================] - 0s 177us/step - loss: 1478.9598 - mean_absolute_error: 1478.9598 - val_loss: 1448.6405 - val_mean_absolute_error: 1448.6405\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 1353.83757\n",
      "Epoch 280/500\n",
      "585/585 [==============================] - 0s 176us/step - loss: 1447.8100 - mean_absolute_error: 1447.8100 - val_loss: 1502.1049 - val_mean_absolute_error: 1502.1049\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 1353.83757\n",
      "Epoch 281/500\n",
      "585/585 [==============================] - 0s 168us/step - loss: 1469.1606 - mean_absolute_error: 1469.1606 - val_loss: 1411.0116 - val_mean_absolute_error: 1411.0116\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 1353.83757\n",
      "Epoch 282/500\n",
      "585/585 [==============================] - 0s 194us/step - loss: 1466.6764 - mean_absolute_error: 1466.6764 - val_loss: 1393.7938 - val_mean_absolute_error: 1393.7938\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 1353.83757\n",
      "Epoch 283/500\n",
      "585/585 [==============================] - 0s 170us/step - loss: 1458.8739 - mean_absolute_error: 1458.8739 - val_loss: 1360.8706 - val_mean_absolute_error: 1360.8706\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 1353.83757\n",
      "Epoch 284/500\n",
      "585/585 [==============================] - 0s 170us/step - loss: 1448.8195 - mean_absolute_error: 1448.8195 - val_loss: 1449.2840 - val_mean_absolute_error: 1449.2840\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 1353.83757\n",
      "Epoch 285/500\n",
      "585/585 [==============================] - 0s 165us/step - loss: 1437.4626 - mean_absolute_error: 1437.4626 - val_loss: 1383.9312 - val_mean_absolute_error: 1383.9312\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 1353.83757\n",
      "Epoch 286/500\n",
      "585/585 [==============================] - 0s 169us/step - loss: 1472.6011 - mean_absolute_error: 1472.6011 - val_loss: 1379.1900 - val_mean_absolute_error: 1379.1900\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 1353.83757\n",
      "Epoch 287/500\n",
      "585/585 [==============================] - 0s 167us/step - loss: 1439.7072 - mean_absolute_error: 1439.7072 - val_loss: 1546.1160 - val_mean_absolute_error: 1546.1160\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 1353.83757\n",
      "Epoch 288/500\n",
      "585/585 [==============================] - 0s 191us/step - loss: 1471.8603 - mean_absolute_error: 1471.8603 - val_loss: 1408.9767 - val_mean_absolute_error: 1408.9767\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 1353.83757\n",
      "Epoch 289/500\n",
      "585/585 [==============================] - 0s 181us/step - loss: 1497.1818 - mean_absolute_error: 1497.1818 - val_loss: 1405.7461 - val_mean_absolute_error: 1405.7461\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 1353.83757\n",
      "Epoch 290/500\n",
      "585/585 [==============================] - 0s 177us/step - loss: 1494.2348 - mean_absolute_error: 1494.2348 - val_loss: 1390.0549 - val_mean_absolute_error: 1390.0549\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 1353.83757\n",
      "Epoch 291/500\n",
      "585/585 [==============================] - 0s 165us/step - loss: 1480.5383 - mean_absolute_error: 1480.5383 - val_loss: 1369.8724 - val_mean_absolute_error: 1369.8724\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 1353.83757\n",
      "Epoch 292/500\n",
      "585/585 [==============================] - 0s 167us/step - loss: 1445.1872 - mean_absolute_error: 1445.1872 - val_loss: 1362.2483 - val_mean_absolute_error: 1362.2483\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 1353.83757\n",
      "Epoch 293/500\n",
      "585/585 [==============================] - 0s 164us/step - loss: 1451.2751 - mean_absolute_error: 1451.2751 - val_loss: 1387.1045 - val_mean_absolute_error: 1387.1045\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 1353.83757\n",
      "Epoch 294/500\n",
      "585/585 [==============================] - 0s 169us/step - loss: 1456.3249 - mean_absolute_error: 1456.3249 - val_loss: 1369.4295 - val_mean_absolute_error: 1369.4295\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 1353.83757\n",
      "Epoch 295/500\n",
      "585/585 [==============================] - 0s 172us/step - loss: 1456.9981 - mean_absolute_error: 1456.9981 - val_loss: 1404.7012 - val_mean_absolute_error: 1404.7012\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 1353.83757\n",
      "Epoch 296/500\n",
      "585/585 [==============================] - 0s 147us/step - loss: 1446.1640 - mean_absolute_error: 1446.1640 - val_loss: 1362.8777 - val_mean_absolute_error: 1362.8777\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 1353.83757\n",
      "Epoch 297/500\n",
      "585/585 [==============================] - 0s 147us/step - loss: 1429.5642 - mean_absolute_error: 1429.5642 - val_loss: 1376.9553 - val_mean_absolute_error: 1376.9553\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 1353.83757\n",
      "Epoch 298/500\n",
      "585/585 [==============================] - 0s 170us/step - loss: 1452.3926 - mean_absolute_error: 1452.3926 - val_loss: 1384.9045 - val_mean_absolute_error: 1384.9045\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 1353.83757\n",
      "Epoch 299/500\n",
      "585/585 [==============================] - 0s 171us/step - loss: 1489.2709 - mean_absolute_error: 1489.2709 - val_loss: 1386.7363 - val_mean_absolute_error: 1386.7363\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 1353.83757\n",
      "Epoch 300/500\n",
      "585/585 [==============================] - 0s 148us/step - loss: 1454.2730 - mean_absolute_error: 1454.2730 - val_loss: 1378.9999 - val_mean_absolute_error: 1378.9999\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 1353.83757\n",
      "Epoch 301/500\n",
      "585/585 [==============================] - 0s 155us/step - loss: 1457.2058 - mean_absolute_error: 1457.2058 - val_loss: 1383.1658 - val_mean_absolute_error: 1383.1658\n",
      "\n",
      "Epoch 00301: val_loss did not improve from 1353.83757\n",
      "Epoch 302/500\n",
      "585/585 [==============================] - 0s 150us/step - loss: 1479.8194 - mean_absolute_error: 1479.8194 - val_loss: 1427.5828 - val_mean_absolute_error: 1427.5828\n",
      "\n",
      "Epoch 00302: val_loss did not improve from 1353.83757\n",
      "Epoch 303/500\n",
      "585/585 [==============================] - 0s 155us/step - loss: 1457.4572 - mean_absolute_error: 1457.4572 - val_loss: 1394.0317 - val_mean_absolute_error: 1394.0317\n",
      "\n",
      "Epoch 00303: val_loss did not improve from 1353.83757\n",
      "Epoch 304/500\n",
      "585/585 [==============================] - 0s 181us/step - loss: 1458.7599 - mean_absolute_error: 1458.7599 - val_loss: 1525.9286 - val_mean_absolute_error: 1525.9286\n",
      "\n",
      "Epoch 00304: val_loss did not improve from 1353.83757\n",
      "Epoch 305/500\n",
      "585/585 [==============================] - 0s 172us/step - loss: 1470.4529 - mean_absolute_error: 1470.4529 - val_loss: 1382.2215 - val_mean_absolute_error: 1382.2215\n",
      "\n",
      "Epoch 00305: val_loss did not improve from 1353.83757\n",
      "Epoch 306/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "585/585 [==============================] - 0s 138us/step - loss: 1458.0091 - mean_absolute_error: 1458.0091 - val_loss: 1376.7742 - val_mean_absolute_error: 1376.7742\n",
      "\n",
      "Epoch 00306: val_loss did not improve from 1353.83757\n",
      "Epoch 307/500\n",
      "585/585 [==============================] - 0s 152us/step - loss: 1446.3009 - mean_absolute_error: 1446.3009 - val_loss: 1439.3009 - val_mean_absolute_error: 1439.3009\n",
      "\n",
      "Epoch 00307: val_loss did not improve from 1353.83757\n",
      "Epoch 308/500\n",
      "585/585 [==============================] - 0s 154us/step - loss: 1453.6007 - mean_absolute_error: 1453.6007 - val_loss: 1399.2522 - val_mean_absolute_error: 1399.2522\n",
      "\n",
      "Epoch 00308: val_loss did not improve from 1353.83757\n",
      "Epoch 309/500\n",
      "585/585 [==============================] - 0s 179us/step - loss: 1476.0228 - mean_absolute_error: 1476.0228 - val_loss: 1475.6263 - val_mean_absolute_error: 1475.6263\n",
      "\n",
      "Epoch 00309: val_loss did not improve from 1353.83757\n",
      "Epoch 310/500\n",
      "585/585 [==============================] - 0s 157us/step - loss: 1454.5514 - mean_absolute_error: 1454.5514 - val_loss: 1391.3134 - val_mean_absolute_error: 1391.3134\n",
      "\n",
      "Epoch 00310: val_loss did not improve from 1353.83757\n",
      "Epoch 311/500\n",
      "585/585 [==============================] - 0s 165us/step - loss: 1483.6441 - mean_absolute_error: 1483.6441 - val_loss: 1371.1115 - val_mean_absolute_error: 1371.1115\n",
      "\n",
      "Epoch 00311: val_loss did not improve from 1353.83757\n",
      "Epoch 312/500\n",
      "585/585 [==============================] - 0s 171us/step - loss: 1459.7604 - mean_absolute_error: 1459.7604 - val_loss: 1521.9297 - val_mean_absolute_error: 1521.9297\n",
      "\n",
      "Epoch 00312: val_loss did not improve from 1353.83757\n",
      "Epoch 313/500\n",
      "585/585 [==============================] - 0s 155us/step - loss: 1465.9428 - mean_absolute_error: 1465.9428 - val_loss: 1384.1069 - val_mean_absolute_error: 1384.1069\n",
      "\n",
      "Epoch 00313: val_loss did not improve from 1353.83757\n",
      "Epoch 314/500\n",
      "585/585 [==============================] - 0s 176us/step - loss: 1488.7083 - mean_absolute_error: 1488.7083 - val_loss: 1513.2801 - val_mean_absolute_error: 1513.2801\n",
      "\n",
      "Epoch 00314: val_loss did not improve from 1353.83757\n",
      "Epoch 315/500\n",
      "585/585 [==============================] - 0s 189us/step - loss: 1514.4083 - mean_absolute_error: 1514.4083 - val_loss: 1400.1420 - val_mean_absolute_error: 1400.1420\n",
      "\n",
      "Epoch 00315: val_loss did not improve from 1353.83757\n",
      "Epoch 316/500\n",
      "585/585 [==============================] - 0s 189us/step - loss: 1506.1072 - mean_absolute_error: 1506.1072 - val_loss: 1391.3585 - val_mean_absolute_error: 1391.3585\n",
      "\n",
      "Epoch 00316: val_loss did not improve from 1353.83757\n",
      "Epoch 317/500\n",
      "585/585 [==============================] - 0s 188us/step - loss: 1523.0202 - mean_absolute_error: 1523.0202 - val_loss: 1407.4888 - val_mean_absolute_error: 1407.4888\n",
      "\n",
      "Epoch 00317: val_loss did not improve from 1353.83757\n",
      "Epoch 318/500\n",
      "585/585 [==============================] - 0s 152us/step - loss: 1455.8156 - mean_absolute_error: 1455.8156 - val_loss: 1428.5816 - val_mean_absolute_error: 1428.5816\n",
      "\n",
      "Epoch 00318: val_loss did not improve from 1353.83757\n",
      "Epoch 319/500\n",
      "585/585 [==============================] - 0s 182us/step - loss: 1436.3821 - mean_absolute_error: 1436.3821 - val_loss: 1387.1207 - val_mean_absolute_error: 1387.1207\n",
      "\n",
      "Epoch 00319: val_loss did not improve from 1353.83757\n",
      "Epoch 320/500\n",
      "585/585 [==============================] - 0s 169us/step - loss: 1457.5329 - mean_absolute_error: 1457.5329 - val_loss: 1512.4947 - val_mean_absolute_error: 1512.4947\n",
      "\n",
      "Epoch 00320: val_loss did not improve from 1353.83757\n",
      "Epoch 321/500\n",
      "585/585 [==============================] - 0s 157us/step - loss: 1457.0944 - mean_absolute_error: 1457.0944 - val_loss: 1404.2030 - val_mean_absolute_error: 1404.2030\n",
      "\n",
      "Epoch 00321: val_loss did not improve from 1353.83757\n",
      "Epoch 322/500\n",
      "585/585 [==============================] - 0s 157us/step - loss: 1440.5604 - mean_absolute_error: 1440.5604 - val_loss: 1404.7132 - val_mean_absolute_error: 1404.7132\n",
      "\n",
      "Epoch 00322: val_loss did not improve from 1353.83757\n",
      "Epoch 323/500\n",
      "585/585 [==============================] - 0s 162us/step - loss: 1440.2567 - mean_absolute_error: 1440.2567 - val_loss: 1447.6346 - val_mean_absolute_error: 1447.6346\n",
      "\n",
      "Epoch 00323: val_loss did not improve from 1353.83757\n",
      "Epoch 324/500\n",
      "585/585 [==============================] - 0s 150us/step - loss: 1471.4426 - mean_absolute_error: 1471.4426 - val_loss: 1426.3267 - val_mean_absolute_error: 1426.3267\n",
      "\n",
      "Epoch 00324: val_loss did not improve from 1353.83757\n",
      "Epoch 325/500\n",
      "585/585 [==============================] - 0s 152us/step - loss: 1440.2675 - mean_absolute_error: 1440.2675 - val_loss: 1385.3499 - val_mean_absolute_error: 1385.3499\n",
      "\n",
      "Epoch 00325: val_loss did not improve from 1353.83757\n",
      "Epoch 326/500\n",
      "585/585 [==============================] - 0s 180us/step - loss: 1444.4058 - mean_absolute_error: 1444.4058 - val_loss: 1453.4759 - val_mean_absolute_error: 1453.4759\n",
      "\n",
      "Epoch 00326: val_loss did not improve from 1353.83757\n",
      "Epoch 327/500\n",
      "585/585 [==============================] - 0s 160us/step - loss: 1456.8157 - mean_absolute_error: 1456.8157 - val_loss: 1459.9511 - val_mean_absolute_error: 1459.9511\n",
      "\n",
      "Epoch 00327: val_loss did not improve from 1353.83757\n",
      "Epoch 328/500\n",
      "585/585 [==============================] - 0s 159us/step - loss: 1445.7953 - mean_absolute_error: 1445.7953 - val_loss: 1365.9611 - val_mean_absolute_error: 1365.9611\n",
      "\n",
      "Epoch 00328: val_loss did not improve from 1353.83757\n",
      "Epoch 329/500\n",
      "585/585 [==============================] - 0s 173us/step - loss: 1480.2615 - mean_absolute_error: 1480.2615 - val_loss: 1399.0013 - val_mean_absolute_error: 1399.0013\n",
      "\n",
      "Epoch 00329: val_loss did not improve from 1353.83757\n",
      "Epoch 330/500\n",
      "585/585 [==============================] - 0s 159us/step - loss: 1446.6958 - mean_absolute_error: 1446.6958 - val_loss: 1362.2860 - val_mean_absolute_error: 1362.2860\n",
      "\n",
      "Epoch 00330: val_loss did not improve from 1353.83757\n",
      "Epoch 331/500\n",
      "585/585 [==============================] - 0s 149us/step - loss: 1459.3608 - mean_absolute_error: 1459.3608 - val_loss: 1475.7663 - val_mean_absolute_error: 1475.7663\n",
      "\n",
      "Epoch 00331: val_loss did not improve from 1353.83757\n",
      "Epoch 332/500\n",
      "585/585 [==============================] - 0s 162us/step - loss: 1434.2855 - mean_absolute_error: 1434.2855 - val_loss: 1421.2815 - val_mean_absolute_error: 1421.2815\n",
      "\n",
      "Epoch 00332: val_loss did not improve from 1353.83757\n",
      "Epoch 333/500\n",
      "585/585 [==============================] - 0s 176us/step - loss: 1440.0947 - mean_absolute_error: 1440.0947 - val_loss: 1389.6181 - val_mean_absolute_error: 1389.6181\n",
      "\n",
      "Epoch 00333: val_loss did not improve from 1353.83757\n",
      "Epoch 334/500\n",
      "585/585 [==============================] - 0s 157us/step - loss: 1457.2355 - mean_absolute_error: 1457.2355 - val_loss: 1373.1401 - val_mean_absolute_error: 1373.1401\n",
      "\n",
      "Epoch 00334: val_loss did not improve from 1353.83757\n",
      "Epoch 335/500\n",
      "585/585 [==============================] - 0s 167us/step - loss: 1462.2225 - mean_absolute_error: 1462.2225 - val_loss: 1418.2949 - val_mean_absolute_error: 1418.2949\n",
      "\n",
      "Epoch 00335: val_loss did not improve from 1353.83757\n",
      "Epoch 336/500\n",
      "585/585 [==============================] - 0s 162us/step - loss: 1460.3571 - mean_absolute_error: 1460.3571 - val_loss: 1437.5113 - val_mean_absolute_error: 1437.5113\n",
      "\n",
      "Epoch 00336: val_loss did not improve from 1353.83757\n",
      "Epoch 337/500\n",
      "585/585 [==============================] - 0s 164us/step - loss: 1441.9437 - mean_absolute_error: 1441.9437 - val_loss: 1418.2341 - val_mean_absolute_error: 1418.2341\n",
      "\n",
      "Epoch 00337: val_loss did not improve from 1353.83757\n",
      "Epoch 338/500\n",
      "585/585 [==============================] - 0s 186us/step - loss: 1476.3124 - mean_absolute_error: 1476.3124 - val_loss: 1394.3786 - val_mean_absolute_error: 1394.3786\n",
      "\n",
      "Epoch 00338: val_loss did not improve from 1353.83757\n",
      "Epoch 339/500\n",
      "585/585 [==============================] - 0s 191us/step - loss: 1494.8539 - mean_absolute_error: 1494.8539 - val_loss: 1626.1484 - val_mean_absolute_error: 1626.1484\n",
      "\n",
      "Epoch 00339: val_loss did not improve from 1353.83757\n",
      "Epoch 340/500\n",
      "585/585 [==============================] - 0s 239us/step - loss: 1518.7818 - mean_absolute_error: 1518.7818 - val_loss: 1441.7169 - val_mean_absolute_error: 1441.7169\n",
      "\n",
      "Epoch 00340: val_loss did not improve from 1353.83757\n",
      "Epoch 341/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "585/585 [==============================] - 0s 239us/step - loss: 1432.5461 - mean_absolute_error: 1432.5461 - val_loss: 1390.8416 - val_mean_absolute_error: 1390.8416\n",
      "\n",
      "Epoch 00341: val_loss did not improve from 1353.83757\n",
      "Epoch 342/500\n",
      "585/585 [==============================] - 0s 184us/step - loss: 1452.3898 - mean_absolute_error: 1452.3898 - val_loss: 1414.3943 - val_mean_absolute_error: 1414.3943\n",
      "\n",
      "Epoch 00342: val_loss did not improve from 1353.83757\n",
      "Epoch 343/500\n",
      "585/585 [==============================] - 0s 165us/step - loss: 1436.8045 - mean_absolute_error: 1436.8045 - val_loss: 1383.6079 - val_mean_absolute_error: 1383.6079\n",
      "\n",
      "Epoch 00343: val_loss did not improve from 1353.83757\n",
      "Epoch 344/500\n",
      "585/585 [==============================] - 0s 155us/step - loss: 1436.1020 - mean_absolute_error: 1436.1020 - val_loss: 1381.6042 - val_mean_absolute_error: 1381.6042\n",
      "\n",
      "Epoch 00344: val_loss did not improve from 1353.83757\n",
      "Epoch 345/500\n",
      "585/585 [==============================] - 0s 168us/step - loss: 1472.1750 - mean_absolute_error: 1472.1750 - val_loss: 1390.2013 - val_mean_absolute_error: 1390.2013\n",
      "\n",
      "Epoch 00345: val_loss did not improve from 1353.83757\n",
      "Epoch 346/500\n",
      "585/585 [==============================] - 0s 160us/step - loss: 1429.1647 - mean_absolute_error: 1429.1647 - val_loss: 1398.8172 - val_mean_absolute_error: 1398.8172\n",
      "\n",
      "Epoch 00346: val_loss did not improve from 1353.83757\n",
      "Epoch 347/500\n",
      "585/585 [==============================] - 0s 157us/step - loss: 1462.4177 - mean_absolute_error: 1462.4177 - val_loss: 1392.3011 - val_mean_absolute_error: 1392.3011\n",
      "\n",
      "Epoch 00347: val_loss did not improve from 1353.83757\n",
      "Epoch 348/500\n",
      "585/585 [==============================] - 0s 153us/step - loss: 1492.1177 - mean_absolute_error: 1492.1177 - val_loss: 1614.0109 - val_mean_absolute_error: 1614.0109\n",
      "\n",
      "Epoch 00348: val_loss did not improve from 1353.83757\n",
      "Epoch 349/500\n",
      "585/585 [==============================] - 0s 164us/step - loss: 1499.8605 - mean_absolute_error: 1499.8605 - val_loss: 1412.1771 - val_mean_absolute_error: 1412.1771\n",
      "\n",
      "Epoch 00349: val_loss did not improve from 1353.83757\n",
      "Epoch 350/500\n",
      "585/585 [==============================] - 0s 164us/step - loss: 1479.6191 - mean_absolute_error: 1479.6191 - val_loss: 1454.8025 - val_mean_absolute_error: 1454.8025\n",
      "\n",
      "Epoch 00350: val_loss did not improve from 1353.83757\n",
      "Epoch 351/500\n",
      "585/585 [==============================] - 0s 167us/step - loss: 1447.8706 - mean_absolute_error: 1447.8706 - val_loss: 1556.8379 - val_mean_absolute_error: 1556.8379\n",
      "\n",
      "Epoch 00351: val_loss did not improve from 1353.83757\n",
      "Epoch 352/500\n",
      "585/585 [==============================] - 0s 160us/step - loss: 1494.9226 - mean_absolute_error: 1494.9226 - val_loss: 1415.3224 - val_mean_absolute_error: 1415.3224\n",
      "\n",
      "Epoch 00352: val_loss did not improve from 1353.83757\n",
      "Epoch 353/500\n",
      "585/585 [==============================] - 0s 157us/step - loss: 1461.9084 - mean_absolute_error: 1461.9084 - val_loss: 1378.9105 - val_mean_absolute_error: 1378.9105\n",
      "\n",
      "Epoch 00353: val_loss did not improve from 1353.83757\n",
      "Epoch 354/500\n",
      "585/585 [==============================] - 0s 155us/step - loss: 1438.1826 - mean_absolute_error: 1438.1826 - val_loss: 1482.1370 - val_mean_absolute_error: 1482.1370\n",
      "\n",
      "Epoch 00354: val_loss did not improve from 1353.83757\n",
      "Epoch 355/500\n",
      "585/585 [==============================] - 0s 162us/step - loss: 1483.3587 - mean_absolute_error: 1483.3587 - val_loss: 1430.4789 - val_mean_absolute_error: 1430.4789\n",
      "\n",
      "Epoch 00355: val_loss did not improve from 1353.83757\n",
      "Epoch 356/500\n",
      "585/585 [==============================] - 0s 172us/step - loss: 1460.4828 - mean_absolute_error: 1460.4828 - val_loss: 1421.3338 - val_mean_absolute_error: 1421.3338\n",
      "\n",
      "Epoch 00356: val_loss did not improve from 1353.83757\n",
      "Epoch 357/500\n",
      "585/585 [==============================] - 0s 160us/step - loss: 1463.2414 - mean_absolute_error: 1463.2414 - val_loss: 1374.5361 - val_mean_absolute_error: 1374.5361\n",
      "\n",
      "Epoch 00357: val_loss did not improve from 1353.83757\n",
      "Epoch 358/500\n",
      "585/585 [==============================] - 0s 161us/step - loss: 1453.9491 - mean_absolute_error: 1453.9491 - val_loss: 1383.0755 - val_mean_absolute_error: 1383.0755\n",
      "\n",
      "Epoch 00358: val_loss did not improve from 1353.83757\n",
      "Epoch 359/500\n",
      "585/585 [==============================] - 0s 161us/step - loss: 1464.5896 - mean_absolute_error: 1464.5896 - val_loss: 1402.4793 - val_mean_absolute_error: 1402.4793\n",
      "\n",
      "Epoch 00359: val_loss did not improve from 1353.83757\n",
      "Epoch 360/500\n",
      "585/585 [==============================] - 0s 156us/step - loss: 1465.9392 - mean_absolute_error: 1465.9392 - val_loss: 1396.6248 - val_mean_absolute_error: 1396.6248\n",
      "\n",
      "Epoch 00360: val_loss did not improve from 1353.83757\n",
      "Epoch 361/500\n",
      "585/585 [==============================] - 0s 167us/step - loss: 1507.5499 - mean_absolute_error: 1507.5499 - val_loss: 1398.3410 - val_mean_absolute_error: 1398.3410\n",
      "\n",
      "Epoch 00361: val_loss did not improve from 1353.83757\n",
      "Epoch 362/500\n",
      "585/585 [==============================] - 0s 160us/step - loss: 1436.0938 - mean_absolute_error: 1436.0938 - val_loss: 1377.4451 - val_mean_absolute_error: 1377.4451\n",
      "\n",
      "Epoch 00362: val_loss did not improve from 1353.83757\n",
      "Epoch 363/500\n",
      "585/585 [==============================] - 0s 172us/step - loss: 1469.4590 - mean_absolute_error: 1469.4590 - val_loss: 1426.1265 - val_mean_absolute_error: 1426.1265\n",
      "\n",
      "Epoch 00363: val_loss did not improve from 1353.83757\n",
      "Epoch 364/500\n",
      "585/585 [==============================] - 0s 157us/step - loss: 1436.9234 - mean_absolute_error: 1436.9234 - val_loss: 1405.3164 - val_mean_absolute_error: 1405.3164\n",
      "\n",
      "Epoch 00364: val_loss did not improve from 1353.83757\n",
      "Epoch 365/500\n",
      "585/585 [==============================] - 0s 170us/step - loss: 1444.9466 - mean_absolute_error: 1444.9466 - val_loss: 1375.1499 - val_mean_absolute_error: 1375.1499\n",
      "\n",
      "Epoch 00365: val_loss did not improve from 1353.83757\n",
      "Epoch 366/500\n",
      "585/585 [==============================] - 0s 157us/step - loss: 1430.6746 - mean_absolute_error: 1430.6746 - val_loss: 1401.8688 - val_mean_absolute_error: 1401.8688\n",
      "\n",
      "Epoch 00366: val_loss did not improve from 1353.83757\n",
      "Epoch 367/500\n",
      "585/585 [==============================] - 0s 150us/step - loss: 1457.8587 - mean_absolute_error: 1457.8587 - val_loss: 1393.0518 - val_mean_absolute_error: 1393.0518\n",
      "\n",
      "Epoch 00367: val_loss did not improve from 1353.83757\n",
      "Epoch 368/500\n",
      "585/585 [==============================] - 0s 147us/step - loss: 1435.2691 - mean_absolute_error: 1435.2691 - val_loss: 1430.9767 - val_mean_absolute_error: 1430.9767\n",
      "\n",
      "Epoch 00368: val_loss did not improve from 1353.83757\n",
      "Epoch 369/500\n",
      "585/585 [==============================] - 0s 168us/step - loss: 1436.0794 - mean_absolute_error: 1436.0794 - val_loss: 1452.1595 - val_mean_absolute_error: 1452.1595\n",
      "\n",
      "Epoch 00369: val_loss did not improve from 1353.83757\n",
      "Epoch 370/500\n",
      "585/585 [==============================] - 0s 147us/step - loss: 1448.7695 - mean_absolute_error: 1448.7695 - val_loss: 1502.4115 - val_mean_absolute_error: 1502.4115\n",
      "\n",
      "Epoch 00370: val_loss did not improve from 1353.83757\n",
      "Epoch 371/500\n",
      "585/585 [==============================] - 0s 186us/step - loss: 1468.2835 - mean_absolute_error: 1468.2835 - val_loss: 1560.9384 - val_mean_absolute_error: 1560.9384\n",
      "\n",
      "Epoch 00371: val_loss did not improve from 1353.83757\n",
      "Epoch 372/500\n",
      "585/585 [==============================] - 0s 220us/step - loss: 1487.3977 - mean_absolute_error: 1487.3977 - val_loss: 1394.8429 - val_mean_absolute_error: 1394.8429\n",
      "\n",
      "Epoch 00372: val_loss did not improve from 1353.83757\n",
      "Epoch 373/500\n",
      "585/585 [==============================] - 0s 261us/step - loss: 1443.7809 - mean_absolute_error: 1443.7809 - val_loss: 1403.6210 - val_mean_absolute_error: 1403.6210\n",
      "\n",
      "Epoch 00373: val_loss did not improve from 1353.83757\n",
      "Epoch 374/500\n",
      "585/585 [==============================] - 0s 170us/step - loss: 1437.8777 - mean_absolute_error: 1437.8777 - val_loss: 1458.4747 - val_mean_absolute_error: 1458.4747\n",
      "\n",
      "Epoch 00374: val_loss did not improve from 1353.83757\n",
      "Epoch 375/500\n",
      "585/585 [==============================] - 0s 157us/step - loss: 1441.0862 - mean_absolute_error: 1441.0862 - val_loss: 1428.4688 - val_mean_absolute_error: 1428.4688\n",
      "\n",
      "Epoch 00375: val_loss did not improve from 1353.83757\n",
      "Epoch 376/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "585/585 [==============================] - 0s 142us/step - loss: 1436.0286 - mean_absolute_error: 1436.0286 - val_loss: 1454.8477 - val_mean_absolute_error: 1454.8477\n",
      "\n",
      "Epoch 00376: val_loss did not improve from 1353.83757\n",
      "Epoch 377/500\n",
      "585/585 [==============================] - 0s 153us/step - loss: 1456.3999 - mean_absolute_error: 1456.3999 - val_loss: 1371.1095 - val_mean_absolute_error: 1371.1095\n",
      "\n",
      "Epoch 00377: val_loss did not improve from 1353.83757\n",
      "Epoch 378/500\n",
      "585/585 [==============================] - 0s 164us/step - loss: 1510.3679 - mean_absolute_error: 1510.3679 - val_loss: 1496.0328 - val_mean_absolute_error: 1496.0328\n",
      "\n",
      "Epoch 00378: val_loss did not improve from 1353.83757\n",
      "Epoch 379/500\n",
      "585/585 [==============================] - 0s 154us/step - loss: 1524.2009 - mean_absolute_error: 1524.2009 - val_loss: 1561.0727 - val_mean_absolute_error: 1561.0727\n",
      "\n",
      "Epoch 00379: val_loss did not improve from 1353.83757\n",
      "Epoch 380/500\n",
      "585/585 [==============================] - 0s 154us/step - loss: 1490.5704 - mean_absolute_error: 1490.5704 - val_loss: 1593.1843 - val_mean_absolute_error: 1593.1843\n",
      "\n",
      "Epoch 00380: val_loss did not improve from 1353.83757\n",
      "Epoch 381/500\n",
      "585/585 [==============================] - 0s 164us/step - loss: 1465.2285 - mean_absolute_error: 1465.2285 - val_loss: 1367.8028 - val_mean_absolute_error: 1367.8028\n",
      "\n",
      "Epoch 00381: val_loss did not improve from 1353.83757\n",
      "Epoch 382/500\n",
      "585/585 [==============================] - 0s 169us/step - loss: 1501.5932 - mean_absolute_error: 1501.5932 - val_loss: 1406.7584 - val_mean_absolute_error: 1406.7584\n",
      "\n",
      "Epoch 00382: val_loss did not improve from 1353.83757\n",
      "Epoch 383/500\n",
      "585/585 [==============================] - 0s 234us/step - loss: 1463.4063 - mean_absolute_error: 1463.4063 - val_loss: 1436.8551 - val_mean_absolute_error: 1436.8551\n",
      "\n",
      "Epoch 00383: val_loss did not improve from 1353.83757\n",
      "Epoch 384/500\n",
      "585/585 [==============================] - 0s 263us/step - loss: 1446.2458 - mean_absolute_error: 1446.2458 - val_loss: 1392.3685 - val_mean_absolute_error: 1392.3685\n",
      "\n",
      "Epoch 00384: val_loss did not improve from 1353.83757\n",
      "Epoch 385/500\n",
      "585/585 [==============================] - 0s 172us/step - loss: 1508.4957 - mean_absolute_error: 1508.4957 - val_loss: 1395.1425 - val_mean_absolute_error: 1395.1425\n",
      "\n",
      "Epoch 00385: val_loss did not improve from 1353.83757\n",
      "Epoch 386/500\n",
      "585/585 [==============================] - 0s 176us/step - loss: 1469.0315 - mean_absolute_error: 1469.0315 - val_loss: 1401.4391 - val_mean_absolute_error: 1401.4391\n",
      "\n",
      "Epoch 00386: val_loss did not improve from 1353.83757\n",
      "Epoch 387/500\n",
      "585/585 [==============================] - 0s 176us/step - loss: 1464.8864 - mean_absolute_error: 1464.8864 - val_loss: 1403.2363 - val_mean_absolute_error: 1403.2363\n",
      "\n",
      "Epoch 00387: val_loss did not improve from 1353.83757\n",
      "Epoch 388/500\n",
      "585/585 [==============================] - 0s 168us/step - loss: 1434.8616 - mean_absolute_error: 1434.8616 - val_loss: 1372.0009 - val_mean_absolute_error: 1372.0009\n",
      "\n",
      "Epoch 00388: val_loss did not improve from 1353.83757\n",
      "Epoch 389/500\n",
      "585/585 [==============================] - 0s 153us/step - loss: 1431.2358 - mean_absolute_error: 1431.2358 - val_loss: 1416.4544 - val_mean_absolute_error: 1416.4544\n",
      "\n",
      "Epoch 00389: val_loss did not improve from 1353.83757\n",
      "Epoch 390/500\n",
      "585/585 [==============================] - 0s 174us/step - loss: 1430.7879 - mean_absolute_error: 1430.7879 - val_loss: 1379.6111 - val_mean_absolute_error: 1379.6111\n",
      "\n",
      "Epoch 00390: val_loss did not improve from 1353.83757\n",
      "Epoch 391/500\n",
      "585/585 [==============================] - 0s 278us/step - loss: 1485.8145 - mean_absolute_error: 1485.8145 - val_loss: 1377.6619 - val_mean_absolute_error: 1377.6619\n",
      "\n",
      "Epoch 00391: val_loss did not improve from 1353.83757\n",
      "Epoch 392/500\n",
      "585/585 [==============================] - 0s 260us/step - loss: 1460.7354 - mean_absolute_error: 1460.7354 - val_loss: 1434.5533 - val_mean_absolute_error: 1434.5533\n",
      "\n",
      "Epoch 00392: val_loss did not improve from 1353.83757\n",
      "Epoch 393/500\n",
      "585/585 [==============================] - 0s 161us/step - loss: 1436.8673 - mean_absolute_error: 1436.8673 - val_loss: 1387.0345 - val_mean_absolute_error: 1387.0345\n",
      "\n",
      "Epoch 00393: val_loss did not improve from 1353.83757\n",
      "Epoch 394/500\n",
      "585/585 [==============================] - 0s 155us/step - loss: 1439.4947 - mean_absolute_error: 1439.4947 - val_loss: 1383.8854 - val_mean_absolute_error: 1383.8854\n",
      "\n",
      "Epoch 00394: val_loss did not improve from 1353.83757\n",
      "Epoch 395/500\n",
      "585/585 [==============================] - 0s 191us/step - loss: 1431.9208 - mean_absolute_error: 1431.9208 - val_loss: 1393.9496 - val_mean_absolute_error: 1393.9496\n",
      "\n",
      "Epoch 00395: val_loss did not improve from 1353.83757\n",
      "Epoch 396/500\n",
      "585/585 [==============================] - 0s 174us/step - loss: 1458.0387 - mean_absolute_error: 1458.0387 - val_loss: 1429.6037 - val_mean_absolute_error: 1429.6037\n",
      "\n",
      "Epoch 00396: val_loss did not improve from 1353.83757\n",
      "Epoch 397/500\n",
      "585/585 [==============================] - 0s 169us/step - loss: 1450.4132 - mean_absolute_error: 1450.4132 - val_loss: 1387.2591 - val_mean_absolute_error: 1387.2591\n",
      "\n",
      "Epoch 00397: val_loss did not improve from 1353.83757\n",
      "Epoch 398/500\n",
      "585/585 [==============================] - 0s 194us/step - loss: 1446.7259 - mean_absolute_error: 1446.7259 - val_loss: 1436.6717 - val_mean_absolute_error: 1436.6717\n",
      "\n",
      "Epoch 00398: val_loss did not improve from 1353.83757\n",
      "Epoch 399/500\n",
      "585/585 [==============================] - 0s 152us/step - loss: 1440.5983 - mean_absolute_error: 1440.5983 - val_loss: 1399.5119 - val_mean_absolute_error: 1399.5119\n",
      "\n",
      "Epoch 00399: val_loss did not improve from 1353.83757\n",
      "Epoch 400/500\n",
      "585/585 [==============================] - 0s 170us/step - loss: 1436.5852 - mean_absolute_error: 1436.5852 - val_loss: 1439.9229 - val_mean_absolute_error: 1439.9229\n",
      "\n",
      "Epoch 00400: val_loss did not improve from 1353.83757\n",
      "Epoch 401/500\n",
      "585/585 [==============================] - 0s 196us/step - loss: 1434.2872 - mean_absolute_error: 1434.2872 - val_loss: 1381.5248 - val_mean_absolute_error: 1381.5248\n",
      "\n",
      "Epoch 00401: val_loss did not improve from 1353.83757\n",
      "Epoch 402/500\n",
      "585/585 [==============================] - 0s 205us/step - loss: 1439.2210 - mean_absolute_error: 1439.2210 - val_loss: 1485.9093 - val_mean_absolute_error: 1485.9093\n",
      "\n",
      "Epoch 00402: val_loss did not improve from 1353.83757\n",
      "Epoch 403/500\n",
      "585/585 [==============================] - 0s 188us/step - loss: 1451.9123 - mean_absolute_error: 1451.9123 - val_loss: 1434.2045 - val_mean_absolute_error: 1434.2045\n",
      "\n",
      "Epoch 00403: val_loss did not improve from 1353.83757\n",
      "Epoch 404/500\n",
      "585/585 [==============================] - 0s 236us/step - loss: 1444.1153 - mean_absolute_error: 1444.1153 - val_loss: 1397.6104 - val_mean_absolute_error: 1397.6104\n",
      "\n",
      "Epoch 00404: val_loss did not improve from 1353.83757\n",
      "Epoch 405/500\n",
      "585/585 [==============================] - 0s 158us/step - loss: 1442.2514 - mean_absolute_error: 1442.2514 - val_loss: 1392.9066 - val_mean_absolute_error: 1392.9066\n",
      "\n",
      "Epoch 00405: val_loss did not improve from 1353.83757\n",
      "Epoch 406/500\n",
      "585/585 [==============================] - 0s 268us/step - loss: 1438.8561 - mean_absolute_error: 1438.8561 - val_loss: 1362.5297 - val_mean_absolute_error: 1362.5297\n",
      "\n",
      "Epoch 00406: val_loss did not improve from 1353.83757\n",
      "Epoch 407/500\n",
      "585/585 [==============================] - 0s 147us/step - loss: 1422.1648 - mean_absolute_error: 1422.1648 - val_loss: 1390.0559 - val_mean_absolute_error: 1390.0559\n",
      "\n",
      "Epoch 00407: val_loss did not improve from 1353.83757\n",
      "Epoch 408/500\n",
      "585/585 [==============================] - 0s 148us/step - loss: 1451.9169 - mean_absolute_error: 1451.9169 - val_loss: 1384.0824 - val_mean_absolute_error: 1384.0824\n",
      "\n",
      "Epoch 00408: val_loss did not improve from 1353.83757\n",
      "Epoch 409/500\n",
      "585/585 [==============================] - 0s 160us/step - loss: 1429.0237 - mean_absolute_error: 1429.0237 - val_loss: 1389.7089 - val_mean_absolute_error: 1389.7089\n",
      "\n",
      "Epoch 00409: val_loss did not improve from 1353.83757\n",
      "Epoch 410/500\n",
      "585/585 [==============================] - 0s 169us/step - loss: 1436.9495 - mean_absolute_error: 1436.9495 - val_loss: 1395.6825 - val_mean_absolute_error: 1395.6825\n",
      "\n",
      "Epoch 00410: val_loss did not improve from 1353.83757\n",
      "Epoch 411/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "585/585 [==============================] - 0s 142us/step - loss: 1440.6663 - mean_absolute_error: 1440.6663 - val_loss: 1370.9399 - val_mean_absolute_error: 1370.9399\n",
      "\n",
      "Epoch 00411: val_loss did not improve from 1353.83757\n",
      "Epoch 412/500\n",
      "585/585 [==============================] - 0s 145us/step - loss: 1430.7318 - mean_absolute_error: 1430.7318 - val_loss: 1389.0688 - val_mean_absolute_error: 1389.0688\n",
      "\n",
      "Epoch 00412: val_loss did not improve from 1353.83757\n",
      "Epoch 413/500\n",
      "585/585 [==============================] - 0s 181us/step - loss: 1464.0849 - mean_absolute_error: 1464.0849 - val_loss: 1387.0628 - val_mean_absolute_error: 1387.0628\n",
      "\n",
      "Epoch 00413: val_loss did not improve from 1353.83757\n",
      "Epoch 414/500\n",
      "585/585 [==============================] - 0s 153us/step - loss: 1470.0071 - mean_absolute_error: 1470.0071 - val_loss: 1483.3073 - val_mean_absolute_error: 1483.3073\n",
      "\n",
      "Epoch 00414: val_loss did not improve from 1353.83757\n",
      "Epoch 415/500\n",
      "585/585 [==============================] - 0s 147us/step - loss: 1429.3571 - mean_absolute_error: 1429.3571 - val_loss: 1467.9948 - val_mean_absolute_error: 1467.9948\n",
      "\n",
      "Epoch 00415: val_loss did not improve from 1353.83757\n",
      "Epoch 416/500\n",
      "585/585 [==============================] - 0s 147us/step - loss: 1453.8750 - mean_absolute_error: 1453.8750 - val_loss: 1377.1377 - val_mean_absolute_error: 1377.1377\n",
      "\n",
      "Epoch 00416: val_loss did not improve from 1353.83757\n",
      "Epoch 417/500\n",
      "585/585 [==============================] - 0s 152us/step - loss: 1482.9141 - mean_absolute_error: 1482.9141 - val_loss: 1395.9010 - val_mean_absolute_error: 1395.9010\n",
      "\n",
      "Epoch 00417: val_loss did not improve from 1353.83757\n",
      "Epoch 418/500\n",
      "585/585 [==============================] - 0s 152us/step - loss: 1452.1292 - mean_absolute_error: 1452.1292 - val_loss: 1431.5127 - val_mean_absolute_error: 1431.5127\n",
      "\n",
      "Epoch 00418: val_loss did not improve from 1353.83757\n",
      "Epoch 419/500\n",
      "585/585 [==============================] - 0s 174us/step - loss: 1455.6617 - mean_absolute_error: 1455.6617 - val_loss: 1521.5823 - val_mean_absolute_error: 1521.5823\n",
      "\n",
      "Epoch 00419: val_loss did not improve from 1353.83757\n",
      "Epoch 420/500\n",
      "585/585 [==============================] - 0s 163us/step - loss: 1532.8602 - mean_absolute_error: 1532.8602 - val_loss: 1478.5578 - val_mean_absolute_error: 1478.5578\n",
      "\n",
      "Epoch 00420: val_loss did not improve from 1353.83757\n",
      "Epoch 421/500\n",
      "585/585 [==============================] - 0s 178us/step - loss: 1446.9426 - mean_absolute_error: 1446.9426 - val_loss: 1372.2802 - val_mean_absolute_error: 1372.2802\n",
      "\n",
      "Epoch 00421: val_loss did not improve from 1353.83757\n",
      "Epoch 422/500\n",
      "585/585 [==============================] - 0s 188us/step - loss: 1458.0919 - mean_absolute_error: 1458.0919 - val_loss: 1440.7603 - val_mean_absolute_error: 1440.7603\n",
      "\n",
      "Epoch 00422: val_loss did not improve from 1353.83757\n",
      "Epoch 423/500\n",
      "585/585 [==============================] - 0s 188us/step - loss: 1485.5254 - mean_absolute_error: 1485.5254 - val_loss: 1373.7290 - val_mean_absolute_error: 1373.7290\n",
      "\n",
      "Epoch 00423: val_loss did not improve from 1353.83757\n",
      "Epoch 424/500\n",
      "585/585 [==============================] - 0s 181us/step - loss: 1445.1435 - mean_absolute_error: 1445.1435 - val_loss: 1388.7892 - val_mean_absolute_error: 1388.7892\n",
      "\n",
      "Epoch 00424: val_loss did not improve from 1353.83757\n",
      "Epoch 425/500\n",
      "585/585 [==============================] - 0s 179us/step - loss: 1484.8789 - mean_absolute_error: 1484.8789 - val_loss: 1415.6200 - val_mean_absolute_error: 1415.6200\n",
      "\n",
      "Epoch 00425: val_loss did not improve from 1353.83757\n",
      "Epoch 426/500\n",
      "585/585 [==============================] - 0s 167us/step - loss: 1478.6274 - mean_absolute_error: 1478.6274 - val_loss: 1440.1165 - val_mean_absolute_error: 1440.1165\n",
      "\n",
      "Epoch 00426: val_loss did not improve from 1353.83757\n",
      "Epoch 427/500\n",
      "585/585 [==============================] - 0s 174us/step - loss: 1447.9033 - mean_absolute_error: 1447.9033 - val_loss: 1407.9963 - val_mean_absolute_error: 1407.9963\n",
      "\n",
      "Epoch 00427: val_loss did not improve from 1353.83757\n",
      "Epoch 428/500\n",
      "585/585 [==============================] - 0s 165us/step - loss: 1445.7060 - mean_absolute_error: 1445.7060 - val_loss: 1501.6127 - val_mean_absolute_error: 1501.6127\n",
      "\n",
      "Epoch 00428: val_loss did not improve from 1353.83757\n",
      "Epoch 429/500\n",
      "585/585 [==============================] - 0s 162us/step - loss: 1443.7865 - mean_absolute_error: 1443.7865 - val_loss: 1372.3860 - val_mean_absolute_error: 1372.3860\n",
      "\n",
      "Epoch 00429: val_loss did not improve from 1353.83757\n",
      "Epoch 430/500\n",
      "585/585 [==============================] - 0s 145us/step - loss: 1434.6048 - mean_absolute_error: 1434.6048 - val_loss: 1399.0561 - val_mean_absolute_error: 1399.0561\n",
      "\n",
      "Epoch 00430: val_loss did not improve from 1353.83757\n",
      "Epoch 431/500\n",
      "585/585 [==============================] - 0s 188us/step - loss: 1445.1401 - mean_absolute_error: 1445.1401 - val_loss: 1503.8748 - val_mean_absolute_error: 1503.8748\n",
      "\n",
      "Epoch 00431: val_loss did not improve from 1353.83757\n",
      "Epoch 432/500\n",
      "585/585 [==============================] - 0s 164us/step - loss: 1442.2699 - mean_absolute_error: 1442.2699 - val_loss: 1483.9247 - val_mean_absolute_error: 1483.9247\n",
      "\n",
      "Epoch 00432: val_loss did not improve from 1353.83757\n",
      "Epoch 433/500\n",
      "585/585 [==============================] - 0s 177us/step - loss: 1448.8478 - mean_absolute_error: 1448.8478 - val_loss: 1535.2168 - val_mean_absolute_error: 1535.2168\n",
      "\n",
      "Epoch 00433: val_loss did not improve from 1353.83757\n",
      "Epoch 434/500\n",
      "585/585 [==============================] - 0s 165us/step - loss: 1437.8966 - mean_absolute_error: 1437.8966 - val_loss: 1390.8212 - val_mean_absolute_error: 1390.8212\n",
      "\n",
      "Epoch 00434: val_loss did not improve from 1353.83757\n",
      "Epoch 435/500\n",
      "585/585 [==============================] - 0s 136us/step - loss: 1427.3753 - mean_absolute_error: 1427.3753 - val_loss: 1390.0440 - val_mean_absolute_error: 1390.0440\n",
      "\n",
      "Epoch 00435: val_loss did not improve from 1353.83757\n",
      "Epoch 436/500\n",
      "585/585 [==============================] - 0s 155us/step - loss: 1430.4688 - mean_absolute_error: 1430.4688 - val_loss: 1389.0112 - val_mean_absolute_error: 1389.0112\n",
      "\n",
      "Epoch 00436: val_loss did not improve from 1353.83757\n",
      "Epoch 437/500\n",
      "585/585 [==============================] - 0s 147us/step - loss: 1416.1022 - mean_absolute_error: 1416.1022 - val_loss: 1419.7853 - val_mean_absolute_error: 1419.7853\n",
      "\n",
      "Epoch 00437: val_loss did not improve from 1353.83757\n",
      "Epoch 438/500\n",
      "585/585 [==============================] - 0s 182us/step - loss: 1426.4026 - mean_absolute_error: 1426.4026 - val_loss: 1377.6069 - val_mean_absolute_error: 1377.6069\n",
      "\n",
      "Epoch 00438: val_loss did not improve from 1353.83757\n",
      "Epoch 439/500\n",
      "585/585 [==============================] - 0s 169us/step - loss: 1452.7716 - mean_absolute_error: 1452.7716 - val_loss: 1405.2348 - val_mean_absolute_error: 1405.2348\n",
      "\n",
      "Epoch 00439: val_loss did not improve from 1353.83757\n",
      "Epoch 440/500\n",
      "585/585 [==============================] - 0s 174us/step - loss: 1452.1754 - mean_absolute_error: 1452.1754 - val_loss: 1380.9299 - val_mean_absolute_error: 1380.9299\n",
      "\n",
      "Epoch 00440: val_loss did not improve from 1353.83757\n",
      "Epoch 441/500\n",
      "585/585 [==============================] - 0s 182us/step - loss: 1521.4521 - mean_absolute_error: 1521.4521 - val_loss: 1398.3127 - val_mean_absolute_error: 1398.3127\n",
      "\n",
      "Epoch 00441: val_loss did not improve from 1353.83757\n",
      "Epoch 442/500\n",
      "585/585 [==============================] - 0s 181us/step - loss: 1467.4430 - mean_absolute_error: 1467.4430 - val_loss: 1484.6279 - val_mean_absolute_error: 1484.6279\n",
      "\n",
      "Epoch 00442: val_loss did not improve from 1353.83757\n",
      "Epoch 443/500\n",
      "585/585 [==============================] - 0s 268us/step - loss: 1438.0843 - mean_absolute_error: 1438.0843 - val_loss: 1403.3390 - val_mean_absolute_error: 1403.3390\n",
      "\n",
      "Epoch 00443: val_loss did not improve from 1353.83757\n",
      "Epoch 444/500\n",
      "585/585 [==============================] - 0s 239us/step - loss: 1450.3764 - mean_absolute_error: 1450.3764 - val_loss: 1395.2045 - val_mean_absolute_error: 1395.2045\n",
      "\n",
      "Epoch 00444: val_loss did not improve from 1353.83757\n",
      "Epoch 445/500\n",
      "585/585 [==============================] - 0s 223us/step - loss: 1432.6390 - mean_absolute_error: 1432.6390 - val_loss: 1378.8305 - val_mean_absolute_error: 1378.8305\n",
      "\n",
      "Epoch 00445: val_loss did not improve from 1353.83757\n",
      "Epoch 446/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "585/585 [==============================] - 0s 162us/step - loss: 1460.1190 - mean_absolute_error: 1460.1190 - val_loss: 1452.0458 - val_mean_absolute_error: 1452.0458\n",
      "\n",
      "Epoch 00446: val_loss did not improve from 1353.83757\n",
      "Epoch 447/500\n",
      "585/585 [==============================] - 0s 187us/step - loss: 1471.5397 - mean_absolute_error: 1471.5397 - val_loss: 1435.4261 - val_mean_absolute_error: 1435.4261\n",
      "\n",
      "Epoch 00447: val_loss did not improve from 1353.83757\n",
      "Epoch 448/500\n",
      "585/585 [==============================] - 0s 197us/step - loss: 1428.2090 - mean_absolute_error: 1428.2090 - val_loss: 1407.1648 - val_mean_absolute_error: 1407.1648\n",
      "\n",
      "Epoch 00448: val_loss did not improve from 1353.83757\n",
      "Epoch 449/500\n",
      "585/585 [==============================] - 0s 245us/step - loss: 1450.5365 - mean_absolute_error: 1450.5365 - val_loss: 1379.0879 - val_mean_absolute_error: 1379.0879\n",
      "\n",
      "Epoch 00449: val_loss did not improve from 1353.83757\n",
      "Epoch 450/500\n",
      "585/585 [==============================] - 0s 199us/step - loss: 1437.6864 - mean_absolute_error: 1437.6864 - val_loss: 1424.6033 - val_mean_absolute_error: 1424.6033\n",
      "\n",
      "Epoch 00450: val_loss did not improve from 1353.83757\n",
      "Epoch 451/500\n",
      "585/585 [==============================] - 0s 182us/step - loss: 1449.7855 - mean_absolute_error: 1449.7855 - val_loss: 1501.6736 - val_mean_absolute_error: 1501.6736\n",
      "\n",
      "Epoch 00451: val_loss did not improve from 1353.83757\n",
      "Epoch 452/500\n",
      "585/585 [==============================] - 0s 160us/step - loss: 1417.4634 - mean_absolute_error: 1417.4634 - val_loss: 1388.5715 - val_mean_absolute_error: 1388.5715\n",
      "\n",
      "Epoch 00452: val_loss did not improve from 1353.83757\n",
      "Epoch 453/500\n",
      "585/585 [==============================] - 0s 191us/step - loss: 1423.4709 - mean_absolute_error: 1423.4709 - val_loss: 1436.2036 - val_mean_absolute_error: 1436.2036\n",
      "\n",
      "Epoch 00453: val_loss did not improve from 1353.83757\n",
      "Epoch 454/500\n",
      "585/585 [==============================] - 0s 172us/step - loss: 1476.4308 - mean_absolute_error: 1476.4308 - val_loss: 1441.7019 - val_mean_absolute_error: 1441.7019\n",
      "\n",
      "Epoch 00454: val_loss did not improve from 1353.83757\n",
      "Epoch 455/500\n",
      "585/585 [==============================] - 0s 172us/step - loss: 1429.3467 - mean_absolute_error: 1429.3467 - val_loss: 1446.2440 - val_mean_absolute_error: 1446.2440\n",
      "\n",
      "Epoch 00455: val_loss did not improve from 1353.83757\n",
      "Epoch 456/500\n",
      "585/585 [==============================] - 0s 176us/step - loss: 1451.7943 - mean_absolute_error: 1451.7943 - val_loss: 1368.5772 - val_mean_absolute_error: 1368.5772\n",
      "\n",
      "Epoch 00456: val_loss did not improve from 1353.83757\n",
      "Epoch 457/500\n",
      "585/585 [==============================] - 0s 188us/step - loss: 1438.6454 - mean_absolute_error: 1438.6454 - val_loss: 1384.5100 - val_mean_absolute_error: 1384.5100\n",
      "\n",
      "Epoch 00457: val_loss did not improve from 1353.83757\n",
      "Epoch 458/500\n",
      "585/585 [==============================] - 0s 185us/step - loss: 1426.8664 - mean_absolute_error: 1426.8664 - val_loss: 1445.3573 - val_mean_absolute_error: 1445.3573\n",
      "\n",
      "Epoch 00458: val_loss did not improve from 1353.83757\n",
      "Epoch 459/500\n",
      "585/585 [==============================] - 0s 249us/step - loss: 1457.6542 - mean_absolute_error: 1457.6542 - val_loss: 1377.3578 - val_mean_absolute_error: 1377.3578\n",
      "\n",
      "Epoch 00459: val_loss did not improve from 1353.83757\n",
      "Epoch 460/500\n",
      "585/585 [==============================] - 0s 191us/step - loss: 1548.0851 - mean_absolute_error: 1548.0851 - val_loss: 1361.1245 - val_mean_absolute_error: 1361.1245\n",
      "\n",
      "Epoch 00460: val_loss did not improve from 1353.83757\n",
      "Epoch 461/500\n",
      "585/585 [==============================] - 0s 196us/step - loss: 1448.8075 - mean_absolute_error: 1448.8075 - val_loss: 1477.9603 - val_mean_absolute_error: 1477.9603\n",
      "\n",
      "Epoch 00461: val_loss did not improve from 1353.83757\n",
      "Epoch 462/500\n",
      "585/585 [==============================] - 0s 159us/step - loss: 1443.4915 - mean_absolute_error: 1443.4915 - val_loss: 1391.2791 - val_mean_absolute_error: 1391.2791\n",
      "\n",
      "Epoch 00462: val_loss did not improve from 1353.83757\n",
      "Epoch 463/500\n",
      "585/585 [==============================] - 0s 167us/step - loss: 1420.5756 - mean_absolute_error: 1420.5756 - val_loss: 1412.1911 - val_mean_absolute_error: 1412.1911\n",
      "\n",
      "Epoch 00463: val_loss did not improve from 1353.83757\n",
      "Epoch 464/500\n",
      "585/585 [==============================] - 0s 167us/step - loss: 1431.8284 - mean_absolute_error: 1431.8284 - val_loss: 1416.4224 - val_mean_absolute_error: 1416.4224\n",
      "\n",
      "Epoch 00464: val_loss did not improve from 1353.83757\n",
      "Epoch 465/500\n",
      "585/585 [==============================] - 0s 159us/step - loss: 1424.4671 - mean_absolute_error: 1424.4671 - val_loss: 1372.7048 - val_mean_absolute_error: 1372.7048\n",
      "\n",
      "Epoch 00465: val_loss did not improve from 1353.83757\n",
      "Epoch 466/500\n",
      "585/585 [==============================] - 0s 234us/step - loss: 1426.3122 - mean_absolute_error: 1426.3122 - val_loss: 1367.8341 - val_mean_absolute_error: 1367.8341\n",
      "\n",
      "Epoch 00466: val_loss did not improve from 1353.83757\n",
      "Epoch 467/500\n",
      "585/585 [==============================] - 0s 189us/step - loss: 1434.8873 - mean_absolute_error: 1434.8873 - val_loss: 1390.3818 - val_mean_absolute_error: 1390.3818\n",
      "\n",
      "Epoch 00467: val_loss did not improve from 1353.83757\n",
      "Epoch 468/500\n",
      "585/585 [==============================] - 0s 174us/step - loss: 1539.9611 - mean_absolute_error: 1539.9611 - val_loss: 1423.0564 - val_mean_absolute_error: 1423.0564\n",
      "\n",
      "Epoch 00468: val_loss did not improve from 1353.83757\n",
      "Epoch 469/500\n",
      "585/585 [==============================] - 0s 142us/step - loss: 1450.6469 - mean_absolute_error: 1450.6469 - val_loss: 1578.2522 - val_mean_absolute_error: 1578.2522\n",
      "\n",
      "Epoch 00469: val_loss did not improve from 1353.83757\n",
      "Epoch 470/500\n",
      "585/585 [==============================] - 0s 164us/step - loss: 1502.0967 - mean_absolute_error: 1502.0967 - val_loss: 1385.8137 - val_mean_absolute_error: 1385.8137\n",
      "\n",
      "Epoch 00470: val_loss did not improve from 1353.83757\n",
      "Epoch 471/500\n",
      "585/585 [==============================] - 0s 150us/step - loss: 1466.5396 - mean_absolute_error: 1466.5396 - val_loss: 1392.1480 - val_mean_absolute_error: 1392.1480\n",
      "\n",
      "Epoch 00471: val_loss did not improve from 1353.83757\n",
      "Epoch 472/500\n",
      "585/585 [==============================] - 0s 155us/step - loss: 1426.3417 - mean_absolute_error: 1426.3417 - val_loss: 1413.6533 - val_mean_absolute_error: 1413.6533\n",
      "\n",
      "Epoch 00472: val_loss did not improve from 1353.83757\n",
      "Epoch 473/500\n",
      "585/585 [==============================] - 0s 153us/step - loss: 1465.4009 - mean_absolute_error: 1465.4009 - val_loss: 1382.8752 - val_mean_absolute_error: 1382.8752\n",
      "\n",
      "Epoch 00473: val_loss did not improve from 1353.83757\n",
      "Epoch 474/500\n",
      "585/585 [==============================] - 0s 186us/step - loss: 1423.2531 - mean_absolute_error: 1423.2531 - val_loss: 1381.6750 - val_mean_absolute_error: 1381.6750\n",
      "\n",
      "Epoch 00474: val_loss did not improve from 1353.83757\n",
      "Epoch 475/500\n",
      "585/585 [==============================] - 0s 166us/step - loss: 1429.9250 - mean_absolute_error: 1429.9250 - val_loss: 1440.7354 - val_mean_absolute_error: 1440.7354\n",
      "\n",
      "Epoch 00475: val_loss did not improve from 1353.83757\n",
      "Epoch 476/500\n",
      "585/585 [==============================] - 0s 170us/step - loss: 1441.0196 - mean_absolute_error: 1441.0196 - val_loss: 1378.3313 - val_mean_absolute_error: 1378.3313\n",
      "\n",
      "Epoch 00476: val_loss did not improve from 1353.83757\n",
      "Epoch 477/500\n",
      "585/585 [==============================] - 0s 162us/step - loss: 1464.8517 - mean_absolute_error: 1464.8517 - val_loss: 1407.4890 - val_mean_absolute_error: 1407.4890\n",
      "\n",
      "Epoch 00477: val_loss did not improve from 1353.83757\n",
      "Epoch 478/500\n",
      "585/585 [==============================] - 0s 164us/step - loss: 1464.8742 - mean_absolute_error: 1464.8742 - val_loss: 1373.7560 - val_mean_absolute_error: 1373.7560\n",
      "\n",
      "Epoch 00478: val_loss did not improve from 1353.83757\n",
      "Epoch 479/500\n",
      "585/585 [==============================] - 0s 179us/step - loss: 1437.0847 - mean_absolute_error: 1437.0847 - val_loss: 1388.3674 - val_mean_absolute_error: 1388.3674\n",
      "\n",
      "Epoch 00479: val_loss did not improve from 1353.83757\n",
      "Epoch 480/500\n",
      "585/585 [==============================] - 0s 148us/step - loss: 1463.8360 - mean_absolute_error: 1463.8360 - val_loss: 1621.2626 - val_mean_absolute_error: 1621.2626\n",
      "\n",
      "Epoch 00480: val_loss did not improve from 1353.83757\n",
      "Epoch 481/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "585/585 [==============================] - 0s 140us/step - loss: 1560.3255 - mean_absolute_error: 1560.3255 - val_loss: 1373.0555 - val_mean_absolute_error: 1373.0555\n",
      "\n",
      "Epoch 00481: val_loss did not improve from 1353.83757\n",
      "Epoch 482/500\n",
      "585/585 [==============================] - 0s 147us/step - loss: 1489.4604 - mean_absolute_error: 1489.4604 - val_loss: 1434.5580 - val_mean_absolute_error: 1434.5580\n",
      "\n",
      "Epoch 00482: val_loss did not improve from 1353.83757\n",
      "Epoch 483/500\n",
      "585/585 [==============================] - 0s 177us/step - loss: 1448.7553 - mean_absolute_error: 1448.7553 - val_loss: 1481.3734 - val_mean_absolute_error: 1481.3734\n",
      "\n",
      "Epoch 00483: val_loss did not improve from 1353.83757\n",
      "Epoch 484/500\n",
      "585/585 [==============================] - 0s 186us/step - loss: 1458.5215 - mean_absolute_error: 1458.5215 - val_loss: 1358.5431 - val_mean_absolute_error: 1358.5431\n",
      "\n",
      "Epoch 00484: val_loss did not improve from 1353.83757\n",
      "Epoch 485/500\n",
      "585/585 [==============================] - 0s 218us/step - loss: 1430.1884 - mean_absolute_error: 1430.1884 - val_loss: 1422.7169 - val_mean_absolute_error: 1422.7169\n",
      "\n",
      "Epoch 00485: val_loss did not improve from 1353.83757\n",
      "Epoch 486/500\n",
      "585/585 [==============================] - 0s 228us/step - loss: 1417.3480 - mean_absolute_error: 1417.3480 - val_loss: 1475.0715 - val_mean_absolute_error: 1475.0715\n",
      "\n",
      "Epoch 00486: val_loss did not improve from 1353.83757\n",
      "Epoch 487/500\n",
      "585/585 [==============================] - 0s 348us/step - loss: 1418.2742 - mean_absolute_error: 1418.2742 - val_loss: 1480.7379 - val_mean_absolute_error: 1480.7379\n",
      "\n",
      "Epoch 00487: val_loss did not improve from 1353.83757\n",
      "Epoch 488/500\n",
      "585/585 [==============================] - 0s 199us/step - loss: 1427.9635 - mean_absolute_error: 1427.9635 - val_loss: 1395.6919 - val_mean_absolute_error: 1395.6919\n",
      "\n",
      "Epoch 00488: val_loss did not improve from 1353.83757\n",
      "Epoch 489/500\n",
      "585/585 [==============================] - 0s 194us/step - loss: 1437.6448 - mean_absolute_error: 1437.6448 - val_loss: 1411.8996 - val_mean_absolute_error: 1411.8996\n",
      "\n",
      "Epoch 00489: val_loss did not improve from 1353.83757\n",
      "Epoch 490/500\n",
      "585/585 [==============================] - 0s 207us/step - loss: 1438.5748 - mean_absolute_error: 1438.5748 - val_loss: 1470.6418 - val_mean_absolute_error: 1470.6418\n",
      "\n",
      "Epoch 00490: val_loss did not improve from 1353.83757\n",
      "Epoch 491/500\n",
      "585/585 [==============================] - 0s 171us/step - loss: 1417.9013 - mean_absolute_error: 1417.9013 - val_loss: 1429.2051 - val_mean_absolute_error: 1429.2051\n",
      "\n",
      "Epoch 00491: val_loss did not improve from 1353.83757\n",
      "Epoch 492/500\n",
      "585/585 [==============================] - 0s 188us/step - loss: 1431.2489 - mean_absolute_error: 1431.2489 - val_loss: 1374.4390 - val_mean_absolute_error: 1374.4390\n",
      "\n",
      "Epoch 00492: val_loss did not improve from 1353.83757\n",
      "Epoch 493/500\n",
      "585/585 [==============================] - 0s 181us/step - loss: 1484.0601 - mean_absolute_error: 1484.0601 - val_loss: 1371.4359 - val_mean_absolute_error: 1371.4359\n",
      "\n",
      "Epoch 00493: val_loss did not improve from 1353.83757\n",
      "Epoch 494/500\n",
      "585/585 [==============================] - 0s 210us/step - loss: 1420.8227 - mean_absolute_error: 1420.8227 - val_loss: 1416.8719 - val_mean_absolute_error: 1416.8719\n",
      "\n",
      "Epoch 00494: val_loss did not improve from 1353.83757\n",
      "Epoch 495/500\n",
      "585/585 [==============================] - 0s 177us/step - loss: 1466.8078 - mean_absolute_error: 1466.8078 - val_loss: 1387.0635 - val_mean_absolute_error: 1387.0635\n",
      "\n",
      "Epoch 00495: val_loss did not improve from 1353.83757\n",
      "Epoch 496/500\n",
      "585/585 [==============================] - 0s 172us/step - loss: 1426.8301 - mean_absolute_error: 1426.8301 - val_loss: 1415.0404 - val_mean_absolute_error: 1415.0404\n",
      "\n",
      "Epoch 00496: val_loss did not improve from 1353.83757\n",
      "Epoch 497/500\n",
      "585/585 [==============================] - 0s 193us/step - loss: 1424.1435 - mean_absolute_error: 1424.1435 - val_loss: 1376.9637 - val_mean_absolute_error: 1376.9637\n",
      "\n",
      "Epoch 00497: val_loss did not improve from 1353.83757\n",
      "Epoch 498/500\n",
      "585/585 [==============================] - 0s 179us/step - loss: 1452.6134 - mean_absolute_error: 1452.6134 - val_loss: 1475.7683 - val_mean_absolute_error: 1475.7683\n",
      "\n",
      "Epoch 00498: val_loss did not improve from 1353.83757\n",
      "Epoch 499/500\n",
      "585/585 [==============================] - 0s 182us/step - loss: 1421.4257 - mean_absolute_error: 1421.4257 - val_loss: 1454.3020 - val_mean_absolute_error: 1454.3020\n",
      "\n",
      "Epoch 00499: val_loss did not improve from 1353.83757\n",
      "Epoch 500/500\n",
      "585/585 [==============================] - 0s 165us/step - loss: 1453.6224 - mean_absolute_error: 1453.6224 - val_loss: 1410.4963 - val_mean_absolute_error: 1410.4963\n",
      "\n",
      "Epoch 00500: val_loss did not improve from 1353.83757\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ae869aff28>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예제에서는 target을 대회에서 주는 target데이터를 기준으로 미리 train데이터와 맞춰졌있지만\n",
    "# gs/lv데이터는 아니다. 그래서 위에서 나누는 기준으로 삼은cut_line=732을 이용하여 데이터 사이즈를 맞춰준다.\n",
    "# 아니면 애시당초에(맨처음에) 훈련용 데이터와 타겟을 만들어 놓는것도 좋다.\n",
    "NN_model.fit(train, target[:cut_line], epochs=500, batch_size=32, validation_split = 0.2, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0719 18:53:10.013879  4492 deprecation_wrapper.py:119] From C:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0719 18:53:10.014877  4492 deprecation_wrapper.py:119] From C:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 500번을 학습하여 나온 결과들중, 가장 좋은(마지막에 저장된) Weights파일을 가져온다.\n",
    "# Load wights file of the best model :\n",
    "# 파일은 이 코드랑 같은 폴더에 위치해있어야 작동\n",
    "wights_file = '맥주date-Weights-226--1353.83757-cat02-vf05.hdf5' # choose the best checkpoint \n",
    "NN_model.load_weights(wights_file) # load it\n",
    "NN_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "여기서 점수란 R-square값을 의미한다.\n",
      "Random forest을 이용한 맥주의 회귀분석 결과 :\n",
      "훈련세트점수 : 0.901\n",
      "검증세트점수 : -1.438\n",
      "XGBoost을 이용한 맥주의 회귀분석 결과 :\n",
      "훈련세트점수 : 0.661\n",
      "검증세트점수 : -1.226\n",
      "LinearRegression을 이용한 맥주의 회귀분석 결과 :\n",
      "훈련세트점수 : 0.454\n",
      "검증세트점수 : -1.080\n",
      "RidgeRegression을 이용한 맥주의 회귀분석 결과 :\n",
      "훈련세트점수 : 0.445\n",
      "검증세트점수 : -1.067\n",
      "LassoRegression을 이용한 맥주의 회귀분석 결과 :\n",
      "훈련세트점수 : 0.454\n",
      "검증세트점수 : -1.080\n",
      "OLS을 이용한 맥주의 회귀분석 결과 :\n",
      "훈련세트점수 : 0.454\n",
      "검증세트점수 : -1.080\n"
     ]
    }
   ],
   "source": [
    "#2016~2018전체를 난수로 0.67:0.33 = 2:1\n",
    "# train3 = combined.loc[:,'temp':]\n",
    "# target3 = combined.loc[:,'qty']\n",
    "# train_X, val_X, train_y, val_y = train_test_split(train3, target3, test_size = 0.33, random_state = 14)\n",
    "\n",
    "# 2016~2017 : 훈련 / 2018 검증 2:1\n",
    "# 1~732 / 732~1096\n",
    "trainXy = Xy[:cut_line]\n",
    "testXy = Xy[cut_line:]\n",
    "\n",
    "# 독립변수들\n",
    "train_X = trainXy.loc[:,'temp':]\n",
    "# 정답(판매량)\n",
    "train_y = trainXy.loc[:,'qty']\n",
    "\n",
    "val_X = testXy.loc[:,'temp':]\n",
    "val_y = testXy.loc[:,'qty']\n",
    "\n",
    "print('여기서 점수란 R-square값을 의미한다.')\n",
    "# RandomForest 회귀분석\n",
    "RFmodel = RandomForestRegressor()\n",
    "RFmodel.fit(train_X,train_y)\n",
    "# Get the mean absolute error on the validation data\n",
    "RFpredicted = RFmodel.predict(val_X)\n",
    "MAE = mean_absolute_error(val_y , RFpredicted)\n",
    "print('Random forest을 이용한 %s의 회귀분석 결과 :'%item)\n",
    "# print('Random forest validation MAE = ', MAE)\n",
    "print('훈련세트점수 : {:.3f}'.format(RFmodel.score(train_X, train_y)))\n",
    "print('검증세트점수 : {:.3f}'.format(RFmodel.score(val_X, val_y)))\n",
    "\n",
    "# XGBRegressor 회귀분석\n",
    "XGBModel = XGBRegressor(objective='reg:squarederror')\n",
    "XGBModel.fit(train_X,train_y , verbose=False)\n",
    "# Get the mean absolute error on the validation data :\n",
    "XGBpredictions = XGBModel.predict(val_X)\n",
    "MAE = mean_absolute_error(val_y , XGBpredictions)\n",
    "print('XGBoost을 이용한 %s의 회귀분석 결과 :'%item)\n",
    "# print('XGBoost validation MAE = ',MAE)\n",
    "print('훈련세트점수 : {:.3f}'.format(XGBModel.score(train_X, train_y)))\n",
    "print('검증세트점수 : {:.3f}'.format(XGBModel.score(val_X, val_y)))\n",
    "\n",
    "linReg = LinearRegression().fit(train_X, train_y)\n",
    "print('LinearRegression을 이용한 %s의 회귀분석 결과 :'%item)\n",
    "print('훈련세트점수 : {:.3f}'.format(linReg.score(train_X, train_y)))\n",
    "print('검증세트점수 : {:.3f}'.format(linReg.score(val_X, val_y)))\n",
    "\n",
    "ridge = Ridge(alpha=0.1, normalize=True, random_state=0, tol=0.001).fit(train_X, train_y)\n",
    "print('RidgeRegression을 이용한 %s의 회귀분석 결과 :'%item)\n",
    "print('훈련세트점수 : {:.3f}'.format(ridge.score(train_X, train_y)))\n",
    "print('검증세트점수 : {:.3f}'.format(ridge.score(val_X, val_y)))\n",
    "\n",
    "lasso = Lasso(alpha=0.1, max_iter=1000).fit(train_X, train_y)\n",
    "print('LassoRegression을 이용한 %s의 회귀분석 결과 :'%item)\n",
    "print('훈련세트점수 : {:.3f}'.format(lasso.score(train_X, train_y)) )\n",
    "print('검증세트점수 : {:.3f}'.format(lasso.score(val_X, val_y)) )\n",
    "\n",
    "columns_in_data = list(train_X.columns)\n",
    "customF = formulaGen(target='qty',ind_features=columns_in_data)\n",
    "olsModel = sm.OLS.from_formula(customF, data=trainXy).fit()\n",
    "print('OLS을 이용한 %s의 회귀분석 결과 :'%item)\n",
    "print('훈련세트점수 : {:.3f}'.format(olsModel.rsquared) )\n",
    "print('검증세트점수 : {:.3f}'.format( r2_score(val_y, olsModel.predict(val_X))   ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "맥주 ols model\n",
      "사람이 직접 식을 때려 박았을때 : -1.128\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    qty   R-squared:                       0.489\n",
      "Model:                            OLS   Adj. R-squared:                  0.485\n",
      "Method:                 Least Squares   F-statistic:                     115.5\n",
      "Date:                Fri, 19 Jul 2019   Prob (F-statistic):          3.74e-102\n",
      "Time:                        18:53:10   Log-Likelihood:                -6535.5\n",
      "No. Observations:                 732   AIC:                         1.308e+04\n",
      "Df Residuals:                     725   BIC:                         1.312e+04\n",
      "Df Model:                           6                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "================================================================================\n",
      "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------\n",
      "Intercept     1.099e+04    438.125     25.075      0.000    1.01e+04    1.18e+04\n",
      "I(temp ** 2)     6.3674      0.287     22.224      0.000       5.805       6.930\n",
      "cloud          -15.1109     43.686     -0.346      0.730    -100.877      70.655\n",
      "wind          -242.2479    104.721     -2.313      0.021    -447.841     -36.654\n",
      "lgt_time       -79.4371     33.476     -2.373      0.018    -145.158     -13.716\n",
      "rain_or_not   -381.0393    194.535     -1.959      0.051    -762.958       0.880\n",
      "snow_or_not    418.2413    415.673      1.006      0.315    -397.824    1234.307\n",
      "==============================================================================\n",
      "Omnibus:                       16.223   Durbin-Watson:                   0.886\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               15.859\n",
      "Skew:                           0.326   Prob(JB):                     0.000360\n",
      "Kurtosis:                       2.692   Cond. No.                     2.73e+03\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.73e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "print(item, 'ols model')\n",
    "\n",
    "# columns_in_data = ['temp', 'cloud', 'wind', 'lgt_time', 'rain_or_not', 'snow_or_not',\n",
    "#                     '공기상태_0', '공기상태_1', '공기상태_2']\n",
    "\n",
    "# formulaGen은 단순 1차 다항식을 제조해준다.\n",
    "# customF = formulaGen(target='qty',ind_features=columns_in_data)\n",
    "# customF = formulaGen(target='qty',ind_features=['temp', 'wind','lgt_time','rain_or_not'])\n",
    "customF = 'qty ~ I(temp**2) + cloud + wind + lgt_time + rain_or_not + snow_or_not'\n",
    "\n",
    "olsModel = sm.OLS.from_formula(customF, data=trainXy).fit()\n",
    "\n",
    "print('사람이 직접 식을 때려 박았을때 : {:.3f}'.format(r2_score(val_y, olsModel.predict(val_X))) )\n",
    "\n",
    "print(olsModel.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# col_list = ['temp', 'cloud', 'wind', 'lgt_time', 'PM10', 'rain_or_not_o', 'snow_or_not_o',\n",
    "#             '공기상태_0', '공기상태_1', '공기상태_2']\n",
    "col_list = ['temp', 'cloud', 'wind', 'lgt_time', 'PM10', 'rain_or_not_o', 'snow_or_not_o',\n",
    "            '공기상태']\n",
    "combined = Xy.loc[:,'temp':]\n",
    "target = Xy.loc[:,'qty']\n",
    "\n",
    "# 가장 좋다고 판명된 설정을 이용하여, 예측qty생산\n",
    "predictions = NN_model.predict(combined)\n",
    "# RandomForest 회귀분석 예측 qty생산\n",
    "RFpredicted = RFmodel.predict(combined)\n",
    "# XGBRegressor 회귀분석 예측 qty생산\n",
    "XGBpredictions = XGBModel.predict(combined)\n",
    "# linearRegression 회귀분석 예측 qty생산\n",
    "linPred = linReg.predict(combined)\n",
    "# Ridge 회귀분석 예측 qty생산\n",
    "ridPred = ridge.predict(combined)\n",
    "# Lasso 회귀분석 예측 qty생산\n",
    "lassoPred = lasso.predict(combined)\n",
    "# OLS 회귀분석 예측 qty생산\n",
    "olsPred = olsModel.predict(combined)\n",
    "\n",
    "result_df = pd.DataFrame()\n",
    "result_df['date'] = gs_day_w['date']\n",
    "result_df['qty'] = Xy.loc[:,'qty']\n",
    "\n",
    "# print(\"keras 신경망 predictions\",predictions.shape)\n",
    "result_df['keras_qty'] = predictions\n",
    "\n",
    "# print(\"randomforest 예상\",RFpredicted.shape)\n",
    "result_df['rf_qty'] = RFpredicted\n",
    "\n",
    "# print(\"XGBpredictions\",XGBpredictions.shape)\n",
    "result_df['xgb_qty'] = XGBpredictions\n",
    "\n",
    "# print(\"linearRegression 예상\",RFpredicted.shape)\n",
    "result_df['lin_qty'] = linPred\n",
    "\n",
    "# print(\"Ridge 예상\",RFpredicted.shape)\n",
    "result_df['ridge_qty'] = ridPred\n",
    "\n",
    "# print(\"Lasso 예상\",RFpredicted.shape)\n",
    "result_df['lasso_qty'] = lassoPred\n",
    "\n",
    "# print(\"OLS 예상\",RFpredicted.shape)\n",
    "result_df['ols_qty'] = olsPred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras 인공 신경망 모델 MAPE \t: 0.15\n",
      "RandomForest 모델 MAPE \t\t: 0.11\n",
      "XGBoosting  모델 MAPE \t\t: 0.15\n",
      "Linear 모델 MAPE \t\t: 0.17\n",
      "Ridge 모델 MAPE \t\t: 0.17\n",
      "Lasso 모델 MAPE \t\t: 0.17\n",
      "OLS 모델 MAPE \t\t\t: 0.16\n"
     ]
    }
   ],
   "source": [
    "# 예측률 계산\n",
    "# https://yamalab.tistory.com/46\n",
    "\n",
    "# RMSE (Root Mean Squared Error) : \n",
    "# OLS 추정에서 일반적인 표준 오차이다. 예측 대상의 scale(단위 크기)에 주의해야하는 단점이 있다. \n",
    "# MSE는 root를 수식에서 제외, SSE는 root와 분모를 제외한 수식으로, SE가 붙은 척도들은 거기서 거기인 척도들이라고 보면 된다.\n",
    "# 다만 디테일한 사용법에 차이가 있을 뿐.\n",
    "\n",
    "# MAPE (Mean Absolute Percentage Error) :\n",
    "\n",
    "# 위 방법의 단점을 보완한 것이다. \n",
    "# At는 실제값, Ft는 예측값인데, 이를 At로 나누어서 오차를 절대적 크기로 보는것이 아닌\n",
    "# 비율의 크기로 보고자 하는 것이 핵심이다.\n",
    "# 이 방법은 At가 0에 가까울수록 비정상적인 값이 나온다는 단점이 있다.\n",
    "\n",
    "# MAPE가 0에 가까울수록 좋은 모델\n",
    "result_df['mape_keras'] = abs((result_df.qty - result_df.keras_qty) / result_df.qty )\n",
    "result_df['mape_rf'] = abs((result_df.qty - result_df.rf_qty) / result_df.qty )\n",
    "result_df['mape_xgb'] = abs((result_df.qty - result_df.xgb_qty) / result_df.qty )\n",
    "result_df['mape_lin'] = abs((result_df.qty - result_df.lin_qty) / result_df.qty )\n",
    "result_df['mape_ridge'] = abs((result_df.qty - result_df.ridge_qty) / result_df.qty )\n",
    "result_df['mape_lasso'] = abs((result_df.qty - result_df.lasso_qty) / result_df.qty )\n",
    "result_df['mape_ols'] = abs((result_df.qty - result_df.ols_qty) / result_df.qty )\n",
    "\n",
    "print('Keras 인공 신경망 모델 MAPE \\t: {:<.2f}'.format(result_df['mape_keras'].sum() / result_df.shape[0] ))\n",
    "print('RandomForest 모델 MAPE \\t\\t: {:<.2f}'.format(result_df['mape_rf'].sum() / result_df.shape[0] ))\n",
    "print('XGBoosting  모델 MAPE \\t\\t: {:<.2f}'.format(result_df['mape_xgb'].sum() / result_df.shape[0] ))\n",
    "print('Linear 모델 MAPE \\t\\t: {:<.2f}'.format(result_df['mape_lin'].sum() / result_df.shape[0] ))\n",
    "print('Ridge 모델 MAPE \\t\\t: {:<.2f}'.format(result_df['mape_ridge'].sum() / result_df.shape[0] ))\n",
    "print('Lasso 모델 MAPE \\t\\t: {:<.2f}'.format(result_df['mape_lasso'].sum() / result_df.shape[0] ))\n",
    "print('OLS 모델 MAPE \\t\\t\\t: {:<.2f}'.format(result_df['mape_ols'].sum() / result_df.shape[0] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1116x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 독립변수 Xy의 col번호: 0=qty\n",
    "# ['qty', 'temp', 'cloud', 'wind', 'lgt_time', 'rain_or_not','snow_or_not', \n",
    "#                                                   '공기상태_0', '공기상태_1', '공기상태_2']\n",
    "\n",
    "# 1~9 : 1 temp ~ 9 공기상태_2\n",
    "n= 1\n",
    "# alpha 값 0~1\n",
    "alp = 1\n",
    "# scatter plot 점 크기\n",
    "dot_size = 20\n",
    "\n",
    "matplotlib.rcParams['font.family'] = 'NanumGothicCoding'\n",
    "plt.figure(figsize=(15.5,7))\n",
    "plt.style.use('ggplot')\n",
    "plt.title('%s - %s vs 판매량' % (item, Xy.columns[n]) )\n",
    "plt.scatter(Xy.iloc[:,n],result_df.qty, label = '실 판매량', s=20, c='k')\n",
    "# plt.scatter(Xy.iloc[:,n],result_df.keras_qty, label = '케라스 신경망 예측', alpha=alp, s=dot_size)\n",
    "# plt.scatter(Xy.iloc[:,n],result_df.rf_qty, label = 'RandomForest 예측', alpha=alp, s=dot_size)\n",
    "# plt.scatter(Xy.iloc[:,n],result_df.xgb_qty, label = 'XGBoosting 예측', alpha=alp, s=dot_size)\n",
    "# plt.scatter(Xy.iloc[:,n],result_df.lin_qty, label = '선형 예측', alpha=alp, s=dot_size)\n",
    "# plt.scatter(Xy.iloc[:,n],result_df.ridge_qty, label = 'Ridge 예측', alpha=alp, s=dot_size)\n",
    "plt.scatter(Xy.iloc[:,n],result_df.ols_qty, label = 'OLS 예측', alpha=alp, s=dot_size)\n",
    "\n",
    "# X axis\n",
    "plt.xlabel('{}'.format(Xy.columns[n]))\n",
    "\n",
    "# y axis\n",
    "plt.ylabel('판매량')\n",
    "\n",
    "# 범례\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실험 구간"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# # 2016~2017 : 훈련 / 2018 검증 2:1\n",
    "# # 1~106 / 106~156\n",
    "# trainXy = gs_week_w.loc[:cut_line]\n",
    "# testXy = gs_week_w.loc[cut_line:]\n",
    "# train_X =pd.DataFrame(trainXy.loc[:,'temp'])\n",
    "# train_y = trainXy.loc[:,'qty']\n",
    "# val_X = pd.DataFrame(testXy.loc[:,'temp'])\n",
    "# val_y = testXy.loc[:,'qty']\n",
    "\n",
    "\n",
    "\n",
    "# print('여기서 점수란 R-square값을 의미한다.')\n",
    "# # RandomForest 회귀분석\n",
    "# RFmodel = RandomForestRegressor()\n",
    "# RFmodel.fit(train_X,train_y)\n",
    "# # Get the mean absolute error on the validation data\n",
    "# RFpredicted = RFmodel.predict(val_X)\n",
    "# MAE = mean_absolute_error(val_y , RFpredicted)\n",
    "# print('Random forest을 이용한 %s의 회귀분석 결과 :'%item)\n",
    "# # print('Random forest validation MAE = ', MAE)\n",
    "# print('훈련세트점수 : {:.3f}'.format(RFmodel.score(train_X, train_y)))\n",
    "# print('검증세트점수 : {:.3f}'.format(RFmodel.score(val_X, val_y)))\n",
    "\n",
    "# # XGBRegressor 회귀분석\n",
    "# XGBModel = XGBRegressor(objective='reg:squarederror')\n",
    "# XGBModel.fit(train_X,train_y , verbose=False)\n",
    "# # Get the mean absolute error on the validation data :\n",
    "# XGBpredictions = XGBModel.predict(val_X)\n",
    "# MAE = mean_absolute_error(val_y , XGBpredictions)\n",
    "# print('XGBoost을 이용한 %s의 회귀분석 결과 :'%item)\n",
    "# # print('XGBoost validation MAE = ',MAE)\n",
    "# print('훈련세트점수 : {:.3f}'.format(XGBModel.score(train_X, train_y)))\n",
    "# print('검증세트점수 : {:.3f}'.format(XGBModel.score(val_X, val_y)))\n",
    "\n",
    "# linReg = LinearRegression().fit(train_X, train_y)\n",
    "# print('LinearRegression을 이용한 %s의 회귀분석 결과 :'%item)\n",
    "# print('훈련세트점수 : {:.3f}'.format(linReg.score(train_X, train_y)))\n",
    "# print('검증세트점수 : {:.3f}'.format(linReg.score(val_X, val_y)))\n",
    "\n",
    "# ridge = Ridge(alpha=0.1, normalize=True, random_state=0, tol=0.001).fit(train_X, train_y)\n",
    "# print('RidgeRegression을 이용한 %s의 회귀분석 결과 :'%item)\n",
    "# print('훈련세트점수 : {:.3f}'.format(ridge.score(train_X, train_y)))\n",
    "# print('검증세트점수 : {:.3f}'.format(ridge.score(val_X, val_y)))\n",
    "\n",
    "# lasso = Lasso(alpha=0.1, max_iter=1000).fit(train_X, train_y)\n",
    "# print('LassoRegression을 이용한 %s의 회귀분석 결과 :'%item)\n",
    "# print('훈련세트점수 : {:.3f}'.format(lasso.score(train_X, train_y)) )\n",
    "# print('검증세트점수 : {:.3f}'.format(lasso.score(val_X, val_y)) )\n",
    "\n",
    "# customF = formulaGen(target='qty',ind_features=['temp'])\n",
    "# olsModel = sm.OLS.from_formula(customF, data=trainXy).fit()\n",
    "# print('OLS을 이용한 %s의 회귀분석 결과 :'%item)\n",
    "# print('훈련세트점수 : {:.3f}'.format(olsModel.rsquared) )\n",
    "\n",
    "# combined = pd.DataFrame(gs_week_w.loc[:,'temp'])\n",
    "# target = gs_week_w.loc[:,'qty']\n",
    "\n",
    "# # 가장 좋다고 판명된 설정을 이용하여, 예측qty생산\n",
    "# # predictions = NN_model.predict(combined)\n",
    "# # RandomForest 회귀분석 예측 qty생산\n",
    "# RFpredicted = RFmodel.predict(combined)\n",
    "# # XGBRegressor 회귀분석 예측 qty생산\n",
    "# XGBpredictions = XGBModel.predict(combined)\n",
    "# # linearRegression 회귀분석 예측 qty생산\n",
    "# linPred = linReg.predict(combined)\n",
    "# # Ridge 회귀분석 예측 qty생산\n",
    "# ridPred = ridge.predict(combined)\n",
    "# # Lasso 회귀분석 예측 qty생산\n",
    "# lassoPred = lasso.predict(combined)\n",
    "# # OLS 회귀분석 예측 qty생산\n",
    "# olsPred = olsModel.predict(combined)\n",
    "\n",
    "# result_df = pd.DataFrame()\n",
    "# result_df['week'] = gs_week_w['week']\n",
    "# result_df['qty'] = gs_week_w.loc[:,'qty']\n",
    "\n",
    "# # print(\"keras 신경망 predictions\",predictions.shape)\n",
    "# # result_df['keras_qty'] = predictions\n",
    "\n",
    "# # print(\"randomforest 예상\",RFpredicted.shape)\n",
    "# result_df['rf_qty'] = RFpredicted\n",
    "\n",
    "# # print(\"XGBpredictions\",XGBpredictions.shape)\n",
    "# result_df['xgb_qty'] = XGBpredictions\n",
    "\n",
    "# # print(\"linearRegression 예상\",RFpredicted.shape)\n",
    "# result_df['lin_qty'] = linPred\n",
    "\n",
    "# # print(\"Ridge 예상\",RFpredicted.shape)\n",
    "# result_df['ridge_qty'] = ridPred\n",
    "\n",
    "# # print(\"Lasso 예상\",RFpredicted.shape)\n",
    "# result_df['lasso_qty'] = lassoPred\n",
    "\n",
    "# # print(\"OLS 예상\",RFpredicted.shape)\n",
    "# result_df['ols_qty'] = olsPred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ============================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_graph = result_df.loc[:,['week','qty','keras_qty','rf_qty','xgb_qty','lin_qty','ridge_qty','lasso_qty','ols_qty']]\n",
    "# for_visual_col = ['week','temp','cloud','wind','lgt_time','snow','rain','PM10']\n",
    "# df = pd.merge(df_graph, gs_week_w[for_visual_col], on='week', how='left')\n",
    "# # df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2016, 온도\n",
    "# df_graph = df.loc[df.week <= 53]\n",
    "# plt.figure(figsize=(15.5, 10))\n",
    "# plt.scatter(df_graph.temp,df_graph.qty, ls='-', label='실제', color='green', alpha=0.5, lw=8)\n",
    "# plt.scatter(df_graph.temp,df_graph.keras_qty, ls='-', label='keras예측', color='r')\n",
    "# plt.scatter(df_graph.temp,df_graph.rf_qty, ls='-', label='rf예측', color='cyan')\n",
    "# plt.scatter(df_graph.temp,df_graph.xgb_qty, ls='-', label='xgb예측', color='b')\n",
    "# plt.scatter(df_graph.temp,df_graph.lin_qty, ls='-', label='linear예측')\n",
    "# plt.scatter(df_graph.temp,df_graph.ridge_qty, ls='-', label='ridge예측')\n",
    "# plt.scatter(df_graph.temp,df_graph.lasso_qty, ls='-', label='lasso예측',color='yellow')\n",
    "# plt.scatter(df_graph.temp,df_graph.ols_qty, ls='-', label='ols예측', color='violet')\n",
    "# plt.legend()\n",
    "# plt.title('{}년도 {} 판매량 실제/예측'.format( '2016',item ))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qty_columns = list(df_graph.columns)[1:9]\n",
    "# weather_columns = list(df_graph.columns)[9:]\n",
    "# print(qty_columns)\n",
    "# print(weather_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_temp = pd.DataFrame()\n",
    "# # x_temp['temp'] = list(range(-10,35,1))\n",
    "# x_temp['temp'] = np.arange(-9,35,0.5)\n",
    "# combined = x_temp\n",
    "# # RandomForest 회귀분석 예측 qty생산\n",
    "# RFpredicted = RFmodel.predict(combined)\n",
    "# # XGBRegressor 회귀분석 예측 qty생산\n",
    "# XGBpredictions = XGBModel.predict(combined)\n",
    "# # linearRegression 회귀분석 예측 qty생산\n",
    "# linPred = linReg.predict(combined)\n",
    "# # Ridge 회귀분석 예측 qty생산\n",
    "# ridPred = ridge.predict(combined)\n",
    "# # Lasso 회귀분석 예측 qty생산\n",
    "# lassoPred = lasso.predict(combined)\n",
    "# # OLS 회귀분석 예측 qty생산\n",
    "# olsPred = olsModel.predict(combined)\n",
    "\n",
    "# # 2016~2018, 일조시간\n",
    "# df_graph = df.copy()\n",
    "# plt.figure(figsize=(15.5, 10))\n",
    "# plt.scatter(df_graph[weather_columns[0]],df_graph['qty'], ls='-', color='k',label='실 판매량', s=100, alpha=0.7)\n",
    "# plt.plot(x_temp, RFpredicted, label = 'rf')\n",
    "# plt.plot(x_temp, XGBpredictions, label = 'xgb')\n",
    "# plt.plot(x_temp, linPred, label = 'line')\n",
    "# plt.plot(x_temp, ridPred, label = 'ridge')\n",
    "# plt.plot(x_temp, lassoPred, label = 'lasso')\n",
    "# plt.plot(x_temp, olsPred, label = 'ols')\n",
    "# plt.plot()\n",
    "# plt.legend()\n",
    "# plt.title('{}년도 {} 판매량 실제/예측'.format( '2016~2018',item ))\n",
    "# plt.xlabel(weather_columns[0])\n",
    "# plt.ylabel('판매량 (단위 : 1개)')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 실험"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intercept_lin = linReg.intercept_\n",
    "# coef_line = linReg.coef_\n",
    "# # list_col\n",
    "# linePredict = list()\n",
    "# x_temp = list(range(-10,38,1))\n",
    "# for temperature in x_temp:\n",
    "#     linePredict.append(intercept_lin + coef_line[0]*temperature)\n",
    "\n",
    "    \n",
    "# # 2016~2018, 일조시간\n",
    "# df_graph = df.copy()\n",
    "# plt.figure(figsize=(15.5, 10))\n",
    "# plt.scatter(df_graph[weather_columns[0]],df_graph['qty'], ls='-', color='k',label='실 판매량', s=100, alpha=0.3)\n",
    "# # for q_name in qty_columns:\n",
    "# #     plt.plot(df_graph[weather_columns[0]],df_graph[q_name], ls='-', label=q_name)\n",
    "# #     plt.scatter(df_graph.lgt_time,df_graph[q_name], ls='-', label='실제', color='green', alpha=0.5, lw=8)\n",
    "# #     plt.scatter(df_graph.lgt_time,df_graph.keras_qty, ls='-', label='keras예측', color='r')\n",
    "# #     plt.scatter(df_graph.lgt_time,df_graph.rf_qty, ls='-', label='rf예측', color='cyan')\n",
    "# #     plt.scatter(df_graph.lgt_time,df_graph.xgb_qty, ls='-', label='xgb예측', color='b')\n",
    "# #     plt.scatter(df_graph.lgt_time,df_graph.lin_qty, ls='-', label='linear예측')\n",
    "# #     plt.scatter(df_graph.lgt_time,df_graph.ridge_qty, ls='-', label='ridge예측')\n",
    "# #     plt.scatter(df_graph.lgt_time,df_graph.lasso_qty, ls='-', label='lasso예측',color='yellow')\n",
    "# #     plt.scatter(df_graph.lgt_time,df_graph.ols_qty, ls='-', label='ols예측', color='violet')\n",
    "# plt.plot(x_temp, linePredict, 'r--', label='linear회귀, 온도만')\n",
    "\n",
    "# plt.legend()\n",
    "# plt.title('{}년도 {} 판매량 실제/예측'.format( '2016~2018',item ))\n",
    "# plt.xlabel(weather_columns[0])\n",
    "# plt.ylabel('판매량 (단위 : 1개)')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 시간의 경과에 따른 예측량 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 2016\n",
    "# df_graph = result_df.loc[result_df.week <=53]\n",
    "# plt.figure(figsize=(15.5, 10))\n",
    "# plt.plot(df_graph.week,df_graph.qty, ls='-', label='실제', color='green', alpha=0.5, lw=8)\n",
    "# plt.plot(df_graph.week,df_graph.keras_qty, ls='-', label='keras예측', color='r')\n",
    "# plt.plot(df_graph.week,df_graph.rf_qty, ls='-', label='rf예측', color='cyan')\n",
    "# plt.plot(df_graph.week,df_graph.xgb_qty, ls='-', label='xgb예측', color='b')\n",
    "# plt.plot(df_graph.week,df_graph.lin_qty, ls='-', label='linear예측')\n",
    "# plt.plot(df_graph.week,df_graph.ridge_qty, ls='-', label='ridge예측')\n",
    "# plt.plot(df_graph.week,df_graph.lasso_qty, ls='-', label='lasso예측',color='yellow')\n",
    "# plt.plot(df_graph.week,df_graph.ols_qty, ls='-', label='ols예측', color='violet')\n",
    "# plt.legend()\n",
    "# plt.title('{}년도 {} 판매량 실제/예측'.format( '2016',item ))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 2017\n",
    "# df_graph = result_df.loc[(result_df.week >=53)&(result_df.week <=105)]\n",
    "# plt.figure(figsize=(15.5, 10))\n",
    "# plt.plot(df_graph.week,df_graph.qty, ls='-', label='실제', color='green', alpha=0.5, lw=8)\n",
    "# plt.plot(df_graph.week,df_graph.keras_qty, ls='-', label='keras예측', color='r')\n",
    "# plt.plot(df_graph.week,df_graph.rf_qty, ls='-', label='rf예측', color='cyan')\n",
    "# plt.plot(df_graph.week,df_graph.xgb_qty, ls='-', label='xgb예측', color='b')\n",
    "# plt.plot(df_graph.week,df_graph.lin_qty, ls='-', label='linear예측')\n",
    "# plt.plot(df_graph.week,df_graph.ridge_qty, ls='-', label='ridge예측')\n",
    "# plt.plot(df_graph.week,df_graph.lasso_qty, ls='-', label='lasso예측',color='yellow')\n",
    "# plt.plot(df_graph.week,df_graph.ols_qty, ls='-', label='ols예측', color='violet')\n",
    "# plt.title('{}년도 {} 판매량 실제/예측'.format( '2017',item ))\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 2018\n",
    "# df_graph = result_df.loc[(result_df.week >=105)]\n",
    "# plt.figure(figsize=(15.5, 10))\n",
    "# plt.plot(df_graph.week,df_graph.qty, ls='-', label='실제', color='green', alpha=0.5, lw=8)\n",
    "# plt.plot(df_graph.week,df_graph.keras_qty, ls='-', label='keras예측', color='r')\n",
    "# plt.plot(df_graph.week,df_graph.rf_qty, ls='-', label='rf예측', color='cyan')\n",
    "# plt.plot(df_graph.week,df_graph.xgb_qty, ls='-', label='xgb예측', color='b')\n",
    "# plt.plot(df_graph.week,df_graph.lin_qty, ls='-', label='linear예측')\n",
    "# plt.plot(df_graph.week,df_graph.ridge_qty, ls='-', label='ridge예측')\n",
    "# plt.plot(df_graph.week,df_graph.lasso_qty, ls='-', label='lasso예측',color='yellow')\n",
    "# plt.plot(df_graph.week,df_graph.ols_qty, ls='-', label='ols예측', color='violet')\n",
    "# plt.title('{}년도 {} 판매량 실제/예측'.format( '2018',item ))\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 2016~2018\n",
    "# plt.figure(figsize=(15.5, 10))\n",
    "# plt.plot(result_df.week,result_df.qty, ls='-', label='실제', color='green', alpha=0.5, lw=8)\n",
    "# plt.plot(result_df.week,result_df.keras_qty, ls='-', label='keras예측', color='r')\n",
    "# plt.plot(result_df.week,result_df.rf_qty, ls='-', label='rf예측', color='cyan')\n",
    "# plt.plot(result_df.week,result_df.xgb_qty, ls='-', label='xgb예측', color='b')\n",
    "# plt.plot(df_graph.week,df_graph.lin_qty, ls='-', label='linear예측')\n",
    "# plt.plot(df_graph.week,df_graph.ridge_qty, ls='-', label='ridge예측')\n",
    "# plt.plot(df_graph.week,df_graph.lasso_qty, ls='-', label='lasso예측',color='yellow')\n",
    "# plt.plot(df_graph.week,df_graph.ols_qty, ls='-', label='ols예측', color='violet')\n",
    "# plt.title('{}년도 {} 판매량 실제/예측'.format( '2016~2018',item ))\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def r2_score(v_true, v_pred):\n",
    "#     ssr = np.sum(np.square(v_pred - np.mean(v_true)))\n",
    "#     sst = np.sum(np.square(v_true - np.mean(v_true)))\n",
    "#     return ( ssr / sst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checked_for = '2016~2017'\n",
    "# combined = aaaaa.loc[:106,'temp':'PM10']\n",
    "# target = aaaaa.loc[:106,'qty']\n",
    "\n",
    "# # 가장 좋다고 판명된 설정을 이용하여, 예측qty생산\n",
    "# predictions = NN_model.predict(combined)\n",
    "# # RandomForest 회귀분석 예측 qty생산\n",
    "# RFpredicted = RFmodel.predict(combined)\n",
    "# # XGBRegressor 회귀분석 예측 qty생산\n",
    "# XGBpredictions = XGBModel.predict(combined)\n",
    "# # linearRegression 회귀분석 예측 qty생산\n",
    "# linPred = linReg.predict(combined)\n",
    "# # Ridge 회귀분석 예측 qty생산\n",
    "# ridPred = ridge.predict(combined)\n",
    "# # Lasso 회귀분석 예측 qty생산\n",
    "# lassoPred = lasso.predict(combined)\n",
    "# # OLS 회귀분석 예측 qty생산\n",
    "# olsPred = olsModel.predict(combined)\n",
    "# qty = target\n",
    "\n",
    "# print(checked_for)\n",
    "# print('RF R2값  \\t: ','{:<.5f}'.format(r2_score(qty, RFpredicted)) )\n",
    "# print('XGB R2값  \\t: ','{:<.5f}'.format(r2_score(qty, XGBpredictions)) )\n",
    "# print('KerasNN R2값\\t: ','{:<.5f}'.format(r2_score(qty,predictions )) )\n",
    "# print('LinReg R2값\\t: ','{:<.5f}'.format(r2_score(qty, linPred)) )\n",
    "# print('Ridge R2값  \\t: ','{:<.5f}'.format(r2_score(qty, ridPred)) )\n",
    "# print('Lasso R2값\\t: ','{:<.5f}'.format(r2_score(qty, lassoPred )) )\n",
    "# print('OLS R2값\\t: ','{:<.5f}'.format(r2_score(qty, olsPred )) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checked_for = '2018'\n",
    "# combined = aaaaa.loc[106:,'temp':'PM10']\n",
    "# target = aaaaa.loc[106:,'qty']\n",
    "\n",
    "# # 가장 좋다고 판명된 설정을 이용하여, 예측qty생산\n",
    "# predictions = NN_model.predict(combined)\n",
    "# # RandomForest 회귀분석 예측 qty생산\n",
    "# RFpredicted = RFmodel.predict(combined)\n",
    "# # XGBRegressor 회귀분석 예측 qty생산\n",
    "# XGBpredictions = XGBModel.predict(combined)\n",
    "# # linearRegression 회귀분석 예측 qty생산\n",
    "# linPred = linReg.predict(combined)\n",
    "# # Ridge 회귀분석 예측 qty생산\n",
    "# ridPred = ridge.predict(combined)\n",
    "# # Lasso 회귀분석 예측 qty생산\n",
    "# lassoPred = lasso.predict(combined)\n",
    "# # OLS 회귀분석 예측 qty생산\n",
    "# olsPred = olsModel.predict(combined)\n",
    "\n",
    "# qty = target\n",
    "\n",
    "# print(checked_for)\n",
    "# print('RF R2값  \\t: ','{:<.5f}'.format(r2_score(qty, RFpredicted)) )\n",
    "# print('XGB R2값  \\t: ','{:<.5f}'.format(r2_score(qty, XGBpredictions)) )\n",
    "# print('KerasNN R2값\\t: ','{:<.5f}'.format(r2_score(qty,predictions )) )\n",
    "# print('LinReg R2값\\t: ','{:<.5f}'.format(r2_score(qty, linPred)) )\n",
    "# print('Ridge R2값  \\t: ','{:<.5f}'.format(r2_score(qty, ridPred)) )\n",
    "# print('Lasso R2값\\t: ','{:<.5f}'.format(r2_score(qty, lassoPred )) )\n",
    "# print('OLS R2값\\t: ','{:<.5f}'.format(r2_score(qty, olsPred )) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checked_for = '2016~2018'\n",
    "# combined = aaaaa.loc[:,'temp':'PM10']\n",
    "# target = aaaaa.loc[:,'qty']\n",
    "\n",
    "# # 가장 좋다고 판명된 설정을 이용하여, 예측qty생산\n",
    "# predictions = NN_model.predict(combined)\n",
    "# # RandomForest 회귀분석 예측 qty생산\n",
    "# RFpredicted = RFmodel.predict(combined)\n",
    "# # XGBRegressor 회귀분석 예측 qty생산\n",
    "# XGBpredictions = XGBModel.predict(combined)\n",
    "# # linearRegression 회귀분석 예측 qty생산\n",
    "# linPred = linReg.predict(combined)\n",
    "# # Ridge 회귀분석 예측 qty생산\n",
    "# ridPred = ridge.predict(combined)\n",
    "# # Lasso 회귀분석 예측 qty생산\n",
    "# lassoPred = lasso.predict(combined)\n",
    "# # OLS 회귀분석 예측 qty생산\n",
    "# olsPred = olsModel.predict(combined)\n",
    "\n",
    "# qty = target\n",
    "\n",
    "# print(checked_for)\n",
    "# print('RF R2값  \\t: ','{:<.5f}'.format(r2_score(qty, RFpredicted)) )\n",
    "# print('XGB R2값  \\t: ','{:<.5f}'.format(r2_score(qty, XGBpredictions)) )\n",
    "# print('KerasNN R2값\\t: ','{:<.5f}'.format(r2_score(qty,predictions )) )\n",
    "# print('LinReg R2값\\t: ','{:<.5f}'.format(r2_score(qty, linPred)) )\n",
    "# print('Ridge R2값  \\t: ','{:<.5f}'.format(r2_score(qty, ridPred)) )\n",
    "# print('Lasso R2값\\t: ','{:<.5f}'.format(r2_score(qty, lassoPred )) )\n",
    "# print('OLS R2값\\t: ','{:<.5f}'.format(r2_score(qty, olsPred )) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = 'D:/project/contest/data/result/'\n",
    "# result_df.to_csv(path+item+'_'+grouped_by+'_predict(lowVIF07).csv', encoding='utf-8', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
