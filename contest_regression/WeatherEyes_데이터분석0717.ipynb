{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "# 필요한 기본 패키지 준비\n",
    "\n",
    "# 데이터 처리 필요 패키지\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "\n",
    "# 시각화 필요 패키지\n",
    "%matplotlib inline\n",
    "from plotnine import *\n",
    "import folium\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc, font_manager\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Machine Learning 분석 환경 준비\n",
    "\n",
    "# 전처리, 스케일링\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 회귀분석\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error \n",
    "from xgboost import XGBRegressor\n",
    "import statsmodels.api as sm\n",
    "#데이터셋 분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 다중공선성(multicollinearity) 처리를 위한VIF 확인 패키지\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "\n",
    "# 한글 처리\n",
    "font_name = font_manager.FontProperties(fname='C:/Windows/Fonts/NanumGothicCoding.ttf').get_name()\n",
    "rc('font',family=font_name)\n",
    "\n",
    "# - 마이너스 사인 처리\n",
    "matplotlib.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# jupyter notebook에서 warning 무시하기\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "# MAD 기반 예제코드\n",
    "def mad_based_outlier(points, thresh=3.5):\n",
    "    if len(points.shape) == 1:\n",
    "        points = points[:,None]\n",
    "    median = np.median(points, axis=0)\n",
    "    diff = np.sum((points - median)**2, axis=-1)\n",
    "    diff = np.sqrt(diff)\n",
    "    med_abs_deviation = np.median(diff)\n",
    "    modified_z_score = 0.6745 * diff / med_abs_deviation\n",
    "    return modified_z_score > thresh \n",
    "\n",
    "# 출처: https://pythonanalysis.tistory.com/7 [Python 데이터 분석]\n",
    "#########################################################################\n",
    "\n",
    "# 소셜 데이터 처리를 위한 함수\n",
    "# 1. 모든 소셜 데이터 column들의 첫번째는 : 날짜다.\n",
    "# 2. 각 소셜데이터는 social_키워드.블로그/트위터/뉴스/총합 으로 되어 있다.\n",
    "def changeColNames(d,to_replace, replaced) : \n",
    "    # 컬럼이름 리스트를 만들어 반환\n",
    "    # 통합하기 쉽게, 모든 데이터들의 날짜컬럼 이름을 date로 통일\n",
    "    new_col_names = ['date']\n",
    "    new_col_names.extend(list(d.columns)[1:])\n",
    "    d.columns = new_col_names\n",
    "    return pd.Series(d.columns).apply(lambda x : x.replace(to_replace,replaced))\n",
    "\n",
    "\n",
    "# ['temp','humid','wind','rain','snow','cloud','sun_time'\n",
    "#                  ,'pm.total', 'health.total','br.total', 'hobby.total','date.total']\n",
    "# modeling 함수로 만들어 처리하기\n",
    "def linReg(df, item, cols_using, score=False):\n",
    "    cols = cols_using\n",
    "    X = df.loc[df['category']==item, cols]\n",
    "    y = df.loc[df['category']==item,'qty']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=0)\n",
    "\n",
    "    model = LinearRegression().fit(X_train, y_train)\n",
    "  \n",
    "    print('LinearRegression을 이용한 %s의 회귀분석 결과 :'%item)\n",
    "    print('훈련세트점수 : {:.2f}'.format(model.score(X_train, y_train)))\n",
    "    print('검증세트점수 : {:.2f}'.format(model.score(X_test, y_test)))\n",
    "    if score ==True:\n",
    "        return model.score(X_train, y_train), model.score(X_test, y_test)\n",
    "    \n",
    "def ridgeReg(df, item, cols_using):\n",
    "    cols = cols_using\n",
    "    X = df.loc[df['category']==item,cols]\n",
    "    y = df.loc[df['category']==item,'qty']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=0)\n",
    "\n",
    "    ridge = Ridge(alpha=0.1, normalize=True, random_state=0, tol=0.001).fit(X_train, y_train)\n",
    "    \n",
    "    print('RidgeRegression을 이용한 %s의 회귀분석 결과 :'%item)\n",
    "    print('훈련세트점수 : {:.2f}'.format(ridge.score(X_train, y_train)))\n",
    "    print('검증세트점수 : {:.2f}'.format(ridge.score(X_test, y_test)))\n",
    "    if score ==True:\n",
    "        return model.score(X_train, y_train), model.score(X_test, y_test)\n",
    "\n",
    "def lassoReg(df, item, cols_using):\n",
    "    cols = cols_using\n",
    "    X = df.loc[df['category']==item,cols]\n",
    "    y = df.loc[df['category']==item,'qty']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=0)\n",
    "\n",
    "    lasso = Lasso(alpha=0.1, max_iter=1000).fit(X=X_train, y=y_train)\n",
    "  \n",
    "    print('LassoRegression을 이용한 %s의 회귀분석 결과 :'%item)\n",
    "    print('훈련세트점수 : {:.2f}'.format(lasso.score(X_train, y_train)) )\n",
    "    print('검증세트점수 : {:.2f}'.format(lasso.score(X_test, y_test)) )\n",
    "\n",
    "    #사용한 특성수\n",
    "    print('사용한 특성수 : {}'.format(np.sum(lasso.coef_ != 0)) )\n",
    "    if score ==True:\n",
    "        return model.score(X_train, y_train), model.score(X_test, y_test)\n",
    "####################################################    \n",
    "def rfReg(df, item, cols_using):\n",
    "    cols = cols_using\n",
    "    X = df.loc[df['category']==item,cols]\n",
    "    y = df.loc[df['category']==item,'qty']\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=0)\n",
    "    \n",
    "    model = RandomForestRegressor()\n",
    "    model.fit(X_train,y_train)\n",
    "    # Get the mean absolute error on the validation data\n",
    "    RFpredicted = model.predict(X_test)\n",
    "    MAE = mean_absolute_error(y_test , RFpredicted)\n",
    "    print('Random forest validation MAE = ', MAE)\n",
    "    print('훈련세트점수 : {:.2f}'.format(model.score(X_train, y_train)))\n",
    "    print('검증세트점수 : {:.2f}'.format(model.score(X_test, y_test)))\n",
    "    if score ==True:\n",
    "        return model.score(X_train, y_train), model.score(X_test, y_test)\n",
    "    \n",
    "def xgbReg(df, item, cols_using):\n",
    "    cols = cols_using\n",
    "    X = df.loc[df['category']==item, cols]\n",
    "    y = df.loc[df['category']==item,'qty']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=0)\n",
    "    XGBModel = XGBRegressor(objective='reg:squarederror')\n",
    "    XGBModel.fit(X_train,y_train , verbose=False)\n",
    "    # Get the mean absolute error on the validation data :\n",
    "    XGBpredictions = XGBModel.predict(X_test)\n",
    "    MAE = mean_absolute_error(y_test , XGBpredictions)\n",
    "    print('XGBoostRegression을 이용한 %s의 회귀분석 결과 :'%item)\n",
    "    print('XGBoost validation MAE = ',MAE)\n",
    "    print('훈련세트점수 : {:.2f}'.format(XGBModel.score(X_train, y_train)))\n",
    "    print('검증세트점수 : {:.2f}'.format(XGBModel.score(X_test, y_test)))\n",
    "    if score ==True:\n",
    "        return model.score(X_train, y_train), model.score(X_test, y_test)\n",
    "    \n",
    "    ###################################\n",
    "def addDayWeek(df):\n",
    "    df_work = df.copy()\n",
    "    df_work['day'] = pd.Series(range(1,df_work.shape[0]+1))\n",
    "    df_work['week'] = df_work['day'].apply(lambda x : x//7)\n",
    "    return df_work\n",
    "    \n",
    "def mergeForAnalysis(df1, df2, df3=None, item='아이스크림'):\n",
    "    merged_df = pd.merge(df1.loc[df1.category==item], df2, on='date',how='left')\n",
    "    if df3 is not None:\n",
    "        merged_df = pd.merge(merged_df, df3, on='date', how='left')\n",
    "    return merged_df\n",
    "#######################\n",
    "def lowVIF(df, n=7, cols_using =['temp', 'cloud', 'wind','humid', 'hpa', 'sun_time', 'lgt_time', \n",
    "       'SO2', 'CO', 'O3', 'NO2', 'PM10', 'PM25'] ):\n",
    "    col_to_use = cols_using\n",
    "    vif = pd.DataFrame()\n",
    "    vif[\"VIF_Factor\"] = [variance_inflation_factor(\n",
    "        df[col_to_use].values, i) for i in range(df[col_to_use].shape[1])]\n",
    "    vif[\"features\"] = col_to_use\n",
    "    vif.sort_values(\"VIF_Factor\")\n",
    "    lowest_vif = vif.sort_values(\"VIF_Factor\")[:n].reset_index()\n",
    "    lowest_vif.drop(columns='index', inplace=True)\n",
    "    return lowest_vif\n",
    "\n",
    "#########################################################################\n",
    "# ols모델용 formula 생성\n",
    "def formulaGen(target, ind_features):\n",
    "    '''\n",
    "    formulaGen(목표컬럼명,[변수컬럼명1, 변수컬럼명2,...])\n",
    "    '''\n",
    "    custom_formula = target + \" ~ \"\n",
    "    for f in range(len(ind_features)):\n",
    "        custom_formula += ind_features[f]\n",
    "        if f!=(len(ind_features)-1):\n",
    "            custom_formula += \" + \"\n",
    "    return custom_formula\n",
    "\n",
    "\n",
    "#########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기 (전처리 된 GS, 랄라블라, 날씨)\n",
    "gs = pd.read_csv('d:/project/contest/data/processed/p_gs.csv', parse_dates=['date'])\n",
    "lv = pd.read_csv('d:/project/contest/data/processed/p_lavla.csv', parse_dates=['date'])\n",
    "w = pd.read_csv('d:/project/contest/data/processed/p_wUVair_seoul.csv', parse_dates=['date'], index_col=0)\n",
    "sns_all = pd.read_csv('d:/project/contest/data/processed/social_all.csv', parse_dates=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GS/lv 서울시만\n",
    "gs_seoul = gs.loc[gs.pvn_nm =='서울특별시']\n",
    "lv_seoul = lv.loc[lv.pvn_nm =='서울특별시']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 컬럼 이름을 Series로 돌려주는 함수를 자체 개발함\n",
    "sns_all.columns = changeColNames(sns_all,'.','_')\n",
    "# 컬럼명의 마침표(.)가 전부 언더스코어(_)로 변경되었다.\n",
    "# ols formula입력시 오류 발생 방지\n",
    "# sns_all.columns\n",
    "# 'p_wUVair_seoul.csv'파일 수정일:2019-07-11기준 자료로\n",
    "# 수정된 자료로 저장되어있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_keep = ['date','bor_nm','gender','age_cd','category','qty']\n",
    "gs_grouped = gs_seoul[cols_to_keep].groupby(by=['date','bor_nm','category']).sum().reset_index()\n",
    "# gs_grouped.tail(2)\n",
    "\n",
    "lv_grouped = lv_seoul[cols_to_keep].groupby(by=['date','bor_nm','category']).sum().reset_index()\n",
    "# lv_grouped.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 서울특별시 단위로 df조정(구단위 데이터를 시단위로 합치기)\n",
    "day_gs_grouped = gs_grouped.groupby(by=['date','category']).sum().reset_index()\n",
    "# day_gs_grouped.tail(3)\n",
    "\n",
    "day_lv_grouped = lv_grouped.groupby(by=['date','category']).sum().reset_index()\n",
    "# day_lv_grouped.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '아이스크림'만 골라서 날씨('w')df와 소셜('sns_all')df와 결합해 새로운 'day_gs_grouped_w_item'생성\n",
    "item = '아이스크림'\n",
    "day_gs_grouped_w_item = mergeForAnalysis(day_gs_grouped, w, sns_all, item)\n",
    "# day_gs_grouped_w_item = pd.merge(day_gs_grouped_w.loc[day_gs_grouped_w.category==item],w,on='date',how='left')\n",
    "# day_gs_grouped_w_item = pd.merge(day_gs_grouped_w_item,sns_all,on='date',how='left')\n",
    "# day_gs_grouped_w_item.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VIF_Factor</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.043588</td>\n",
       "      <td>temp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.006264</td>\n",
       "      <td>PM25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.958003</td>\n",
       "      <td>lgt_time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.745850</td>\n",
       "      <td>wind</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VIF_Factor  features\n",
       "0    2.043588      temp\n",
       "1    3.006264      PM25\n",
       "2    3.958003  lgt_time\n",
       "3    4.745850      wind"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list_col = ['temp', 'cloud', 'wind', 'lgt_time','PM25',]\n",
    "list_col = ['temp', 'wind', 'lgt_time','PM25',]\n",
    "lowVIF(w,15,list_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression을 이용한 아이스크림의 회귀분석 결과 :\n",
      "훈련세트점수 : 0.73\n",
      "검증세트점수 : 0.73\n",
      "RidgeRegression을 이용한 아이스크림의 회귀분석 결과 :\n",
      "훈련세트점수 : 0.72\n",
      "검증세트점수 : 0.72\n",
      "LassoRegression을 이용한 아이스크림의 회귀분석 결과 :\n",
      "훈련세트점수 : 0.73\n",
      "검증세트점수 : 0.73\n",
      "사용한 특성수 : 4\n",
      "Random forest validation MAE =  3498.120668693009\n",
      "훈련세트점수 : 0.98\n",
      "검증세트점수 : 0.86\n",
      "XGBoostRegression을 이용한 아이스크림의 회귀분석 결과 :\n",
      "XGBoost validation MAE =  3304.918952733188\n",
      "훈련세트점수 : 0.93\n",
      "검증세트점수 : 0.87\n"
     ]
    }
   ],
   "source": [
    "# ind_vars = ['temp','humid','wind','sun_time']\n",
    "# ind_vars = ['temp','humid','wind','rain','snow','cloud','sun_time']\n",
    "# ind_vars = ['temp','humid','wind','rain','snow','cloud','sun_time'\n",
    "#                 ,'pm_total', 'health_total','br_total', 'hobby_total','date_total']\n",
    "\n",
    "ind_vars = list_col\n",
    "linReg(day_gs_grouped_w_item,item,ind_vars)\n",
    "ridgeReg(day_gs_grouped_w_item,item,ind_vars)\n",
    "lassoReg(day_gs_grouped_w_item,item,ind_vars)\n",
    "rfReg(day_gs_grouped_w_item,item,ind_vars)\n",
    "xgbReg(day_gs_grouped_w_item,item,ind_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    qty   R-squared:                       0.731\n",
      "Model:                            OLS   Adj. R-squared:                  0.730\n",
      "Method:                 Least Squares   F-statistic:                     740.6\n",
      "Date:                Wed, 17 Jul 2019   Prob (F-statistic):          4.75e-309\n",
      "Time:                        17:53:38   Log-Likelihood:                -11157.\n",
      "No. Observations:                1096   AIC:                         2.232e+04\n",
      "Df Residuals:                    1091   BIC:                         2.235e+04\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept   -514.5738    925.006     -0.556      0.578   -2329.566    1300.419\n",
      "temp         942.5277     18.068     52.165      0.000     907.076     977.980\n",
      "wind        1035.4740    290.081      3.570      0.000     466.294    1604.654\n",
      "lgt_time     469.4795     49.829      9.422      0.000     371.709     567.250\n",
      "PM25          81.1326     14.822      5.474      0.000      52.050     110.216\n",
      "==============================================================================\n",
      "Omnibus:                       23.846   Durbin-Watson:                   0.416\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               25.108\n",
      "Skew:                           0.369   Prob(JB):                     3.53e-06\n",
      "Kurtosis:                       2.920   Cond. No.                         155.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "Xy = day_gs_grouped_w_item.loc[day_gs_grouped_w_item['category']==item,ind_vars+['qty']]\n",
    "customF = formulaGen('qty',ind_vars)\n",
    "model = sm.OLS.from_formula(customF, data=Xy)\n",
    "\n",
    "print(model.fit().summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_items = gs.category.unique()\n",
    "lv_items = lv.category.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['temp', 'wind', 'lgt_time', 'PM25']\n",
      "\n",
      " 라면  판매량 분석 - VIF작은거 5개만 \n",
      "LinearRegression을 이용한 라면의 회귀분석 결과 :\n",
      "훈련세트점수 : 0.16\n",
      "검증세트점수 : 0.12\n",
      "RidgeRegression을 이용한 라면의 회귀분석 결과 :\n",
      "훈련세트점수 : 0.16\n",
      "검증세트점수 : 0.12\n",
      "LassoRegression을 이용한 라면의 회귀분석 결과 :\n",
      "훈련세트점수 : 0.16\n",
      "검증세트점수 : 0.12\n",
      "사용한 특성수 : 4\n",
      "Random forest validation MAE =  1911.0759878419453\n",
      "훈련세트점수 : 0.85\n",
      "검증세트점수 : 0.10\n",
      "XGBoostRegression을 이용한 라면의 회귀분석 결과 :\n",
      "XGBoost validation MAE =  1865.754577080167\n",
      "훈련세트점수 : 0.47\n",
      "검증세트점수 : 0.12\n",
      "\n",
      "\n",
      " 과자  판매량 분석 - VIF작은거 5개만 \n",
      "LinearRegression을 이용한 과자의 회귀분석 결과 :\n",
      "훈련세트점수 : 0.11\n",
      "검증세트점수 : 0.06\n",
      "RidgeRegression을 이용한 과자의 회귀분석 결과 :\n",
      "훈련세트점수 : 0.11\n",
      "검증세트점수 : 0.06\n",
      "LassoRegression을 이용한 과자의 회귀분석 결과 :\n",
      "훈련세트점수 : 0.11\n",
      "검증세트점수 : 0.06\n",
      "사용한 특성수 : 4\n",
      "Random forest validation MAE =  5342.733130699088\n",
      "훈련세트점수 : 0.83\n",
      "검증세트점수 : -0.06\n",
      "XGBoostRegression을 이용한 과자의 회귀분석 결과 :\n",
      "XGBoost validation MAE =  5077.232718702508\n",
      "훈련세트점수 : 0.42\n",
      "검증세트점수 : 0.07\n",
      "\n",
      "\n",
      " 마스크  판매량 분석 - VIF작은거 5개만 \n",
      "LinearRegression을 이용한 마스크의 회귀분석 결과 :\n",
      "훈련세트점수 : 0.25\n",
      "검증세트점수 : 0.15\n",
      "RidgeRegression을 이용한 마스크의 회귀분석 결과 :\n",
      "훈련세트점수 : 0.25\n",
      "검증세트점수 : 0.15\n",
      "LassoRegression을 이용한 마스크의 회귀분석 결과 :\n",
      "훈련세트점수 : 0.25\n",
      "검증세트점수 : 0.15\n",
      "사용한 특성수 : 4\n",
      "Random forest validation MAE =  311.4179331306991\n",
      "훈련세트점수 : 0.88\n",
      "검증세트점수 : 0.13\n",
      "XGBoostRegression을 이용한 마스크의 회귀분석 결과 :\n",
      "XGBoost validation MAE =  324.2954299602103\n",
      "훈련세트점수 : 0.85\n",
      "검증세트점수 : 0.13\n",
      "\n",
      "\n",
      " 맥주  판매량 분석 - VIF작은거 5개만 \n",
      "LinearRegression을 이용한 맥주의 회귀분석 결과 :\n",
      "훈련세트점수 : 0.35\n",
      "검증세트점수 : 0.33\n",
      "RidgeRegression을 이용한 맥주의 회귀분석 결과 :\n",
      "훈련세트점수 : 0.35\n",
      "검증세트점수 : 0.33\n",
      "LassoRegression을 이용한 맥주의 회귀분석 결과 :\n",
      "훈련세트점수 : 0.35\n",
      "검증세트점수 : 0.33\n",
      "사용한 특성수 : 4\n",
      "Random forest validation MAE =  1689.0851063829787\n",
      "훈련세트점수 : 0.88\n",
      "검증세트점수 : 0.31\n",
      "XGBoostRegression을 이용한 맥주의 회귀분석 결과 :\n",
      "XGBoost validation MAE =  1553.3710610989742\n",
      "훈련세트점수 : 0.61\n",
      "검증세트점수 : 0.41\n",
      "\n",
      "\n",
      " 생리대  판매량 분석 - VIF작은거 5개만 \n",
      "LinearRegression을 이용한 생리대의 회귀분석 결과 :\n",
      "훈련세트점수 : 0.23\n",
      "검증세트점수 : 0.15\n",
      "RidgeRegression을 이용한 생리대의 회귀분석 결과 :\n",
      "훈련세트점수 : 0.22\n",
      "검증세트점수 : 0.15\n",
      "LassoRegression을 이용한 생리대의 회귀분석 결과 :\n",
      "훈련세트점수 : 0.23\n",
      "검증세트점수 : 0.15\n",
      "사용한 특성수 : 4\n",
      "Random forest validation MAE =  242.85379939209724\n",
      "훈련세트점수 : 0.86\n",
      "검증세트점수 : 0.11\n",
      "XGBoostRegression을 이용한 생리대의 회귀분석 결과 :\n",
      "XGBoost validation MAE =  229.16798915689114\n",
      "훈련세트점수 : 0.50\n",
      "검증세트점수 : 0.18\n",
      "\n",
      "\n",
      " 생수  판매량 분석 - VIF작은거 5개만 \n",
      "LinearRegression을 이용한 생수의 회귀분석 결과 :\n",
      "훈련세트점수 : 0.41\n",
      "검증세트점수 : 0.55\n",
      "RidgeRegression을 이용한 생수의 회귀분석 결과 :\n",
      "훈련세트점수 : 0.41\n",
      "검증세트점수 : 0.55\n",
      "LassoRegression을 이용한 생수의 회귀분석 결과 :\n",
      "훈련세트점수 : 0.41\n",
      "검증세트점수 : 0.55\n",
      "사용한 특성수 : 4\n",
      "Random forest validation MAE =  1471.3310030395135\n",
      "훈련세트점수 : 0.89\n",
      "검증세트점수 : 0.36\n",
      "XGBoostRegression을 이용한 생수의 회귀분석 결과 :\n",
      "XGBoost validation MAE =  1365.3157784598213\n",
      "훈련세트점수 : 0.76\n",
      "검증세트점수 : 0.56\n",
      "\n",
      "\n",
      " 숙취해소제  판매량 분석 - VIF작은거 5개만 \n",
      "LinearRegression을 이용한 숙취해소제의 회귀분석 결과 :\n",
      "훈련세트점수 : 0.04\n",
      "검증세트점수 : 0.02\n",
      "RidgeRegression을 이용한 숙취해소제의 회귀분석 결과 :\n",
      "훈련세트점수 : 0.03\n",
      "검증세트점수 : 0.02\n",
      "LassoRegression을 이용한 숙취해소제의 회귀분석 결과 :\n",
      "훈련세트점수 : 0.04\n",
      "검증세트점수 : 0.02\n",
      "사용한 특성수 : 4\n",
      "Random forest validation MAE =  617.9851063829788\n",
      "훈련세트점수 : 0.82\n",
      "검증세트점수 : -0.11\n",
      "XGBoostRegression을 이용한 숙취해소제의 회귀분석 결과 :\n",
      "XGBoost validation MAE =  591.5906151304854\n",
      "훈련세트점수 : 0.39\n",
      "검증세트점수 : -0.01\n",
      "\n",
      "\n",
      " 스타킹  판매량 분석 - VIF작은거 5개만 \n",
      "LinearRegression을 이용한 스타킹의 회귀분석 결과 :\n",
      "훈련세트점수 : 0.10\n",
      "검증세트점수 : 0.10\n",
      "RidgeRegression을 이용한 스타킹의 회귀분석 결과 :\n",
      "훈련세트점수 : 0.10\n",
      "검증세트점수 : 0.10\n",
      "LassoRegression을 이용한 스타킹의 회귀분석 결과 :\n",
      "훈련세트점수 : 0.10\n",
      "검증세트점수 : 0.10\n",
      "사용한 특성수 : 4\n",
      "Random forest validation MAE =  279.44620060790277\n",
      "훈련세트점수 : 0.93\n",
      "검증세트점수 : 0.62\n",
      "XGBoostRegression을 이용한 스타킹의 회귀분석 결과 :\n",
      "XGBoost validation MAE =  278.0920772842361\n",
      "훈련세트점수 : 0.79\n",
      "검증세트점수 : 0.65\n",
      "\n",
      "\n",
      " 아이스크림  판매량 분석 - VIF작은거 5개만 \n",
      "LinearRegression을 이용한 아이스크림의 회귀분석 결과 :\n",
      "훈련세트점수 : 0.73\n",
      "검증세트점수 : 0.73\n",
      "RidgeRegression을 이용한 아이스크림의 회귀분석 결과 :\n",
      "훈련세트점수 : 0.72\n",
      "검증세트점수 : 0.72\n",
      "LassoRegression을 이용한 아이스크림의 회귀분석 결과 :\n",
      "훈련세트점수 : 0.73\n",
      "검증세트점수 : 0.73\n",
      "사용한 특성수 : 4\n",
      "Random forest validation MAE =  3510.4398176291793\n",
      "훈련세트점수 : 0.97\n",
      "검증세트점수 : 0.86\n",
      "XGBoostRegression을 이용한 아이스크림의 회귀분석 결과 :\n",
      "XGBoost validation MAE =  3304.918952733188\n",
      "훈련세트점수 : 0.93\n",
      "검증세트점수 : 0.87\n",
      "\n",
      "\n",
      " 탄산음료  판매량 분석 - VIF작은거 5개만 \n",
      "LinearRegression을 이용한 탄산음료의 회귀분석 결과 :\n",
      "훈련세트점수 : 0.36\n",
      "검증세트점수 : 0.29\n",
      "RidgeRegression을 이용한 탄산음료의 회귀분석 결과 :\n",
      "훈련세트점수 : 0.36\n",
      "검증세트점수 : 0.29\n",
      "LassoRegression을 이용한 탄산음료의 회귀분석 결과 :\n",
      "훈련세트점수 : 0.36\n",
      "검증세트점수 : 0.29\n",
      "사용한 특성수 : 4\n",
      "Random forest validation MAE =  1031.1914893617022\n",
      "훈련세트점수 : 0.88\n",
      "검증세트점수 : 0.33\n",
      "XGBoostRegression을 이용한 탄산음료의 회귀분석 결과 :\n",
      "XGBoost validation MAE =  1016.6327204834727\n",
      "훈련세트점수 : 0.64\n",
      "검증세트점수 : 0.37\n",
      "\n",
      "\n",
      " 면도기  판매량 분석 - VIF작은거 5개만 \n",
      "LinearRegression을 이용한 면도기의 회귀분석 결과 :\n",
      "훈련세트점수 : 0.12\n",
      "검증세트점수 : 0.04\n",
      "RidgeRegression을 이용한 면도기의 회귀분석 결과 :\n",
      "훈련세트점수 : 0.12\n",
      "검증세트점수 : 0.05\n",
      "LassoRegression을 이용한 면도기의 회귀분석 결과 :\n",
      "훈련세트점수 : 0.12\n",
      "검증세트점수 : 0.04\n",
      "사용한 특성수 : 4\n",
      "Random forest validation MAE =  55.4082066869301\n",
      "훈련세트점수 : 0.82\n",
      "검증세트점수 : -0.03\n",
      "XGBoostRegression을 이용한 면도기의 회귀분석 결과 :\n",
      "XGBoost validation MAE =  53.60456203472288\n",
      "훈련세트점수 : 0.42\n",
      "검증세트점수 : 0.03\n",
      "\n",
      "\n",
      " 우산  판매량 분석 - VIF작은거 5개만 \n",
      "LinearRegression을 이용한 우산의 회귀분석 결과 :\n",
      "훈련세트점수 : 0.27\n",
      "검증세트점수 : 0.33\n",
      "RidgeRegression을 이용한 우산의 회귀분석 결과 :\n",
      "훈련세트점수 : 0.27\n",
      "검증세트점수 : 0.32\n",
      "LassoRegression을 이용한 우산의 회귀분석 결과 :\n",
      "훈련세트점수 : 0.27\n",
      "검증세트점수 : 0.33\n",
      "사용한 특성수 : 4\n",
      "Random forest validation MAE =  1072.8705673758866\n",
      "훈련세트점수 : 0.84\n",
      "검증세트점수 : 0.16\n",
      "XGBoostRegression을 이용한 우산의 회귀분석 결과 :\n",
      "XGBoost validation MAE =  1094.5753155536686\n",
      "훈련세트점수 : 0.59\n",
      "검증세트점수 : 0.30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 한번에 처리 gs\n",
    "print(list_col)\n",
    "gs_scores = pd.DataFrame()\n",
    "for item in gs_items:\n",
    "#     print('\\n',item,' 판매량 분석 - 모든 독립변수 포함(날씨+sns(합계))')\n",
    "#     df_working = mergeForAnalysis(day_gs_grouped, w, sns_all, item)\n",
    "    temp_df \n",
    "    print('\\n',item,' 판매량 분석 - VIF작은거 5개만 ')\n",
    "    df_working = mergeForAnalysis(day_gs_grouped, w, item=item)\n",
    "    tr_score, test_score = linReg(df_working,item,ind_vars,score=True)\n",
    "    gs_scores['물품'] = item\n",
    "    ridgeReg(df_working,item,ind_vars,score=True)\n",
    "    lassoReg(df_working,item,ind_vars,score=True)\n",
    "    rfReg(df_working,item,ind_vars,score=True)\n",
    "    xgbReg(df_working,item,ind_vars,score=True)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['temp', 'wind', 'lgt_time', 'PM25']\n",
      "\n",
      " 립컬러  판매량 분석 - 모든 독립변수 포함\n",
      "LinearRegression을 이용한 립컬러의 회귀분석 결과 :\n",
      "훈련세트점수 : 0.02\n",
      "검증세트점수 : 0.01\n",
      "RidgeRegression을 이용한 립컬러의 회귀분석 결과 :\n",
      "훈련세트점수 : 0.02\n",
      "검증세트점수 : 0.01\n",
      "LassoRegression을 이용한 립컬러의 회귀분석 결과 :\n",
      "훈련세트점수 : 0.02\n",
      "검증세트점수 : 0.01\n",
      "사용한 특성수 : 4\n",
      "Random forest validation MAE =  6716.045896656536\n",
      "훈련세트점수 : 0.79\n",
      "검증세트점수 : -0.09\n",
      "XGBoostRegression을 이용한 립컬러의 회귀분석 결과 :\n",
      "XGBoost validation MAE =  6181.15594278353\n",
      "훈련세트점수 : 0.52\n",
      "검증세트점수 : 0.01\n",
      "\n",
      " 립케어  판매량 분석 - 모든 독립변수 포함\n",
      "LinearRegression을 이용한 립케어의 회귀분석 결과 :\n",
      "훈련세트점수 : 0.23\n",
      "검증세트점수 : 0.23\n",
      "RidgeRegression을 이용한 립케어의 회귀분석 결과 :\n",
      "훈련세트점수 : 0.23\n",
      "검증세트점수 : 0.23\n",
      "LassoRegression을 이용한 립케어의 회귀분석 결과 :\n",
      "훈련세트점수 : 0.23\n",
      "검증세트점수 : 0.23\n",
      "사용한 특성수 : 4\n",
      "Random forest validation MAE =  2445.3045592705166\n",
      "훈련세트점수 : 0.85\n",
      "검증세트점수 : 0.11\n",
      "XGBoostRegression을 이용한 립케어의 회귀분석 결과 :\n",
      "XGBoost validation MAE =  2154.6541794426175\n",
      "훈련세트점수 : 0.57\n",
      "검증세트점수 : 0.25\n",
      "\n",
      " 마스크팩  판매량 분석 - 모든 독립변수 포함\n",
      "LinearRegression을 이용한 마스크팩의 회귀분석 결과 :\n",
      "훈련세트점수 : 0.01\n",
      "검증세트점수 : -0.00\n",
      "RidgeRegression을 이용한 마스크팩의 회귀분석 결과 :\n",
      "훈련세트점수 : 0.01\n",
      "검증세트점수 : -0.00\n",
      "LassoRegression을 이용한 마스크팩의 회귀분석 결과 :\n",
      "훈련세트점수 : 0.01\n",
      "검증세트점수 : -0.00\n",
      "사용한 특성수 : 4\n",
      "Random forest validation MAE =  40217.33282674772\n",
      "훈련세트점수 : 0.79\n",
      "검증세트점수 : -0.43\n",
      "XGBoostRegression을 이용한 마스크팩의 회귀분석 결과 :\n",
      "XGBoost validation MAE =  36401.50619775836\n",
      "훈련세트점수 : 0.55\n",
      "검증세트점수 : -0.19\n",
      "\n",
      " 바디로션  판매량 분석 - 모든 독립변수 포함\n",
      "LinearRegression을 이용한 바디로션의 회귀분석 결과 :\n",
      "훈련세트점수 : 0.25\n",
      "검증세트점수 : -0.00\n",
      "RidgeRegression을 이용한 바디로션의 회귀분석 결과 :\n",
      "훈련세트점수 : 0.24\n",
      "검증세트점수 : -0.00\n",
      "LassoRegression을 이용한 바디로션의 회귀분석 결과 :\n",
      "훈련세트점수 : 0.25\n",
      "검증세트점수 : -0.00\n",
      "사용한 특성수 : 4\n",
      "Random forest validation MAE =  4545.26838905775\n",
      "훈련세트점수 : 0.85\n",
      "검증세트점수 : -0.01\n",
      "XGBoostRegression을 이용한 바디로션의 회귀분석 결과 :\n",
      "XGBoost validation MAE =  4423.107214837813\n",
      "훈련세트점수 : 0.62\n",
      "검증세트점수 : -0.01\n",
      "\n",
      " 체중조절  판매량 분석 - 모든 독립변수 포함\n",
      "LinearRegression을 이용한 체중조절의 회귀분석 결과 :\n",
      "훈련세트점수 : 0.03\n",
      "검증세트점수 : -0.07\n",
      "RidgeRegression을 이용한 체중조절의 회귀분석 결과 :\n",
      "훈련세트점수 : 0.03\n",
      "검증세트점수 : -0.05\n",
      "LassoRegression을 이용한 체중조절의 회귀분석 결과 :\n",
      "훈련세트점수 : 0.03\n",
      "검증세트점수 : -0.07\n",
      "사용한 특성수 : 4\n",
      "Random forest validation MAE =  720.3313069908814\n",
      "훈련세트점수 : 0.63\n",
      "검증세트점수 : -2.05\n",
      "XGBoostRegression을 이용한 체중조절의 회귀분석 결과 :\n",
      "XGBoost validation MAE =  640.7296235336721\n",
      "훈련세트점수 : 0.91\n",
      "검증세트점수 : -0.63\n",
      "\n",
      " 크림로션  판매량 분석 - 모든 독립변수 포함\n",
      "LinearRegression을 이용한 크림로션의 회귀분석 결과 :\n",
      "훈련세트점수 : 0.03\n",
      "검증세트점수 : 0.02\n",
      "RidgeRegression을 이용한 크림로션의 회귀분석 결과 :\n",
      "훈련세트점수 : 0.03\n",
      "검증세트점수 : 0.02\n",
      "LassoRegression을 이용한 크림로션의 회귀분석 결과 :\n",
      "훈련세트점수 : 0.03\n",
      "검증세트점수 : 0.02\n",
      "사용한 특성수 : 4\n",
      "Random forest validation MAE =  4509.372948328268\n",
      "훈련세트점수 : 0.83\n",
      "검증세트점수 : -0.01\n",
      "XGBoostRegression을 이용한 크림로션의 회귀분석 결과 :\n",
      "XGBoost validation MAE =  4214.230387122436\n",
      "훈련세트점수 : 0.56\n",
      "검증세트점수 : 0.01\n",
      "\n",
      " 훼이셜클렌저  판매량 분석 - 모든 독립변수 포함\n",
      "LinearRegression을 이용한 훼이셜클렌저의 회귀분석 결과 :\n",
      "훈련세트점수 : 0.04\n",
      "검증세트점수 : 0.02\n",
      "RidgeRegression을 이용한 훼이셜클렌저의 회귀분석 결과 :\n",
      "훈련세트점수 : 0.04\n",
      "검증세트점수 : 0.02\n",
      "LassoRegression을 이용한 훼이셜클렌저의 회귀분석 결과 :\n",
      "훈련세트점수 : 0.04\n",
      "검증세트점수 : 0.02\n",
      "사용한 특성수 : 4\n",
      "Random forest validation MAE =  3196.1051671732525\n",
      "훈련세트점수 : 0.82\n",
      "검증세트점수 : -0.28\n",
      "XGBoostRegression을 이용한 훼이셜클렌저의 회귀분석 결과 :\n",
      "XGBoost validation MAE =  2795.679758738602\n",
      "훈련세트점수 : 0.53\n",
      "검증세트점수 : -0.04\n",
      "\n",
      " 선케어  판매량 분석 - 모든 독립변수 포함\n",
      "LinearRegression을 이용한 선케어의 회귀분석 결과 :\n",
      "훈련세트점수 : 0.30\n",
      "검증세트점수 : 0.33\n",
      "RidgeRegression을 이용한 선케어의 회귀분석 결과 :\n",
      "훈련세트점수 : 0.30\n",
      "검증세트점수 : 0.33\n",
      "LassoRegression을 이용한 선케어의 회귀분석 결과 :\n",
      "훈련세트점수 : 0.30\n",
      "검증세트점수 : 0.33\n",
      "사용한 특성수 : 4\n",
      "Random forest validation MAE =  1835.1486322188448\n",
      "훈련세트점수 : 0.85\n",
      "검증세트점수 : 0.30\n",
      "XGBoostRegression을 이용한 선케어의 회귀분석 결과 :\n",
      "XGBoost validation MAE =  1779.1477221457067\n",
      "훈련세트점수 : 0.77\n",
      "검증세트점수 : 0.34\n",
      "\n",
      " 네일  판매량 분석 - 모든 독립변수 포함\n",
      "LinearRegression을 이용한 네일의 회귀분석 결과 :\n",
      "훈련세트점수 : 0.29\n",
      "검증세트점수 : 0.31\n",
      "RidgeRegression을 이용한 네일의 회귀분석 결과 :\n",
      "훈련세트점수 : 0.29\n",
      "검증세트점수 : 0.31\n",
      "LassoRegression을 이용한 네일의 회귀분석 결과 :\n",
      "훈련세트점수 : 0.29\n",
      "검증세트점수 : 0.31\n",
      "사용한 특성수 : 4\n",
      "Random forest validation MAE =  2209.764741641338\n",
      "훈련세트점수 : 0.89\n",
      "검증세트점수 : 0.39\n",
      "XGBoostRegression을 이용한 네일의 회귀분석 결과 :\n",
      "XGBoost validation MAE =  2056.2486138155396\n",
      "훈련세트점수 : 0.72\n",
      "검증세트점수 : 0.47\n",
      "\n",
      " 제모제  판매량 분석 - 모든 독립변수 포함\n",
      "LinearRegression을 이용한 제모제의 회귀분석 결과 :\n",
      "훈련세트점수 : 0.40\n",
      "검증세트점수 : 0.40\n",
      "RidgeRegression을 이용한 제모제의 회귀분석 결과 :\n",
      "훈련세트점수 : 0.39\n",
      "검증세트점수 : 0.40\n",
      "LassoRegression을 이용한 제모제의 회귀분석 결과 :\n",
      "훈련세트점수 : 0.40\n",
      "검증세트점수 : 0.40\n",
      "사용한 특성수 : 4\n",
      "Random forest validation MAE =  562.9705167173252\n",
      "훈련세트점수 : 0.89\n",
      "검증세트점수 : 0.43\n",
      "XGBoostRegression을 이용한 제모제의 회귀분석 결과 :\n",
      "XGBoost validation MAE =  513.5890331326285\n",
      "훈련세트점수 : 0.75\n",
      "검증세트점수 : 0.54\n"
     ]
    }
   ],
   "source": [
    "# 한번에 처리 lv\n",
    "print(list_col)\n",
    "\n",
    "for item in lv_items:\n",
    "    print('\\n',item,' 판매량 분석 - 모든 독립변수 포함')\n",
    "    df_working = mergeForAnalysis(day_lv_grouped, w, item=item)\n",
    "    linReg(df_working,item,ind_vars)\n",
    "    ridgeReg(df_working,item,ind_vars)\n",
    "    lassoReg(df_working,item,ind_vars)\n",
    "    rfReg(df_working,item,ind_vars)\n",
    "    xgbReg(df_working,item,ind_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
